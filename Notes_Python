#!/usr/bin/env python3

------ATUL------Posted GitHub

===============================================================================================
==============================5=================================================================
===============================================================================================
===============================================================================================
===============================================================================================

#notes for Programming in Python3
#IDLE
#or
#https://repl.it/languages/python3

#Reminder of topics<===========
===============
CONTENTS
CHAPTER: 1 Rapid Intro to Procedural Programming
CHAPTER: 2 Data Types
CHAPTER: 3 Collection Data Types
CHAPTER: 4 Control Structures and Functions
CHAPTER: 5 Modules
CHAPTER: 6 OOP - Object Oriented Programming
CHAPTER: 7 File Handling
CHAPTER: 8 Advanced Programming Techniques
CHAPTER: 9 Debugging, Testing, and Profiling
CHAPTER: 10 Processes and Threading
CHAPTER: 11 Networking
CHAPTER: 12 Database Programming
CHAPTER: 13 Regular Expressions
CHAPTER: 14 Intro to Parsing
CHAPTER: 15 Intro to GUI Programming
===============

===============================================================================================
CHAPTER: 1 Rapid Intro to Procedural Programming
CHAPTER BEGIN
===============================================================================================

#Reminder of topics<===========
CHAPTER 1 Rapid Intro to Procedural Programming

Creating and Running Python Programs
Pythons Beautiful Heart
    Piece 1: Data Types
    Piece 2: Object References
    Piece 3: Collection Data Types
    Piece 4: Logical Operators
    Piece 5: Control Flow Statements
    Piece 6: Arithmetic Operators
    Piece 7: Input/Output
    Piece 8: Creating and Calling Functions
Examples
    bigdigits.py 
    generate_grid.py 
Summary
Exercises

#CODE LISTING:
average1_ans.py
average2_ans.py
awfulpoetry1_ans.py
awfulpoetry2_ans.py
bigdigits.py
bigdigits_ans.py
echoargs.py
generate_grid.py
hello.py
sum1.py
sum2.py 

# on Unix or Mac OS the shebang line can be either
#!/user/bin/python3
#or
#!/usr/bin/env python3

#If using 1st form then specified interpret is used. This may be needed to run Python
#programs that are to be run by a web server
#If using the 2nd form is more versatile b/c it allows for the possiblity that the Python 3
#interpreter is not located in /usr/bin (ie it could in /uer/local/bin or installed
#under $HOME)

=============== BEGIN Introducing Python 2015 Bill Lubanovic
dictionary     {}           empty_dictionary_example = {}
set -->        set()        empty_set_nameing_example = set()
list -->       []           list slice --> [:]
tuple -->      ()           empty_tuple_example = ()
tuple vs list   tuple                       list 
                use less space              use more space 
                have fewer functions        have more functions 
                named tuple = handy 
                function arguments passable
                is YES scriptable           is NOT scriptable

convert list into dictionary        must be a two item list --> list = lol
                                                                dict(lo)
>>> empty_list = []
>>> empty_list 
[]
>>> another_empty_list = list()
>>> another_empty_list
[]



Comprehension = creating data structure via iterator
#why useful? using less syntax, you can create the data structure using iterators
#and can even combine loops and conditionals.
--> allows less syntax while creating Python data structure using an iterator 

List Comprehension
                   --> creating a list data structure using iterator
list comprehension --> compact way to create data structure using iterator (Pythonic)

"""
print(list(range(1,23)))                        # NOT kept in memory 
>>> print(list(range(1,23)))
[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]
>>> 

>>> Daddy = range(10,24)                        # in memory is the technical range statement 
>>> print(Daddy)
range(10, 24)                                   # like this 
>>> Daddy2 = list(range(10,24))                 # in memory is the list of numbers in the range statement
>>> print(Daddy2)
[10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]
>>> 





>>> print(list(range(1,3)))
[1, 2]


"""







#use iterator and to create list comprehension
>>> for number in range(1,10):
...     number_list.append(number)
... 
>>> number_list 
[1, 2, 3, 4, 5, 6, 7, 8, 9]

#use range to directly create list comprehension
>>> number_listA = list(range(1,20))
>>> number_listA 
[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]

Rule 
[expression for item in iterable]
#use list comprehension to build integer list (#list data structure using iterator)
>>> number_listB = [number for number in range(1,15)]
>>> number_listB
[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]

>>> number_listC = [number-2 for number in range(1,15)]
>>> number_listC 
[-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]

Rule
[expression for item in iterable if condition]
#use list comprehension to build EVEN integers
>>> number_listEVEN = [number for number in range(1,30) if number %2 == 0]
>>> number_listEVEN
[2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28]

>>> number_listODD = [number for number in range(1,30) if number %2 == 1]
>>> number_listODD
[1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29]


>>> 10 / 2
5.0
>>> 10 % 2
0
>>> 10 // 2
5
>>> 

#use list comprehension to interate by nested loop (ie create list data structure using iterator)
>>> number_list_nested_loop = []
>>> for number in range(1,50):
...     if number % 2 == 1:
...             number_list_nested_loop.append(number)
... 
>>> number_list_nested_loop
[1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]
>>> 

#create list comprehension using nested for loops (ie create list data structure using iterator)
>>> rows = range(1,4)
>>> cols = range(1,3)
>>> for row in rows:
...     for col in cols:
...             print(row, col)
... 
1 1
1 2
2 1
2 2
3 1
3 2

#create list comprehension and assign using nested for loops
>>> rows = range(1,4)
>>> cols = range(1,3)
>>> cells = [(row, col) for row in rows for col in cols]
>>> cells
[(1, 1), (1, 2), (2, 1), (2, 2), (3, 1), (3, 2)]

#simple print statement
>>> for cell in cells:
...     print(cell)
... 
(1, 1)
(1, 2)
(2, 1)
(2, 2)
(3, 1)
(3, 2)

#use tuple unpacking to extract row and col from each tuple as iterate over list
>>> for row, col in cells:
...     print(row, col)
... 
1 1
1 2
2 1
2 2
3 1
3 2


Dictionary Comprehension --> creating a dictionary using an iterator
Rule
{ key_expression : value_expression for expression in iterable }

>>> word = 'letters'
>>> word
'letters'

>>> letter_counts = {letter: word.count(letter) for letter in word}
>>> letter_counts
{'r': 1, 'l': 1, 'e': 2, 's': 1, 't': 2}

>>> word2 = 'hamburger'
>>> letter_counts2 = {letter : word2.count(letter) for letter in word2}
>>> letter_counts2
{'u': 1, 'e': 1, 'a': 1, 'b': 1, 'm': 1, 'h': 1, 'r': 2, 'g': 1}


>>> Ford = 'letter'
>>> Porche_count = {xxx: Ford.count(xxx) for xxx in Ford}
>>> Porche_count
{'r': 1, 'l': 1, 'e': 2, 't': 2}

>>> school = 'BroadmeadoW'
>>> Needham_District_count_dictionary = {yyy: school.count(yyy) for yyy in school}
>>> Needham_District_count_dictionary 
{'W': 1, 'B': 1, 'm': 1, 'a': 2, 'r': 1, 'd': 2, 'o': 2, 'e': 1}
>>> school = 'BroadmeadoWww'
>>> Needham_District_count_dictionary = {yyy: school.count(yyy) for yyy in school}
>>> Needham_District_count_dictionary
{'W': 1, 'B': 1, 'm': 1, 'a': 2, 'r': 1, 'd': 2, 'o': 2, 'w': 2, 'e': 1}


Dictionary Comprehension using string vs using set
#notice that letters in set are in different order
#why? b/c iterating set(word) returns letters in different order than iterating over string.
>>> word = 'abcdefgabcd'
>>> letter_counts = {letter: word.count(letter) for letter in word}
>>> letter_counts 
{'b': 2, 'd': 2, 'c': 2, 'f': 1, 'a': 2, 'g': 1, 'e': 1}
>>> word = 'abcdefgabcd'
>>> letter_counts = {letter: word.count(letter) for letter in set(word)}
>>> letter_counts
{'d': 2, 'b': 2, 'a': 2, 'c': 2, 'f': 1, 'g': 1, 'e': 1}


Set Comprehension

Rule
{ expression for expression in iterable }

             <----3       <-2       START 1      >=4=<
>>> a_set = {number for number in range(1,25) if number % 3 == 1}
>>> a_set
{1, 4, 7, 10, 13, 16, 19, 22}

>>> even_set = {number for number in range(1,25) if number % 2 == 0}  #even --> 0
>>> even_set
{2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24}

>> odd_set = {number for number in range(1,25) if number % 2 == 1}    #odd --> 1
>>> odd_set
{1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23}


Generator Comprehension --> returns or creates a Generator Object
>>> number_thing = (number for number in range(1,10))
>>> number_thing
<generator object <genexpr> at 0x1019e0990>
>>> print(number_thing)
<generator object <genexpr> at 0x1019e0990>

>>> for callitwhateveryouwant in number_thing:
...     print(callitwhateveryouwant)
... 
1
2
3
4
5
6
7
8
9

Make a Generator Comprehension work like a List Comprehension

>>> type(number_list)
<class 'list'>
>>> type(number_thing)
<class 'generator'>

>>> number_thing_setexample = {number for number in range(1,10)}
>>> number_thing_setexample
{1, 2, 3, 4, 5, 6, 7, 8, 9}
>>> type(number_thing_setexample)
<class 'set'

>>> number_thing_listexample = (number for number in range(1,10))
>>> number_thing_listexample
<generator object <genexpr> at 0x1019e0990>
>>> type(number_thing_listexample)
<class 'generator'>

Now wrap a list() around a generator comprehension to make it work like a list comprehension

>>> number_thing_generatorwrapped = list(number_thing_listexample)
>>> number_thing_generatorwrapped
[1, 2, 3, 4, 5, 6, 7, 8, 9]

#generator can only be run ONCE. Why?
#b/c lists, sets, strings, and dictionaries exist in memory
#vs. generators do NOT exist in memory b/c generator creates its values on the fly
#and so hands the values out one at a time through an iterator BUT NOT into memory.
#so you can NOT restart or back up a generator.
#Generators are one way to provide data to an iterator
#Generators good for large sets of results where you dont know if you need all the endresults
#at the same time at the end. Or if you dont want to allocate all the memory for all results at
#the same time.
#Example - perform 'filesystem' search program. You could perform search in its entireity,
#collect the results, and display them all at once. All results would need to be collected
#before showing them. Thus all results would need to be in memory.
#Or you could display the results while you search which is more memory efficient and
#user friendly. Latter could be done by passing the result printing function to the 
#filesystem search function.
#Or you could make the search function a generator and iterating over the result.

#Another explanation:
#to treat the results one at a time, avoiding building huge lists of results that you
#would process separately


#Example
#os.path.walk() --> old filesystem walking function with callback
#os.walk() --> new filesystem walking generator

#To make the generator into a list, just make the generator a list:
big_list = list(the_generator)

CallBacks





#Enter the Python interpreter and import this module with the following command:
>>> import this

import this     #The Zen of Python by Tim Peters

concatenate #on command line
alaphabet = ''
alaphabet = 'abcd'
alaphabet += 'efgh'
alaphabet += 'ijkl'
alaphabet += 'mnop'
alaphabet

#on command line
>>> alaphbet = ''
...     'abcd' + \
...     'efgh' + \
...     'ijklmnop' + \
...     'qrstuv12345'
>>> alphabet 

_ATUL 

dir()
globals()
locals()
    




#from python standard library, python tutorial 
6. Modules
#for longer programs, you are better off using a text editor to prepare the input for the 
#interpreter and running the interpreter with THAT FILE as input instead. This is known as
#creating a script. For longer, programs, split the script into several files for easier
#maintenance.

#If you have some handy function that you created, and want access it via a script or via the
#python interpreter, then this is called using a MODULE. Defintiions from a module can be
#IMPORTED into other modules or into the MAIN module.

#A module is a file name with the suffix .py appended.

_ATUL

FROM TERMINAL
1 import file from pwd into python interpreter
2 to access that file and that function
                            >>> modulename.functionname(input)
so,
                            >>> import test
                            >>> test.fib(80)            #print() will print no commas, just uses blank spaces ' '
                            1 1 2 3 5 8 13 21 34 55 
                            >>> test.fib(80)            #return result will print with commas and [ ] 
                            [1, 1, 2, 3, 5, 8, 13, 21, 34, 55]


                            >>> import temp
                            >>> A = list(range(1,50))
                            >>> temp.find_max(A)
                            >>> temp.find_max(A)
                            49

VERIFY IT EXISTS ON laptop                      ls command on Terminal

can run from Terminal                           python3 test4.py
but need "__main__" snippit to run               python3 test4.py <argument>

CREATED A MODULE IN text editor                 used Sublime Text 2

IMPORT THAT MODULE from interpreter             >>> import test4
                            NOTE - no .py needed

ACCESS THAT MODULE from interpreter using       >>> modulename.functionname(input)

                                                >>> test4.fib2(7)
                                                [1, 1, 2, 3, 5]
                                                >>> test4.fib2(50)
                                                [1, 1, 2, 3, 5, 8, 13, 21, 34]

can assign it a local name within interpreter if want to call frequently
                                                >>> Jennifer = test4.fib
                                                >>> Jennifer(6)
                                                [1, 1, 2, 3, 5]

                                                >>> import test4
                                                Hello World
                                                >>> test4.fib2(7)
                                                [1, 1, 2, 3, 5]
                                                >>> test4.fib2(50)
                                                [1, 1, 2, 3, 5, 8, 13, 21, 34]
                                                >>> crazynewway = test4.fib2
                                                >>> crazynewway(80)
                                                [1, 1, 2, 3, 5, 8, 13, 21, 34, 55]
                                                >>> test4.fib1(50)
                                                1 1 2 3 5 8 13 21 34 



                        test1.py
                        #!/usr/bin/env python3

                        import string

                        def letter_count(text, letters=string.ascii_letters):
                            letters = frozenset(letters)
                            count = 0
                            for char in text:
                                if char in letters:
                                    count += 1
                            return count

                        saved, test1.py in pwd
                        so, from INTERPRETER

                        >>> import test1
                        >>> test1.letter_count('hello_world')
                        10
                        >>> test1.letter_count('helloworld')
                        10
                        >>> test1.letter_count('helloworl')
                        9



CREATED A MODULE IN text editor

#!/usr/bin/env python3
#Finbonacci numbers module

def fib(n):         #write Fibonacci series up to n
    a, b = 0, 1
    while b < n:
        print(b, end=' ')       #if no end, then prints line by line including >>>
        a, b = b, a+b
    print()                     #adding this prints new >>> on new line

def fib2(n):        #return Fibonacci series up to n
    result = []
    a, b = 0, 1
    while b < n:
        result.append(b)
        a, b = b, a+b
    return result



IMPORT THAT MODULE from interpreter

>>> import fibo
#From text editor --> file saved as fibo.py
#NOTE that this does not enter the names fo the functions defined in fibo directly into the current
#symbol table; it only enters the module name fibo there. Using the module name you can THEN
#access the functions.

ACCESS THAT MODULE from interpreter

>>> import fibo
>>> fibo.fib(1000)
1 1 2 3 5 8 13 21 34 55 89 144 233 377 610 987 
>>> fibo.fib2(100)
[1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89]
>>> fibo.__name__
'fibo'

#If you intend to use a function often then you can assign it a local name:
>>> fib = fibo.fib
>>> fib(500)
1 1 2 3 5 8 13 21 34 55 89 144 233 377 
>>> 

INITIALIZE THE MODULE from interpreter
#the executable statements are intended to initialize the module. They are executed
#only the FIRST TIME the module name is encountered in an import statement.
#Each module has its own private symbol table, which is used as the global symbol table by
#all functions defined in that module. Thus the author of the mdoule can use global
#variables within the module without worrying about accidental clashes with a user's global
#variables. On the other hand, if you know what you are doing you can touch a module's global
#variables with the same notation used to refer to its functions:
modname.itemname

#Variant of the import statment allowing to import names from a module directly into the
#importing module's symbol table, for example
>>> from fibo import fib, fib2
>>> fib(500)
1 1 2 3 5 8 13 21 34 55 89 144 233 377 
#This does NOT introduce the module name from which the imports are taken in the local
#symbol table (so in this example, fibo is NOT defined).
#importing ALL names that a module defines
>>> from fibo import *
>>> fib(500)
1 1 2 3 5 8 13 21 34 55 89 144 233 377 
#this imports ALL the names except those beginning with an undescore. But this can introduce an
#UNKNOWN set of names into the interpreter which can be problematic, so dont do it.
#Note, each module is only imported once per interpreter session. So if you change your modules
#you must restart the interpreter or if its just one module you want to test interactively then
#use
importlib.reload()
#for example    >>> import importlib; importlib.reload(modulename)

EXECUTING MODULES AS SCRIPTS
#when you run a python module FROM THE TERMINAL with
python3 fibo.py <arguments>
#the code in the module will be executed, just as if you imported it, but with
#the __name__ set to "__main__"
#This means that by adding this code at the end of your module:
if __name__ == "__main__":
    import sys
    fib(int(sys.argv[1]))
#you make the file usable as a script as well as an importable module, b/c the code that 
#parses the command line only runs if the module is executed as the "main" file

so fibo.py BEFORE was
#!/usr/bin/env python3
#Finonacci numbers module
def fib(n):         #write Fibonacci series up to n
    a, b = 0, 1
    while b < n:
        print(b, end=' ')
        a, b = b, a+b
    print()

def fib2(n):        #return Fibonacci series up to n
    result = []
    a, b = 0, 1
    while b < n:
        result.append(b)
        a, b = b, a+b
    return result


#and now with ADDITIONAL __name__ == "__main__" code ADDED

if __name__ == "__main__":
    import sys
    fib(int(sys.argv[1]))

#IT ACTUALLY WORKS!!!!!

Atuls-MBP:python_proginpython3 atulgolhar$ ls
Notes_ProgInPython3.py  results.txt     test3.py
Shape.py        test.py         test4.py
__pycache__     test1.py        testPython3book.py
fibo.py         test2.py
Atuls-MBP:python_proginpython3 atulgolhar$ python3 fibo.py 50
Atuls-MBP:python_proginpython3 atulgolhar$ 
Atuls-MBP:python_proginpython3 atulgolhar$ python3 fibo.py 50
1 1 2 3 5 8 13 21 34 

#BUT NOTE, if the that UPDATED module is imported to the interpreter,
#the code is NOT run:
>>> import fibo
>>> 
#ie nothing happened.
#Why do this? this is often used either to provide a convenient user interface to a module, 
#or for testing purposes (running the module as a script executes a test suite).

Lists as stacks
#Using lists as stacks: last element added is first element retrieved (last in first out)
#no special import needed
#    notice [] for creating but () for appending
                            >>> jelly.append(7)
                            >>> jelly = [3,4,5]
                            >>> jelly.append(7)
                            >>> jelly
                            [3, 4, 5, 7]

#    error if try to use [] to append
                            >>> stack.append[8]
                            Traceback (most recent call last):
                              File "<stdin>", line 1, in <module>
                            TypeError: 'builtin_function_or_method' object is not subscriptable

Lists as queues
#Using lists as queues: first element in is first element out (first in first out)
from collections import deque 

                            >>> butter = ["Eric", "John", "Ted"]
                            >>> butter
                            ['Eric', 'John', 'Ted']
                            >>> pan = ("x1", "x2", "x3")
                            >>> pan
                            ('x1', 'x2', 'x3')
                            >>> type(butter)
                            <class 'list'>
                            >>> type(pan)
                            <class 'tuple'>

                            >>> butter.append("Sam")
                            >>> butter
                            ['Eric', 'John', 'Ted', 'Sam']



Atuls-MBP:python_proginpython3 atulgolhar$ python3 test4.py 400
Hello World
1 1 2 3 5 8 13 21 34 55 89 144 233 377 
Atuls-MBP:python_proginpython3 atulgolhar$ 

To run this, must line up correct function name refer
ence


                            #!/usr/bin/env python3

                            print("Hello World")

                            def fib1(n):
                              a, b = 0, 1
                              while b < n:
                                print(b, end=' ')
                                a, b = b, a+b
                              print()

                            def fib2(n):
                              result = []
                              a, b = 0, 1
                              while b < n:
                                result.append(b)
                                a, b = b, a+b
                              print()
                              return result

                            if __name__ == "__main__":
                              import sys
                              fib1(int(sys.argv[1]))


-----------1st EFFORT - posted on GitHub
#!/usr/bin/env python3
#fibonacci.py
#multiple methods to execute fibonacci (interpreter vs command line)

def fib1(n):
  a, b = 0, 1
  while b < n:
    print(b, end=' ')
    a, b = b, a+b
  print()

def fib2(n):
  result = []
  a, b = 0, 1
  while b < n:
    result.append(b)
    a, b = b, a+b
  print()
  return result

if __name__ == "__main__":
  import sys
  fib1(int(sys.argv[1]))

-----------1st EFFORT - posted on GitHub


PACKAGES
#allows for structuring Python's module namespace by using "dotted module names" (saves worry 
#about conflicting namespace if using mulitple modules that contain SAME submodule names.)




-----REVIEW---------BEGIN---

- with NO __name__ == "__main__" code
    run from Terminal python3 test4.py 400 30 --> does not work

    Atuls-MBP:python_proginpython3 atulgolhar$ python3 test4.py 400 30
    Hello World

- with YES __name__ == "__main__" code
    run from Terminal python3 test4.py 400 30 --> YES works

    Atuls-MBP:python_proginpython3 atulgolhar$ python3 test4.py 400 30
    Hello World
    1 1 2 3 5 8 13 21 34 55 89 144 233 377 check-fib1

- notice 1st argument is tapped

    if __name__ == "__main__":
      import sys
      fib1(int(sys.argv[1]))

- notice 2nd argument is tapped 

    if __name__ == "__main__":
      import sys
      fib1(int(sys.argv[2]))

    Atuls-MBP:python_proginpython3 atulgolhar$ python3 test4.py 400 30
    Hello World
    1 1 2 3 5 8 13 21 check-fib1

-----REVIEW---------END---


ATUL EXERCISES

- playing with fibonacci function

                #!/usr/bin/env python3
                def fib(n):
                    a, b = 0, 1
                    while b < n:
                        print(b, end=' ')
                        a, b = b, a+b
                        print()             #prints new line each iteration

                #!/usr/bin/env python3
                def fib(n):
                    a, b = 0, 1
                    while b < n:
                        print(b, end=' ')
                        a, b = b, a+b
                    print()                 #prints SAME line b/c b collects all values



=========================================================END Introducing Python 2015


===============================================================================================
CHAPTER: 1 Rapid Intro to Procedural Programming
CHAPTER BEGIN
#Begin notes for Programming in Python3
===============================================================================================


print ("Hello World")
print("Hello World")
print ('Hello World')

import webbrowser
webbrowser.open('http://www.google.com')


IDLE

===============
Pythons Beautiful Heart
===============

===============
1 Data Types
===============

use [] to access an item from a sequence

"Hard Times"[5]
int("45")
int("     45     ")
>>> int("45")
45
>>> int("      45      ")
45
#this it tolerant of leading and trainling white spaces.

str(912)
If interger conversion fails then ValueError exception is raised

===============
2 Object References
===============
#python does not use variables, but instead uses object references 
x = "blue"
y = "green"
z = x
Rebinding example
print(x,y,z)
z=y
print(x,y,z)
x=z
print(x,y,z)
#now all 3 objects refer to the same string
Python uses dynamic typing, so you do NOT need to PREDEFINE the variable.
#can call methods upon objects

ATUL NOTES
x_list = [1,2,3,4,5]
print(x_list)
x_list += [6]
print(x_list)
x_list.append(10)
print(x_list)

is vs not is = identity operators to check if two objects references refer to same thing 
in vs not in = membership testing (can be slow)


===============
3 Collection Data Types
===============
tuples are immutable
list created using []
call functions and pass in data items as arguments
all python data items are called objects = instances of a class 
objects can have methods

x = ["zebra", 49, -879, "aardvarkl", 200]
x.append("more")
list.append(x,"extra")    #also works. See Inheritance and OOP for Chap 6

functionName(arguments)               #calling a function
objectName.methodName(arguments)      #calling a method
dot = access attribute operator

Exception handling #see Beautiful Piece #5 and Chap 4


Summary:

dictionary     {}           empty_dictionary_example = {}
set -->        set()        empty_set_nameing_example = set()
list -->       []           list slice --> [:]
tuple -->      ()           empty_tuple_example = ()
tuple vs list   tuple                       list 
                use less space              use more space 
                have fewer functions        have more functions 
                named tuple = handy 
                function arguments passable



===============
4 Logical Operators (4 types of operators: identity, comparison, membership, logical)
===============

1 Identity Operator 
returns True or False
a = ["Retention", 3, None]
b = ["Retention", 3, None]
a is b #false
b = a
a is b #true (not intuitive)
operators here only compare the memory addresses, not the actual objects themselves


2 Comparison Operator = == < > <= >= !=


3 Membership Operator 
p = (4, "frog", 9, -33, 9, 2)
2 in p 


4 Logical Operators
and
or


5 Control Flow Statements
5.1 conditional branching (if elif else)
5.2 conditional looping (while)   ---> prematurely terminated using brake statement 
                                       and switch control using continue statement 
5.3 looping (for in)              ---> prematurely terminated using brake statement
                                       and switch control using continue statement 
5.4 exception handling (try except blocks)

===============
    if Statement 
===============
if boolean1:
    elif boolean2:
    else booleanN:
    else:
        else suite      #final else is optional
indentation --> 4 spaces per level of indentation

===============
    while Statement 
===============

while booleanTrue:
    suite


===============
    for...in Statement
===============

for ... in statement
for variable in iterable:
    suite
for country in ["Denmark", "Finland", "Norway", "Sweeden"]:
    print(country)


for letter in "abcdefghijklmnopqrstuvwxyz":
    if letter in "aeiou":
        print(letter.capitalize, "is a vowel")
    else:
        print(letter.capitalize, "is a constant")

===============
    Basic Exception Handling 
===============
Basic Exception Handling
exception is an object like any other object

#here control is passed to the first exception raised, 
#thus any following statements are not executed
#if an unhandled exception is raised, then Python 
#prints a traceback as well as exception message text
try:
    try_suite
except exception1 as variable1:         #as variable is optional 
    exception_suite1                      #as may only care that an exception was in fact raised
except exception2 as variable2:         #and not so much about what the exception is (message text)
    exception_suite2
except exception3 as variable3:
    exception_suite3
except exceptionN as variableN:
    exception_suiteN


s = input("enter an integer: ")
try:
    i = int(s)
    print("valid integer entered: ", i)
except ValueError as err:
    print(err)
  

===============
    Arithmetic Operator
===============
6 Arithmetic Operator
seeds = ["sesame", "sunflower"]
seeds += ["pumpkin"]
seeds
#can append a list using []
seeds += 5    error 
seeds =+ [5]  ok

seeds = ["sesame", "sunflower"]
seeds += ["pumpkin"]
seeds
seeds += "durian"
seeds
> ['sesame', 'sunflower', 'pumpkin', 'd', 'u', 'r', 'i', 'a', 'n']
#each character within the iterable string is individually appended


===============
    Input/Output
===============
7 Input/Output 

from Bash or Terminal command line
python3 test4.py

#then that command looks to test4.py file and executes it

Saved as test4.py
#!/usr/bin/env python3
line1 = input("integer: ")
print(line1)




From within terminal accessing python iterpreter

{Atuls-MBP:python_proginpython3 atulgolhar$ python3
Python 3.5.1 (v3.5.1:37a07cee5969, Dec  5 2015, 21:12:44) 
[GCC 4.2.1 (Apple Inc. build 5666) (dot 3)] on darwin
Type "help", "copyright", "credits" or "license" for more information.
>>>
                                    >>> line1 = input("integer:")
                                    integer:3
                                    >>> print(line1)
                                    3

line2 = input("some text: ")
print(line2)

>>> line = input("integer: ")
integer: 3
>>> line
3

# Calculates the avg number and prints out the data.
print("Type integers, each followed by Enter; or just Enter to finish.")

total = 0
count = 0


while True:
    line = input("integer: ")
    if line:
        try:
            number = int(line)          #test here for the while statement
        except ValueError as err:     #verfied test is prior line b/c exception raised here
            print(err)                  #print the error message
            continue                    #switches control to the start of the loop AGAIN ("continue to loop")
        total += number               #regain control here
        count += 1
    else:
        break                         #breaks out to the while loop

if count:                         #if user never enters an integer, summary output is avoided and
    print("count =", count, "total =", total, "mean = ", total/count) #division by zero is avoided



python3 test.py > results.txt     #ERROR here

#refactored to acccount for EOF Error issue
#why? as blank line EOF or text characters input will increment Count. Wrong.
#also if input text characters, then last Number is added Again to total. Wrong.
#some input files contain blank lines so more robust using ControlD
#why ControlD? it acts as a hard stop, forcing a break triggering this 
    Integer input: Traceback (most recent call last):
      File "test1.py", line 11, in <module>
        line = input("Integer input: ")
    EOFError

#stopped printing a prompt for each input since redirected input is redundant
#used single try block with two exception handlers (less code lines)

print("Type integers, each followed by Enter; or ControlD to finish.")

total = 0
count = 0

while True:
    try:
        line = input("Enter integer: ")
        if line:
            number = int(line)    #flow of control immediately switches to relevant except block
            total += number       #so neither total nor count gets incremented
            count += 1
    except ValueError as err:     #verfied test is prior line b/c exception raised here
        print(err)                  #print the error message
        continue                    #switches control to the start of the loop AGAIN
    except EOFError:
        break 

if count:                         #if user never enters an integer, summary output is avoided and
    print("count =", count, "total =", total, "mean = ", total/count) #division by zero is avoided

python3 test.py > results.txt



===============
    Creating and Calling Functions 
===============
                    print("Hello World")

                    #!/usr/bin/env python3
                    age = ("Enter your age: ")

                    #!/usr/bin/env python3
                    age = input("Enter your age: ")

                    #!/usr/bin/env python3
                    age = input("Enter your age: ")
                    print(age)
                    print("This is my new variable: ", age)

                    #!/usr/bin/env python3
                    def basic_new_function_get_age(arguments):
                        input(arguments)
                    age = basic_new_function_get_age("Enter your age: ")


#NOTE nothing is saved in memory 
>>> def xxx(arguments):
...     input(arguments)
...     print(xxx)
...     print(arguments)
...     print(type(arguments))
... 
>>> agexxx1 = xxx("Enter your age: ")       #created new object of xxx class
Enter your age: 48
<function xxx at 0x1063b2d08>


...     input(arguments)
...     print("request printing xxx: ", xxx)
...     print("request printing 'arguments': ", arguments)
...     print("request prints type of arguments: ", type(arguments))
... 
>>> agexxx1 = xxx("Enter your age: ")
Enter your age: 49
request printing xxx:  <function xxx at 0x1063811e0>
request printing 'arguments':  Enter your age: 
request prints type of arguments:  <class 'str'>



8 Creating and Calling Functions
#want abilty to encapsulate suites as functions which can be parameterized by the 
#arguments the functions are passed
#every python function has a return value or defaults to None

def functionName(arguments):
    suite

#example
#note single argument is mandatory b/c have provided no default value
#Chap 4 deals with flexible syntax for function parameters supporting default argument values
#and positional and keyword arguments


def get_int(msg):                 #takes in one argument msg
    while True:                     #inside while loop
        try:
            i = int(input(msg))         #user prompted to enter an integer
            return i
        except ValueError as err:     #if enter something invalid, then
            print(err)                  #error message is printed
age = get_int("enter your age: ")



-----
#!/usr/bin/env python3
#Test Driven Development - Flow of Control Check
#727

def get_int(arguments):
    print("Check2: ", arguments, type(arguments))
    while True:
        try:
            i = int(input(arguments)), print("Check3", arguments)
            print("Check4: ", arguments, type(arguments))
            print("Check5: ", i)
            return i
        except ValueError as err:
            print("Check6", type(err), err)

print("Check1 Flow of control check\n")

age = get_int("Enter your age: ")

print("Check7: ", type(age), age)
-----


#a python module is just a .py file containing python code such as custom function and
#class definitions and variables.
#need to import the module like this
import sys            #use import statement followed by name of the .py file
#import statement is about import a MODULE
#once imported, we can access any functions, classes or variables

print(sys.argv)     #sys module provides the argv variable --> a list whose first item is the
                    #name under which the program was invoked

#syntax to use a module
moduleName.functionName(arguments)
#standard modules all have lowercase names, so programmers MAY use title-case names for their OWN
#modules to keep them distinct

import random
x = random.randint(1,6)
y = random.choice(["apple", "banana", "cherry", "durian"])
print(x)
print(y)
#conventional to put all import statements at beginning of .py file after shebang line
#recommend importing
standard library modules then
third party library modules then
your own modules




#Reminder of topics<===========
CHAPTER 1 Rapid Intro to Procedural Programming

#CODE LISTING HERE
    average1_ans.py
    average2_ans.py
    awfulpoetry1_ans.py
    awfulpoetry2_ans.py
    bigdigits.py
    bigdigits_ans.py
echoargs.py
generate_grid.py
hello.py
sum1.py
sum2.py 



===============
    EXAMPLES
==============

#bigdigits.py 

#!/usr/bin/env python3

#Given a number on the command line, the program outputs the same number onto the console
#using "big" digits. Execute: input digit 1 to 9 from cmd line for example:
python3 bigdigits.py 8 7

#!/usr/bin/env python3
#bigdigits.py 
import sys      #we read in an argument from Bash cmd line, so we need to access sys.argv list

Zero = ["  **  ", " *  * ", "*    *", "*    *", "*    *", " *  * ", "  **  "]
One =  ["   * ", "  ** ", "   * ", "   * ", "   * ", "   * ", "  ***"]
Two =  [" *** ", "*   *", "*  * ", "  *  ", " *   ", "*    ", "*****"]
Three =[" ****", "    *", "    *", " ****", "    *", "    *", " ****"]
Four = ["*   *", "*   *", "*   *", "*****", "    *", "    *", "    *"]
Five = ["*****", "*    ","*    ", "*****", "    *", "    *", "*****"]
Six =  ["*    ", "*    ", "*    ", "*****", "*   *", "*   *", "*****"]
Seven =["*****", "    *", "   * ", "  *  ", " *   ", "*    ", "*    "]
Eight =["*****", "*   *", "*   *", "*****", "*   *", "*   *", "*****"]
Nine = ["*****", "*   *", "*   *", "*****", "    *", "    *", "    *"]
Digits = [Zero, One, Two, Three, Four, Five, Six, Seven, Eight, Nine]


try:
    digits = sys.argv[1]
#   digits = sys.argv[2]
    row = 0
    while row < 7:
        line = ""
        column = 0
        while column < len(digits):
            number = int(digits[column])
            digit = Digits[number]
            line += digit[row] + "  "
            column += 1
        print(line)
        row += 1
except IndexError:
    print("usage: bigdigits.py <number>")
except ValueError as err:
    print(err, "in", digits)



bigdigits.py REFACTORED
#code is wrapped in an exception handler that has two error catches
import sys      #we read in an argument from cmd line, so we need to access sys.argv list

Zero  = ["  **  ", " *  * ", "*    *", "*    *", "*    *", " *  * ", "  **  "]
One   = ["   * ", "  ** ", "   * ", "   * ", "   * ", "   * ", "  ***"]
Two   = [" *** ", "*   *", "*  * ", "  *  ", " *   ", "*    ", "*****"]
Three = [" ****", "    *", "    *", " ****", "    *", "    *", " ****"]
Four  = ["*   *", "*   *", "*   *", "*****", "    *", "    *", "    *"]
Five  = ["*****", "*    ", "*    ", "*****", "    *", "    *", "*****"]
Six   = ["*    ", "*    ", "*    ", "*****", "*   *", "*   *", "*****"]
Seven = ["*****", "    *", "   * ", "  *  ", " *   ", "*   ", "*     "]
Eight = ["*****", "*   *", "*   *", "*****", "*   *", "*   *", "*****"]
Nine  = ["*****", "*   *", "*   *", "*****", "    *", "    *", "    *"]

Digits = [Zero, One, Two, Three, Four, Five, Six, Seven, Eight, Nine]

print("Enter a number as 1st argument then the program outputs the same in big number format:")
                    #note that no argument is given thus trying to access the second item
try:                #of a one item list causing IndexError exception to be raised
    digits = sys.argv[1]    #and if IndexError exception is triggered then flow of control
    row = 0                 #immediately switches to corresponding exception-handling block
    while row < 7:          #use while loop to interate over each row but better to use range()
        line = ""           #range() usage will come up later
        column = 0
        while column < len(digits):         #iterate here, or could have used this
            number = int(digits[column])      #for row in (0,1,2,3,4,5,6):
            digit = Digits[number]            #later on will use built-in range() function
            line += digit[row] + "  "         #use line string to hold the row strings from all digits
            column += 1                        
        print(line)
        row += 1
except IndexError:
    print("IndexError usage: bigdigits.py <number>")
except ValueError as err:
    print(err, "in", digits)

#Note for 
            line += digit[row] + "  "         #use line string to hold the row strings from all digits
            column += 1                     
#each time the inner while loop finishes, we print the line that has been built up. The key
#to understanding this program is where we append each digit's row string to the current row's
#line.






======ATUL====== #focus on internal iterator capture and print verification
#!/usr/bin/env python3
#bigdigits_ans.py

import sys      #we read in an argument from Bash cmd line, so we need to access sys.argv list

Figure_Zero = ["  **  ", " *  * ", "*    *", "*    *", "*    *", " *  * ", "  **  "]
Figure_One =  ["   * ", "  ** ", "   * ", "   * ", "   * ", "   * ", "  ***"]
Figure_Two =  [" *** ", "*   *", "*  * ", "  *  ", " *   ", "*    ", "*****"]
Figure_Three =[" ****", "    *", "    *", " ****", "    *", "    *", " ****"]
Figure_Four = ["*   *", "*   *", "*   *", "*****", "    *", "    *", "    *"]
Figure_Five = ["*****", "*    ","*    ", "*****", "    *", "    *", "*****"]
Figure_Six =  ["*    ", "*    ", "*    ", "*****", "*   *", "*   *", "*****"]
Figure_Seven =["*****", "    *", "   * ", "  *  ", " *   ", "*    ", "*    "]
Figure_Eight =["*****", "*   *", "*   *", "*****", "*   *", "*   *", "*****"]
Figure_Nine = ["*****", "*   *", "*   *", "*****", "    *", "    *", "    *"]
Digits = [Figure_Zero, Figure_One, Figure_Two, Figure_Three, 
            Figure_Four, Figure_Five, Figure_Six, Figure_Seven, 
            Figure_Eight, Figure_Nine]

try:
    digits = sys.argv[1]
    row = 0
    while row < 7:
        line = ""
        column = 0
        while column < len(digits):
            number = int(digits[column])
            digit = Digits[number]
            line += digit[row] + "  "
            column += 1
        print(line)
        row += 1
except IndexError:
    print("IndexError usage: bigdigits.py <number>")
except ValueError as err:
    print(err, "in", digits)


#!/usr/bin/env python3
#bigdigits_ans.py

import sys      #we read in an argument from Bash cmd line, so we need to access sys.argv list

Zero = ["  **  ", " *  * ", "*    *", "*    *", "*    *", " *  * ", "  **  "]
One =  ["   * ", "  ** ", "   * ", "   * ", "   * ", "   * ", "  ***"]
Two =  [" *** ", "*   *", "*  * ", "  *  ", " *   ", "*    ", "*****"]
Three =[" ****", "    *", "    *", " ****", "    *", "    *", " ****"]
Four = ["*   *", "*   *", "*   *", "*****", "    *", "    *", "    *"]
Five = ["*****", "*    ","*    ", "*****", "    *", "    *", "*****"]
Six =  ["*    ", "*    ", "*    ", "*****", "*   *", "*   *", "*****"]
Seven =["*****", "    *", "   * ", "  *  ", " *   ", "*    ", "*    "]
Eight =["*****", "*   *", "*   *", "*****", "*   *", "*   *", "*****"]
Nine = ["*****", "*   *", "*   *", "*****", "    *", "    *", "    *"]

Digits = [Zero, One, Two, Three, Four, Five, Six, Seven, Eight, Nine]

try:
    digits = sys.argv[1]                            4 input str
    row = 0                                         0
    while row < 7:                                  0<7 is 0123456 less 7
        line = ""                                       why? note row <= 7 changes total columns to 8
        column = 0                                  0
        while column < len(digits):                 0< 1 length from 4 input str
            number = int(digits[column])            int of input[column 0]
            digit = Digits[number]                  Digit List[column 0]

            line += digit[row] + "  "               4 int[0] and this iterates from column 0 to 6
            column += 1                             column = 1 to exit while loop
        print(line)                                 print 4 int[0]
                                                    print 4 int[1]
                                                    print 4 int[2]
                                                    print 4 int[3]
                                                    print 4 int[4]
                                                    print 4 int[5]
                                                    print 4 int[6]
        row += 1
except IndexError:
    print("usage: bigdigits.py <number>")
except ValueError as err:
    print(err, "in", digits)




#!/usr/bin/env python3
#bigdigits_ans.py

import sys      #we read in an argument from Bash cmd line, so we need to access sys.argv list

Zero = ["  **  ", " *  * ", "*    *", "*    *", "*    *", " *  * ", "  **  "]
One =  ["   * ", "  ** ", "   * ", "   * ", "   * ", "   * ", "  ***"]
Two =  [" *** ", "*   *", "*  * ", "  *  ", " *   ", "*    ", "*****"]
Three =[" ****", "    *", "    *", " ****", "    *", "    *", " ****"]
Four = ["*   *", "*   *", "*   *", "*****", "    *", "    *", "    *"]
Five = ["*****", "*    ","*    ", "*****", "    *", "    *", "*****"]
Six =  ["*    ", "*    ", "*    ", "*****", "*   *", "*   *", "*****"]
Seven =["*****", "    *", "   * ", "  *  ", " *   ", "*    ", "*    "]
Eight =["*****", "*   *", "*   *", "*****", "*   *", "*   *", "*****"]
Nine = ["*****", "*   *", "*   *", "*****", "    *", "    *", "    *"]

Digits = [Zero, One, Two, Three, Four, Five, Six, Seven, Eight, Nine]

try:
    digits = sys.argv[1]                           
    row = 0                                         
    while row < 7:                                 
        line = ""
        column = 0                                  
        while column < len(digits):                 
            number = int(digits[column])           
            digit = Digits[number]                 

            line += digit[row] + "  "              
            column += 1
        print(line, row, number, Digits[number])
        row += 1
except IndexError:
    print("IndexError, usage: bigdigits.py <number>")
except ValueError as err:
    print(err, "in", digits)


Atuls-MBP:python_proginpython3 atulgolhar$ python3 test1.py 4
*   *   0 4 ['*   *', '*   *', '*   *', '*****', '    *', '    *', '    *']
*   *   1 4 ['*   *', '*   *', '*   *', '*****', '    *', '    *', '    *']
*   *   2 4 ['*   *', '*   *', '*   *', '*****', '    *', '    *', '    *']
*****   3 4 ['*   *', '*   *', '*   *', '*****', '    *', '    *', '    *']
    *   4 4 ['*   *', '*   *', '*   *', '*****', '    *', '    *', '    *']
    *   5 4 ['*   *', '*   *', '*   *', '*****', '    *', '    *', '    *']
    *   6 4 ['*   *', '*   *', '*   *', '*****', '    *', '    *', '    *']





#!/usr/bin/env python3
#bigdigits_ans.py

import sys      #we read in an argument from Bash cmd line, so we need to access sys.argv list

Zero = ["  **  ", " *  * ", "*    *", "*    *", "*    *", " *  * ", "  **  "]
One =  ["   * ", "  ** ", "   * ", "   * ", "   * ", "   * ", "  ***"]
Two =  [" *** ", "*   *", "*  * ", "  *  ", " *   ", "*    ", "*****"]
Three =[" ****", "    *", "    *", " ****", "    *", "    *", " ****"]
Four = ["*   *", "*   *", "*   *", "*****", "    *", "    *", "    *"]
Five = ["*****", "*    ","*    ", "*****", "    *", "    *", "*****"]
Six =  ["*    ", "*    ", "*    ", "*****", "*   *", "*   *", "*****"]
Seven =["*****", "    *", "   * ", "  *  ", " *   ", "*    ", "*    "]
Eight =["*****", "*   *", "*   *", "*****", "*   *", "*   *", "*****"]
Nine = ["*****", "*   *", "*   *", "*****", "    *", "    *", "    *"]

Digits = [Zero, One, Two, Three, Four, Five, Six, Seven, Eight, Nine]

try:
    digits = sys.argv[1]                           
    row = 0                                         
    while row < 7:                                 
        line = ""
        column = 0                                  
        while column < len(digits):
            number = int(digits[column])
            digit = Digits[number]

            for c in digit[row]:
                if c == "*":
                    c = str(number)
                line += c

            line += digit[row] + "  "
            column += 1
        print(line, row, number, Digits[number])
        row += 1
except IndexError:
    print("IndexError, usage: bigdigits.py <number>")
except ValueError as err:
    print(err, "in", digits)



Atuls-MBP:python_proginpython3 atulgolhar$ python3 test1.py 4
4   4*   *   0 4 ['*   *', '*   *', '*   *', '*****', '    *', '    *', '    *']
4   4*   *   1 4 ['*   *', '*   *', '*   *', '*****', '    *', '    *', '    *']
4   4*   *   2 4 ['*   *', '*   *', '*   *', '*****', '    *', '    *', '    *']
44444*****   3 4 ['*   *', '*   *', '*   *', '*****', '    *', '    *', '    *']
    4    *   4 4 ['*   *', '*   *', '*   *', '*****', '    *', '    *', '    *']
    4    *   5 4 ['*   *', '*   *', '*   *', '*****', '    *', '    *', '    *']
    4    *   6 4 ['*   *', '*   *', '*   *', '*****', '    *', '    *', '    *']
Atuls-MBP:python_proginpython3 atulgolhar$ python3 test1.py 3
 3333 ****   0 3 [' ****', '    *', '    *', ' ****', '    *', '    *', ' ****']
    3    *   1 3 [' ****', '    *', '    *', ' ****', '    *', '    *', ' ****']
    3    *   2 3 [' ****', '    *', '    *', ' ****', '    *', '    *', ' ****']
 3333 ****   3 3 [' ****', '    *', '    *', ' ****', '    *', '    *', ' ****']
    3    *   4 3 [' ****', '    *', '    *', ' ****', '    *', '    *', ' ****']
    3    *   5 3 [' ****', '    *', '    *', ' ****', '    *', '    *', ' ****']
 3333 ****   6 3 [' ****', '    *', '    *', ' ****', '    *', '    *', ' ****']
Atuls-MBP:python_proginpython3 atulgolhar$ 


================




EXAMPLES

generate_grid.py
#one frequently needs to generate test data. How? no single generic program for doing this b/c
#test data varies enormously. Python is often used to write test data b/c Python is so easy to
#write and modify Python programs.

#Here we generate a grid of random integers
#user specifies how many rows and columns and over what range integers span
#code has 4 parts: import, def get_int() function, user interaction, and processing itself

#note value of None means no default value so user must enter an integer

import random       #need random module to get access to random.randint() function

def get_int(msg, minimum, default):     #to get default the user presses Enter only
    while True:                           #ATUL LEARN THIS LOGIC
        try:
            line = input(msg)
            if not line and default is not None:    #default as None means user must enter integer
                return default                      #flow of control drops thru to int(line) conversion
            i = int(line)                           #print("Internal Default is ", default)
            if i < minimum:
                print("must be >=", minimum)
            else:
                return i 
        except ValueError as err:
            print("ValueError", err)
#so this function will always return either default (if user pressed Enter) or a valid integer
#that is greater than or equal to the specified minimum

#user interaction
rows = get_int("rows: ", 1, None)
columns = get_int("columns: ", 1, None)
minimum = get_int("minimum (or Enter for 0): ", -1000000, 0)

default = 1000          #supply default value of 1000 or twice the minimum if min is greater than
if default < minimum:   #or equal to 1000
    default = 2 * minimum
maximum = get_int("maximum (or Enter for " + str(default) + "): ", minimum, default)

#to generate the grid, we use three while loops, with outer one working by rows, middle
#one by columns, and inner one by characters.

#processing - use 3 while loops to generate grid with 
#outer loop for rows, middle loop for columns, and inner loop for character spacing
row = 0
while row < rows:
    line = ""
    column = 0
    while column < columns:
        i = random.randint(minimum, maximum)        #obtain random number in specified range 
        s = str(i)                                  #and convert it into a string
        while len(s) < 10:        #to pad string with leading spaces so set string at 10 charaters wide
            s = " " + s           #to crudely pad the string with leading spaces
        line += s                 #use line string to accumulate the numbers as strings for each row
        column += 1
    print(line)
    row += 1



ATUL TEST FACTORING
import sys

#print("input any number:",msg)
#input(msg)
#print(msg)

msg = input("enter a integer: ")
try:
    i = int(msg)
    print("Valid integer entered: ", i)
except ValueError as err:
    print("ValueError", err)



#!/usr/bin/env python3

import sys

msg = input("enter a message: ")
try:
    i = (msg)
    print(type(i))
    i = int(msg)
    print(type(i))
    print(msg)
except: pass




===============
CHAPTER 1 EXERCISES
===============

1) Variation on bigdigits.py
#One nice variation is where instead of printing *s, the relevant digit is printed instead.
#So change the printed * to the actual digit used. How? change processing code

#Two approaches can be taken, easiest is simply change the *s in the lists. But this is not
#versatile and not the approach you should take. Instead, change the processing code so that 
#rather than adding each digit's row string to the line in one go, you instead
#add character by character thus adding the relevant digit

#Note python statements normally occupy a single line, but they can span multiple lines if they
#are a parenthesized expression, a list, set, or dictionary literal, a function call argument list, 
#or a multiline statement with every end-of-line character except the last is followed by a \.

#Copy bigdigits.py and change about 5 lines.

#CODE HERE
bigdigits_ans.py


#!/usr/bin/env python3
#bigdigits_ans.py

import sys 

Zero  = ["  **  ", " *  * ", "*    *", "*    *", "*    *", " *  * ", "  **  "]
One   = ["   * ", "  ** ", "   * ", "   * ", "   * ", "   * ", "  ***"]
Two   = [" *** ", "*   *", "*  * ", "  *  ", " *   ", "*    ", "*****"]
Three = [" ****", "    *", "    *", " ****", "    *", "    *", " ****"]
Four  = ["*   *", "*   *", "*   *", "*****", "    *", "    *", "    *"]
Five  = ["*****", "*    ", "*    ", "*****", "    *", "    *", "*****"]
Six   = ["*    ", "*    ", "*    ", "*****", "*   *", "*   *", "*****"]
Seven = ["*****", "    *", "   * ", "  *  ", " *   ", "*   ", "*     "]
Eight = ["*****", "*   *", "*   *", "*****", "*   *", "*   *", "*****"]
Nine  = ["*****", "*   *", "*   *", "*****", "    *", "    *", "    *"]

Digits = [Zero, One, Two, Three, Four, Five, Six, Seven, Eight, Nine]   #list of the lists

try:
    digits = sys.argv[1]
    row = 0
    while row < 7:          #use a while loop to iterate. Could have used for row in (0,1,2,3,4,5,6):
        line = ""           #even better way to iterate here is use built-in range() function --> see later
        column = 0
        while column < len(digits):         #iterate here, or c
            number = int(digits[column])      #for row in (0,1,2,3,4,5,6):
            digit = Digits[number]            #later on will use built-in range() function
            for c in digit[row]:        #New
                if c == "*":            #New
                    c = str(number)     #New
                line += c               #New
            line += " "               #old  line += digit[row] + "  "
            column += 1
        print(line)
        row += 1
except IndexError:
    print("usage: bigdigits.py <number>")
except ValueError as err:
    print(err, "in", digits)


2) average.py 

#create calculator that prompts user to enter a number in a while loop, 
#gradually build up list
#when user has finished by pressing ENTER, print out numbers, count, 
#sum of, lowest, highest and mean.
average1_ans.py (google it)
#4 lines to initialize variables
#less than 15 lines for while loop including basic error handling
#while program including blank lines should be less than 25

#CODE HERE
average1_ans.py


#BASIC
#!/usr/bin/env python3

numbers = []
total = 0
lowest = None
highest = None

while True:
    try:
        #enter a number
        #build up list
    except ValueError as err:
        print(err)
print("numbers: ", numbers)


#DETAIL ----> ATUL
#!/usr/bin/env python3

        #track lowest and highest
        if xxx:
            lowest = number
        if xxx:
            highest = number


#DETAIL
#!/usr/bin/env python3

numbers = []
total = 0
lowest = None
highest = None

while True:
    try:
        line = input("enter a number or Enter to finish: ")
        if not line:
            break
        number = int(line)      
        numbers.append(number)
        total += number 
        if lowest is None or lowest > number:
            lowest = number
        if highest is None or highest < number:
            highest = number
    except ValueError as err:
        print(err)
print("numbers: ", numbers)
if numbers:
    print("count =", len(numbers),
            "sum =", total,
            "lowest =", lowest,
            "highest =", highest,
            "mean =", total / len(numbers))


------ATUL---first try---
#!/usr/bin/env python3 #average1_ans.py
numbers = []
total = 0
lowest, highest = None, None

while True:
    try:
        line = input("Enter a number or Enter to finish: ")
        if not line: 
            break
        number = int(line)
        numbers.append(number)
        total += number

        if lowest is None or lowest > number:
            lowest = number
        if highest is None or highest < number:
            highest = number
    except ValueError as err:
        print(err)
print("All Numbers Used: ", numbers)
print("Count: ", len(numbers))
print("Sum of: ", total)
print("Lowest: ", lowest)
print("Highest: ", highest)
mean = total / len(numbers)
print("Mean: ", mean)
-------------


average1_ans.py

------ATUL---2nd try---Posted GitHub
#!/usr/bin/env python3 
#average1_ans.py
#Simple calculator prompts user to enter a number using while loop. Gradually build up list.
#When finished press Enter, print out numbers, count, sum, lowest, highest and mean.

numbers = []
total = 0
lowest, highest = None, None

while True:
    try:
        line = input("Enter a number or Enter to finish: ")
        if not line: 
            break
        number = int(line)
        numbers.append(number)
        total += number
        if lowest is None or lowest > number:
            lowest = number
        if highest is None or highest < number:
            highest = number
    except ValueError as err:
        print(err)
if numbers:
    print("\nAll Numbers Used: ", numbers, 
        "\nCount: ", len(numbers), "\nSum: ", total,
        "\nLowest: ", lowest, "\nHighest: ", highest,
        "\nMean: ", total / len(numbers))
-------------



3) awfulpoetry1_ans.py

#create a awful poems test text by
#use lists of words for 
#articles ("the", "a")
#subjects ("cat", "dog", "man", "woman")
#verbs ("sang", "ran", "jumped")
#adverbs ("loudly", "quietly", "well", "badly")
#then loop five times and on each iteration use
random.choice() #function one of each (article, subject, verb, adverb)
#then use
random.randint() #to choose between two sentence structures
#article, subject, verb and adverb OR
#article, subject, verb only
#print the sentence
awfulpeotry1_ans.py 
#will need to import
random module
#lists done in 4-10 lines depending upon how many words put inside them
#loop less than 10 lines
#so with blank lines, total is 20 lines



awfulpoetry1_ans.py

#CODE HERE
#awfulpoetry1_ans.py
#!/usr/bin/env python3

import random

articles = ["the", "a"]
subjects = ["cat", "dog", "man", "woman"]
verbs = ["sang", "ran", "jumped"]
adverbs = ["loudly", "quietly", "well", "badly"]

for _ in [1, 2, 3, 4, 5]:
    article = random.choice(articles)
    subject = random.choice(subjects)
    verb = random.choice(verbs)
    if random.randint(0, 1) == 0:
        print(article, subject, verb)
    else:
        adverb = random.choice(adverbs)
        print(article, subject, verb, adverb)

OR #both processing blocks are correct

for _ in [1, 2, 3, 4, 5]:
    sentense_type = sentence[random.randint(0,1)]
    line = ""
    column = 0
    while column < len(sentense_type):
        line += random.choice(sentense_type[column])
        line += " "
        column += 1
    print(line)




------ATUL---2nd try---Posted GitHub
#!/usr/bin/env python3
#awfulpoetry1_ans.py 
#Loop five times and on each iteration use random.choice() function 
#and random.randint() function to choose sentence structure,
#three sentence structure (article, subject, verb) or  
#four (article, subject, verb and adverb)

import random

articles = ["the", "a", "an", "his", "her", "their"]
subjects = ["cat", "dog", "man", "woman", "boy", "girl", "animal"]
verbs = ["sang", "ran", "jumped", "flew", "ate", "saw", "carried"]
adverbs = ["loudly", "quietly", "well", "badly", "nicely",
            "intensely", "quickly", "slowly", "meanly", "rudely"]

for _ in [1, 2, 3, 4, 5]:
    article = random.choice(articles)
    subject = random.choice(subjects)
    verb = random.choice(verbs)
    adverb = random.choice(adverbs)
    if random.randint(0,1) == 0:
        print(article, subject, verb)
    else:
        print(article, subject, verb, adverb)
-------------


4) awfulpoetry2_ans.py

#To make the awful poetry program more versatile, add some code to it so that if 
#the user enters a number on the command line (between 1 and 10 inclusive), the 
#program will output that many lines. If no command-line argument is given, default 
#to printing five lines as before. Youll need to change the main loop (e.g., to a 
#while loop). Keep in mind that Pythons comparison operators can be chained, so 
#theres no need to use logical and when checking that the argument is inrange. 
#The additional functionality can be done by adding about ten lines of code. 
#A solution is provided as awfulpoetry2_ans.py.

#CODE HERE
awfulpoetry2_ans.py

#BASIC
#!/usr/bin/env python3

import random
import sys

articles = []
subjects = []
verbs = []
adverbs = []

lines = 5
if len(sys.argv) > 1:
    try:
        pass
    except ValueError:
        pass

while lines:
    pass



#DETAIL
#!/usr/bin/env python3

import random
import sys

articles = ["the", "a", "another", "her", "his"]
subjects = ["cat", "dog", "horse", "man", "woman", "boy", "girl"]
verbs = ["sang", "ran", "jumped", "said", "fought", "swam", "laughed",
         "heard", "felt", "slept", "hopped", "crawled", "cried", "walked"]
adverbs = ["loudly", "quietly", "quickly", "slowly", "well", "badly", "rudely"]

lines = 5
if len(sys.argv) > 1:
    try:
        temp = int(sys.argv[1])
        if 1 <= temp <= 10:
            lines = temp
        else:
            print("lines must be 1-10 inclusive")
    except ValueError:
        print("usage: badpoetry.py [lines]")

while lines:
    article = random.choice(articles)
    subject = random.choice(subjects)
    verb = random.choice(verbs)
    if random.randint(0, 1) == 0:
        print(article, subject, verb)
    else:
        adverb = random.choice(adverbs)
        print(article, subject, verb, adverb)
    lines -= 1




------ATUL---2nd try---Posted GitHub
#!/usr/bin/env python3
#awfulpoetry2_ans.py 

import sys
import random

articles = ["the", "a", "an", "his", "her", "their"]
subjects = ["cat", "dog", "man", "woman", "boy", "girl", "animal"]
verbs = ["sang", "ran", "jumped", "flew", "ate", "saw", "carried"]
adverbs = ["loudly", "quietly", "well", "badly", "nicely",
            "intensely", "quickly", "slowly", "meanly", "rudely"]

lines = 5 #default

if len(sys.argv) > 1:
    try:
        temp = int(sys.argv[1])
        if 1 <= temp <= 10:
            lines = temp
        else:
            print("Note: number of lines must be 1-10 inclusive")
    except ValueError:
        print("ValueError usage: badpoetry.py [input lines]")

while lines:
    article = random.choice(articles)
    subject = random.choice(subjects)
    verb = random.choice(verbs)
    adverb = random.choice(adverbs)
    if random.randint(0,1) == 0:
        print(article, subject, verb)
    else:
        print(article, subject, verb, adverb)
    lines -= 1
-------------




5) average2_ans.py 

#calculate median and mean for averages program. Can be done using
list.sort()
#but not yet covered by book so dont use it.
#so sort the list any way you like, (see swapped Boolean) 
#then after sorted list exists, find median value which is middle value if odd number of items
#and is average of two values if even number of items
#calculate median and output it along with rest of info from Exercise 2
#sorting done in 12 lines
#median calculation done in 4 lines

#Text
#It would be nice to be able to calculate the median (middle value) as well 
#as the mean for the averages program in Exercise 2, but to do this we must 
#sort the list. In Python a list can easily be sorted using the list.sort()
#random. rand- int() and random. choice() method, but we havent covered that yet, 
#so we wont use it here. Ex- tend the averages program with a block of code that
#sorts the list of numbersefficiency is of no concern, just use the easiest 
#approach you can think of. Once the list is sorted, the median is the middle 
#value if the list has an odd number of items, or the average of the two 
#middle values if the list has an even number of items. Calculate the median 
#and output that along with the other information.
#This is rather tricky, especially for inexperienced programmers. 
#If you have some Python experience, you might still find it challenging, 
#at least if you keep to the constraint of using only the Python we have 
#covered so far. The sorting can be done in about a dozen lines and 
#the median calculation (where you cant use the modulus operator, since it 
#hasnt been covered yet) in four lines. A solution is provided in average2_ans.py.


#CODE HERE
average2_ans.py 

#!/usr/bin/env python3
#average2_ans.py 

numbers = []
indexes = []
total = 0
lowest = None
highest = None

while True:
    try:
        line = input("enter a number or Enter to finish: ")
        if not line:
            break
        indexes.append(len(numbers))
        number = int(line)
        numbers.append(number)
        total += number 
        if lowest is None or lowest > number:
            lowest = number 
        if highest is None or highest < number:
            highest = number 
    except ValueError as err:
        print(err)

swapped = True
while swapped:
    swapped = False
    for index in indexes:
        if index + 1 == len(numbers):
            break 
        if numbers[index] > numbers[index +1]:
            temp = numbers[index]
            numbers[index] = numbers[index +1]
            numbers[index + 1] = temp
            swapped = True 

if numbers:
    index = int(len(numbers) /2)
    median = numbers[index]
    if index and index * 2 == len(numbers):
        median = (median + number[index-1]) /2

print("numbers:", numbers)
if numbers:
    print("count =", len(numbers), "total =", total,
            "lowest =", lowest, "highest =", highest,
            "mean =", total / len(numbers), "median =", median)









#Reminder of topics<===========
===============================================================================================
CHAPTER: 2 Data Types
CHAPTER BEGIN
===============================================================================================
Identifiers and Keywords
Integral Types 
    Integers
    Booleans
Floating Point Types 
    Floating-Point Numbers 
    Complex Numbers 
    Decimal Numbers
Strings 
    Comparing Strings 
    Slicing and Striding Strings 
    String Operators and Methods 
    String Formatting with str.format Method
    Character Encoding 
Examples 
    quadratic.py 
    csv2html.py 
Summary
Exercises


#CODE LISTING
csv2html.py
csv2html1_ans.py
csv2html2_ans.py
print_unicode.py
print_unicode_ans.py
print_unicode_uni.py
print_unicode_uni_ans.py
quadratic.py
quadratic_ans.py
quadratic_uni.py
quadratic_uni_ans.py 




===============
Identifiers and Keywords 
===============
#object references = identifiers = names = variables
#dont use Keywords
#and as assert break class continue def del elif else except False finally for from
#global if import in is lambda None nonlocal not or pass raise return True try
#while with yield 
#use built-in
dir()
#to return a list of an object's attributes
print(dir())
['__builtins__', '__cached__', '__doc__', '__file__', 
'__loader__', '__name__', '__package__', '__spec__']

print(dir(__builtins__))
#if begin with capital letter then called built-in exceptions
['ArithmeticError', 'AssertionError', 'AttributeError', 
'BaseException', 'BlockingIOError', 'BrokenPipeError', 
'BufferError', 'BytesWarning', 'ChildProcessError', 
'ConnectionAbortedError', 'ConnectionError', 'ConnectionRefusedError', 
'ConnectionResetError', 'DeprecationWarning', 'EOFError', 'Ellipsis', 
'EnvironmentError', 'Exception', 'False', 'FileExistsError', 
'FileNotFoundError', 'FloatingPointError', 'FutureWarning', 
'GeneratorExit', 'IOError', 'ImportError', 'ImportWarning', 
'IndentationError', 'IndexError', 'InterruptedError', 'IsADirectoryError', 
'KeyError', 'KeyboardInterrupt', 'LookupError', 'MemoryError', 
'NameError', 'None', 'NotADirectoryError', 'NotImplemented', 
'NotImplementedError', 'OSError', 'OverflowError', 'PendingDeprecationWarning', 
'PermissionError', 'ProcessLookupError', 'RecursionError', 
'ReferenceError', 'ResourceWarning', 'RuntimeError', 
'RuntimeWarning', 'StopAsyncIteration', 'StopIteration', 
'SyntaxError', 'SyntaxWarning', 'SystemError', 'SystemExit', 
'TabError', 'TimeoutError', 'True', 'TypeError', 
'UnboundLocalError', 'UnicodeDecodeError', 'UnicodeEncodeError', 
'UnicodeError', 'UnicodeTranslateError', 'UnicodeWarning', 
'UserWarning', 'ValueError', 'Warning', 'ZeroDivisionError', 

#all the rest are function and data type names
'__build_class__', '__debug__', '__doc__', '__import__', '__loader__', 
'__name__', '__package__', '__spec__', 'abs', 'all', 'any', 'ascii', 
'bin', 'bool', 'bytearray', 'bytes', 'callable', 'chr', 'classmethod', 
'compile', 'complex', 'copyright', 'credits', 'delattr', 'dict', 
'dir', 'divmod', 'enumerate', 'eval', 'exec', 'exit', 'filter', 
'float', 'format', 'frozenset', 'getattr', 'globals', 'hasattr', 
'hash', 'help', 'hex', 'id', 'input', 'int', 'isinstance', 
'issubclass', 'iter', 'len', 'license', 'list', 'locals', 
'map', 'max', 'memoryview', 'min', 'next', 'object', 
'oct', 'open', 'ord', 'pow', 'print', 'property', 
'quit', 'range', 'repr', 'reversed', 'round', 
'set', 'setattr', 'slice', 'sorted', 'staticmethod', 
'str', 'sum', 'super', 'tuple', 'type', 'vars', 'zip']

#see Chapter 5 for single leading underscores
#dont create double underscore names __example__
#see Chapter 6 for double leading underscores

#holds the result of the last expression then writes over it
for _ in (0,1,2,3,4,5):
    print ("Hello")
    print (_)
#use this when dont care about items being looped over


#Reminder of topics<===========
CHAPTER 2 Data Types

Identifiers and Keywords
Integral Types 
    Integers
    Booleans
Floating Point Types 
    Floating-Point Numbers 
    Complex Numbers 
    Decimal Numbers
Strings 
    Comparing Strings 
    Slicing and Striding Strings 
    String Operators and Methods 
    String Formatting with str.format Method
    Character Encoding 
Examples 
    quadratic.py 
    csv2html.py 
Summary
Exercises

#CODE LISTING
csv2html.py
csv2html1_ans.py
csv2html2_ans.py
print_unicode.py
print_unicode_ans.py
print_unicode_uni.py
print_unicode_uni_ans.py
quadratic.py
quadratic_ans.py
quadratic_uni.py
quadratic_uni_ans.py 




===============
Integral Types --> 2 types exist 
===============

int
bool

Integers
binary numeric operations
augmented binary numeric operations

binary numbers written with a leading 0b
octal numbers with a leading 0o
hexadecimal numbers with a leading 0x

#same
assign a literal to a variable
x = 17
calling the relevant data type as a function
x = int(17)

x = int()
print(x)
>0

x // y --> results in truncting any fraction thus gives integer only
x % y --> results in the modulus = remainder

print(bin(1))
print(hex(1))
print(int(1))
print(oct(1))

Integer Bitwise Operators
i|j 
i^j 
i&j 
i<<j 
i>>j 
-i



#Reminder of topics<===========
CHAPTER 2 Data Types

Identifiers and Keywords
Integral Types 
    Integers
    Booleans
Floating Point Types 
    Floating-Point Numbers 
    Complex Numbers 
    Decimal Numbers
Strings 
    Comparing Strings 
    Slicing and Striding Strings 
    String Operators and Methods 
    String Formatting with str.format Method
    Character Encoding 
Examples 
    quadratic.py 
    csv2html.py 
Summary
Exercises

#CODE LISTING
csv2html.py
csv2html1_ans.py
csv2html2_ans.py
print_unicode.py
print_unicode_ans.py
print_unicode_uni.py
print_unicode_uni_ans.py
quadratic.py
quadratic_ans.py
quadratic_uni.py
quadratic_uni_ans.py 



===============
Floating Point Types
===============

built-in float type 
complex type 
decimal.Decimal type    #for high precision, by default 28 decimal places

Floating Point Numbers
import sys.float_info
help(sys.float_info)

Complex Numbers 
import cmath

Decimal Numbers 
import decimal

math.exp(x) vs x.exp(x)     #first is a float while second is a decimal.Decimal

=========== #RETURNING BACK TO REVIEWING BOOK pg 61
#print("input any number:",msg)
#input(msg)
#print(msg)

msg = input("enter an integer: ")
try:
    i = int(msg)
    print("valid integer entered: ", i)
except ValueError as err:
    print(err)
    print("error = ----> ", err)

x_list = [1,2,3,4,5]
print(x_list)
x_list += [6]
print(x_list)
x_list.append(10)
print(x_list)

print (0.0, 5.4, -2.5, 8.9e-4)
===========


#Reminder of topics<===========
CHAPTER 2 Data Types

Identifiers and Keywords
Integral Types 
    Integers
    Booleans
Floating Point Types 
    Floating-Point Numbers 
    Complex Numbers 
    Decimal Numbers
Strings 
    Comparing Strings 
    Slicing and Striding Strings 
    String Operators and Methods 
    String Formatting with str.format Method
    Character Encoding 
Examples 
    quadratic.py 
    csv2html.py 
Summary
Exercises

#CODE LISTING
csv2html.py
csv2html1_ans.py
csv2html2_ans.py
print_unicode.py
print_unicode_ans.py
print_unicode_uni.py
print_unicode_uni_ans.py
quadratic.py
quadratic_ans.py
quadratic_uni.py
quadratic_uni_ans.py 



===============
Strings 
===============

a = "single quotes work 'here' to show a quote. "
print(a)

import re 

python string escapes vs string literal concatenation
new line escaping

raw strings

ascii() 

===============
    Comparing Strings 
===============

===============
    Slicing and Striding Strings 
===============

Rules
[start:end:step]
[:]     #extracts entire sequence from start to end
[start:]
[:end]

The Waxwork Man example
s = "The waxwork man"
>>> s
'The waxwork man'

s = "The waxwork man"
print("rule s = 'The waxwork man' ")
print(s)
print()

s = s[:12]
print("rule s = 's = s[:12]' ")
print(s)
print()

s = "The waxwork man"
print("rule s = 'The waxwork man' ")
print(s)
print()

s = s[12:] + "wo" + s[12:]
print("rule s = 's = s[12:] + 'wo' + s[12:]' ")
print(s)
print()

s = "The waxwork man"
print("s = 'The waxwork man' ")
print(s)
print()

s = "The waxwork man"
s = s[:12] + "wo" + s[12:]
print("rule s = 's = s[:12] + 'wo' + s[12:]' ")
print(s)
print()

s = "The waxwork man"
print("rule s = 'The waxwork man' ")
print(s)
print()

Sequence Striding 
s = "The waxwork man"
s= s[::-2]
print(s)

s = "The waxwork man"
s1 = s[::-1]
print(s, s1)

>>> s = "The waxwork man"
>>> s1 = s[::-1]
>>> print(s, s1)
The waxwork man nam krowxaw ehT
>>> 

str(join) method

split()
word_example_here.split(',')            #use () when calling functions.



===============
    String Operators and Methods 
===============

membership testing with in
concatenation with +   but better with str(join) method 
appending with +=
replication with *
augmented assignment replication with *=

treaties = ["Arthmetica", "Conics", "Elements"]
print("".join(treaties))
print("-<>-".join(treaties))

String Methods 
                                                        >>> y
                                                        'The waxwork woman'

s.capitalize()              str.title()
                                                        >>> str.title(y)
                                                        'The Waxwork Woman'
s.center(width, char)       str.ljust()   str.rjust()   str.format()
s.count(t, start, end)
s.encode(encoding, err)
s.endwidth(x, start, end)   str.startswith()
s.expands(size)
s.find(t, start, end)       str.rfind()    str.index()
s.format(...)
s.index(t, start, end)
s.isalnum() 
s.isalpha()
s.isdecimal()
s.isdigit()
s.isidentifier()
s.islower()                 str.isupper()
                                                        >>> str.isupper(y)
                                                        False
                                                        >>> y
                                                        'The waxwork woman'
                                                        >>> new_word = str.title(y)
                                                        >>> new_word
                                                        'The Waxwork Woman'
                                                        >>> y
                                                        'The waxwork woman'
                                                        >>> new_word2 = str.upper(y)
                                                        >>> new_word2
                                                        'THE WAXWORK WOMAN'
s.isnumberic()
s.isprintable()
s.isspace() 
s.istitle()                 str.title()
s.isupper()                 str.islower()
s.join(seq)
s.ljust(width, char)        str.rjust()     str.center()    str.format()
s.lower()                   str.upper()
                                                        >>> str.upper(x)
                                                        'THE WAXWORK MAN'
s.maketrans()               str.translate()
s.partition(t)              str.rpartition(t)
s.replace(t, u, n)
s.split(t, n)               str.rsplit()
                                                        >>> s.split(x)
                                                        ['nam krowxaw ehT']
                                                        >>> x
                                                        'The waxwork man'
s.splitlines(f)
s.startswith(x, start, end) str.endswith()
s.strip(chars)              str.lstrip()    str.rstrip()
s.swapcase                  str.lower()     str.upper()
                                                        >>> str.upper(y)
                                                        'THE WAXWORK WOMAN'
                                                        >>> str.lower(y)
                                                        'the waxwork woman'
s.title()                   str.istitle()
s.translate()               str.maketrans()
s.upper()                   str.lower()
                                                        >>> x.upper()
                                                        'THE WAXWORK MAN'
s.zfill(w)                  

str.join(reversed(s))       s[::-1]

s = "=" * 5
print(s)

s = "=" * 15
print(s)


str.index()
str.find()
#both are equal ways to find string inside a string
#extract_from_tag() function explained here
extract_from_tag("red", "what a <red>rose</red> this is")
#code snippet 1
#cleaner code here

def extract_from_tag(tag, line):
    opener = "<" + tag + ">"
    closer = "</" + tag + ">/"
    try:
        i = line.index(opener)
        start = i + len(opener)
        j = line.index(closer, start)
        return line[start:j]
    except ValueError:
        return None 



#code snippit 2
#still valid but not as clean code

def extract_from_tag(tag, line):
    opener = ">" + tag + ">"
    closer = ">" + tag + ">"
    i = line.find(opener)
    if i != -1:
        start = i + len(opener)
        j = line.find(closer, start)
        if j != -1:
            return line[start:j]
    return None


#ATUL PRINTING DOES NOT WORK
x = extract_from_tag("red", "what a <red>rose</red> this is")
print(x)

>>> string1 = "red"
>>> string2 = "what a <red>rose</red> this is")

#all these accept up to two positional arguments: a start position and end position
str.count() 
str.endswith() 
str.find() 
str.rfind() 
str.index() 
str.rindex() 
str.startswith()
#these are equivalence statements (assuming s is a string)
s.count("m", 6) == s[6:].count("m")
s.count("m", 5, -3) == s[5:3].count("m")
#so here, string methods that accept start and end indexes operate on a slice of the string
#as specified by the those indexes

#to clarify behavior of str.partition():
#code snippet 1
result = s.rpartition("/")

#code snippet 2
i = s.rfind("/")
if i == -1:
    result = s, "", ""
else:
    result = s[:i], s[i], s[i+1]

#these snippets are NOT equal as snippet 2 creates a new variable i
#we can assign tuples without formality, and that in both cases we looked for the 
#rightmost occurrence of /
#if s = "/usr/local/bin/firefox"
#then both snippets produce same result     ('usr'/local/bin', '/', 'firefox')

#can str.endswith() (and str.startswith()) with a single string argument
#for example s.startswith("From:") or with a tuple of strings
#here is a statement that uses both str.endswith() and str.lower() to print a filename if
#its a JPEG file
if filename.lower().endswith((".jpg", ".jpeg")):
    print(filename, "is a JPEG image")

#is methods
isalpha() and isspace()
                        >>> "917.5".isdigit(), "".isdigit(), "-2".isdigit(), "203".isdigit()
                        (False, False, False, True)

#when receive strings from external sources, may contain unwanted leading or 
#trailing whitespaces can strip using
str.lstrip()
str.rstrip()
str.strip()

#can give a string as an argument to the strip methods
s = "\t no parking "
print( s.lstrip(), s.rstrip(), s.strip() )
                                        >>> import re
                                        >>> s = "\t no parking"
                                        >>> s
                                        '\t no parking'
                                        >>> str.lstrip(s)
                                        'no parking'

                                        >>> print(s.lstrip(), s.rstrip(), s.strip())
                                        no parking   no parking no parking
t = "<[unbracketed]>"
print ( t.strip("[](){}<>") )
                                        >>> t = "<[unbracketed]>"
                                        >>> print(t.strip("[](){}<>"))
                                        unbracketed
#split string into list of strings
str.split()
record = "Leo Tolstoy*1828-8-28*1910-11-20"
fields = record.split("*")
print(fields)
                                         $ python3 test.py
                                         ['Leo Tolstoy', '1828-8-28', '1910-11-20']
                                         ['1828', '8', '28']
born = fields[1].split("-")       #1 is index value
print(born)

died = fields[2].split("-")
print(died)

print( "lived about", int(died[0]) - int(born[0]), "years" )

                                        #!/usr/bin/env python3
                                        #test.py 
                                        import re

                                        record = "Leo Tolstoy*1828-8-28*1910-11-20"
                                        fields = record.split("*")
                                        print(fields)

                                        name = fields[0].split("-")
                                        print(name)

                                        born = fields[1].split("-")
                                        print(born)

                                        died = fields[2].split("-")
                                        print(died)

                                        $ python3 test.py
                                        ['Leo Tolstoy', '1828-8-28', '1910-11-20']
                                        ['Leo Tolstoy']
                                        ['1828', '8', '28']
                                        ['1910', '11', '20']



ALTERNATIVE --> INTERPRETER then import test allowing work INSIDE INTERPRETER 

                    >>> import test
                    ['Leo Tolstoy', '1828-8-28', '1910-11-20']
                    ['Leo Tolstoy']
                    born ['1828', '8', '28']
                    died ['1910', '11', '20']
                    >>> dir()
                    ['__builtins__', '__doc__', '__loader__', '__name__', '__package__', '__spec__', 'test']
                    >>> test.fields
                    ['Leo Tolstoy', '1828-8-28', '1910-11-20']
                    >>> 
#translate strings
str.maketrans()
str.translate()

#example of translating strings from Bengali digits to Englist digits
table = "".maketrans(
    "\N{bengali digit zero}"
    "\N{bengali digit one}\N{bengali digit two}"
    "\N{bengali digit three}\N{bengali digit four}"
    "\N{bengali digit five}\N{bengali digit six}"
    "\N{bengali digit seven}\N{bengali digit eight}"
    "\N{bengali digit nine}", "0123456789")
print("20749".translate(table))

print(
    "\N{bengali digit two}07\N{bengali digit four}"
    "\N{bengali digit nine}".translate(table))

#other translation libraries to look up
difflib               #to show differences between strings or files
io.StringIO class     #allows to read and write to strings as though they were files
textwrap module 
ascii_letteers
ascii_lowercase

String Formatting with str.format() Methods
"The novel '{0}' was published in {1}".format("Hard Times", 1854)
#{} are replacement field strings with field names default to index position

#using braces inside format strings
"{{{0}}} {1} ;-}}".format("I'm in braces", "I'm not")
                                >>> "{{{0}}} {1} ;-}}".format("I'm in braces", "I'm not")
                                "{I'm in braces} I'm not ;-}"
#concatenate strings and a number
"{0}{1}".format("The amound due is $", 200)

#concatenate strings using str.format()
x = "three"
s = "{0} {1} {2}"
s = s.format("The", x, "tops")
print(s)
                                >>> x = "three"
                                >>> s = "{0} {1} {2}"
                                >>> s = s.format("The", x, "tops")
                                >>> s
                                'The three tops'
#replacement field syntaxes are ok
{field_name}
{field_name!conversion}
{field_name:format_specification}
{field_name!conversion:format_specification}

#next look at each replacement field

Replacement Field Names - using keywords vs positional arguments
"{who} turned {age} this year". format(who='She', age=88)

                    >>> "{who} turned {age} this year".format(who="She", age=88)
                    'She turned 88 this year'

#notice in argument list, keywords always follow positional arguments
"The {who} was {0} last week".format(12, who="boy") 

                    >>> "The {who} was {0} last week".format(12, who="boy")
                    'The boy was 12 last week'

stock = ["paper", "envelopes", "notepads", "pens", "paper clips"]
"We have {0[1]} and {0[2]} in stock".format(stock)

                    >>> "We have {0[1]} and {0[2]} in stock".format(stock)
                    'We have envelopes and notepads in stock'

                    >>> stock
                    ['paper', 'envelopes', 'notepads', 'pens', 'paper clips']
                    >>> cars = ["car1", "car2"]
                    >>> bus = ["bus1", "bus2"]
                    >>> taxi = ["taxi1", "taxi2"]
                    >>> "We have {2[0]} and {3[0]} in stock".format(stock, cars, bus, taxi)
                    'We have bus1 and taxi1 in stock'

Python Dictionaries =store key value items
d = dict(animal="elephant", weight=12000)
"The {0} weighs {0}kg".format(d)
"The {0[animal]} weighs {0[weight]}kg".format(d)
#so here we can access list and tuple items using an integer position index
#and here we access dictionary using a key

                    >>> d = dict(animal="elephant", weight=12000)
                    >>> "The {0[animal]} weighs {0[weight]}kg".format(d)
                    'The elephant weighs 12000kg'

import sys
import math
"math.pi=={0.pi} sys.maxunicode=={1.maxunicode}".format(math, sys)

                    >>> import sys
                    >>> import math
                    >>> "math.pi=={0.pi} sys.maxunicode=={1.maxunicode}".format(math, sys)
                    'math.pi==3.141592653589793 sys.maxunicode==1114111'
                    
#summary
#field name syntax allows us to refer to positional and keyword arguments
#that are passed to str.format() method
#if the arguments are data collection types like lists or dictionaries or have 
#attributes, then we can access THE PART WE WANT by using [] or .notation


Conversions

import decimal
decimal.Decimal("3.4084")
print(decimal.Decimal("3.4084"))

                    >>> import decimal
                    >>> decimal.Decimal("3.4084")
                    Decimal('3.4084')

#python can provide either in representational form (interpreter) or in string form (humans)
"{0} {0!s} {0!r} {0!a}".format(decimal.Decimal("93.4"))

                    >>> "{0} {0!s} {0!r} {0!a}".format(decimal.Decimal("93.4"))
                    "93.4 93.4 Decimal('93.4') Decimal('93.4')"

                    >>> "{0}".format(decimal.Decimal("93.4"))
                    '93.4'
                    >>> type("{0}".format(decimal.Decimal("93.4")))
                    <class 'str'>

                    >>> "{0!s}".format(decimal.Decimal("93.4"))
                    '93.4'
                    >>> type("{0!s}".format(decimal.Decimal("93.4")))
                    <class 'str'>

                    >>> "{0!r}".format(decimal.Decimal("93.4"))
                    "Decimal('93.4')"
                    >>> type("{0!r}".format(decimal.Decimal("93.4")))
                    <class 'str'>

                    >>> "{0!a}".format(decimal.Decimal("93.4"))
                    "Decimal('93.4')"
                    >>> type("{0!a}".format(decimal.Decimal("93.4")))
                    <class 'str'>

#Examples
s = "The sword of truth"
"{0}".format(s)
"{0:25}".format(s)
"{0:>25}".format(s)
"{0:^25}".format(s)
"{0:-^25}".format(s)
"{0:.<25}".format(s)
"{0:.10}".format(s)

                    >>> s = "The sword of truth"
                    >>> "{0}".format(s)
                    'The sword of truth'
                    >>> "{0:25}".format(s)
                    'The sword of truth       '
                    >>> "{0:>25}".format(s)
                    '       The sword of truth'
                    >>> "{0:^25}".format(s)
                    '   The sword of truth    '
                    >>> "{0:-^25}".format(s)
                    '---The sword of truth----'
                    >>> "{0:.^25}".format(s)
                    '...The sword of truth....'
                    >>> "{0:.<25}".format(s)
                    'The sword of truth.......'
                    >>> "{0:.>25}".format(s)
                    '.......The sword of truth'
                    >>> "{0:.10}".format(s)
                    'The sword '

#Nested Specification Fields = allows for computed formats

maxwidth = 12
"{0}".format(s[:maxwidth])          #same results, uses standard string slicing
"{0:.{1}}".format(s, maxwidth)      #same results, uses inner replacement field

                    >>> maxwidth = 12
                    >>> "{0}".format(s[:maxwidth])
                    'The sword of'
                    >>> "{0:.{1}}".format(s, maxwidth)
                    'The sword of'

#Integer Format Specification

#begins with colon, after which we can have optional characters
#next is optional sign character (forces it, positive, negative)
#next is optional minimum width integer
#0-padding allowed in different ways
"".format(8749203)
"{0:0=12}".format(8749203)      padding with 0s
"{0:0=12}".format(-8749203)
"{0:012}".format(8749203)
"{0:012}".format(-8749203)

                    >>> n
                    8749203
                    >>> neg_n
                    -8749203
                    >>> "{0:0=12}".format(n)
                    '000008749203'
                    >>> "{0:0=12}".format(neg_n)
                    '-00008749203'
                    >>> "{0:012}".format(n)
                    '000008749203'
                    >>> "{0:012}".format(neg_n)
                    '-00008749203'

#Alignment Examples
"{0:*<15}".format(8749203)
"{0:*>15}".format(8749203)
"{0:*^15}".format(8749203)
"{0:*^15}".format(-8749203)

                    >>> "{0:0=12}".format(n)
                    '000008749203'
                    >>> "{0:0=12}".format(neg_n)
                    '-00008749203'
                    >>> "{0:012}".format(n)
                    '000008749203'
                    >>> "{0:012}".format(neg_n)
                    '-00008749203'
                    >>> "{0:*<15}".format(n)
                    '8749203********'
                    >>> "{0:*>15}".format(n)
                    '********8749203'
                    >>> "{0:*^15}".format(n)
                    '****8749203****'
                    >>> "{0:*^15}".format(neg_n)
                    '***-8749203****'

#Effects of Sign Characters
"".format()
"[]".format(539802, -539802)
"[{} {}]".format(539802, -539802)
"[{0: } {1: }]".format(539802, -539802)
"[{0:+} {1:+}]".format(539802, -539802)
"[{0:-} {1:-}]".format(539802, -539802)

                    >>> n
                    539802
                    >>> neg_n
                    -539802
                    >>> "[]".format(n, neg_n)
                    '[]'
                    >>> "[{} {}]".format(n, neg_n)
                    '[539802 -539802]'
                    >>> "[{0: } {1: }]".format(n, neg_n)
                    '[ 539802 -539802]'
                    >>> "[{0:+} {1:+}]".format(n, neg_n)
                    '[+539802 -539802]'
                    >>> "[{0:-} {1:-}]".format(n, neg_n)
                    '[539802 -539802]'

#Using Type Characters
"".format()
"{} {} {} {}".format()
"{0:b} {0:o} {0:x} {0:X}".format(14613198)
"{0:#b} {0:#o} {0:#x} {0:#X}".format(14613198)

                    >>> "".format()
                    ''
                    >>> "{} {} {} {}".format()
                    Traceback (most recent call last):
                      File "<stdin>", line 1, in <module>
                    IndexError: tuple index out of range
                    >>> "{0:b} {0:o} {0:x} {0:X}".format(14613198)
                    '110111101111101011001110 67575316 deface DEFACE'
                    >>> "{0:#b} {0:#o} {0:#x} {0:#X}".format(14613198)
                    '0b110111101111101011001110 0o67575316 0xdeface 0XDEFACE'

#must use this as first executable statements
import locale
locale.setlocale(locale.LC_ALL, "")

                    >>> import locale
                    >>> locale.setlocale(locale.LC_ALL, "")
                    'en_US.UTF-8'

x,y = (1234567890, 1234.56)
locale.setlocale(locale.LC_ALL, "C")
c = "{0:n} {1:n}".format(x,y)
c
                    >>> import locale
                    >>> locale.setlocale(locale.LC_ALL, "")
                    'en_US.UTF-8'
                    >>> x, y = (1234567890, 1234.56)
                    >>> locale.setlocale(locale.LC_ALL, "C")
                    'C'
                    >>> c = "{0:n} {1:n}".format(x,y)
                    >>> c
                    '1234567890 1234.56'

locale.setlocale(locale.LC_ALL, "en_US.UTF-8")
en = "{0:n} {1:n}".format(x,y)
en

                    >>> locale.setlocale(locale.LC_ALL, "en_US.UTF-8")
                    'en_US.UTF-8'
                    >>> en = "{0:n} {1:n}".format(x,y)
                    >>> en
                    '1,234,567,890 1,234.56'

locale.setlocale(locale.LC_ALL, "de_US.UTF-8")
de = "{0:n} {1:n}".format(x,y)
de
                    >>> locale.setlocale(locale.LC_ALL, "de_US.UTF-8")
                    Traceback (most recent call last):
                      File "<stdin>", line 1, in <module>
                      File "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/locale.py", line 595, in setlocale
                        return _setlocale(category, locale)
                    locale.Error: unsupported locale setting
                    >>> 

amount = (10 ** 3) * math.pi 
"".format()
"[{}] [{}]".format(amount)
"[{0:12.2e}] [{0:12.2f}]".format(amount)
"[{0:*>12.2e}] [{0:*>12.2f}]".format(amount)
"[{0:*>+12.2e}] [{0:*>+12.2f}]".format(amount)
word = None

                    >>> math.pi
                    3.141592653589793
                    >>> amount = (10 ** 3) * math.pi
                    >>> amount
                    3141.592653589793
                    >>> "".format()
                    ''
                    >>> "[{}] [{}]".format(amount)
                    Traceback (most recent call last):
                      File "<stdin>", line 1, in <module>
                    IndexError: tuple index out of range
                    >>> "[{0:12.2e}] [{0:12.2f}]".format(amount)
                    '[    3.14e+03] [     3141.59]'
                    >>> "[{0:*>12.2e}] [{0:*>12.2f}]".format(amount)
                    '[****3.14e+03] [*****3141.59]'
                    >>> "[{0:*>+12.2e}] [{0:*>+12.2f}]".format(amount)
                    '[***+3.14e+03] [****+3141.59]'

#Formating complex and imaginary parts of a number as individual floating point numbers
#so here access each attribute of the complex number as individual components
"".format()
"{}{}".format(4.75917+1.2042)
"{0.real:.3f}{0.imag:+.3f}j".format(4.75917+1.2042j)
"{0.real:.3f}{0.imag:+.3f}j".format(4.75917-1.2042j)

                    >>> "".format()
                    ''
                    >>> "{}{}".format(4.75917+1.2042)
                    Traceback (most recent call last):
                      File "<stdin>", line 1, in <module>
                    IndexError: tuple index out of range
                    >>> "{0.real:.3f}{0.imag:+.3f}j".format(4.75917+1.2042j)
                    '4.759+1.204j'
                    >>> "{0.real:.3f}{0.imag:+.3f}j".format(4.75917-1.2042j)
                    '4.759-1.204j'

Example: print_unicode.

#just 25 lines executable code, import two modules (sys and unicodedata), defines one
#custom function = print_unicode_table()
#output = if no arguments, program outputs table of every Unicode character

#Prints all chararacters for given input, ie all Z characters.
#default characeter is A is none given.


word = None                                 #assume user gave no CMDL input
if len(sys.argv) > 1:                       #assume CMDL argument is given
    if sys.argv[1] in ("-h", "--help"):       #assume CMDL argument given AND is -h or --help
        print("usage: {0} [string]".format(sys.argv[0]))    #then print useage info AND
        word = 0                                #flag here is RESET to 0 indicating are finished
    else:                                     #otherwise
        word = sys.argv[1].lower()              #set word to lowercase copy of argument
if word != 0:                               #use flag, if flag is not 0 then print table
    print_unicode_table(word)

    #these are equal statements
    print("usage: {0} [string]".format(sys.argv[0])) 
    print("usage: {0[0]} [string]".format(sys.argv))
    #using second code approach, the first 0 is the index position of the argument and
    #[0] is the index WITHIN the argument which only works b/c sys.argv is a LIST

#ATUL this is how I typed it up (to better understand the mechanics)
def print_unicode_table(word):
    print()
    print()

    code = ord(" ")
    end = 

    while code < end:
        c = 
        name = 
        if word is None or word in name.lower():
            print()
        code +=1

#partial code block
def print_unicode_table(word):
    print("".format())
    print("".format())

    code = ord(" ")
    end = sys.maxunicode

    while code < end:
        c = chr(code)
        name = unicodedata.name()
        if word is None or word in name.lower():
            print("".format())
        code +=1

#completed code block
def print_unicode_table(word):
    print("decimal  hex   chr   {0:^40}".format("name"))        #print title line
    print("-------  ---   ---   {0:-<40}".format(""))           #print title line

    code = ord(" ")
    end = sys.maxunicode    #set end variable to the highest Unicode code point available
                            #which matters depending upon whether Python uses UCS-2 or UCS-4
    while code < end:       #UCS-2 or UCS-4 is character encoding
        c = chr(code)       #we get Unicode character that corresponds to code point using chr()
        name = unicodedata.name(c, "*** unknown ***")       #see explained below1
        if word is None or word in name.lower():            #see explained below2
            print("{0:7} {0:5X} {0:^3c} {1}".format(code, name.title()))  #see explained below3
        code +=1

#two different approaches for second print statement
    print("-------  ---   ---   {0:-<40}".format(""))           #original
    print("-------  ---   ---   {0}".format("-" * 40))          #alternative
#alternative = used string replication operator (*) to create suitable string and inserted
#that string into the formatted string
 print("----------------------------------------", string)    #3rd alternative - cumbersome

 #see below1 code block explanation
 #unicodedata.name() returns the Unicode character name for the given c Unicode character
 #and the optional second argument is default "*** unknown ***" if no character name is defined

 #see below2 code block explanation
 #if user did not specify a word (ie word = None), or if they did specify some word and
 #typed it using lowercase, then we print the corresponding row

 #see below3 code block explanation
 #when printing, we pass the code variable to the string format only once BUT it is used three
 #times in the format string code line.
 #first to print the code as a integer with character field width = 7
 #second to print the code as uppercase hexadecimal number in character field width = 5
 #third to print the code using title case

------ATUL---0xx try---Posted GitHub - SHOULD HAVE INCLUDED THIS - NEXT TIME
#Prints all chararacters for given input, ie all Z characters.
#default characeter is A is none given.
------ATUL---1st try---Posted GitHub
#!/usr/bin/env python3
#print_unicode_table.py

import sys
import unicodedata

def print_unicode_table(word):
    print("decimal  hex  chr  {0:^40}".format("name"))
    print("-------  ---  ---  {0:-<40}".format(""))

    code = ord("M")             #prints all letters inclusive, after this
    end = sys.maxunicode

    while code < end:
        c = chr(code)
        name = unicodedata.name(c, "*** unknown ***")
        if word is None or word in name.lower():
            print("{0:7} {0:5X} {0:^3c} {1}".format(code, name.title()))
        code += 1

word = None
if len(sys.argv) > 1:
    if sys.argv[1] in ("-h", "-help"):
        print("usage: {0} [string]".format(sys.argv[0]))
        word = 0
    else:
        word = sys.argv[1].lower()
if word != 0:
    print_unicode_table(word)
------ATUL---1st try---Posted GitHub



Character Encodings Example
#specific character for old software --> one-to-one correspondence
#internationalization meant univerally adopted Unicode encoding
#store 1 character per bit in a 32-bit integer, so its one integer per character
#USC-2 format = 16 bit unsiged integer --> 65535 code points
#USC-4 format = 32 bit integer --> 1114111
#but if passed over network connections, then UTF-8 used --> 
#one byte per character for first 127 code points then
#two or more bytes per character for other code points
#UTF-16 uses two bytes per character and four for some

str.encode()
#returns a byte sequence (see Chap 7)


===============
Examples from within CHAPTER 2
===============
#1 
#first example is math based and 35 lines code
#second example if text processing based and 80 lines of code


quadratic.py
#write program that accepts a,b,c factors from user with b and c allowed to be 0.
#then calculate and output the root(s)

import cmath      #need b/c sq root functions for complex numbers
import math       #need b/c sq root functions for real numbers
import sys        #need b/c sys.float_info.epsilon which compares floating-point numbers with 0

#need a function that can get the floating point number from a user
def get_float(msg, allow_zero):           #second argument says whether 0 is acceptable
    x = None
    while x is None:
        try:
            x = float(input(msg))
            if not allow_zero and abs(x) < sys.float_info.epsilon:
                print("zero is not allowed")
                x = None
        except ValueError as err:
            print(err)
    return x
#this function loops until user enters valid floating point number and
#will accept 0 only if allow_zero is True

#user interaction
print("ax\N{SUPERSCRIPT TWO} + bx + c = 0")
a = get_float("Enter a: ", False)       #user must enter
b = get_float("Enter b: ", True)        #allows for zero
c = get_float("Enter x: ", True)        #allows for zero

x1 = None
x2 = None 
discriminant = (b ** 2) - (4 * a * c)
if discriminant == 0:                  #note1
    x1 = -(b / (2*a) )                   #note2
else:
    if discriminant > 0:
        root = math.sqrt(discriminant)              #NEED import math HERE
    else:     #discriminant < 0
        root = cmath.sqrt(discriminant)             #NEED import cmath HERE
    x1 = (-b + root) / (2*a)
    x2 = (-b - root) / (2*a)
#This code looks a bit different to the formula b/c we being by calculating the discriminat.
#If the discriminant = 0 then we know that we have one real solution so calculate it directly (note2).
#Otherwise, we take the real or complex square root of the discriminat and calculate two roots.

equation = ("{0}x\N{SUPERSCRIPT TWO} + {1}x + {2} = 0" 
             " \N{RIGHTWARDS ARROW} x = {3}").format(a, b, c, x1)
if x2 is not None:
    equation += " or x = {0}".format(x2)
print(equation)


#bash output
Atuls-MBP:python_proginpython3 atulgolhar$ python3 testPython3book.py
ax + b + c = 0
enter a: 3
enter b: 4
enter x: 2
3.0x + 4.0x + 2.0 = 0  x = (-0.6666666
  666666666+0.47140452079103173j) or x = (-0.6666666666666666-0.47140452079103173j)


#ATUL - build this from ground up 

-----------1st EFFORT
#!/usr/bin/env python3
#quadratic.py

import cmath
import math
import sys

def get_float(msg, allow_zero):
    x = None
    while x is None:
        try:
            x = float(input(msg))
        except:
            pass

#print(ax2 + bx + c = 0)

a = get_float("Enter a: ", False)   #user must enter a number
b = get_float("Enter b: ", True)    #allows for zero
c = get_float("Enter c: ", True)    #allows for zero


Atuls-MBP:python_proginpython3 atulgolhar$ python3 test.py
Enter a: 3
Enter b: 4
Enter c: 5
-----------1st EFFORT


-----------2nd EFFORT
Enter a: 0
Enter b: 0
Enter c: 0
Atuls-MBP:python_proginpython3 atulgolhar$ 

Atuls-MBP:python_proginpython3 atulgolhar$ python3 test.py
Enter a: 2
Enter b: 3
Enter c: 4
Atuls-MBP:python_proginpython3 atulgolhar$ python3 test.py
Enter a: 0
zero is not allowed
Enter a: 3
Enter b: 4
Enter c: 
ValueError  could not convert string to float: 
Enter c: 6
Atuls-MBP:python_proginpython3 atulgolhar$ python3 test.py
Enter a: 0
zero is not allowed
Enter a: 1
Enter b: 0
Enter c: 0
Atuls-MBP:python_proginpython3 atulgolhar$ 

#!/usr/bin/env python3
#quadratic.py

import cmath
import math
import sys

def get_float(msg, allow_zero):
    x = None
    while x is None:
        try:
            x = float(input(msg))
            if not allow_zero and abs(x) < sys.float_info.epsilon:
                print("zero is not allowed")
                x = None
        except ValueError as err:
            print("ValueError ", err)

#print(ax2 + bx + c = 0)

a = get_float("Enter a: ", False)   #user must enter a number
b = get_float("Enter b: ", True)    #allows for zero
c = get_float("Enter c: ", True)    #allows for zero

-----------2nd EFFORT

-----------3rd EFFORT
print("ax\N{SUPERSCRIPT TWO} + b + c = 0")
a = get_float("Enter a: ", False)   #user must enter a number
b = get_float("Enter b: ", True)    #allows for zero
c = get_float("Enter c: ", True)    #allows for zero

Atuls-MBP:python_proginpython3 atulgolhar$ python3 test.py
ax + b + c = 0
Enter a: 3
Enter b: 4
Enter c: 5

-----------3rd EFFORT

-----------4th EFFORT - posted on GitHub
#!/usr/bin/env python3
#quadratic.py
#calculates the root(s) of a quadratic equation.

import cmath
import math
import sys


def get_float(msg, allow_zero):
    x = None
    while x is None:
        try:
            x = float(input(msg))
            if not allow_zero and abs(x) < sys.float_info.epsilon:
                print("zero is not allowed")
                x = None
        except ValueError as err:
            print("ValueError,", err)
    return x
    

print("ax\N{SUPERSCRIPT TWO} + bx + c = 0")
a = get_float("Enter a: ", False)   #user must enter a number
b = get_float("Enter b: ", True)    #allows for zero
c = get_float("Enter c: ", True)    #allows for zero


x1 = None
x2 = None
discriminant = (b ** 2) - (4 * a * c)
if discriminant == 0:
    x1 = -(b / (2*a))
else:
    if discriminant > 0:
        root = math.sqrt(discriminant)
    else:
        root = cmath.sqrt(discriminant)
    x1 = (-b + root) / (2*a)
    x2 = (-b - root) / (2*a)

equation = ("{0}x\N{SUPERSCRIPT TWO} + {1}x + {2} = 0"
            "\N{RIGHTWARDS ARROW} x = {3}").format(a, b, c, x1)
if x2 is not None:
    equation += " or x = {0}".format(x2)
print(equation)
-----------4th EFFORT - posted on GitHub


#2
#second example if text processing based and 80 lines of code

csv2html.py
#take data set and present it using HTML
#python has a module to handle CSV but here do all by hand
#each field can be string or number
#output HTML table with text left-aligned and numbers right-aligned
#output one row per record and one cell per field

sample data
"COUNTRY", "2000","2001",2002,2003,2004
"ANTIGUA and BARBUDA",0,0,0,0
"ARGENTINA",37,35,33,36,39
"BAHAMAS, THE",1,1,1,1,1
"BAHRAIN",5,6,6,6,6
#assume same data file called data/co2-sample.csv
#assume command csv2html.py < data/co2-sample.csv > co2-sample.html
#assume HTML 4 transitional with no style sheet

#ATUL - note need to create the item then execute it

import sys

main()    #always LAST statement in the file which triggers initial execution


#so program structure is 
import sys
def main():
def print_start():
def print_line():
def extract_fields():
def escape_html():
def print_end():
main()


def main():
    maxwidth = 100
    print_start()
    count = 0
    while True:
        try:
            line = input()
            if count == 0:
                color = "lightgreen"
            elif count % 2:
                color = "white"
            else:
                color = "lightyellow"
            print_line(line, color, maxwidth)
            count += 1
        except EOFError:
            break
print_end()


def print_start():
    print("<table border='1'>")


def print_end():
    print("</table>")


def print_line(line, color, maxwidth):
    print("<tr bgcolor='{0}'>".format(color))
    fields = extract_fields(line)           #so once we have list of fields as strings
    for field in fields:                    #with no surrounding quotes then can   
        if not field:                       #iterate over creating a table cell for each
            print("<td></td>")  #empty field
        else:
            number = field.replace(",", "")     #quotes removed here
            try:
                x = float(number)
                print("<td align='right'>{0:d}</td>".format(round(x)))
            except ValueError:
                field = field.title()
                field = field.replace(" And ", " and ")
                field = escape_html(field)
                if len(formatfield) <= maxwidth:
                    print("<td>{0}</td>".format(field))
                else:   
                    print("<td>{0:.{1}} ...</td>".format(field, maxwidth))
    print("</tr>")

#notes
#can not use str.split(",") to split lines into fields b/c commas 
#can occur inside quoted strings, so we farmed this out to 
extract_fields() function
#KNOWTHIS so once we have list of fields as strings with no surrounding quotes then can 
#iterate over creating a table cell for each

#to account for potential number with commas, we copy the field with commas removed then
#try to convert the field to a float. 
#if successful conversion, then output right-aligned 
#cell with rounded and outputed as integer.
#if conversion fails, then output the field as string. So here use str.title() to 
#clean up case of letters and replace And with and. 
#Then escape any special HTML characters
#and either print whole field or print first maxwidth characters
#or instead of using inner replacement, we could have used string slicing
print("<td>{0} ...</td>".format(field[:maxwidth]))

def extract_fields(line):
    fields = []
    field = ""
    quoted = None
    for c in line:
        if c in "\"'":
            if quote is None:   #start of quoted string
                quote = c
            elif quote == c:    #end of quoted string
                quote = None
            else:
                field += c
            continue
        if quote is None and c == ",":    #end of a field
            fields.append(field)
            field = ""
        else:
            field += c
        if field:
            fields.append(field)    #adding the last field
        return fields 


#ATUL need to build up the different ways to read quoted single vs double vs no quotes vs commas

def escape_html(text):                  #replaces each special HTML character with appropriate
    text = test.replace("&", "&amp;")     #HTML entity (see Exercises Chap 2 and Chap 7)
    text = test.replace("<", "&lt;")
    text = test.replace(">", "&gt;")
    return text





#CODE HERE
csv2html.py 

-----------1st EFFORT - posted on GitHub
#!/usr/bin/env python3
#csv2html.py 

#take data set and present it using HTML
#assume same data file called data/co2-sample.csv
assume command:
python3 test.py < data/co2-sample.csv > co2-sample.html
or
python3 csv2html.py < co2-sample.csv > co2-sample.html
or
python3 csv2html.py < co2-sample.csv > data/co2-sample199.html
or
language filename.py < ingesting_filename > output_filename
                        location?            location?

#so program structure is 
                          #import sys
                          #def main()
                          #def print_start()
                          #def print_line()
                          #def extract_fields()
                          #def escape_html()
                          #def print_end()
                          #main()
sample data         
"COUNTRY", "2000","2001",2002,2003,2004
"ANTIGUA and BARBUDA",0,0,0,0
"ARGENTINA",37,35,33,36,39
"BAHAMAS, THE",1,1,1,1,1
"BAHRAIN",5,6,6,6,6

import syscs


def main():
    maxwidth = 100
    print_start()
    count = 0
    while True:
        try:
            line = input()
            if count == 0:
                color = "lightgreen"
            elif count % 2:
                color = "white"
            else:
                color = "lightyellow"
            print_line(line, color, maxwidth)
            count += 1
        except EOFError:
            break
print_end()


def print_start():
    print("<table border='1'>")


def print_line(line, color, maxwidth):
    print("<tr bgcolor='{0}'>".format(color))
    fields = extract_fields(line)
    for field in fields:
        if not field:
            print("<td></td>")
        else:
            number = field.replace(",", "")
            try:
                x = float(number)
                print("<td align='right'>{0:d}</td>".format(round(x)))
            except ValueError:
                field = field.title()
                field = field.replace(" And ", " and ")
                field = escape_html(field)
                if len(field) <= maxwidth:
                    print("<td>{0}</td>".format(field))
                else:
                    print("<td>{0:.{1}} ...</td>".format(field, maxwidth))
    print("</tr>")
-----------1st EFFORT - posted on GitHub




#KNOWTHIS - ATUL
#instead of using inner replacement, we could have used string slicing
#print("<td>{0} ...</td>".format(field[:maxwidth]))


def extract_fields(line):
    fields = []
    field = ""
    quoted = None
    for c in line:
        if c in "\"'":
            if quote is None:   #start of quoted string
                quote = c
            elif quote == c:    #end of quoted string
                quote = None
            else:
                field += c
            continue
        if quote is None and c == ",":    #end of a field
            fields.append(field)
            field = ""
        else:
            field += c
        if field:
            fields.append(field)    #adding the last field
    return fields 


def escape_html(text):          #replaces each special HTML character with appropriate
    text = test.replace("&", "&amp;")     #HTML entity (see Exercises Chap 2 and Chap 7)
    text = test.replace("<", "&lt;")
    text = test.replace(">", "&gt;")
    return text


def print_end():
    print("</table>")


main()


#ATUL how to run this?
#take data set and present it using HTML
#assume same data file called data/co2-sample.csv
#assume command test.py < data/co2-sample.csv > co2-sample.html


#create text input file
#debug
#execute main()
#START WITH SMALL PORTION AND BUILDUP FROM THERE

Exericise csv2html.py 

#BASIC
import sys

def main():
    maxwidth = 100
    print_start()
    count = 0
    while True:
        try:
            pass
        except EOFError:
            break
    print_end()

def print_start():
    print()

def print_line(line, color, maxwidth):
    print()
    fields = 
    for field in fields:
        if not field:
            print
        else:
            number = 
            try:
                x = 
                print
            except ValueError:
                field = 
                field = 
                if len(field) xxx:
                    field = 
                else:
                    field = 
                print()
    print()

def extract_fields(line):
    fields = 
    field = 
    quote = 
    for c in line:
        if c in xxx:
            if xxx:
            elif xxx:
                quote = 
            else:
                field += c 
            continue
        if quote is xxx:
            fields.append(field)
            field = 
        else:
            field += c
    if field:
        fields.append(field)
    return fields 

def escape_html(text):
    text = 
    text = 
    text =
    return text 

def print_end():
    print()

main()



#CODE HERE
csv2html.py 

#!/usr/bin/env python3

import sys

def main():
    maxwidth = 100
    print_start()
    count = 0
    while True:
        try:
            line = input()
            if count == 0:
                color = "lightgreen"
            elif count %2:
                color = "white"
            else:
                color = "lightyellow"
            print_line(line, color, maxwidth)
            count += 1
        except EOFError:
            break
    print_end()

def print_start():
    print("<table border='1'>")

def print_line(line, color, maxwidth):
    print("<tr bg color='{0}'>".format(color))
    fields = extract_fields(line)
    for field in fields:
        if not field:
            print("<td></td>")
        else:
            number = field.replace(",", "")
            try:
                x = float(number)
                print("<td align='right'>{0:d}</td>".format(round(x)))
            except ValueError:
                field = field.title()
                field = field.replace(" And ", " and ")
                if len(field) <= maxwidth:
                    field = escape_html(field)
                else:
                    field = "{0} ...".format(escape_html(field[:maxwidth]))
                print("<td>{0}</td>".format(field))
    print("</tr>")

def extract_fields(line):
    fields = []
    field = ""
    quote = None
    for c in line:
        if c in "\"'":
            if quote is None:   #start of quoted string
                quote = c
            elif quote == c:    #end of quoted string
                quote = None
            else:
                field += c      #other quote inside quoted string
            continue
        if quote is None and c == ",":      #end of a field
            fields.append(field)
            field = ""
        else:
            field += c          #accumulating a field
    if field:
        fields.append(field)    #adding the last field
    return fields 

def escape_html(text):
    text = text.replace("&", "&amp;")
    text = text.replace("<", "&lt;")
    text = text.replace(">", "&gt;")
    return text 

def print_end():
    print("</table>")

main()



-----------1st EFFORT - posted on GitHub
#!/usr/bin/env python3
#csv2html.py
#ingest csv data set and present it into HTML table


import sys


def main():
    maxwidth = 100
    print_start()
    count = 0
    while True:
        try:
            line = input()
            if count == 0:
                color = "lightgreen"
            elif count % 2:
                color = "white"
            else:
                color = "lightyellow"
            print_line(line, color, maxwidth)
            count += 1
        except EOFError:
            break
    print_end()


def print_start():
    print("<table border='1'>")


def print_line(line, color, maxwidth):
    print("<tr bgcolor='{0}'>".format(color))
    fields = extract_fields(line)
    for field in fields:
        if not field:
            print("<td></td>")
        else:
            number = field.replace(",", "")
            try:
                x = float(number)
                print("<td align='right'>{0:d}</td>".format(round(x)))
            except ValueError:
                field = field.title()
                field = field.replace(" And ", " and ")
                if len(field) <= maxwidth:
                    field = escape_html(field)
                else:
                    field = "{0} ...".format(escape_html(field[:maxwidth]))
                print("<td>{0}</td>".format(field))
    print("</tr>")


def extract_fields(line):
    fields = []
    field = ""
    quote = None
    for c in line:
        if c in "\"'":
            if quote is None:       #start of quoted string
                quote = c
            elif quote == c:        #end of quoted string
                quote = None
            else:
                field += c          #another quoted inside quoted string
            continue
        if quote is None and c == ",":      #end of a field
            fields.append(field)
            field = ""
        else:
            field += c
        if field:
            fields.append(field)
        return fields


def escape_html(text):
    text = text.replace("&", "&amp;")
    text = text.replace(">", "&lt;")
    text = text.replace("<", "&gt;")
    return text


def print_end():
    print("</table>")


main()
-----------1st EFFORT - posted on GitHub


#Reminder of topics<===========
CHAPTER 2 Data Types

Identifiers and Keywords
Integral Types 
    Integers
    Booleans
Floating Point Types 
    Floating-Point Numbers 
    Complex Numbers 
    Decimal Numbers
Strings 
    Comparing Strings 
    Slicing and Striding Strings 
    String Operators and Methods 
    String Formatting with str.format Method
    Character Encoding 
Examples 
    quadratic.py 
    csv2html.py 
Summary
Exercises

#CODE LISTING
csv2html.py
csv2html1_ans.py
csv2html2_ans.py
print_unicode.py
print_unicode_ans.py
print_unicode_uni.py
print_unicode_uni_ans.py
quadratic.py
quadratic_ans.py
quadratic_uni.py
quadratic_uni_ans.py 



===============
Summary Chapter 2
===============
#when two integers are divided, result is always a float
#if want integer division then use // operator
#math module
#slicing, striding, concatentation (str.join() method), augmented assignment (+= and *=_)
#python string support (RYAN GENE QUESTION)
#str.format() method
#character encoding issues: using UTF-8 as default and default for XML files
str.encode()
bytes.decode() see Chap 7



===============
EXERCISES CHAPTER 2
===============
#1 
#modify print_unicode.py so user can enter several separate words on 
#CMDL and print rows only where unicode character name contains all the 
#words user has specified so can type commands like
print_unicode_ans.py greek symbol
#one way to do this is replace 
word variable with a words list
#need to update the usage information and code itself
#changes add less then 10 lines code and change less than 10 other lines of code

#CODE HERE

#solution
print_unicode_uni_ans.py (windows)
print_unicode_ans.py (apple)

#partial code snippet 
#!/usr/bin/env python3
import sys
import unicodedata

def print_unicode_table(words):
    filename = 
    with open() as file:
        file.write("".format())
        file.write("".format())
words = [] 
if words is not None:
    print_unicode_table(words)


#DETAIL
-----------1st EFFORT - posted on GitHub
#!/usr/bin/env python3
#print_unicode_ans.py           (same name)
#print_unicode_ans_table.py     (same name)

#User enters several separate words on cmd line and prints rows
#only where unicode character names contains all the words that 
#user has specified.


import sys
import unicodedata


def print_unicode_table(words):
    print("decimal   hex   chr  {0:^40}".format("name"))
    print("-------  -----  ---  {0:-<40}".format(""))

    code = ord(" ")
    end = min(0xD800, sys.maxunicode) # Stop at surrogate pairs

    while code < end:
        c = chr(code)
        name = unicodedata.name(c, "*** unknown ***")
        ok = True
        for word in words:
            if word not in name.lower():
                ok = False
                break
        if ok:
            print("{0:7}  {0:5X}  {0:^3c}  {1}".format(code, name.title()))
        code += 1


words = []
if len(sys.argv) > 1:
    if sys.argv[1] in ("-h", "--help"):
        print("usage: {0} [string1 [string2 [... stringN]]]".format(sys.argv[0]))
        words = None
    else:
        for word in sys.argv[1:]:
            words.append(word.lower())
if words is not None:
    print_unicode_table(words)
-----------1st EFFORT - posted on GitHub




Atuls-MBP:python_proginpython3 atulgolhar$ python3 test.py Greek oxia with and small eta
decimal   hex   chr                    name                  
-------  -----  ---  ----------------------------------------
   7972   1F24      Greek Small Letter Eta With Psili And Oxia
   7973   1F25      Greek Small Letter Eta With Dasia And Oxia
   8084   1F94      Greek Small Letter Eta With Psili And Oxia And Ypogegrammeni
   8085   1F95      Greek Small Letter Eta With Dasia And Oxia And Ypogegrammeni
   8132   1FC4      Greek Small Letter Eta With Oxia And Ypogegrammeni




#2 
#modify quadratic.py so that 0.0 factors are not output and so that negative
#factors are output as - n rather than as + -n
#involves replaceing the last 5 lines of code with about 15 lines of code
#solution
quadratic__ans.py


Atuls-MBP:python_proginpython3 atulgolhar$ python3 test.py
ax + bx + c = 0
Enter a: 3
Enter b: 4
Enter c: 5
3.0x + 4.0x + 5.0 = 0 x = (-0.6666666666666666+1.1055415967851332j) or x = (-0.6666666666666666-1.1055415967851332j)


Atuls-MBP:python_proginpython3 atulgolhar$ python3 test.py
ax + bx + c = 0
Enter a: -3
Enter b: -4
Enter c: -5
-3.0x + -4.0x + -5.0 = 0 x = (-0.6666666666666666-1.1055415967851332j) or x = (-0.6666666666666666+1.1055415967851332j)


Atuls-MBP:python_proginpython3 atulgolhar$ python3 test.py
ax + bx + c = 0
Enter a: 0
zero is not allowed
Enter a: 4
Enter b: 5
Enter c: 0
4.0x + 5.0x + 0.0 = 0 x = 0.0 or x = -1.25


#Just need to change these 2 lines into 11 lines:
#OLD
equation = ("{0}x\N{SUPERSCRIPT TWO} + {1}x + {2} = 0"
            "\N{RIGHTWARDS ARROW} x = {3}").format(a, b, c, x1)

#UPDATED
equation = "{0}x\N{SUPERSCRIPT TWO} ".format(a)
if b != 0:
    if b < 0:
        equation += "- {0}x ".format(abs(b))
    else:
        equation += "+ {0}x ".format(b)
if c != 0:
    if c < 0:
        equation += "- {0} ".format(abs(c))
    else:
        equation += "+ {0} ".format(c)





#DETAIL
#!/usr/bin/evn python3
#quadratic__ans.py

import cmath
import math
import sys

def get_float(msg, allow_zero):
    x = None
    while x is None:
        try:
            x = float(input(msg))
            if not allow_zero and abs(x) < sys.float_info.epsilon:
                print("zero is not allowed")
                x = None
        except ValueError as err:
            print(err)
    return x 

print("ax\N{SUPERSCRIPT TWO} + bx + x = 0")
a = get_float("enter a: ", False)
b = get_float("enter b: ", True)
c = get_float("enter c: ", True)

x1 = None 
x2 = None 
discriminant = (b ** 2) - (4 * a * c)
if discriminant == 0:
    x1 = -(b / (2 * a))
else:
    if discriminant > 0:
        root = math.sqrt(discriminant)
    else:   #discriminant < 0
        root = cmath.sqrt(discriminant)
    x1 = (-b + root) / (2 * a)
    x2 = (-b - root) / (2 * a)

equation = "{0}x\N{SUPERSCRIPT TWO} ".format(a)
if b != 0:
    if b < 0:
        equation += "- {0}x ".format(abs(b))
    else:
        equation += "+ {0}x ".format(b)
if c != 0:
    if c < 0:
        equation += "- {0} ".format(abs(c))
    else:
        equation += "+ {0} ".format(c)

equation += "= 0 \N{RIGHTWARDS ARROW} x = {0}".format(x1)
if x2 is not None:
    equation += " or x = {0}".format(x2)
print(equation)




Atuls-MBP:python_proginpython3 atulgolhar$ python3 test.py
Enter a: 0
zero is not allowed
Enter a: 4
Enter b: 5
Enter c: 0
4.0x + 5.0x + 0.0 = 0 x = 0.0 or x = -1.25

Atuls-MBP:python_proginpython3 atulgolhar$ python3 test8.py
ax + bx + x = 0
enter a: 4
enter b: 5
enter c: 0
4.0x + 5.0x = 0  x = 0.0 or x = -1.25



Atuls-MBP:python_proginpython3 atulgolhar$ python3 test.py
ax + bx + c = 0
Enter a: -3
Enter b: -4
Enter c: -5
-3.0x + -4.0x + -5.0 = 0 x = (-0.6666666666666666-1.1055415967851332j) or x = (-0.6666666666666666+1.1055415967851332j)
Atuls-MBP:python_proginpython3 atulgolhar$ python3 test8.py
ax + bx + x = 0
enter a: -3
enter b: -4
enter c: -5
-3.0x - 4.0x - 5.0 = 0  x = (-0.6666666666666666-1.1055415967851332j) or x = (-0.6666666666666666+1.1055415967851332j)



-----------1st EFFORT - posted on GitHub
#!/usr/bin/evn python3
#quadratic__ans.py

import cmath
import math
import sys

def get_float(msg, allow_zero):
    x = None
    while x is None:
        try:
            x = float(input(msg))
            if not allow_zero and abs(x) < sys.float_info.epsilon:
                print("zero is not allowed")
                x = None
        except ValueError as err:
            print(err)
    return x 

print("ax\N{SUPERSCRIPT TWO} + bx + x = 0")
a = get_float("enter a: ", False)
b = get_float("enter b: ", True)
c = get_float("enter c: ", True)

x1 = None 
x2 = None 
discriminant = (b ** 2) - (4 * a * c)
if discriminant == 0:
    x1 = -(b / (2 * a))
else:
    if discriminant > 0:
        root = math.sqrt(discriminant)
    else:   #discriminant < 0
        root = cmath.sqrt(discriminant)
    x1 = (-b + root) / (2 * a)
    x2 = (-b - root) / (2 * a)

equation = "{0}x\N{SUPERSCRIPT TWO} ".format(a)   #eliminates unnecessary sign
if b != 0:
    if b < 0:                                   
        equation += "- {0}x ".format(abs(b))
    else:
        equation += "+ {0}x ".format(b)
if c != 0:
    if c < 0:
        equation += "- {0} ".format(abs(c))
    else:
        equation += "+ {0} ".format(c)
equation += "= 0 \N{RIGHTWARDS ARROW} x = {0}".format(x1)   #elimininates 0.0 format
if x2 is not None:
    equation += " or x = {0}".format(x2)
print(equation)
-----------1st EFFORT - posted on GitHub





#3
#delete the escape_html() function from csv2html.py 
#and use the xml.sax.saxutils.escape() function
#from the xml.sax.saxutils modules instead
#is easy requiring one new line of code (the import statement), five deleted lines of
#code (the unwanted function) and one changed line (to use xml.sax.saxutils.escape()
#instead of escape_html() )
#solution
csv2html1_ans.py

-----------1st EFFORT - posted on GitHub
#!/usr/bin/env python3
#csv2html1_ans.py
#enter any key and prints in xml format upper case value
#use xml.sax.saxutils.escape() instead of escape_html()
#deletes the escape_html() function and add xml.sax.saxutils module


import sys
import xml.sax.saxutils


def main():
    maxwidth = 100
    print_start()
    count = 0
    while True:
        try:
            line = input()
            if count == 0:
                color = "lightgreen"
            elif count % 2:
                color = "white"
            else:
                color = "lightyellow"
            print_line(line, color, maxwidth)
            count += 1
        except EOFError:
            break
    print_end()


def print_start():
    print("<table border='1'>")


def print_line(line, color, maxwidth):
    print("<tr bgcolor='{0}'>".format(color))
    fields = extract_fields(line)
    for field in fields:
        if not field:
            print("<td></td>")
        else:
            number = field.replace(",", "")
            try:
                x = float(number)
                print("<td align='right'>{0:d}</td>".format(round(x)))
            except ValueError:
                field = field.title()
                field = field.replace(" And ", " and ")
                if len(field) <= maxwidth:
                    field = xml.sax.saxutils.escape(field)
                else:
                    field = "{0} ...".format(xml.sax.saxutils.escape(field[:maxwidth]))
                print("<td>{0}</td>".format(field))
    print("</tr>")


def extract_fields(line):
    fields = []
    field = ""
    quote = None
    for c in line:
        if c in "\"'":
            if quote is None:       #start of quoted string
                quote = c
            elif quote == c:        #end of quoted string
                quote = None
            else:
                field += c          #another quoted inside quoted string
            continue
        if quote is None and c == ",":      #end of a field
            fields.append(field)
            field = ""
        else:
            field += c
        if field:
            fields.append(field)
        return fields


def print_end():
    print("</table>")


main()
-----------1st EFFORT - posted on GitHub




Atuls-MBP:python_proginpython3 atulgolhar$ python3 test.py
<table border='1'>
4
<tr bgcolor='lightgreen'>
<td align='right'>4</td>
</tr>
t
<tr bgcolor='white'>
<td>T</td>
</tr>
G
<tr bgcolor='lightyellow'>
<td>G</td>
</tr>
^CTraceback (most recent call last):
  File "test.py", line 92, in <module>
    main()
  File "test.py", line 18, in main
    line = input()
KeyboardInterrupt





#4 modify csv2html.py again but now add new function called 
process_options()
#this function should be called from main() and returns a tuple
#of two values: maxwidth (an int) and format (a str)
#When process_options() is called it should set a default maxwidth of 100, and
#a default format of ".0f" -- 
#this will be used as the format specifier when outputting numbers
#If user types "-h" or "--help" on CMDL then usage message should be output and
#(None, None) returned (so in this case main() should do nothing).
#Othewise the function should read any CMDL arguments that are given and perform
#appropriate assignments. For example, setting maxwidth if "maxwidth=n" is given
#and similarly setting format if "format=s" is given
#Here is a run showing the usage output:

csv2html2_ans.py -h
usage:
csv2html.py [maxwidth=int] [format=str] < infile.csv > outfile.html

maxwidth is an optional integer; if specified, it sets the maximum number of
characters that can be outoput for string fields,
otherwise a default of 100 characters is used.

format is the format to use for numbers; if not specified it defaults
to "0.f".

#and here is a CMDL with both options set:
csv2html2_ans.py maxwidth=20 format=0.2f < mydata.csv > mydata.html

#Dont forget to modify print_line() to make use of the format for outputting
#numbers -- you will need to pass in an extra argument, add one line, and modify
#another line. And this will slightly affect main() too. The process_options()
#function should be about 25 lines including about 9 for the usage message).
#This exercise may prove challenging for INEXERPIENCED programmers.

#Two files of test data are provided:
data/co2-sample.csv #and
data/co2-from-fossilfuels.csv
#solution is provided in
csv2html2_ans.py

#In Chapter 5 will see how to use Python's 
optparse module #to simplify CMDL processing

#KNOWTHIS

#CODE IS HERE
csv2html2_ans.py


-----------1st EFFORT - posted on GitHub
#!/usr/bin/env python3
#csv2html2_ans.py
import sys
import xml.sax.saxutils


def main():
    maxwidth, format = process_options()
    if maxwidth is not None:
        print_start()
        count = 0
        while True:
            try:
                line = input()
                if count == 0:
                    color = "lightgreen"
                elif count % 2:
                    color = "white"
                else:
                    color = "lightyellow"
                print_line(line, color, maxwidth, format)
                count += 1
            except EOFError:
                break
        print_end()


def process_options():
    maxwidth_arg = "maxwidth="
    format_arg = "format="
    maxwidth = 100
    format = ".0f"
    for arg in sys.argv[1:]:
        if arg in ["-h", "--help"]:
            print("""\
usage:
csv2html.py [maxwidth=int] [format=str] < infile.csv > outfile.html                

maxwidth is an optional integer; if specified, it sets the maximum
number of characters that can be output for string fields,
otherwise a default of {0} characters is used.

format is the format to use for numbers; if not specified it
defaults to "{1}".""".format(maxwidth, format))
        elif arg.startswith(maxwidth_arg):
            try:
                maxwidth = int(arg[len(maxwidth_arg):])
            except ValueError:
                pass
        elif arg.startswith(format_arg):
            format = arg[len(format_arg):]
    return maxwidth, format


def print_start():
    print("<table border='1'>")


def print_line(line, color, maxwidth, format):
    print("<tr bgcolor='{0}'>".format(color))
    numberFormat = "<td align='right'>{{0:{0}}}</td>".format(format)
    fields = extract_fields(line)
    for field in fields:
        if not field:
            print("<td></td>")
        else:
            number = field.replace()
            try:
                x = float(number)
                print(numberFormat.format(x))
            except ValueError:
                field = field.title()
                field = field.replace(" And ", " and ")
                if len(field) <= maxwidth:
                    field = xml.saxutils.escape(field)
                else:
                    field = "{0} ...".format(xml.sax.saxutils.escape(field[:maxwidth]))
                print("<td>{0}</td>".format(field))
    print("</tr>")


def extract_fields(line):
    fields = []
    field = ""
    quote = None
    for c in line:
        if c in "\"'":
            if quote is None:
                quote = c 
            elif quote == c:
                quote = None
            else:
                field += c 
            continue 
        if quote is None and c == ",":
            fields.append(field)
            field = ""
        else:
            field += c 
    if field:
        fields.append(field)
    return fields


def print_end():
    print("</table>")


main()
-----------1st EFFORT - posted on GitHub






===============================================================================================
CHAPTER: 3 Collection Data Types
CHAPTER BEGIN
===============================================================================================
#tuples, lists, new collection data types (sets and dictionaries)
#how to use data items from C, C++ structs or Pascal records)
#test file handling in detail --> see Chapter 7

===============
CHAPTER 3 Collection Data Types
Sequence Types
    tuples                                                  Tuples
    Named Tuples
    Lists                                                   Lists 
        List Comprehensions
    Set Types
        Sets                                                New Collection Types
            Set Comprehensions                                  Set Comprehensions
        Frozen Sets                                             Frozen Sets
Mapping Types                                                   Mapping (dictionaries)
    Dictionaries
        Dictionary Comprehensions
    Default Dictionaries 
Iterating and Copying Collections                               Iterables and Copying
    Iterators and Iterable Operation and Functions              Collections
    Copying Collections
Examples 
    generate_usernames.py
    statistics.py 
Summary
Exercises
===============

#CODE LISTING
external_sites.py
external_sites_ans.py
generate_test_names1.py
generate_test_names2.py
generate_usernames.py
generate_usernames_ans.py
grepword.py
statistics.py
uniquewords1.py
uniquewords2.py
uniquewords_ans.py 




===============
Sequence Types
===============

#sequence type suppports membership operator (in), size function (len()), slices ([]), 
#and is iterable
5 types of sequences
bytearray --> see Chapter 7
bytes --> see Chapter 7
list
str --> see Chapter 2
tuple

===============
    Tuples
===============
#use list() conversion to modify a tuple
#tuple() with no arguments returns an emtpy tuple
#to pass tuple 1,2,3 onto a function we write
function((1,2,3))

#tuples have only two methods (same methods available for lists as well)
t.count(x)
t.index(x)

+       concatentation
*       replication
[]      slicing
in      membership testing
not in
+=      augmented assignments (by creating a new tuple)
*=

>> hair = "black", "brown", "blonde", "red"
>>> hair
('black', 'brown', 'blonde', 'red')
>>> hair[2]
'blonde'
>>> hair[-1]
'red'
>>> hair[:2], "gray", hair[2:]
(('black', 'brown'), 'gray', ('blonde', 'red'))
>>> hair
('black', 'brown', 'blonde', 'red')

#TypeErrors here b/c Python thinks trying to concatenate a string and a tuple
#do correctly, need comma AND parentheses
>>> hair[:2] + "gray" + hair[2:]
Traceback (most recent call last):
    File "<pyshell#151>", line 1, in <module>
        hair[:2] + "gray" + hair[2:]
TypeError: can only concatenate tuple (not "str") to tuple 

>>> hair[:2] + ("gray") + hair[2:]
Traceback (most recent call last):
    File "<pyshell#152>", line 1, in <module>
        hair[:2] + ("gray") + hair[2:]
TypeError: can only concatenate tuple (not "str") to tuple

>>> hair[:2], 'gray', hair[2:]
(('black', 'brown'), 'gray', ('blonde', 'red'))

>>> hair[:2] + "gray" + hair[2:]
Traceback (most recent call last):
    File "<pyshell#154>", line 1, in <module>
        hair[:2] + "gray" + hair[2:]
TypeError: can only concatenate tuple (not "str") to tuple

>>> hair[:2] + 'gray' + hair[2:]
Traceback (most recent call last):
    File "<pyshell#155>", line 1, in <module>
        hair[:2] + 'gray' + hair[2:]
TypeError: can only concatenate tuple (not "str") to tuple

>>> hair[:2] + ("gray",) + hair[2:]
('black', 'brown', 'gray', 'blonde', 'red')



>>> hair = ['0hair', '1hair', '2hair', '3hair', '4hair', '5hair', '6hair', '7hair']
>>> hair
['0hair', '1hair', '2hair', '3hair', '4hair', '5hair', '6hair', '7hair']


#use standard formatting for tuples going forward
a, b = (1, 2)

del a,b

del f(x):
    return x, x**2

for x, y in ((1,1),(2,4),(3,9)):
    print(x, y)

#nested tuples
    eyes = ("brown","hazel","amber","green","blue","gray")
>>> colors = (hair, eyes)
>>> eyes
('brown', 'hazel', 'amber', 'green', 'blue', 'gray')
>>> colors
(('black', 'brown', 'blonde', 'red'), ('brown', 'hazel', 'amber', 'green', 'blue', 'gray'))
>>> colors[1]
('brown', 'hazel', 'amber', 'green', 'blue', 'gray')
>>> colors[1][3:-1]
('green', 'blue')

>>> things = (1, -7.5, ("pea", (5,"Xyz"), "queue"))
>>> things
(1, -7.5, ('pea', (5, 'Xyz'), 'queue'))
>>> things[2][1][1][2]
'z'
>>> things[2][1][1][1]
'y'
z
#complex nested data structures --> tuples can hold any data type including collection types
#hold object references to avoid to confusion
#give names to particular references, for example
MANUFACTURER, MODEL, SEATING = (0,1,2)
MINIMUM, MAXIMUM = (0,1)
aircraft = ("Airbus", "A320-200", (100, 220))

MANUFACTURER, MODEL, SEATING = (0,1,2)

>>> MINIMUM, MAXIMUM = (0,1)
>>> aircraft = ("Airbus", "A320-200", (100, 220))
>>> aircraft[SEATING][MAXIMUM]
220
>>> 

for x, y in ((-3,4), (5,12), (28,-45)):
    print(math.hypot(x,y))

5.0
13.0
53.0
                    >>> for x, y in ((4,6), (7,8), (2,5), (23,56)):
                    ...     print(math.hypot(x,y))
                    ... 
                    7.211102550927978
                    10.63014581273465
                    5.385164807134504
                    60.53924347066124
#here we loop over a tupe of 2-tuples, UNPACKING each 2-tuple into variables x and y


#Reminder of topics<===========
CHAPTER 3 Collection Data Types
Sequence Types
    Tuples
    Named Tuples
    Lists
        List Comprehensions
    Set Types
        Sets 
            Set Comprehensions
        Frozen Sets 
Mapping Types 
    Dictionaries
        Dictionary Comprehensions
    Default Dictionaries 
Iterating and Copying Collections
    Iterators and Iterable Operation and Functions
    Copying Collections
Examples 
    generate_usernames.py
    statistics.py 
Summary
Exercises


===============
    Named Tuples
===============
#adds the ability to refer to items in the tuple by name AND by index position
#allows us to create aggregates of data items
#collections module provides namedtuple() function

#use named tuples to create custom tuple data types
import collections      #collections module must be imported
Sale = collections.namedtuple("Sale", "productid customerif date quantity price")
#first argument = Sale = name of the custom tuple   
#second argument is a string of space-separated names with one name for each item)
#function returns a custom class
#can treat Sale just like any other Python class, thus can create objects of type Sale

sales = []
sales.append(Sale())
sales.append(Sale(432, 921, "2008-09-14", 3, 7.99))
sales.append(Sale(419, 874, "2008-09-15", 1, 18.49))
#here we created a list of two Sale items = two custom tuples
#we can refer to items in the tuple using index position.
sales[0][-1]

>>> sales[0][-1]
7.99

total = 0 
for sale in sales:
    total += sale.quantity * sale.price
print("Total ${0:.2f}".format(total))

>>> for sale in sales:
    total += sale.quantity * sale.price
>>> print("Total ${0:.2f}".format(total))
Total $42.46
>>> 
#so note Total Sales = 3 * 7.99 + 1 * 18.49 and looping thru gets total

#doing the Aircraft example with named tuples
Aircraft = collections.namedtuple("Aircraft", "manufacturer model seating")
Seating = collections.namedtuple("Seating", "minimum maximum")
aircraft = Aircraft("Airbus", "A320-200", Seating(100,220))
aircraft.seating.maximum

>>> Aircraft = collections.namedtuple("Aircraft", "manufacturer model seating")
>>> Seating = collections.namedtuple("Seating", "minimum maximum")
>>> aircraft = Aircraft("Airbus", "A320-200", Seating(100,220))
>>> aircraft.seating.maximum
220
#this works and is convenient
#OOP in Chapter 6 will do this even easier by creating custom data types that
#hold data items and that have their own custom methods



#Reminder of topics<===========
CHAPTER 3 Collection Data Types
Sequence Types
    Tuples
    Named Tuples
    Lists
        List Comprehensions
    Set Types
        Sets 
            Set Comprehensions
        Frozen Sets 
Mapping Types 
    Dictionaries
        Dictionary Comprehensions
    Default Dictionaries 
Iterating and Copying Collections
    Iterators and Iterable Operation and Functions
    Copying Collections
Examples 
    generate_usernames.py
    statistics.py 
Summary
Exercises


===============
    Lists
===============
#ordered sequence of zero of more object references
#support slicing, striding
#mutable (unlike immutable tuples)

#list data type can be called as a function list()
#with no arguments returns empty list

#list data type called as a function with no arguments returns empty list
list()

#create an empty list
[]

#list comprehension also creates lists (later in this chapter)

L = [-17.5, "kilo", 49, "V", ["ram", 5, "echo"], 7]
>>> L[0] == L[-6] == -17.5
True
>>> L[0] == L[-6] == 17.5
False

>>> L[1][0]
'k'
>>> L[1][0] == L[-5][0]
True
>>> L[1][0] == L[-5][0]==k
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
NameError: name 'k' is not defined
>>> L[1][0] == L[-5][0]== 'k'
True
>>> 

#Iterable Sequence Unpacking Operator
#*rest --> is called starred expressions
>>> first, *rest = [9,2,-4,8,7]
>>> first
9
>>> rest
[2, -4, 8, 7]
>>> 
>>> first,rest
(9, [2, -4, 8, 7])

>>> first, *mid, last = "Charles Philip Arthur George Windsor".split()
>>> first
'Charles'
>>> mid
['Philip', 'Arthur', 'George']
>>> last
'Windsor'

>>> *directories, executable = "/usr/local/bin/gvim".split("/")
>>> directories
['', 'usr', 'local', 'bin']
>>> executable
'gvim'

>>> L
[-17.5, 'kilo', 49, 'V', ['ram', 5, 'echo'], 7]
>>> L.append("abc")
>>> L
[-17.5, 'kilo', 49, 'V', ['ram', 5, 'echo'], 7, 'abc']
>>> L.append('defg')
>>> L
[-17.5, 'kilo', 49, 'V', ['ram', 5, 'echo'], 7, 'abc', 'defg']
>>> 

L.append(x)
L.count(x)
L.extend(m)
                        >>> m = "hi_there"
                        >>> L.extend(m)
                        >>> L
                        [-17.5, 'kilo', 49, 'V', ['ram', 5, 'echo'], 7, 
                        23, ['', 'usr', 'local', 'bin'], 'h', 'i', '_', 
                        't', 'h', 'e', 'r', 'e']

L.index(x, start, end)
L.insert(i, x)
L.pop()
L.pop(i)
L.remove(x)
L.reverse()

                        >>> L.reverse
                        <built-in method reverse of list object at 0x10180c608>
                        >>> L
                        ['e', 'r', 'e', 'h', 't', '_', 'i', 'h', ['', 'usr', 'local', 'bin'], 23, 7, ['ram', 5, 'echo'], 'V', 49, 'kilo', -17.5]
                        >>> L.reverse()
                        >>> L
                        [-17.5, 'kilo', 49, 'V', ['ram', 5, 'echo'], 7, 23, ['', 'usr', 'local', 'bin'], 'h', 'i', '_', 't', 'h', 'e', 'r', 'e']
                        >>> N
                        [-17.5, 'kilo', 49, 'V', ['ram', 5, 'echo'], 7, 23, ['', 'usr', 'local', 'bin'], 'h', 'i', '_', 't', 'h', 'e', 'r', 'e']


#starred arguments function
def product(a,b,c):
    return a*b*c

launch python3 in Terminal
#automatically launches irb

>>> def product(a,b,c):
...     return a*b*c
... 
>>> product(2,3,5)
30
>>> L = [2,3,6]
                        >>> def product(a,b,c):
                        ...     return a*b*c
                        ... 
                        >>> product(3,4,5)
                        60

#List is Unpacked by * Operator --> called the Sequence Unpacking Operator
#this is being used as a Unary Operator
#also called Unpacking a List
#alternatively can use the * for multiplication as well --> binary operator
>>> product(*L)
36
>>> L = [2,3,4,5]
>>> product(*L)
Traceback (most recent call last):
    File "<stdin>", line 1, in <module>
TypeError: product() takes 3 positional arguments but 4 were given
>>> 

#
>>> product(2, *L[1:])
30

#
>>> product(8, *L[1:])
120
>>> L
[2, 3, 5]
>>> 8*15
120
>>> product(6, *L[1:])
90
>>> 6*3*5
90

#del = deletes the object reference

#Garbage Cleanup and Nondeterminism
>>> x = 8143
>>> x
8143
>>> del x
>>> x
Traceback (most recent call last):
    File "<stdin>", line 1, in <module>
NameError: name 'x' is not defined

                        >>> x = 8143
                        >>> x
                        8143
                        >>> del x
                        >>> x
                        Traceback (most recent call last):
                          File "<stdin>", line 1, in <module>
                        NameError: name 'x' is not defined

#so here Python offers 2 solutions to the Nondeterminism issue
#first is to use 
try ... finally #block to ensure that cleanup is done
#second option is to use
with #statement --> see Chap 8

#to iterate over items in a list
for item in L:
    pass

#this returns an iterator that provides integers
for i in range(len(L)):
    L[i] = process(L[i])

# can use this to increment all the numbers in a list of integers
for i in range(len(numbers)):
    numbers[i] += 1

#lists support slicing to extend the list
woods = ["Cedar", "Yew", "Fir"]

woods += ["Kauri", "Larch"] | woods.extend(["Kauri", "Larch"])

>>> import sys
>>> woods
['Cedar', 'Yew', 'Fir', 'Kauri', 'Larch']
>>> woods += ["Kauri", "Larch"] | woods.extend(["Kauri", "Larch"])
Traceback (most recent call last):
    File "<stdin>", line 1, in <module>
TypeError: unsupported operand type(s) for |: 'list' and 'NoneType'
>>> woods
['Cedar', 'Yew', 'Fir', 'Kauri', 'Larch', 'Kauri', 'Larch']

#also can append a list using 
list.append()
list.insert() #inserted at any index position

#can insert in either of two ways

woods
woods[2:2] = ["Pine"]
woods.insert(2, "Pine")
#or 
woods[2:2] = ["Pine"]
woods.insert(2, "Pine")
#
woods[2:2] = ["Pine"] | woods.insert(2, "Pine")

>>> woods
['Cedar', 'Yew', 'Fir', 'Kauri', 'Larch', 'Kauri', 'Larch']
>>> woods[2:2] = ["Pinesfirst"]
>>> woods
['Cedar', 'Yew', 'Pinesfirst', 'Fir', 'Kauri', 'Larch', 'Kauri', 'Larch']
>>> woods.insert(2, "Pinesecond")
>>> woods
['Cedar', 'Yew', 'Pinesecond', 'Pinesfirst', 'Fir', 'Kauri', 'Larch', 'Kauri', 'Larch']
>>> 

>>> woods
['Cedar', 'Yew', 'Pinesecond', 'Pinesfirst', 'Fir', 'Kauri', 'Larch']
>>> woods[2] = 'RedwoodReplacement'
>>> woods
['Cedar', 'Yew', 'RedwoodReplacement', 'Pinesfirst', 'Fir', 'Kauri', 'Larch']
>>> 

#can remove and replace splices
L = ["A", "B", "C", "D", "E", "F", "G", "H"]
      0    1    2    3    4    5    6    7
                ----------------
>>> L[2:5] = ["X", "Y"]
>>> L
['A', 'B', 'X', 'Y', 'F', 'G', 'H']

#removing items
list.pop()
list.remove()
del woods[4]
woods[2:4] = []
del woods[2:4]

#Striding to remove every nth item              Striding every nth itme in List
x = [1,2,3,4,5,6,7,8,9,10]
#want to set every odd item to 0
x[::2]
>>> x[::2]        #yields subset without chaning original object x
[1, 3, 5, 7, 9]
>>> x
[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
>>> x[1::2]       #give an initial starting index position of 1
[2, 4, 6, 8, 10]
>>> x[1::2] = [0] * len(x[1::2])    #CORRCT  0 times stridded slice portion
# * is replication operator
>>> x
[1, 0, 3, 0, 5, 0, 7, 0, 9, 0]

                        >>> x = [1,2,3,4,5,6,7,8,9]
                        >>> x[::2]
                        [1, 3, 5, 7, 9]
                        >>> x
                        [1, 2, 3, 4, 5, 6, 7, 8, 9]
                        >>> x[1::2]
                        [2, 4, 6, 8]
                        >>> x[2::2]
                        [3, 5, 7, 9]
                        >>> y = x[1::2]
                        >>> z = x[2::2]
                        >>> x
                        [1, 2, 3, 4, 5, 6, 7, 8, 9]
                        >>> x[1::2] = [0] * len(x[1::2])
                        >>> x
                        [1, 0, 3, 0, 5, 0, 7, 0, 9]
>>> x
[1, 0, 3, 0, 5, 0, 7, 0, 9, 0]
>>> x = [1,2,3,4,5,6,7,8,9,10]
>>> x[1::2]
[2, 4, 6, 8, 10]
>>> x[1::3]
[2, 5, 8]
>>> x[1::4]
[2, 6, 10]
>>> x[1::5]
[2, 7]
>>> 
#always read RIGHT TO LEFT to follow logic

>>> y = [1,2,3,4,5,6,7,8,9,10]
>>> y
[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
>>> y[0::1]
[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
>>> y[3::1]
[4, 5, 6, 7, 8, 9, 10]
>>> y
[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
>>> 

#other functions to use
list.sort(x)
list.reverse(x)
>>> x
[10, 9, 8, 7, 6, 5, 4, 3, 2, 1]

>>> woods
['Cedar', 'Yew', 'RedwoodReplacement', 'Pinesfirst', 'Fir', 'Kauri', 'Larch']
>>> woods.sort(key=str.lower)
>>> woods
['Cedar', 'Fir', 'Kauri', 'Larch', 'Pinesfirst', 'RedwoodReplacement', 'Yew']
>>> 
#key argument is used to specify a function applied to each item 
#and that key is used to compare when sorting
list.reverse()
list.sort()
woods.sort(key=str.lower)

                        >>> y
                        [1, 2, 3, 4, 5, 6, 7, 8, 9]
                        >>> list.reverse(y)
                        >>> y
                        [9, 8, 7, 6, 5, 4, 3, 2, 1]
                        
list.append()
list.pop()
list.remove() #worst performance
list.index()  #worst performance using membership testing
#if need to do membership testing then use a set or dict for collection choice



#Reminder of topics<===========
CHAPTER 3 Collection Data Types
Sequence Types
    Tuples
    Named Tuples
    Lists
        List Comprehensions
    Set Types
        Sets 
            Set Comprehensions
        Frozen Sets 
Mapping Types 
    Dictionaries
        Dictionary Comprehensions
    Default Dictionaries 
Iterating and Copying Collections
    Iterators and Iterable Operation and Functions
    Copying Collections
Examples 
    generate_usernames.py
    statistics.py 
Summary
Exercises


===============
        List Comprehensions
===============
#for small lists, use list literals
#for large lists, use list comprehensions
#List Comprehension = expression with a loop and optional conditions
#allows to filter out unwanted items

#for lists of integers
list(range(n))  #or
range()

#for longer lists
leaps = []
for year in range():
    if () or ():
        leaps.append(year)

                        >> leaps = []
                        >>> for year in range(2000, 2011):
                        ...     if (year %2 ==0):
                        ...     
                            
                        ...             leaps.append(year)
                        ... 
                        >>> leaps
                        [2000, 2002, 2004, 2006, 2008, 2010]

leaps = []
for year in range(1900, 1940):
    if (year % 4 == 0 and year % 100 != 0) or (year % 100 == 0):
        leaps.append(year)
#range() is given two inputs, n and m, the iterator produced is n, n+1, m-1
#exact range is easy to determine 
leaps = [1904, 1908, 1912, 1916, 1920, 1924 1928, 1932, 1936]

                        >>> leaps = []
                        >>> for year in range(1900, 1930):
                        ...     if (year %4 == 0):
                        ...             leaps.append(year)
                        ... 
                        >>> leaps
                        [1900, 1904, 1908, 1912, 1916, 1920, 1924, 1928]
                        >>> leaps = []
                        >>> for year in range(1900, 1930):
                        ...     if (year %4 == 0 and year %100 != 0):
                        ...             leaps.append(year)
                        ...             
                        >>> leaps
                        [1904, 1908, 1912, 1916, 1920, 1924, 1928]

#simplest form of List Comprehension
[item for item in iterable]
#powerful use of list comprehension is using expressions with a condition
[expression for item in iterable]
[expression for item in iterable if condition]

#note second syntax is equal to
temp = []
for item in iterable:
    if condition:
        temp.append(expression)

#now refactor code
#1st stage --> generate list that has all years in given range
leaps = [y for y in range()]
leaps = [y for y in range(1900, 1940)]
#could also be done using
leaps = list(range(1900, 1940))

#2nd stage refactor --> add simple condition
leaps = [y for y in range(1900, 1940) if ]
leaps = [y for y in range(1900, 1940) if y % 4 == 0]

#3rd stage refactor --> complete version
leaps = [y for y in range(1900, 1940) 
          if () ]
leaps = [y for y in range(1900, 1940) 
          if ( () and () or () )]
leaps = [y for y in range(1900, 1940) 
          if (y % 4 == 0 and y % 100 != 0) or (y % 100 == 0)]

#so original code --> 4 lines
leaps = []
for year in range(1900, 1940):
    if (year % 4 == 0 and year % 100 != 0) or (year % 100 == 0):
        leaps.append(year)

#list comprehension --> 2 lines
leaps = [y for y in range(1900, 1940) 
          if (y % 4 == 0 and y % 100 != 0) or (y % 100 == 0)]

#nested list comprehensions is same as having nested for...in loops

#for example
#generate all possible clothing label codes for given sets of 
#sexes, sizes, and colors, but exclude labels for full-figured women
#as fashion industry routinely ignores.
#use nested for...in loops

codes = []
for sex in "MF":
    for size in "SMLX":
        if sex and size:
            continue
        for color in "BGW":
            codes.append(sex+size+color)

#complete code
codes = []
for sex in "MF":
    for size in "SMLX":
        if sex == "F" and size == "X":  #skipping logic here (middle loop)
            continue                      #skipping logic here (middle loop)
        for color in "BGW":
            codes.append(sex+size+color)
print(codes)

>>>['MSB', 'MSG', 'MSW', 'MMB', 'MMG', 'MMW', 
'MLB', 'MLG', 'MLW', 'MXB', 'MXG', 'MXW', 
'FSB', 'FSG', 'FSW', 'FMB', 'FMG', 'FMW', 
'FLB', 'FLG', 'FLW']
#produces 21 item list

#refactor using List Comprehension
codes = []

codes = [s+z+c for s in xxx for z in yyy for c in zzz
        if not ()]

codes = [s+z+c for s in xxx for z in yyy for c in zzz
        if not ()]
 
#NOTE
#simplest form of List Comprehension
[item for item in iterable]
#powerful use of list comprehension is using expressions with a condition
[expression for item in iterable if condition]

#therefore
codes = [s+z+c for s in "MF" for z in "SMLX" for c in "BGW"
        if not (s == "F" and z == "X")]
print(codes)
#explained --> each item in list is produced by the expression
#logic is different now, as skip invalid sex/size combinations in innermost loop
#in for...in loop, skipping logic sits in middle loop
#so any List Comprehension can be refactored using one or more for...in loops

irb
codes = [s+z+c for s for z for c if not ()]
codes = [s+z+c for s in xxx for z in xxx for c in xxx if not ()]
codes = [s+z+c for s in "MF" for z in "SMLX" for c in "BWG" if not (s=="F" and z=="X")]

#if list is very large, use a Generator (not a List Comprehension --> see Chapter 8)


#Reminder of topics<===========
CHAPTER 3 Collection Data Types
Sequence Types
    Tuples
    Named Tuples
    Lists
        List Comprehensions
    Set Types
        Sets 
            Set Comprehensions
        Frozen Sets 
Mapping Types 
    Dictionaries
        Dictionary Comprehensions
    Default Dictionaries 
Iterating and Copying Collections
    Iterators and Iterable Operation and Functions
    Copying Collections
Examples 
    generate_usernames.py
    statistics.py 
Summary
Exercises


===============
    Set Types
===============
#collection data type that supports membership operator (in), size fucntion (len()),
#and is iterable.
set.isdisjoint() #method and support for comparision and bitwise operations (unions, etc)
set #mutable
frozenset #immutable

#when iterated, items are provided in arbitrary order
#only a hashable object can be added to a set
hashable objects --> __hash__() #special method whose return value is always the same
#useful when comparing for equality using 
__eq__() #special method
#Special Methods --> use TWO UNDERSCORES --> see Chapter 6

#builtin immutable data types are
float, frozenset, int, str, tuple

#builtin mutable data types are NOT hashable b/c their hash value changes depending
#upon the items they contain therefore they can NOT be added to sets
dict, list, set

#set types compared using
< <= == != >= > 




#Reminder of topics<===========
CHAPTER 3 Collection Data Types
Sequence Types
    Tuples
    Named Tuples
    Lists
        List Comprehensions
    Set Types
        Sets 
            Set Comprehensions
        Frozen Sets 
Mapping Types 
    Dictionaries
        Dictionary Comprehensions
    Default Dictionaries 
Iterating and Copying Collections
    Iterators and Iterable Operation and Functions
    Copying Collections
Examples 
    generate_usernames.py
    statistics.py 
Summary
Exercises


===============
        Sets 
===============
#unordered collection of object references that refer to hashable objects
#sets are mutable
#sets are unordered so no index position (so no slicing or striding)
#set created
S = {}
                        >>> S
                        {}
                        >>> type(S)
                        <class 'dict'>

S = {7, "veil", 0, -29, (), "", frozenset ({}), 913}
                        >>> S ={7, "veil", 0, -29, (), "", frozenset({}), 913}
                        >>> S
                        {'', 0, -29, 7, frozenset(), 'veil', 913, ()}
#calling a set
set()
#if no arguments supplied then it returns an empty set
#does not accept more than one argument
#can create a set using Set Comprehension
#sets are often used to eliminate duplicate items

#if x is a list of strings, then all of x's strings will be unique and in arbitrary order
x = list(set(x)) 
#will eliminate duplicates plus
#sets support len() function, and fast membership testing using in and not in
union |
intersection &
difference - 
symmetric difference ^

#Fast Membership Testing
#example give users a usage message if they dont enter any command
#line arguments, or if they enter an argument of "-h" or "--help"
if len(sys.argv) == 1 or sys.argv[1] in {"-h", "--help"}:
    pass

#also common use case for sets is to ensure dont process duplicate data
#example
#have an iterable (ie list) containing the IP address from web server's log
#and wanted to process each unique address
#assume IP addresses are hashable and are in iterable ips
#assume function we want called for each one is called 
process_ip()
#and is already defined, then both code snippets will do this but with
#subtly different behavior
#1st code snippet
seen = set()
for ip in ips:
    if ip not in seen:
        seen.add(ip)
        process_ip(ip)

#vs 2nd code snippets
for ip in set(ips):
    process_ip(ip)

#for 1st code snippet
#if not previously processed IP address before, then process it, otherwise ignore
#for 2nd code snippet
#we only process each unqiue IP address that we have seen ALREADY
#differences
#difference #1: 1st creates seen set() while 2nd does not need seen set()
#difference #2: snippet 1 processes IP address in the order they are encountered
#in ips iterable while snippet 2 processes IP addresses in arbitrary order
#2nd snippet is easier to code but if ordering matters then we must either
#use snippet 1 or change snippet 2 to something like this
for ip in sorted(set(ips)):
    pass
#snippet 2 might be slower if number of items in ips is very large b/c it
#creates the set in one go (as opposed to snippet 1 creating the set incrementally)

>>> pecan = []
>>> pie = []
>>> pecan =["p","e","c","a","n"]
                        >>> pecan.extend("pecan")
                        >>> pecan
                        ['p', 'e', 'c', 'a', 'n']

>>> pie = ["p","i","e"]
                        >>> pie = []
                        >>> pie.extend(pie)
                        >>> pie
                        []
                        >>> pie.extend("pie")
                        >>> pie
                        ['p', 'i', 'e']

>>> set(pecan) | set(pie)         #Union
{'a', 'n', 'c', 'i', 'p', 'e'}
>>> set(pecan) & set(pie)         #Intersection
{'p', 'e'}
>>> set(pecan) - set(pie)         #Difference
{'n', 'a', 'c'}
>>> set(pecan) ^ set(pie)         #Symmetric Difference
{'c', 'n', 'a', 'i'}

                        >> set(pecan) | set(pie)
                        {'n', 'i', 'e', 'a', 'c', 'p'}
                        >>> set(pecan) & set(pie)
                        {'p', 'e'}
                        >>> set(pecan) - set(pie)
                        {'a', 'n', 'c'}
                        >>> set(pecan) ^ set(pie)
                        {'n', 'i', 'a', 'c'}

Set Methods and Operators
s.add(x)                              #add x to set s if not already in s

s.clear()                             #removes all items from set s

s.copy()                              #return SHALLOW copy from set s

s.difference(t)                       #returns new set 
s - t 

s.difference_update(t)                #removes every item in original set s
s -= t 

s.discard(x)                          #removes x from s
set.remove()                          #see also this

s.intersection(t)                     #returns new set
s & t 

s.intersection_update(t)              #adds every item to original set s
s &= t 

s.isdisjoint(t)                       #returns True if sets s and t have no items in commmon

s.issubset(t)                         #returns True if set s is equal to or subset of set t
s <= t 

s.issuperset(t)                       #
s >= t 

s.pop(t)                              #raises KeyError exception if set s is empty

s.remove(t)                           #raises KeyError exception if item is not in set s
set.discard                           #see also this

s.symmetric_difference(t)             #returns new set
s ^ t 

s.symmetric_difference_update(t)      #returns original set s with new parameters
s ^= t 

s.union(t)                            #returns new set
s | t 

s.update(t)                           #
s |= t 

#sets used to eliminate unwanted items
#example if we have a list of filenames but dont want any makefiles included
filenames = set(filenames)
for makefile in {"", "", ""}:
    filenames.discard(makefile)

filenames = set(filenames)
for makefile in {"MAKEFILE", "Makefile", "makefile"}:
    filenames.discard(makefile)
#this will remove any makefile that is in the list

#do same with 1 line of code
filenames = set() - {}

filenames = set(filenames) - {"MAKEFILE", "Makefile", "makefile"}
#we can also use set.remove() to remove items BUT this will raise 
#KeyError exception if the item it is asked to remove is not in the set



#Reminder of topics<===========
CHAPTER 3 Collection Data Types
Sequence Types
    Tuples
    Named Tuples
    Lists
        List Comprehensions
    Set Types
        Sets 
            Set Comprehensions
        Frozen Sets 
Mapping Types 
    Dictionaries
        Dictionary Comprehensions
    Default Dictionaries 
Iterating and Copying Collections
    Iterators and Iterable Operation and Functions
    Copying Collections
Examples 
    generate_usernames.py
    statistics.py 
Summary
Exercises


===============
            Set Comprehensions
===============
#create sets by calling set() or by using a set literal or by creating set comprehnsions
#set comprehension = an expression and a loop with optional condition enclosed in braces

{expression for item in iterable}
{expression for item in iterable if condition}

#use these to achieve the filtering effect as long as ORDER DOES NOT MATTER
#example
html = {}

html = {x for x in files if xxx}

html = {x for x in files if x.lower().endswith((".htm",".html"))}



===============
        Frozen Sets 
===============

#once created then can NOT be changed (immutable), but can rebind the variable
frozenset()

set methods are:
frozenset.copy()
frozenset.difference()
frozenset.intersection()
frozenset.isdisjoint()
frozenset.issubset()
frozenset.issuperset()
frozenset.union()
frozenset.symmetric_difference()

#if f is frozenset and s is set --> data type is driven by LEFT hand operand's data type
f & s --> a frozenset
s & f --> a set


#Reminder of topics<===========
CHAPTER 3 Collection Data Types
Sequence Types
    Tuples
    Named Tuples
    Lists
        List Comprehensions
    Set Types
        Sets 
            Set Comprehensions
        Frozen Sets 
Mapping Types 
    Dictionaries
        Dictionary Comprehensions
    Default Dictionaries 
Iterating and Copying Collections
    Iterators and Iterable Operation and Functions
    Copying Collections
Examples 
    generate_usernames.py
    statistics.py 
Summary
Exercises


===============
Mapping Types 
===============

#supports the membership operator (in), the size function (len()), and is iterable
#mappings are collections of key-value items
#when iterated, mapping types provide items in arbitrary order
#two mapping types allowed
dict()                        #built-in type
collections.defaultdict()     #standard library's type

#what can be allowed as keys? only hashable types so immutable types ok
float, frozenset, int, str, tuple
#so mutable types NOT allowed
dict, list, set 

#what can be values? anything

#standard comparison operators are allowed
< <= == != >= >
#but only meaningful comparision operators are
== !=



#Reminder of topics<===========
CHAPTER 3 Collection Data Types
Sequence Types
    Tuples
    Named Tuples
    Lists
        List Comprehensions
    Set Types
        Sets 
            Set Comprehensions
        Frozen Sets 
Mapping Types 
    Dictionaries
        Dictionary Comprehensions
    Default Dictionaries 
Iterating and Copying Collections
    Iterators and Iterable Operation and Functions
    Copying Collections
Examples 
    generate_usernames.py
    statistics.py 
Summary
Exercises


===============
    Dictionaries = collection of unordered key, value pairs
===============

#unordered collection of key-value pairs wherein the keys are object-references
#to hashable objects
dict()        #dict data type called as a function

#all these produce the same dictionary                  CREATED using..
d1 = dict({"key": value, "key": value})                 #dictionary literal
d1 = dict({"id": 1948, "name": "Washer", "size": 3})

d2 =dict(key=value, key=value, key=value)               #keyword arguments
d2 =dict(id=1948, name="Washer", size=3)

d3 = dict([(), (), ()])                                 #from sequences
d3 = dict([(key,value), (key,value), (key,value)])
d3 = dict([("id",1948), ("name", "Washer"), ("size",3)])

d4 = dict(zip((),()))                                   #from zip sequences
d4 = dict(zip(("id", "name", "size"),(1948, "Washer", 3)))

d5 = {}                                                 #from dictionary literal
d5 = {key:value, key:value, key:value}
d5 = {"id":1948, "name":"Washer", "size":3}

#d1 created using dictionary literal
#d2 created using keyword arguments --> most compact and convenient
#d3 d3 created from sequences
#d3 d4 created from sequences using zip() function returns list of tuples
#d5 created from dictionary literal

d = {"root": 18, "blue": [75, "R", 2], 21: "venus", -14: None, "mars": "rover", (4,11): 18, 0: 45}

d["value"] #--> used to access invdividual values or add/delete items
>>> d["root"]
18

#to add use
=
#to delete use
del

>>> d["X"] = 59     #to add
>>> del d["mars"]   #to delete, works or will raise KeyError exception if no item
>>> d
{(4, 11): 18, 'blue': [75, 'R', 2], -14: None, 'X': 59, 21: 'venus', 0: 45, 'root': 18}
>>> 

dict.pop() method    #also to remove and return an item

#support membership testing
in
not in

===============
Dictionary Methods
===============

d.clear()             #removes all items from dict d
d.copy()              #returns shallow copy of dict d
d.fromkeys(s, v)      #returns dict whose keys are items in seqence s
d.get(k)              #returns k's associated value or None if k is not in dict d
d.get(k, v)           #returns k's associated value or v if k is not in dict d
d.items()             #returns a view of all the key,value paris in dict d
d.keys()              #returns a view of all the keys in dict d
d.pop(k)              #returns key's associated value and removes it or raises KeyError
d.pop(k, v)           #returns key's associated value and removes it or returns v if not there
d.popitem()           #returns and removes arbitrary (key,value) pair or raises KeyError
d.setdefault(k ,v)    #changes associated value, but if not in D, then new item is inserted
d.update(a)           #adds every (key, value) pair from a
d.values()            #returns a iew of all the values in dict d

#to iterate overy keys to and to change the value using brackets operator
#example increment every value in dict d assuming all values are numbers
for key in d:
  d[key] += 1

#all these return dictionary views --> read-only iterable object
dict.items()
dict.keys()
dict.values()

#how is iterable different from a view?
#1st difference = if the dict the view refers to is changed, then the view reflects that change
#2nd difference= key and item view support some set-like operations
v & x     #intersection
v | x     #union
v - x     #differencee
v ^ x     #symmetric difference

#use membership operator to see whether particular key is in a dictionary
x in d
#use union operator to see which keys from a given set are in a dictionary
d = {}.fromkeys("ABCD", 3)
>>> d
{(4, 11): 18, 'blue': [75, 'R', 2], -14: None, 21: 'venus', 0: 45, 'mars': 'rover', 'root': 18}
>>> e=d 
>>> e = {}.fromkeys("ABCD",3 )
>>> e
{'C': 3, 'D': 3, 'B': 3, 'A': 3}

#using membership operator to union match particular keys in e with keys in another dict s
>>> e = {}.fromkeys("ABCD",3 )
>>> s = set("ACX")
>>> matches = e.keys() & s
>>> matches
{'C', 'A'}
>>> 

#dictionaries used to keep count of unique items
#example counting occurences of each unique word in a file
uniquewords1.py 
#lists every word and counts its occurrences

import string
import sys

words = {}
strip = string.whitespace + string.punctuation + string.digits + "\" ' "
for filename in sys.argv[1:]:               #1
    for line in open(filename):             #2
        for word in line.lower().split():   #3
            word = word.strip(strip)        #4
            if len(word) > 2:               #5
                words[word] = words.get(word,0) + 1
for word in sorted(words):
    print (" '{0}' occurs {1} times".format(word, words[word]))

#begin by creating empty dictionary called words
#then we create a string that contains the characters we want to ignore.
#how? by concatenating some useful strings provided by string module.
#1st iterate over each filename given on the command line AND
#2nd iterate over each line in each file
#See GRAY BOX for side note "Reading and Writing Text Files" for an
#explanation of the open() function.

#Note that we did not specify encoding b/c we dont know WHAT the encoding is, so
#we let python open each file using default local encoding
#3we split each lower case line into words then
#4strip off the characters we want to ignore from both ends of each word
ATUL - test point 5
#5if resultant word is at least three characters long then add it to dictionary
#note we can NOT use the syntax of 
words[word] += 1 #why?
#b/c this will raise a KeyError exception the first time a new word is encountered
#ie we can not increment the value of an item that does not yet exist in our dict
#so use subtler approach: how? by calling dict.get() with a default value of 0
#so now if the word is already in the dict then dict.get() will return the
#associated number and this value gets added by 1 as the item's new value
#if the word is not in the dict, then dict.get() will supply the default value of 0
#and this 0 plus 1 will be the new value of a new item whose key is the string held 
#by the word 
#to clarify this point, look at two code snippets
#1st code snippet --> more efficient
words[word] = words.get(word,0) + 1
#2nd code snippet --> less efficient but still works
if word not in words:       # ,0 action is what is compared
    words[word] = 0         # 0 value is what is done
words[word] += 1            # +1 all on same line

#back to main explanation

#Once we have accumulated the dictionary of words, we iterate over its keys in
#sorted order, and print each word and the number of times it occurs.

#Using dict.get() allows us to easily update dictionary values, providing that
#the values are single items like numbers of strings.

#But what if each value is itself a collection? (longer explanation) 

#alternative solution is in next subsection --> default dictionaries


#uniquewords1.py - yes alaphabetical (order), yes freq using basic dictionary
#uniquewords2.py - yes alaphabetical, yes freq using DEFAULT dictionary
#uniquewords_ans.py - no alaphabetical, yes orders freq

-----------1st EFFORT - posted on GitHub
#!/usr/bin/env python
#uniquewords1.py

import string
import sys

words = {}
strip = string.whitespace + string.punctuation + string.digits + "\"'"

for filename in sys.argv[1:]:
    for line in open(filename):         #SEE GRAY BOX FOR EXPLANATION
        for word in line.lower().split():
            word = word.strip(strip)
            if len(word) > 2:
                words[word] = words.get(word,0) + 1
for word in sorted(words):
    print("'{0}' occurs {1} times".format(word, words[word]))
-----------1st EFFORT - posted on GitHub


#***GRAY BOX***BEGIN
#now to explain OPEN

Reading and Writing Text Files 
#files are opened using built-in 
open() function
#which returns a "file object" of type io.TextIOWrapper for text files
#the open() function takes one mandatory argument --> the filename
#which may include a path
#and up to six optional arguments, two of which we cover here
#the second argument taken is the mode
#mode is used to specify whether the file is to be treated as a text file or a binary file
#and whether the file is to be opened for reading, writing, appending, or a
#combination of these.
#For text files, python uses an encoding that is platform-dependent. So where possible
#it is best to specify the encoding using open()'s encoding argument
#so the syntaxes we normally use for opening files are:
fin = open(filename, encoding="utf-8")        #for reading text
fout = open(filename, "w", encoding="utf-8")  #for writing text
#b/c open()'s mode defaults to "read text", and by using a keyword rather than a 
#positional argument for the encoding argument, we can omit the other optional
#positional arguments when opening for reading.
#And similarly, when opening to write we need to give only the arguments we actually want
#to use. Argument passing is covered in Chapter 4.
#Once a file is opened for reading in text mode, we can read the whole file into a single
#string using the file object's read() method, or into a list of strings using the file
#object's readlines() method. A very common idiom for reading line by line is to treat
#the file object as an iterator:
for line in open(filename, encoding="utf-8"):
    process(line)
#This works b/c a file object can be iterated over, just a like a seqeuence,
#with each successive item being a string containing the next line from the file.
#The lines we get back include the line termination character \n
#If we specify a mode of "w" then the file is opened in "write text" mode.
#We write to a file using the file object's write() method, which takes a single 
#string as its argument. Each line written should end with a \n
#Python automatically translates between \n and the underlying platform's line
#termination characters when reading and writing.
#Once we have finished using a file object, we can call its close() method.
#This will cause any outstanding writes to be flushed.
#In small Python programs it is very common NOT to bother calling close() since
#Python does this automatically when the file object goes out of scope. If a
#problem does arise, it will be indicated by an exception being raised.
#***GRAY BOX***END

#but what if each value is itself a collection? (longer explanation) SEE BELOW
#to demonstrate how to handle this, we look at a program that reads HTML files 
#given on a command line and prints a list of each unique Web site that is
#referred to in the files with a list of the referring files listed indented
#below the name of the Web site.

#Structurally, the program (external_sites.py) is very similar to the unique words
#program we have just reviewed.
#main part of the code:
sites = {}
for filename in sys.argv[1:]:
    for line in open(filename):
        i = 0
        while True:
            site = None
            i = line.find("http://", i)
            if i > -1:
                i += len("http://")
            for j in range(i, len(line)):
                if not (line[j]isalnum() or line[j] in ".-"):
                    site = line[i:j].lower()
                    break
            if site and "." in site:
                sites.setdefault(site, set()).add(filename)
            i = j
        else:
            break

#create an empty dict
#then iterate over each file listed on command line and
#iterate over each line within each file
#keep calling str.find() until it fails. Why? b/c we must account for potential that
#each line may refer to any number of Web sites
#if we find a string "http://" then we increment i by the length of string "http://"
#and then we look at each succeeding character until we reach one that is not valid
#for a web site's name.
#if we find a site, we add it to the dict
#we can NOT use syntax like 
sites[site].add(filename)
#b/c this will raise a KeyError exception the first time a new site is encountered
#why? KeyError exception is raised b/c we can not set a value of an item that does NOT
#yet exist in the dict

#So must use different approach.
dict.setdefault() method #returns an object reference to the item in the dict
#that has the given key (ie the first argument).
#If there is no such item, then this method creates a new item with the key and
#sets its value either to None or the given default value (the second argument).
#In this case, we pass a default value of set(), ie an empty set.
#So the call to dict.setdefault() always returns an object reference to a value,
#either one that existed before or a new one.
#Note that if the given key is not hashable, then a TypeError exception will be raised.

#In this example, the returned object reference always refers to a set.
#That set may be empty the first time for any particular key until the site
#is encountered at which point we add the filename that refers to the site 
#to the site's set of filenames. By using a set, we ensure that even if a file
#refers to a site repeatedly, we record the filename only once for the site.

#To make the dict.setdefault() method functionality clear, here are two equal
#code snippets
#1st code snippet
sites.setdefault(site, site()).add(fname)
#2nd code snippet
if site not in sites:
    sites[site] = set()
sites[site].add(fname)

#for the sake of completeness here is the rest of the program
for site in sorted(sites):
    print( "{0} is referred to in:".format(site) )
    for filename in sorted(sites[site], key=str.lower):
        print("     {0}". format(filename))

#each web site is printed with the files that refer to it printed indented underneath
#The sorted() call in the outer for...in loop sorts all the dictionary's keys -->
#whenever a dictionary is used in a context that requires an iterable it is the keys
#that are used.
#If we want an iterable to be the (key,value) items or the values, we can use 
#dict.items() or dict.values() 
#The inner for...in loop iterates over the sorted filenames from the current site's
#set of filenames.


#COMPLETE CODE
external_sites.py 
#for external_sites_ans.py --> see Exercises

#!/usr/bin/env python3

import sys

sites = {}
for filename in sys.argv[1:]:
    with open(filename) as file:
        for line in file:
            i = 0
            while True:
                site = None
                i = line.find("http://", i)
                if i > -1:
                    i += len("http://")
                    for j in range(i, len(line)):
                        if not (line[j].isalnum() or line[j] in ".-"):
                            site = line[i:j].lower()
                            break
                    if site and "." in site:
                        sites.setdefault(site, set()).add(filename)
                    i = j
                else:
                    break

for site in sorted(sites):
    print("{0} is referred to in:".format(site))
    for filename in sorted(sites[site], key=str.lower):
        print("    {0}".format(filename))



#external_sites.py
#reads HTML files on a command line, prints list of each unique Web site 
#that is referred to in the files with a list of the referring files
#indented below the name of the Web site

-----------1st EFFORT - posted on GitHub
#!/usr/bin/env python3
#external_sites.py

import sys


sites = {}
for filename in sys.argv[1:]:
    with open(filename) as file:
        for line in file:
            i = 0
            while True:
                site = None
                i = line.find("http://", i)
                if i > -1:
                    i += len("http://")
                    for j in range(i, len(line)):
                        if not (line[j].isalnum() or line[j] in ".-"):
                            site = line[i:j].lower()
                            break
                    if site and "." in site:
                        sites.setdefault(site, set()).add(filename)
                    i = j
                else:
                    break


for site in sorted(sites):
    print("{0} is referred to in:".format(site))
    for filename in sorted(sites[site], key=str.lower):
        print("    {0}".format(filename))

-----------1st EFFORT - posted on GitHub




#Reminder of topics<===========
CHAPTER 3 Collection Data Types
Sequence Types
    Tuples
    Named Tuples
    Lists
        List Comprehensions
    Set Types
        Sets 
            Set Comprehensions
        Frozen Sets 
Mapping Types 
    Dictionaries
        Dictionary Comprehensions
    Default Dictionaries 
Iterating and Copying Collections
    Iterators and Iterable Operation and Functions
    Copying Collections
Examples 
    generate_usernames.py
    statistics.py 
Summary
Exercises


===============
        Dictionary Comprehensions
===============
#is an expression and a loop with a optional condition enclosed in braces
#very similar to a set comprehension
#there are two syntaxes
{keyexpression: valueexpression for key, value in iterable}
{keyexpression: valueexpression for key, value in iterable if condition}

#here is how we could use a dictionary comprehension to create a dictionary where
#each key is the name of a file in the current dictionary and each value is the 
#size of the file in bytes:
file_sizes = {name: os.path.getsize(name) for name in or.listdir(".")}
#the os module's os.listdir() function returns a list of file and directories
#in the path it is passed, although it never includes "." or ".." in the list.
#The os.path.getsize() function returns the size of the given file in bytes.
#We can avoid directories and other nonfile entries by adding a condition:
file_sizes = {name: os.path.getsize(name) for name in or.listdir(".")
              if os.path.isfile(name)}
#here the os.path module's os.path.isfile() returns True if the path passed to it
#is that of a file, and False otherwise (ie for directories, links and so on).

#dictionary comprehension can also be used to create an inverted dictionary.
#example
#given dictionary d, we can produce a new dictionary whose keys are d's values
#and whose values are d's keys
inverted_d = {v: k for k, v in d.items()}
#note that the resultant dictionary can be inverted back to the original dictionary
#if all the original dictionary's values are unique but the inversion will fail
#with a TypeError being raised if any value is not hashable.
#just like a list and set comprehension, the iterable in a dictionary comprehension
#can be another comprehension, so all kinds of nested comprehensions are possible.


Iterating and Copying Collections

#Common use 1
#once we have collections of data items, its natural to want to iterate over all
#items they contain.
#Common use 2, to copy a collection. Some subtleties involved here b/c of Python's
#use of object references 




#Reminder of topics<===========
CHAPTER 3 Collection Data Types
Sequence Types
    Tuples
    Named Tuples
    Lists
        List Comprehensions
    Set Types
        Sets 
            Set Comprehensions
        Frozen Sets 
Mapping Types 
    Dictionaries
        Dictionary Comprehensions
    Default Dictionaries 
Iterating and Copying Collections
    Iterators and Iterable Operation and Functions
    Copying Collections
Examples 
    generate_usernames.py
    statistics.py 
Summary
Exercises

===============
Iterating and Copying Collections
===============

#Once we have collections of data items, we can iterate over all items they contain.
#first section = python iterators and operators and functions that involve iterators
#second section = copy a collection. Some subtleties here b/c of python's use of object
#references, so break this up into (1) how to copy collections then (2) how to get the
#beahvior that we want (how to use them correctly).



===============
    Iterators and Iterable Operation and Functions
===============

#an iterable data type is that can return each of its items one at a time.
#any object that has an
__iter__() method     #or
#any sequence that has an
__getitem__() method  #taking integer arguments starting from 0 
#is also considered an iterable and can provide an iterator

#The order in which items are returned depends upon the underlying iterable.
#for lists and tuples, items are normally returned in sequential oder starting from 
#first item (index position 0).
#some iterators return items in arbitrary order such as dictionary and set iterators.

#an iterator is an object that provides a
__next__() method #and raises a
StopIteration exception 

List of Common Iterable Operators and Functions
s + t                   #concatenates sequences s and t
s * n                   #concatenates sequences n times
x in i                  #returns True if item x is iterable i
x not in i              #returns True if item is x not in iterable i
all(i)                  #returns True if every item in iterable i evaluates to True
any(i)                  #returns True if any item in iterable i evalutes to True
enumerate(i, start)     #normally used in for...in loops to provide a sequence of tuples
len(x)                  
max(i, key)
min(i, key)
range(start, stop, step)
reversed(i)
sorted(i, key, reverse)
sum(i, start)
zip(i1, ..., iN)

#built-in iter() function has two quite different behaviors
#1)returns an iterator for the object it is passed, used for custom collection data types or 
#raises a TypeError if the object cannot be iterated. This arises when creating custom
#collection data types, but it rarely needed in other contexts.
#OR
#2)returns a function's return value when passed a callable (ie function or method) and
#a sentinel value. This this case, the function that is passed is called ONCE at each
#iteration, returning the fucntion's return value each time, or raising a StopIteration
#exception if the return value equals the sentinel.


#two code examples
#1st code snippet --> using a for...in loop to create the iterable
product = 1
for i in [1,2,4,8]:       #here python calls iter()
  product *= i
print(product)
>>> 
1
2
8
64
                        >>> product = 1
                        >>> for i in [1,2,4,8]:
                        ...     product *= i
                        ... 
                        >>> print(product)
                        64
                        >>> product = 1
                        >>> for i in [1,2,4,8]:
                        ...     product *= i
                        ...     print(product)
                        ... 
                        1
                        2
                        8
                        64

#2nd code snippet --> using an explicit iterator next()
product = 1
i = iter([1,2,4,8])
while True:
    try:
        product *= next(i)    #alternative way to get iterator's next item calling next()
    except StopIteration:
        break
print(product)
                        Atuls-MBP:python_proginpython3 atulgolhar$ python3 test.py
                        64

                        product = 1
                        i = iter([1,2,4,8])
                        while True:
                            try:
                                product *= next(i)
                                print(product)
                            except StopIteration:
                                break
                        Atuls-MBP:python_proginpython3 atulgolhar$ python3 test.py
                        1
                        2
                        8
                        64

#any finite iterable i can be converted into a tuple by calling tuple(i)
#or can be converted into a list by calling list(i)
all()
any()
len()
min()
max()
sum()
#usage examples
x = [-2, 9, 7, -4, 3]
all(x), any(x), len(x), min(x), max(x), sum(x)

                        >>> all(x), any(x), len(x), min(x), max(x), sum(x)
                        (True, True, 5, -4, 9, 13)

x.append(0)
all(x), any(x), len(x), min(x), max(x), sum(x)
                        >>> x.append(0)
                        >>> x
                        [-2, 9, 7, -4, 3, 0]
                        >>> all(x), any(x), len(x), min(x), max(x), sum(x)
                        (False, True, 6, -4, 9, 13)

enumerate()
#enumerate() function takes an iterator and returns an enumerator object

                        >>> enumerate(x)
                        <enumerate object at 0x101eb7d80>
                        >>> x
                        [-2, 9, 7, -4, 3, 0]
#example
grepword.py
#takes a word and one or more filenames on the command line and outputs the filename,
#line number, and line whenever the line contains the given word
#note in Chapter 9 we will see two other implementations of this
#grepword-p.py --> spread work over multiple processes
#grepword-t.py --> spread work over multiple threads
#sample output should look like this
grepword.py Dom data/forenames.txt
data/forenames.txt:615:Dominykas
data/forenames.txt:1435:Dominik
data/forenames.txt:1611:Domhnall
data/forenames.txt:3314:Dominic


#CODE HERE
grepword.py

#!/usr/bin/env python3

import sys

if len(sys.argv) < 3:
    print("usage: grepword.py word infile1 [infile2 [... infileN]]")
    sys.exit()

word = sys.argv[1]
for filename in sys.argv[2:]:
    for lino, line in enumerate(open(filename), start=1):
        if word in line:
            print("{0}:{1}:{2:.40}".format(filename, lino, line.rstrip()))
#Begin by checking that there are at least two command line arguments
#if not, we print message and terminate program
sys.exit() #performs immediate clean termination
#note that sys.exit() accepts an optional int argument which is passed to
#the calling shell.
#Assume first arugment is the searching word and other arguments are file names to look in.
#Deliberately called open() without specifying encoding so python uses default approach =
#platform-dependent encoding.
#the file object returned by open(filename) will return an iterator
#thus returning ONE LINE OF THE FILE PER ITERATION
#then by passing the iterator onto enumerate() we get an enumerator iterator that
#returns the iterator number (CALLED lino) and ALSO returns a single line from the file.
#Then if user search word is in line then print that filename, line number and first 40
#characters of the line with right side whitespace stripped.
#enuerate() accepts an optional argument, which defaults to 0. We start at 1 b/c
#by convention, text line numbers start at 1.

#Different way to code grepword.py
#!/usr/bin/env python3

import sys

if len(sys.argv) < 3:
    print("usage: grepword.p word infile1 [infile2 [... infileN]]")
    sys.exit()

word = sys.argv[1]
for filename in sys.argv[2:]:
    with open(filename) as file:
        for lino, line in enumerate(file, start=1):
            if word in line:
                print("{0}:{1}:{2:.40}".format(filename, lino, line.restrip()))





-----------1st EFFORT - posted on GitHub
#!/usr/bin/env python
#grepword.py
#usage: grepword.py word infile1 [infile2 [... infileN]]
#searches and prints specified word from target file

import sys


if len(sys.argv) < 3:
    print("usage: grepword.py word infile1 [infile2 [... infileN]]")
    sys.exit()

word = sys.argv[1]
for filename in sys.argv[2:]:
    for lino, line in enumerate(open(filename), start=1):
        if word in line:
            print("{0}:{1}:{2:.40}".format(filename, lino, line.rstrip()))

-----------1st EFFORT - posted on GitHub

#                                                          WORD   infile1
Atuls-MBP:python_proginpython3 atulgolhar$ python3 test.py result test3.py 
test3.py:15:  result = []
test3.py:18:    result.append(b)
test3.py:22:  return result



#!/usr/bin/env python3
#test3.py

print("Test_flag 3.1")

def fib1(n):
  a, b = 0, 1
  while b < n:
    print(b, end=' ')
    a, b = b, a+b
  print("Test_flag 3.2")
  print("check-fib1")

def fib2(n):
  result = []
  a, b = 0, 1
  while b < n:
    result.append(b)
    a, b = b, a+b
  print("Test_flag 3.3")
  print("check-fib2")
  return result





Atuls-MBP:python_proginpython3 atulgolhar$ python3 test.py codes testPython3book.py
testPython3book.py:5:codes = []
testPython3book.py:11:      codes.append(sex+size+color)
testPython3book.py:14:print(codes)

#so command is
$python3 grep_filename word filename_to_be_searched



#Enumerator vs Iterator
#sometimes (actually often) we dont need an enumerator, but rather an iterator that
#returns successive integers --> range() function provides this. 
>>> list(range(5))
[0, 1, 2, 3, 4]
>>> list(range(9,14))
[9, 10, 11, 12, 13]
>>> tuple(range(10,-11,-5))
(10, 5, 0, -5, -10)
                        >>> list(range(20, -11, -5))
                        [20, 15, 10, 5, 0, -5, -10]
                        >>> tuple(range(20, -11, -5))
                        (20, 15, 10, 5, 0, -5, -10)
#range() function most commonly used for two purposes:
#to create lists or tuples of integers
#to provide loop counting in for...in loops

#Examples:
#1st code snippet
for i in range(len(x)):
    x[i] = abs(x[i])

#2nd code snippet
i = 0
while i < len(x):
    x[i] = abs(x[i])
    i += 1

#1st code snippet
#if x originally is [11, -3, -12, 8, -1]
>>> x
[11, -3, -12, 8, -1]
>>> for i in range(len(x)):
...     x[i] = abs(x[i])
... 
>>> x
[11, 3, 12, 8, 1]

#2nd code snippet
>>> x
[11, -3, -12, 8, -1]
>>> i = 0
>>> while i < len(x):
...     x[i] = abs(x[i])
...     i += 1          #notice need += 1 here but not in example above
... 
>>> x
[11, 3, 12, 8, 1]

#now since we can unpack an iterable using * operator, we can also unpack
#the iterator function returned by the range() function
#example
#if we have a function called calcuate() that takes 4 arguments, here are some
#ways to call it with 4 arguments:

calculate(1,2,3,4)
t = (1,2,3,4)
calculate(*t)
calculate(*range(1,5))
#notice that in all 3 calls, we are passing 4 arguments
#2nd call will unpack a 4-tuple
#3rd call will unpack the iterator returned by the range() function


#NOW for first time, lets write to a file as well as incorporate everything so far:

generate_test_names1.py

#reads in file of forenames and file of surnames, creating two lists, and then
#creates the file
test-names1.txt
#and writes 100 random names into it.
#lets use random.choice() function
#first look at function that returns the list of names (BASIC VERSION)
def get_forenames_and_surnames():
    forenames = []
    surnames = []
    for names, filename in ():
        for name in open():
            names.append()
    return forenames, surnames

#DETAILED VERSION
def get_forenames_and_surnames():
    forenames = []
    surnames = []
    for names, filename in ((forenames, "data/forenames.txt"),(surnames, "data/surnames.txt")):
        for name in open(filename, encoding="utf-8"):
            names.append(name.rstrip())
    return forenames, surnames
#so here in outer for...in loop, we iterate over two 2-tuples unpacking each
#2-tuple into two variables. Even though the lists could be large, we are only
#passing object references.
#note for
data/forenames.txt
data/surnames.txt
#with these two paths, it is always convenient to use Unix-style paths since 
#they can be typed without need for escaping and they work on all platforms including
#Windows. If we have a path we want to present to the user in, say variable path, we
#can always import os module and call
path.replace("/", os.sep) #to replace forward slashes with platform-specific 
#directory separators.

#rest of the program (BASIC)
forenames, surnames = get_forenames_and_surnames()
fh = open("", "", endcoding="")
for i range():
    line = "".format()
    fh.write(line)

#rest of the program (DETAILED)
forenames, surnames = get_forenames_and_surnames()
fh = open("test-names1.txt", "w", endcoding="utf-8")
for i range(100):
    line = " {} {}\n ".format(random.choice(forenames), random.choice(surnames))
    fh.write(line)
#1st retrieve the output files
#next open output files and keep the file object inside variable fh --> file handle
#then loop 100 times and in each iteration we create a line to be written to the file
#remember to include a NEWLINE at the end of every line
#note no need to make use of variable i as its need ONLY to satify for...in loop syntax.
#so entire program is:
#so here we paired items from two separate lists together into strings.

generate_test_names1.py

def get_forenames_and_surnames():
    forenames = []
    surnames = []
    for names, filename in ((forenames, "data/forenames.txt"),(surnames, "data/surnames.txt")):
        for name in open(filename, encoding="utf-8"):
            names.append(name.rstrip())
    return forenames, surnames
forenames, surnames = get_forenames_and_surnames()
fh = open("test-names1.txt", "w", endcoding="utf-8")
for i range(100):
    line = " {} {}\n ".format(random.choice(forenames), random.choice(surnames))
    fh.write(line)





#COMPLETE CODE HERE for 
generate_test_names1.py 

#BASIC
#!/usr/bin/env python3

import random

def get_forenames_and_surnames():
    forenames = []
    surnames = []
    for names, filename in ():
        with open() as file:
            for name in file:
                names.append(name.rstrip())
    return forenames, surname

forenames, surnames = get_forenames_and_surnames()
with open() as file:
    for i in range(100):
        line = "".format()
        file.write(line)


#DETAIL
#!/usr/bin/env python3

import random

def get_forenames_and_surnames():
    forenames = []
    surnames = []
    for names, filename in ((forenames, "data/forenames.txt"),
                            (surnames, "data/surnames.txt")):
        with open(filename, encoding="utf8") as file:
            for name in file:
                names.append(name.rstrip())
    return forenames, surname

forenames, surnames = get_forenames_and_surnames()
with open("test-names1.txt", "w", encoding="utf8") as file:
    for i in range(100):
        line = "{0} {1}\n".format(random.choice(forenames), random.choice(surnames))
        file.write(line)



-----------1st EFFORT - posted on GitHub
#!/usr/bin/env python
#generate_test_names1.py

#ingests forenames.txt and surnames.txt
#creates test-names1.txt with random new names

import random


def get_forenames_and_surnames():
    forenames = []
    surnames = []
    for names, filename in ((forenames, "data/forenames.txt"), (surnames, "data/surnames.txt")):
        with open(filename, encoding="utf-8") as file:
            for name in file:
                names.append(name.rstrip())
    return forenames, surnames


forenames, surnames = get_forenames_and_surnames()
with open("test-names1.txt", "w", encoding="utf-8") as file:
    for i in range(100):
        line = " {} {}\n".format(random.choice(forenames), random.choice(surnames))
        file.write(line)
-----------1st EFFORT - posted on GitHub




#another way of combining items from two or more lists is use zip() function.
#zip() takes one or more iterables and returns an iterable that returns tuples.
#first tuple has the first item from every iterable.
#second tuple has the second item from every iterable, and so on.
#stops when one of the iterables is exhausted.
#example
>>> 
for t in zip():
    print(t)

for t in zip(range(4), range(0, 10, 2), range(1, 10, 2)):
    print(t)
                        >>> for t in zip(range(4), range(0, 10, 2), range(1, 10, 2)):
                        ...     print(t)
                        ... 
                        (0, 0, 1)
                        (1, 2, 3)
                        (2, 4, 5)
                        (3, 6, 7)

                        >>> for t in zip(range(4), range(1,10,3), range(1,10,2)):
                        ...     print(t)
                        ... 
                        (0, 1, 1)
                        (1, 4, 3)
                        (2, 7, 5)

                        >>> for t in zip(range(4)):
                        ...     print(t)
                        ... 
                        (0,)
                        (1,)
                        (2,)
                        (3,)

                        >>>> for t in zip(range(4), range(0,10,2)):
                        ...     print(t)
                        ... 
                        (0, 0)
                        (1, 2)
                        (2, 4)
                        (3, 6)

                        >>> for t in zip(range(4), range(0,10,5)):
                        ...     print(t)
                        ... 
                        (0, 0)
                        (1, 5)

#so second iterator limits the first iterator within the zip() function

#new code snippet
#next is a modified version of the program to generate test names
#each test name occupies 25 characters and is followed by random year.

                        >>> y = list(range(1,4)) *3
                        >>> y
                        [1, 2, 3, 1, 2, 3, 1, 2, 3]

generate_test_names2.py
#output is test-names2.txt
#same get_forenames_and_surnames() function and same open() call
#only diference is here BASIC
limit = 100
years = list() * 3
for year, forename, surname in zip():
    name = "".format()
    fh.write("".format())

#DETAILED (ATUL --> STILL NOT DETAILED ENOUGH)
limit = 100
years = list(range(1970, 2013)) * 3
for year, forename, surname in zip(random.sample(years, limit), 
        random.sample(forenames, limit),
        random.sample(surnames, limit)):
    name = " {0} {1}".format(forename, surname)
    fh.write("{0}:.<25\n".format(name, year))
#set limit on how many names to generate --> 100
#create a list of years from 1970 to 2012 INCLUSIVE
#replicate the list of years by 3 so that final list has three occurrences of each year
#note random.sample() function takes an itererable and a limit on 
#how many items to produce within the for...in loop we unpack each tuple 
#using zip() function
#want to limit length of each name to 25 characters so need to 
#first create complete string and then
#set maximum width when calling that string a SECOND TIME using str.format()
#left align the 25 characters to ensure names occupy the full field and mandate that 
#separation between names and year is by a period.


                        #!/usr/bin/env python
                        #generate_test_names2.py

                        #ingests forenames.txt and surnames.txt
                        #creates test-names2.txt with random new names

                        import random


                        def get_forenames_and_surnames():
                            forenames = []
                            surnames = []
                            for names, filename in ((forenames, "data/forenames.txt"), (surnames, "data/surnames.txt")):
                                with open(filename, encoding="utf8") as file:
                                    for name in file:
                                       names.append(name.rstrip())
                            return forenames, surnames

                        forenames, surnames = get_forenames_and_surnames()
                        with open("test-names2.txt", "w", encoding="utf8") as file:
                            limit = 10
                            years = list(range(1970, 2013)) * 3
                            for year, forename, surname in zip(random.sample(years, limit), random.sample(forenames, limit), random.sample(surnames, limit)):
                                name = "{0} {1}".format(forename, surname)
                                fh.write("{0}:.<25\n".format(name, year))



                        Atuls-MBP:python_proginpython3 atulgolhar$ python3 test.py
                        Traceback (most recent call last):
                          File "test.py", line 25, in <module>
                            fh.write("{0}:.<25\n".format(name, year))
                        NameError: name 'fh' is not defined

#COMPLETE CODE HERE for 
generate_test_names2.py 
#!/usr/bin/env python3

import random

def get_forenames_and_surnames():
    forenames = []
    surnames = []
    for names, filename in ((forenames, "data/forenames.txt"), (surnames, "data/surnames.txt")):
        with open(filename, encoding="utf8") as file:
            for name in file:
                names.append(name.rstrip())
    return forenames, surnames

forenames, surnames = get_forenames_and_surnames()
with open("test-names2.txt", "w", encoding="utf8") as file:
    limit = 100
    years = list(range(1970, 2013)) * 3
    for year, forename, surname in zip(random.sample(years, limit), random.sample(forenames, limit), random.samoke(surnames, limit)):
        name = "{0} {1}".format(forename, surname)
        file.write("{0:.<25}.{1}\n".format(name, year))



-----------1st EFFORT - posted on GitHub
#!/usr/bin/env python
#generate_test_names2.py

#ingests forenames.txt and surnames.txt
#creates test-names2.txt with random new names and related year

import random


def get_forenames_and_surnames():
    forenames = []
    surnames = []
    for names, filename in ((forenames, "data/forenames.txt"), (surnames, "data/surnames.txt")):
        with open(filename, encoding="utf8") as file:
            for name in file:
               names.append(name.rstrip())
    return forenames, surnames

forenames, surnames = get_forenames_and_surnames()
with open("test-names2.txt", "w", encoding="utf8") as file:
    limit = 30
    years = list(range(1970, 2013)) * 3
    for year, forename, surname in zip(random.sample(years, limit), random.sample(forenames, limit), random.sample(surnames, limit)):
        name = "{0} {1}".format(forename, surname)
        file.write("{0:.<25}.{1}\n".format(name, year))
-----------1st EFFORT - posted on GitHub



                        test-names2.txt


                        Arlington Simon...........2001
                        Juliana Norwood...........1970
                        Caldicott Christy.........2007
                        Jennifer Nguyen...........1992
                        French Mitchell...........2006
                        Weinman Arisa.............1970
                        Liam Glen.................2003
                        Heather Kivambe...........1987
                        Friedman Nir..............2012
                        Kimura Granik.............1991
                        Newton Maria..............2006
                        Fontes Kathy..............1981
                        Hillside Eisikovits.......1972
                        Rotherwood Tatsuo.........2010
                        Caldicott Cantor..........1991
                        John Steber...............2004
                        Adam Yu...................2008
                        Dominic Maulid............1988
                        Yuko Kippy................1977
                        Michael Aedin.............1972
                        Will Salama...............1987
                        Eugene Zhanna.............2000
                        Kesney Lugono.............1975
                        Dsouza Jafari.............1988
                        Lisa Ichinose.............1997
                        Gistrak Green.............1998
                        Butts Sholemson...........1971
                        Maebh Naomi...............1997
                        Walnut John...............1998
                        Newton LuAnn..............2001



#lets conclude this subsection by mentioning two other iterable-related functions
sorted()
reversed()

                        >>> list(range(6))
                        [0, 1, 2, 3, 4, 5]
                        >>> list(reversed(range(6)))
                        [5, 4, 3, 2, 1, 0]

#more sophisticated examples BASIC
x = []
for t in zip():
    x += t

#DETAILED
x = []
for t in zip(range(-10, 0, 1), range(0, 10, 2), range(1, 10, 2)):
    x += t

                        >>> x = []
                        >>> t = 0
                        >>> for t in zip(range(-10, 0, 1)):
                        ...     x += t
                        ... 
                        >>> x
                        [-10, -9, -8, -7, -6, -5, -4, -3, -2, -1]
                        >>> t
                        (-1,)

x
sorted(x)
sorted(x, reverse=True)
sorted(x, key=abs)

                        >>> x = []
                        >>> x
                        []
                        >>> for t in zip(range(-10,0,1), range(0,10,2), range(1,10,2)):
                        ...     x += t                #fill up x array with t output
                        ... 
                        >>> x
                        [-10, 0, 1, -9, 2, 3, -8, 4, 5, -7, 6, 7, -6, 8, 9]
                        
                        >>> sorted(x)
                        [-10, -9, -8, -7, -6, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
                        >>> x                                                 #notice x did not change
                        [-10, 0, 1, -9, 2, 3, -8, 4, 5, -7, 6, 7, -6, 8, 9]

                        >>> sorted(x, reverse=True)
                        [9, 8, 7, 6, 5, 4, 3, 2, 1, 0, -6, -7, -8, -9, -10]

                        >>> sorted(x, key=abs)              #created "decorated" list here
                        [0, 1, 2, 3, 4, 5, 6, -6, -7, 7, -8, 8, -9, 9, -10] 

#so note, here created an empty array, calcuated x using zip() function
+= operator --> extends a list (ie appends each time)

#1st sort statement --> conventional sort order
#2nd sort statement --> returns a copy of the list in reverse of the conventional sort order
#3rd sort statement --> specifies a "key" function
Passing a Function to a Function
#so here we are passing a function to a function. How b/c they are all object references.
#so in 3rd sort statement, we creating a "decorated" list
#what does this mean? --> when a key function is passed then it is called
#once for every item in the list
#here abs() is called once each item in the list
#this then creates a "decorated list"
#then the decorated list is sorted, and the sorted list is returned WITHOUT the decoration
#is returned as the result.
#We are free to use our own custom function as the key function, as we will see shortly.

#For example --> we can case-insensitively sort a list of strings by passing the 
#str.lower() method as a key
x = ["Sloop", "Yawl", "Cutter", "schooner", "ketch"]
#sort this case insersitively using DSU --> Decorate, Sort, Undecorate with 
#a SINGLE line  of code by passing a key function, or do the DSU explicitly, as these
#two equivalent code snippets show:  (1 line vs 6 lines!)

#1st code snippet
x = sorted(x, key=str.lower)

#2nd code snippet
temp = []
for item in x:
    temp.append((item.lower(), item))
x = []
for key, value in sorted(temp):
    x.append(value)

                        >>> x = ["Sloop", "Yawl", "Cutter", "schooner", "ketch"]
                        >>> temp = []
                        >>> for item in x:
                        ...     temp.append((item.lower(), item))
                        ... 
                        >>> x
                        ['Sloop', 'Yawl', 'Cutter', 'schooner', 'ketch']
                        >>> temp
                        [('sloop', 'Sloop'), ('yawl', 'Yawl'), ('cutter', 'Cutter'), ('schooner', 'schooner'), ('ketch', 'ketch')]

                        >>> x = []
                        >>> for key, value in sorted(temp):
                        ...     x.append(value)
                        ... 
                        >>> x
                        ['Cutter', 'ketch', 'schooner', 'Sloop', 'Yawl']
                        >>> temp
                        [('sloop', 'Sloop'), ('yawl', 'Yawl'), ('cutter', 'Cutter'), ('schooner', 'schooner'), ('ketch', 'ketch')]


                        >>> x1 = ["Sloop", "Yawl", "Cutter", "schooner", "ketch"]
                        >>> x2 = sorted(x1, key=str.lower)      #key is alaphabetizing 
                        >>> 
                        >>> x1
                        ['Sloop', 'Yawl', 'Cutter', 'schooner', 'ketch']
                        >>> x2
                        ['Cutter', 'ketch', 'schooner', 'Sloop', 'Yawl']

#ATUL notice in last or 3rd snippet, x2 is alphabetized in lower case but printed normal

#explained: both snippets produce a new list which is alphabetized without regard to capital
#or lower case letters --> this is the Decorate then sort then undecorate.
#So here, snippets are not identical b/c 2nd snippet creates the temp list variable

#Python's sort algorithm is an adaptive stable mergesort that is both fast and smart
#it is especially well optimized for partially sorted lists
adaptive #means that the sort algorithm adapts to circumstances such as taking advantage
#of partially sorted data.
stable #means that items that sort equally are not moved in relation to each other
#(as there is no need)
#and the mergesort part is the generic name for the sorting algorithm used.

#when sorting collections of integers, strings or other simple types working 
#recursively to any depth
#example
x = list(zip())
x = list(zip((1,3,1,3), ("pram", "dorie", "kayak", "canoe")))

                        >>> x = list(zip((1,3,1,3), ("pram", "dorie", "kayak", "canoe")))
                        >>> x
                        [(1, 'pram'), (3, 'dorie'), (1, 'kayak'), (3, 'canoe')]

sorted(x)
                        >>> sorted(x)
                        [(1, 'kayak'), (1, 'pram'), (3, 'canoe'), (3, 'dorie')]
#here python sorts the list of tuples by comparing the first item of each tuple,
#then when these are the same, it compares the second item of each tuple.
#this give sort order based upon the integers, with strings as tiebreakers.

#We can force the sort to be based upon strings and use integers as tiebreakers by
#creating a new definition:
def swap(t):
    returnsturn t[1], t[0]

                        >>> def swap(t):
                        ...     return t[1], t[0]
                        ... 
                        >>> swap
                        <function swap at 0x1010dba60>

sorted(x, key=swap)
                        >>> temp
                        [('sloop', 'Sloop'), ('yawl', 'Yawl'), ('cutter', 'Cutter'), ('schooner', 'schooner'), ('ketch', 'ketch')]
                        >>> x
                        [(1, 'pram'), (3, 'dorie'), (1, 'kayak'), (3, 'canoe')]
                        >>> key
                        'yawl'
                        >>> sorted(x, key=swap)
                        [(3, 'canoe'), (3, 'dorie'), (1, 'kayak'), (1, 'pram')]

#lists can be sorted in place using 
list.sort() method
#which takes same optional arguments as sorted()

#sorting can be applied ONLY to collections where all items can be compared
#with each other.
#to compare integers, floating point numbers, and strings containing numbers
#then we can give float() as the key function
sorted([],key=float)
>>> sorted(["1.3", "-7.5", "5", 4, "-2.4", 1],key=float)
['-7.5', '-2.4', 1, '1.3', 4, '5']
#note that if any strings can NOT be converted to a number then a TypeError occurs

sorted([], key=float)
                        >>> sorted(["1.3", "-7.5", "5", 4, "spanner", "-2.14", 1], key=float)
                        Traceback (most recent call last):
                          File "<stdin>", line 1, in <module>
                        ValueError: could not convert string to float: 'spanner'
                        >>> sorted(["1.3", "-7.5", "5", 4, "-2.14", 1], key=float)
                        ['-7.5', '-2.14', 1, '1.3', 4, '5']



#Reminder of topics<===========
CHAPTER 3 Collection Data Types
Sequence Types
    Tuples
    Named Tuples
    Lists
        List Comprehensions
    Set Types
        Sets 
            Set Comprehensions
        Frozen Sets 
Mapping Types 
    Dictionaries
        Dictionary Comprehensions
    Default Dictionaries 
Iterating and Copying Collections
    Iterators and Iterable Operation and Functions
    Copying Collections
Examples 
    generate_usernames.py
    statistics.py 
Summary
Exercises


===============
    Copying Collections
===============

#since Python uses object references when using the assignment operator, 
#then no copying takes place.

#so when applying this to long lists, the savings are very apparent

songs = ["Because", "Boys", "Carol"]
beatles = songs
beatles, songs
#so here beatles is the new object reference and it points to songs
#thus no copying has taken place
                        >>> songs = ["Because", "Boys", "Carol"]
                        >>> beatles = songs
                        >>> beatles, songs
                        (['Because', 'Boys', 'Carol'], ['Because', 'Boys', 'Carol'])

#lists are mutable
beatles[2] = "Cayanne"
                        >>> beatles, songs
                        (['Because', 'Boys', 'Carol'], ['Because', 'Boys', 'Carol'])
                        >>> beatles[2] = "Cayanne"
                        >>> beatles, songs
                        (['Because', 'Boys', 'Cayanne'], ['Because', 'Boys', 'Cayanne'])



                        # NOTE if using references only then the copy WILL CHANGE the source:
                                            >>> source = ['A', 'B', 'C']
                                            >>> copy = source
                                            >>> copy, source
                                            (['A', 'B', 'C'], ['A', 'B', 'C'])
                                            >>> copy[2]
                                            'C'
                                            >>> copy[2] = ['0123']
                                            >>> copy, source
                                            (['A', 'B', ['0123']], ['A', 'B', ['0123']])
                                            >>> 
                        # but if use DATA ELEMENTS (not pointers) then copy will NOT change                     
                                            >>> source = ["A", "B", "C"]
                                            >>> copy = ["A", "B", "C"]
                                            >>> copy, source
                                            (['A', 'B', 'C'], ['A', 'B', 'C'])
                                            >>> copy[2] = ['0123']
                                            >>> copy, source
                                            (['A', 'B', ['0123']], ['A', 'B', 'C'])
                                            >>>


#this means that we can pass a list as an argument to a function, modify the list
#WITHIN the function, and know that the modified list will STILL be accessible AFTER
#the function call has been completed.

#IF however, in some situation we want an INDEPENDENT copy of the collection or other
#other mutable object --> such as a slice --> songs[:2]
songs
                        >>> songs
                        ['Because', 'Boys', 'Carol']
                        >>> beatles
                        ['Because', 'Boys', 'Cayanne']

                        >>> beatles     #starting point given prior changes
                        ['Because', 'Boys', 'Cayanne']
                        >>> songs
                        ['Because', 'Boys', 'Carol']

                        >>> beatles = songs  #back to original starting point
                        >>> beatles
                        ['Because', 'Boys', 'Carol']
                        >>> songs
                        ['Because', 'Boys', 'Carol']        

>>> beatles = songs[:] #no change yet
                        >>> beatles[2] = "NewSong1"
                        >>> beatles
                        ['Because', 'Boys', 'NewSong1']


                        >>> beatles[:2] = "SliceNewSong2"
                        >>> beatles
                        ['S', 'l', 'i', 'c', 'e', 'N', 'e', 'w', 'S', 'o', 'n', 'g', '2', 'NewSong1']
                        
                        >>> songs
                        ['Because', 'Boys', 'Carol']

#dictionaries and sets --> copying done by dict.copy
dict.copy() function
set.copy() function

copy.copy() function from copy module which returns copy of the object it is given

#another way to copy built-in collections is to use the type as a function with 
#collection to be copied as its argument. For example:
copy_of_dict_d = dict(d)
copy_of_list_L = list(L)
copy_of_set_s = set(s)

#these are all SHALLOW copying techniques --> only the object references are copied
#and not the object themselves

#Shallow copying implies
#for immutable data types (numbers and strings) this has same effect as copying
#for mutable data types (nested collections) that the objects they refer to are
#themselves both referred by the original collection and the by the copied collection

                        >>> x = [53, 68, ['A', 'B', 'C']]
                        >>> x
                        [53, 68, ['A', 'B', 'C']]
                        
Shallow Copy #changes to original will follow thru to the shallow copy b/c using references 
#or pointers
                        >>> y = x[:]                  #shallow copy
                        >>> x
                        [53, 68, ['A', 'B', 'C']]
                        >>> y
                        [53, 68, ['A', 'B', 'C']]
                        >>> x, y
                        ([53, 68, ['A', 'B', 'C']], [53, 68, ['A', 'B', 'C']])

                        >>> y[1] = 40
                        >>> x, y
                        ([53, 68, ['A', 'B', 'C']], [53, 40, ['A', 'B', 'C']])
                        >>> x[2][0] = 'Q'
                        >>> x, y            #y was impacted as well --> why? y is a shallow copy
                        ([53, 68, ['Q', 'B', 'C']], [53, 40, ['Q', 'B', 'C']])
#so here x is original collection
#y is shallow copy so any changes to original collection follow thru to shallow copy
#original copy is also called nested list

Deep Copy
#Deep copy --> to change the independent nested collection = deep copy

                        >>> import copy
                        >>> x
                        [53, 68, ['Q', 'B', 'C']]
                        >>> y                       #y is a shallow copy       
                        [53, 40, ['Q', 'B', 'C']]   #so 40 remains b/c its a pointer reference
                        >>> y = copy.deepcopy(x)    #force the deep copy
                        >>> y
                        [53, 68, ['Q', 'B', 'C']]   #now 40 is changed to 68 b/c is memory change

                        >>> x
                        [53, 68, ['Q', 'B', 'C']]
                        >>> y
                        [53, 68, ['Q', 'B', 'C']]

                        >>> y[1] = 40
                        >>> y
                        [53, 40, ['Q', 'B', 'C']]

                        >>> x[2][0] = 'QDeepCopy' 
                        >>> x, y
                        ([53, 68, ['QDeepCopy', 'B', 'C']], [53, 40, ['Q', 'B', 'C']])

#so here x and y are completely independent copies.
#from now on, copy = shallow copy
#if need deep copy, we will explicitly say so.


Examples - Chapter 3

generate_usernames.py
statistics.py

#examples - now have completed review of Python's built-in collection data types 
#and two of the standard library collection types --> 
collections.namedtuple
collections.defaultdict
#python also provides 
collections.deque #type and other collections types as well
#see Python Package Index
pypi.python.org/pypi

#now for the examples
#first program is 70 lines long and invovles text processing
#second program is 90 lines long and involves mathematical processing
#combined, these program make use of dictionaries, lists, named tuples, and
#sets and both make great use of str.format() method from Chapter 2

generate_usernames.py
#Hypo: imagine we are setting up a new computer system and need to generate usernames
#for all our organization's staff. We have plain text data file (UTF-8 encoding)
#where each line represents a record and fields are colon-delimited.
#Each record concerns one member of the staff and the fields are
#their unique staff ID, forename, middle name (may be empty), surname, and dept name.
#extract of few lines of data file:
data/users.txt

1601:Albert:Lukas:Montgomery:Legal
3702:Albert:Lukas:Montgomery:Sales
4730:Nadelle::Landale:Warehousing

#program must read in all the data files given on the command line
#for every line (record) must extract the fields and return the data with a
#suitable username. Each username must be unique and based upon user's name.
#Output must be text sent to the console, sorted alphabetically by surname
#and forename, for example:
Name                          ID      Username
----------------------------- ------  ----------
Landale, Nadelle............. (4730)  nlandale
Montgomery, Albert L......... (1601)  almontgo     
Montgomery, Albert L......... (3702)  almontgol

#each record has exactly five fields, and although we could refer to them by number
#we prefer to use names to keep our code clear:
ID, FORENAME, MIDDLENAME, SURNAME, DEPARTMENT = range(5)

#Python convention is to use identifiers that are written in all uppercase characters and
#to be treated as constants.
#Also need to create a named tuple type for holding the data on each user:
User = collections.namedtuple("User", "username forename middlename surname id")

#we will see how the constants and User named tupple are used when looking at rest
#of the code.

#program's overall logic is captured in the main() function:
def main():
    if len(sys.argv) == 1 or sys.argv[1] in {"-h", "--help"}:
        print("usage: {0} file1 [file2 [... fileN]]".format(sys.argv[0]))
        sys.exit()

    usernames = set()
    users = {}
    for filename in sys.argv[1:]:
        for line in open(filename, encoding="utf-8"):
            line = line.rstrip()    #strip trailing whitespaces
            if line:                #process only non-empty lines
                user = process_line(line, usernames)  #track usernames to avoid duplicates
                users[(user.surname.lower(), user.forename.lower(), user.id)] = user #dicationary
    print_users(users) #tuple of   key              #values         #value

#If user doesnt provide any filenames on the command line, or they type "-h" or 
#"--help" on the command line, then print usage message and terminate program
#For each line read, strip off trailing whitespaces (eg \n) and process only
#nonempty lines. Thus ignoring any blank line in data file.
#Keep track of all allocated usernames in usernames set to ensure that we dont
#create any duplicates.
#Data itself is stored in users dictionary wherein each user is stored as the
#dictionary item key which is tuple of the user's surname, forename and ID.
#so key is 3 items --> 3 item tuple.
#why do it this way? using a tuple of the user's surname, forename and ID for
#the dictionary's key means that if we call sorted() on the dictionary, then
#the iterable returned will be in the order we want (surname, forename, ID),
#without us having to provide a key function.

def process_line(line, usernames):
    fields = line.split(":")
    username = generate_username(fields, usernames)
    user = User(username, fields[FORENAME], fields[MIDDLENAME], fields[SURNAME], fields[ID])
    return user
#since the data format for each record is so simple, and b/c we have already
#stripped the trailing whitespaces from the line, we can extract the fields simply
#by splitting on the colons. (ASSUMES that colons are known to exist splitting the data)
#We pass fields and usernames to the generate_username() function
#and we create an instance of the User named tuple type which we then return to
#the caller main() which inserts the user into the users dictionary, thus
#now ready for priting.

#If we had not created suitable constants to the hold the index positions, we could be
#reduced to using numeric indexes, for example:
user = User(username, fields[1], fields[2], fields[3], fields[0])
#although this is certainly shorter, it is POOR python practice. Why?
#First, it is not clear to future maintainers what each field is, and second
#it is vulnerable to data file format changes --> if the order or number of fields
#in a record changes, this code will break everywhere it is used. But by using
#named constants in the face of changes to the record structure, we would have
#to change only the values of the constants thus allowing all uses of the 
#constants to continue to work.

#BASIC
def generate_username(fields, usernames):
    username = ((fields[][] + fields [][] + fields[]).replace().replace())
    username = original_name = username[].lower()
    count = 1
    while username in usernames:
        username = "{}{}".format()
        count += 1
    usernames.add()
    return username

#DETAILED
def generate_username(fields, usernames):
    username = ((fields[FORENAME][0] + fields [MIDDLENAME][:1] +
                fields[SURNAME]).replace("-", "").replace("'", ""))
    username = original_name = username[:8].lower()
    count = 1
    while username in usernames:
        username = "{0}{1}".format(original_name, count)
        count += 1
    usernames.add(username)
    return username
#We make a first attempt at creating a username by concatenating the first letter
#of the forename, the first letter of the middle name, and the whole surname.
#Also deleting any hyphens or single quotes from the resultant string.
#Code for getting middlename field letter is quite subtle by using a slice: if we had used 
#fields[MIDDLENAME][0] then we would get an IndexError exception for an empty
#middle names. But by using a slice, we get the first letter if there is one, or
#an empty string otherwise thus making the slice usability very useful.

#Next make username lowercase and no more than 8 characters long. If the 
#username is already in use, try the username with a "1" tacked on, or try "2"
#until we get on that is ok.
#Then add the username to the set of usernames and return to the caller.


#BASIC
def print_users(users):
    namewidth = 32
    usernamewidth = 9

    print("".format())
    print("".format())

    for key in sorted(users):
        user = users[key]
        initial = ""
        if user.middlename:
            initial = " " + user.middlename[0]
        name = "".format()
        print("".format())


#DETAILED
def print_users(users):
    namewidth = 32
    usernamewidth = 9

    print("{0:<{nw}} {1:^6} {2:{uw}}".format("Name", "ID", "Username", nw=namewidth, uw=usernamewidth))
    print("{0:-<{nw}} {0:-<6} {0:-<{uw}}".format("", nw=namewidth, uw=usernamewidth))

    for key in sorted(users):
        user = users[key]
        initial = ""
        if user.middlename:
            initial = " " + user.middlename[0]
        name = "{0.surname}, {0.forename}{1}".format(user, initial)
        print("{0:.<{nw}} ({1.id:4}) {1.username:{uw}}".format(name, user, nw=namewidth, uw=usernamewidth))
#Once all the records have been processed, then print_users() function is called
#with users dictionary passed in as its parameter.
#First print statement prints column titles, and second prints hyphens under each title.
#The second statement's str.format() call is slightly subtle. The string we give to
#be printed is "" --> which is an empty string --> we get the hyphens by printing the
#empty string padded with hyphens to the given widths.
#Next we use a for...in loop to print the details of each user, extracting the key for
#each user's dictionary item in sorted order.
#For convenience, we create the user variable so that we dont have to keep
#writing users[key] throughout the rest of the function.

#In the loop's first call to str.format() we set the name variable to the user's name
#in surname, forename, and the optional initial form.
#We access items in the user named tuple by name.
#Once we have the user's name as a single string we print the user's details, constraining
#each column of (name, ID, username) to the widths we want.

#so complete program is called
generate_usernames.py
#Note that the program structure -->
#   read in a data file
#   process each record
#   write output
#is a VERY frequently used and we will it again in the next example.



#COMPLETE CODE HERE
generate_usernames.py 

#!/usr/bin/env 

#BASIC
import collections
import sys

ID, FORENAME, MIDDLENAME, SURNAME, DEPARTMENT = range(5)

User = collections.namedtuple()

def main():

def process_line():

def generate_username():

def print_users():

main()


#BASIC WITH SOME DETAIL
import collections
import sys

ID, FORENAME, MIDDLENAME, SURNAME, DEPARTMENT = range(5)

User = collections.namedtuple()

def main():
    if len() == 1 or sys.argv[1] in {}:
        print("".format())
        sys.exit()

    usernames = set()
    users = {}
    for filename in sys.argv[]:
        with open() as file:
            for line in file:
                line = line.rstrip()
                if line:
                    user = process_line()
                    users[] = user
    print_users()

def process_line():
    fields = line.split()
    username = generate_username()
    user = User()
    return user

def generate_username():
    username = (().replace().replace())
    username = original_name = username[:8].lower()
    count = 1
    while username in usernames:
        username = "".format()
        count += 1
    usernames.add(username)
    return username

def print_users():
    namewidth = 32
    usernamewidth = 9

    print("".format())
    print("".format())

    for key in sorted(users):
        user = users[key]
        initial = ""
        if user.middlename:
            initial = 
        name = "".format()
        print("".format())

main()




#DETAIL

#!/usr/bin/env pythong3
import collections
import sys

ID, FORENAME, MIDDLENAME, SURNAME, DEPARTMENT = range(5)

User = collections.namedtuple("User", "username forename middlename surname id")

def main():
    if len(sys.argv) == 1 or sys.argv[1] in {"-h", "--help"}:
        print("usage: {0} file1 [file2 [... fileN]]".format(sys.argv[0]))
        sys.exit()

    usernames = set()
    users = {}
    for filename in sys.argv[1:]:
        with open(filename, encoding="utf8") as file:
            for line in file:
                line = line.rstrip()
                if line:
                    user = process_line(line, usernames)
                    users[(user.surname.lower(), user.forname.lower(), user.id)] = user
    print_users()

def process_line(line, usernames):
    fields = line.split(":")
    username = generate_username(fields, usernames)
    user = User(username, fields[FORENAME], fields[MIDDLENAME], fields[SURNAME], fields[ID])
    return user

def generate_username(fields, usernames):
    username = ((fields[FORNAME][0] + fields[MIDDLENAME][:1] + 
                    fields[SURNAME][]).replace("-","").replace("'",""))
    username = original_name = username[:8].lower()
    count = 1
    while username in usernames:
        username = "{0}{1}".format(original_name, count)
        count += 1
    usernames.add(username)
    return username

def print_users(users):
    namewidth = 32
    usernamewidth = 9

    print("{0:<{nw}} {1:^6} {2:{uw}}".format(
            "Name", "ID", "Username", nw=namewidth, uw=usernamewidth))
    print("{0:-<{uw}} {0:-<6} {0:-<{uw}}".format(
            "", nw=namewidth, uw=usernamewidth))

    for key in sorted(users):
        user = users[key]
        initial = ""
        if user.middlename:
            initial = " " + user.middlename[0]
        name = "{0.surname}, {0.forename}{1}".format(user, initial)
        print("{0:<.{nw}} ({1.id:4}) {1.username:{uw}}".format(
                name, user, nw=namewidth, uw=usernamewidth))

main()



-----------1st EFFORT - posted on GitHub
#!/usr/bin/env python
#generate_usernames.py
#text processing - ingest plain text data from external file
#to create usernames

import collections
import sys

ID, FORENAME, MIDDLENAME, SURNAME, DEPARTMENT = range(5)

User = collections.namedtuple("User", "username forename middlename surname id")


def main():
    if len(sys.argv) == 1 or sys.argv[1] in {"-h" "--help"}:
        print("usage: {0} file1 [file2 [... fileN]]".format(sys.argv[0]))
        sys.exit()

    usernames = set()
    users = {}
    for filename in sys.argv[1:]:
        with open(filename, encoding="utf8") as file:
            for line in file:
                line = line.rstrip()
                if line:
                    user = process_line(line, usernames);
                    users[(user.surname.lower(), user.forename.lower(), user.id)] = user
    print_users(users)


def process_line(line, usernames):
    fields = line.split(":")
    username = generate_username(fields, usernames)
    user = User(username, fields[FORENAME], fields[MIDDLENAME], fields[SURNAME], fields[ID])
    return user   


def generate_username(fields, usernames):
    username = ((fields[FORENAME][0] + fields[MIDDLENAME][:1] + 
                fields[SURNAME]).replace("-", "").replace("'", ""))
    username = original_name = username[:8].lower()
    count = 1
    while username in usernames:
        username = "{0}{1}".format(original_name, count)
        count += 1
    usernames.add(username)
    return username


def print_users(users):
    namewidth = 32
    usernamewidth = 9
    print("{0:<{nw}} {1:^6} {2:{uw}}".format("Name", "ID", "Username", nw=namewidth, uw=usernamewidth))
    print("{0:-<{nw}} {0:-<6} {0:-<{uw}}".format("", nw=namewidth, uw=usernamewidth))

    for key in sorted(users):
        user = users[key]
        initial = ""
        if user.middlename:
            initial = " " + user.middlename[0]
        name = "{0.surname}, {0.forename}{1}".format(user, initial)
        print("{0:.<{nw}} ({1.id:4}) {1.username:{uw}}".format(name, user, nw=namewidth, uw=usernamewidth))

main()



data/users_data.txt

1601:Albert:Lukas:Montgomery:Legal
3702:Albert:Lukas:Montgomery:Sales
4730:Nadelle::Landale:Warehousing




Atuls-MBP:python_proginpython3 atulgolhar$ python3 test.py data/users_data.txt
Name                               ID   Username 
-------------------------------- ------ ---------
Landale, Nadelle................ (4730) nlandale 
Montgomery, Albert L............ (1601) almontgo 
Montgomery, Albert L............ (3702) almontgo1

-----------1st EFFORT - posted on GitHub






statistics.py
#Example
#Suppose we have a bunch of data files containing numbers relating to some processing
#we have done, and want to produce some basic statistics to give us some kind of overview
#of the data. Each file uses plain text (ASCII encoding) with one or more numbers
#per line (whitespace separated).
#Here is an example of ths kind of output we want to produce:
count     = 183
mean      = 130.56
median    = 43.00
mode      = [5.00, 7.00, 50.00]
std. dev  = 235.01
#Here we read 183 numbers, with 5, 7, and 50 occuring most frequently, and with 
#sample standard deviation of 235.01

#The statistics themselves are held in a named tuple called Statistics
Statistics = collections.namedtuple("Statistics", "mean mode median std_dev")


#The main function also serves as an overview of the program's structure:
def main():
    if len(sys.argv) == 1 or sys.argv[1] in {"-h", "--help"}:
        print("usage: {} file1 [file2 [... fileN]]".format(sys.argv[0]))
        sys.exit()

    numbers = []
    frequencies = collections.defaultdict(int)      #int() factory function
    for filename in sys.argv[1:]:
        read_data(filename, numbers, frequencies)   #read in all the data
    if numbers:
        statistics = calculate_statistics(numbers, frequencies)
        print_results(len(numbers), statistics)
    else:
        print("no numbers found")

#We store all the numbers from all the files in the numbers list.
#To calculate the mode numbers, we need to know how many times each number
#occurs, so we create a default dictionary using the int() factory function
#to keep track of the counts.

#We iterate over each filename and read in its data.
#We pass the list and default dictionary as additional parameters so that the
#read_data() function can update them.
#Once we have read all the data, assuming some numbers were successfully read,
#we call calculate_statistics()
#This returns a named tuple of type Statistics which we then use to print 
#the results.

def read_data(filename, numbers, frequencies):
    for lino, line in enumerate(open(filename, encoding="ascii"), start=1):
        for x in line.split():
            try:
                number = float(x)
                numbers.append(number)
                frequencies[number] += 1
            except ValueError as err:
                print("{0}:{1}: skipping {2}: {3}".format(filename, lino, x, err))
#We split every line on whitespace
#for each item we attempt to convert it to a float.
#If a conversion succeeds, as it will for integers and for floating-point 
#numbers in both decimal and exponential notations, then we add the number
#to the numbers list and update the frequencies default dictionary.
#Note that if we had used the plain dict, then the updating code would have been
frequencies[number] = frequencies.get(number,0) +1
#If a conversion fails, we output the line number (starting from line 1
#as is traditional for text files). We also output the text we attempted
#to convert and the ValueError exception's error text.

def calculate_statistics(numbers, frequencies):
    mean = sum(numbers) / len(numbers)
    mode = calculate_mode(frequencies, 3)
    median = calculate_median(numbers)
    std_dev = calculate_std_dev(numbers, mean)
    return Statistics(mean, mode, median, std_dev)  #return a named tuple
#This function is used to gather all the statistics together.
#Because the mean ("average") is so easy to calculate, we do so directly here.
#For the other statistics we call dedicated functions, and at the end we return a 
#Statistics named tuple object that contains the four statistics we have calculated.

#BASIC
def calculate_mode(frequencies, maximum_modes):
    highest_frequency = max(frequencies.values())
    mode = []
    if not ():
        mode = None
    else: 
        mode.sort()
    return mode

#DETAILED
def calculate_mode(frequencies, maximum_modes):
    highest_frequency = max(frequencies.values())
    mode = [number for number, frequency in frequencies.items() if math.fabs(frequency - highest_frequency) <= sys.float_info.epsilon]
    if not (1 <= len(mode) <= maximum_modes):
        mode = None
    else:
        mode.sort()
    return mode
#There may be more than one most-frequently occurring number, so in addition to 
#the dictionary of frequencies, this function also requires the caller to specify
#the maximum number of modes that are acceptable.
#The calculate_statistics() function is the caller, and it specified a maximum
#of 3 modes.

#The max() function is used to find the highest value in the frequencies dictionary.
#Then we use a list comprehension to create a list of those modes whose frequency
#equals the highest value. Since the numbers may be floating-point we compare
#the difference in absolute values 
using math.fabs() since it gives better results than abs()
#with the smallest number the machine can measure.

#If the number of modes is 0 or greater than the maximum nodes that are acceptable ie 3,
#then a mode of None is returned; otherwise a sorted list of modes is returned

def calculate_median(numbers):
    numbers = sorted(numbers)       #ascending order
    middle = len(numbers) // 2      #truncacting integer division to find index position of middle 
    median = numbers[middle]        #extract middle number and store as median
    if len(numbers) % 2 == 0:       #if number of numbers is even
        median = (median + numbers[middle - 1]) / 2 #median = middle number
    return median
#The median (ie middle value) is the value that occurs in the middle
#if the numbers are arranged in order ie odd, except when the number of numbers is even,
#in which the middle falls between two numbers, so in that case the median is the 
#middle of those two middle numbers.

#ATUL - if you have an even amount of numbers then the middle falls between two numbers
#so in this case the mediam is the mean of those two numbers.

#We begin by sorting the numbers into ascending order. Then we use truncating integer division
#to find the index position of the middle number, which we
#extract and store as median. If the number of numbers is even, we make the median
#the mean of the two middle numbers.

def calculate_std_dev(numbers, mean):
    total = 0
    for number in numbers:                    #loop to aggreate sum of squares
        total += ((number - mean) ** 2)         #Sum of the squares individual calculation
    variance = total / (len(numbers) - 1)
    return math.sqrt(variance)
#the sample standard deviation is a measure of dispersion, that is, how far the
#numbers differ from the mean. This function calculates the sample standard deviation
#using the formula s = sqrt[ (SUM(x - mean_x) **2) / (n - 1) ]
#where x is each number, mean_x is the mean, and n is the number of numbers.

def print_results(count, statistics):
    real = "9.2f"

    if statistics.mode is None:
        modeline = ""
    elif len(statistics.mode) == 1:
        modeline = "mode     = {0:{fmt}}\n".format(statistics.mode[0], fmt=real)
    else:
        modeline = ("mode     = [" + ", ".join(["{0:.2f}".format(m) for m in statistics.mode]) + "]\n")
#                                           joining them          list comprehension here
    print("""\
count       = {0:6}
mean        = {1.mean:{fmt}}
median      = {1.median:{fmt}}
{2}\
std. dev.   = {1.std_dev:{fmt}}""".format(count, statistics, modeline, fmt=real))
#Most of this function deals with formatting the modes list into the modeline string.
#If there are no modes, the mode line is not printed at all.

#If there is one mode, the mode list has just one item (mode[0]) which is printed
#using the same format as is used for the other statistics.

#If there are several modes, we print them as a list with each one formatted
#appropriately. This is done using a list comprehension to produce a list of
#mode strings and then joining all the strings in the list together with "," in
#between each one.

#Print here is easy b/c we used a named tuple. This lets us access the statistics
#in the statistics object using names rather than numeric indexes and thanks to
#Python's triple-quoted strings, we can layout the text to printed in an
#understandable way.

#One subtle point to make here. The modes are printed as format item {2}, which
#is followed by a backslash. The backslash escapes the newline, so if the mode
#is the empty string then no blank line will appear.
#And it is b/c we have escaped the newline that we must put \n at the end of the
#modeline string if is is not empty.




#BASIC
statistics.py
#!/usr/bin/env python3

import collections
import math
import sys

Statistics = collections.namedtuple()

def main():

def read_data():

def calculate_statistics():

def calculate_mode():

def calculate_median():

def calculate_std_dev():

def print_results():

main()




            ======ATUL 1st EFFORT AT CODING NOTES=======
            #!/usr/bin/env python
            #statistics.py
            #ingest plain text (ASCII encoding) files and gives overview of basic data statistics

            import sys
            import collections
            import math


            Statistics = collections.namedtuple("Statistics", "mean mode median std_dev")

            def main():
                if len(sys.argv) == 1 or sys.argv[1] in {"-h", "--help"}:
                    print("usage: {0} file1 [file2 [... fileN]]".format(sys.argv[0]))
                    sys.exit()

                numbers = []
                frequencies = collections.defaultdict(int)
                for filename in sys.argv[1:]:
                    read_data(filename, numbers, frequencies)
                if numbers:
                    statistics = calculate_statistics(numbers, frequencies)
                    print_results(len(numbers), statistics)
                else:
                    print("no numbers found")


            def read_data(filename, numbers, frequencies):
                for lino, line in enumerate(filename, encoding="ascii", start=1):
                    for x in line.split():
                        try:
                            number = float(x)
                            numbers.append(number)
                            frequencies[number] += 1
                        except ValueError as err:
                            print("{0}:{1}: skipping {2}: {3}".format(filename, lino, x, err))


            def calculate_statistics():
                mean = sum(numbers) / len(numbers)
                mode = calculate_mode(frequencies, 3)       #specified max # of possible modes
                median = calculate_median(numbers)
                std_dev = calculate_std_dev(numbers, mean)
                return Statistics(mean, mode, median, std_dev)


            def calculate_mode(frequencies, maximum_modes):
                highest_frequency = max(frequencies.values())
                mode = [number for number, frequency in frequencies.items() if math.fabs(frequency - highest_frequency) <= sys.float_info.epsilon]
                if not (1 <= len(mode) <= maximum_modes):
                    mode = None
                else:
                    mode.sort()
                return mode

            def calculate_median(numbers):
                numbers = sorted(numbers)
                middle = len(numbers) // 2
                median = numbers[middle]
                if len(numbers) % 2 == 0:
                    median = (median + numbers[middle - 1]) / 2
                return median


            def calculate_std_dev(numbers, mean):
                total = 0
                for number in numbers:
                    total += ((number - mean) ** 2)
                variance = total / (len(numbers) - 1)
                return math.sqrt(variance)


            def print_results(count, statistics):
                real = "9.2f"

                if statistics.mode is None:
                    modeline = ""
                elif len(statistics.mode) == 1:
                    modeline = "mode    = {0:{fmt}}\n".format(statistics.mode[0].fmt=real)
                else:
                    modeline = "mode    = [" + ", ".join(["{0:.2f}".format(m) for m in statistics.mode)] + "]\n")
                print("""   
                    count       = {0:6}
                    mean        = {1.mean:{fmt}} 
                    median      = {1.median:{fmt}}
                    [2]\
                    std. dev.   = {1.std_dev:{fmt}}""").format(count, statistics.modeline, fmt=real))





            main()


            ============================================




#DETAIL
statistics.py
#!/usr/bin/env python3

import collections
import math
import sys

Statistics = collections.namedtuple("Statistics", "mean mode median std_dev")

def main():
    if len(sys.argv) == 1 or sys.argv[1] in {"-h", "--help"}:
        print("usage: {0} file1 [file2 [... fileN]]".format(sys.argv[0]))
        sys.exit()

    numbers = []
    frequencies = collections.defaultdict(int)
    for filename in sys.argv[1:]:
        read_data(filename, numbers, frequencies)
    if numbers:
        statistics = calculate_statistics(numbers, frequencies)
        print_results(len(numbers), statistics)
    else:
        print("no numbers found")

def read_data(filename, numbers, frequencies):
    with open(filename, encoding="ascii") as file:
        for lino, line in enumerate(file, start=1):
            for x in line.split():
                try:
                    number = float(x)
                    numbers.append(number)
                    frequencies[number] += 1
                except ValueError as err:
                    print("{filename}:{lino}: skipping {x}: {err}".format(**locals()))

def calculate_statistics(numbers, frequencies):
    mean = sum(numbers)  len(numbers)
    mode = calculate_mode(frequencies, 3)
    median = calculate_median(numbers)
    std_dev = calculate_std_dev(numbers, mean)
    return Statistics(mean, mode, median, std_dev)

def calculate_mode(frequencies, maximum_modes):
    highest_frequency = max(frequencies.values())
    mode = [number for number, frequency in frequencies.items() if frequency == highest_frequency]
    if not (1 <= len(mode) <= maximum_modes):
        mode = None
    else:
        mode.sort()
    return mode

def calculate_median(numbers):
    mumbers = sorted(numbers)
    middle = len(numbers) // 2
    median = numbers[middle]
    if len(numbers) % 2 == 0:
        median = (median + numbers[middle - 1]) / 2
    return median

def calculate_std_dev(numbers, mean):
    total = 0
    for number in numbers:
        total += ((number - mean) ** 2)
    variance = total / (len(numbers) - 1)
    return math.sqrt(variance)

def print_results(count, statistics):
    real = "9.2f"

    if statistics.mode is None:
        modeline = ""
    elif len(statistics.mode) == 1:
        modeline = "mode        = {0:{fmt}}\n".format(statistics.mode[0], fmt=real)
    else:
        modeline = ("mode       = [" + ", ".join([ .format() for m in statistics.mode])
    print   ("""\
count       = {0:6}
mean        = {mean:{fmt}}
median      = {median:{fmt}}
{1}\
std. dev.   =  {std_dev:{fmt}}""".format(conunt, modeline, fmt=real, **statistics._asdict()))


main()




-----------did not work, yielding formatting error
#statistics_print_results_question.py

def print_results(count, statistics):
    real = "9.2f"

    if statistics.mode is None:
        modeline = ""
    elif len(statistics.mode) == 1:
        modeline = "mode    = {0:{fmt}}\n".format(statistics.mode[0], fmt=real)
    else:
        modeline = "mode    = [" + ", ".join(["{0:.2f}".format(m) for m in statistics.mode]) + "]\n")
    print("""\   
        count       = {0:6}
        mean        = {mean:{fmt}} 
        median      = {median:{fmt}}
        {1}\
        std. dev.   = {std_dev:{fmt}}""").format(count, modeline, fmt=real, **statistics._asdict()))
-----------




#random sample of numbers
sample_numbers = random.sample(range(1,100), 5)
sample_numbers

                        >>> sample_numbers = random.sample(range(1,100), 5)
                        >>> sample_numbers
                        [26, 24, 22, 97, 19]



#random_numbers1.txt
#note commas cause error
data/random_numbers1.txt:8: skipping 11,: could not convert string to float: '11,'
data/random_numbers1.txt:8: skipping 18,: could not convert string to float: '18,'
count     =      4
mean      =     47.00
median    =     44.00
std. dev. =     37.98



#random_numbers2.txt
#note no commas, just numbers
Atuls-MBP:python_proginpython3 atulgolhar$ python3 test.py data/random_numbers2.txt
count     =      5
mean      =     16.40
median    =     13.00
std. dev. =     10.09
Atuls-MBP:python_proginpython3 atulgolhar$ 



Atuls-MBP:python_proginpython3 atulgolhar$ python3 test.py data/random_numbers2.txt
data/random_numbers.txt:2: skipping 44,: could not convert string to float: '44,'
data/random_numbers.txt:8: skipping 38,: could not convert string to float: '38,'
data/random_numbers.txt:8: skipping 7,: could not convert string to float: '7,'
data/random_numbers.txt:8: skipping 13,: could not convert string to float: '13,'
data/random_numbers.txt:8: skipping 11,: could not convert string to float: '11,'
data/random_numbers.txt:8: skipping 18,: could not convert string to float: '18,'
count     =      4
mean      =     47.00
median    =     44.00
std. dev. =     37.98



-----------1st EFFORT - posted on GitHub
#!/usr/bin/env python
#statistics.py
#ingest numbers and gives overview of basic data statistics

import sys
import collections
import math


Statistics = collections.namedtuple("Statistics", "mean mode median std_dev")

def main():
    if len(sys.argv) == 1 or sys.argv[1] in {"-h", "--help"}:
        print("usage: {0} file1 [file2 [... fileN]]".format(sys.argv[0]))
        sys.exit()

    numbers = []
    frequencies = collections.defaultdict(int)
    for filename in sys.argv[1:]:
        read_data(filename, numbers, frequencies)
    if numbers:
        statistics = calculate_statistics(numbers, frequencies)
        print_results(len(numbers), statistics)
    else:
        print("no numbers found")


def read_data(filename, numbers, frequencies):
    with open(filename, encoding="ascii") as file:
        for lino, line in enumerate(file, start=1):
            for x in line.split():
                try:
                    number = float(x)
                    numbers.append(number)
                    frequencies[number] += 1
                except ValueError as err:
                    print("{filename}:{lino}: skipping {x}: {err}".format(**locals()))


def calculate_statistics(numbers, frequencies):
    mean = sum(numbers) / len(numbers)
    mode = calculate_mode(frequencies, 3)       #specified max # of possible modes
    median = calculate_median(numbers)
    std_dev = calculate_std_dev(numbers, mean)
    return Statistics(mean, mode, median, std_dev)


def calculate_mode(frequencies, maximum_modes):
    highest_frequency = max(frequencies.values())
    mode = [number for number, frequency in frequencies.items() if frequency == highest_frequency]
    if not (1 <= len(mode) <= maximum_modes):
        mode = None
    else:
        mode.sort()
    return mode


def calculate_median(numbers):
    numbers = sorted(numbers)
    middle = len(numbers) // 2
    median = numbers[middle]
    if len(numbers) % 2 == 0:
        median = (median + numbers[middle - 1]) / 2
    return median


def calculate_std_dev(numbers, mean):
    total = 0
    for number in numbers:
        total += ((number - mean) ** 2)
    variance = total / (len(numbers) - 1)
    return math.sqrt(variance)


def print_results(count, statistics):
    real = "9.2f"

    if statistics.mode is None:
        modeline = ""
    elif len(statistics.mode) == 1:
        modeline = "mode      = {0:{fmt}}\n".format(
                statistics.mode[0], fmt=real)
    else:
        modeline = ("mode      = [" +
                    ", ".join(["{0:.2f}".format(m)
                    for m in statistics.mode]) + "]\n")

    print("""\
count     = {0:6}
mean      = {mean:{fmt}}
median    = {median:{fmt}}
{1}\
std. dev. = {std_dev:{fmt}}""".format(
    count, modeline, fmt=real, **statistics._asdict()))


main()
-----------1st EFFORT - posted on GitHub






#Reminder of topics<===========
CHAPTER 3 Collection Data Types
Sequence Types
    Tuples
    Named Tuples
    Lists
        List Comprehensions
    Set Types
        Sets 
            Set Comprehensions
        Frozen Sets 
Mapping Types 
    Dictionaries
        Dictionary Comprehensions
    Default Dictionaries 
Iterating and Copying Collections
    Iterators and Iterable Operation and Functions
    Copying Collections
Examples 
    generate_usernames.py
    statistics.py 
Summary
Exercises


===============
Summary Chapter 3
===============
#We covered all Python built-in collection types and some types from standard library.
#We covered the collection sequence types, tuple, collections.namedtuple, and list, 
#which support the same slicing and striding syntax as strings.
#We also covered the set types, set and frozenset, and the mapping types, dict and
#collections.defaultdict

#We saw how to use the named tuples provided by Python's standard library to 
#create simple custom tuple data types whose items can be accessed by index
#position, or more conveniently by name.
#We also saw how to create constants by using variables with all uppercase names.

#In the coverage of lists, we say that everything that can be done to tuples can
#be done to lists. And thanks to lists being mutable, they offer considerably more
#functionality than tuples. This includes methods that modify the list and ability
#to have slices on the left hand side of an assignment, to provide insertion, 
#replacement, and deletion of slices. Lists are ideal for holding sequences of
#items, especially if we need fast access by index position.

#When we discussed set and frozenset types, we noted that they may contain only
#hashable items. Sets provide fast membership testing and are useful for filtering
#out duplicate data.

#Dictionaries are in some ways similar to sets, for example, their keys must
#be hashable and are unique just like the items in a set. But dictionaries hold
#key-value pairs, whose values can be of any type. The dictionary coverage
#included the dict.get() and dict.setdefault() methods, and the coverage of
#default dictionaries showed an alternative to use these methods. Like sets,
#dicationaries provide very fast membership testing and fast access by key.

#Lists, sets, and dictionaries all offer compact comprehension syntaxes
#that can be used to create collections of these types from iterables (which
#themselves can be comprehensions), and with conditions attached if required.
#The range() and zip() functions are frequently used in the creation of
#collections, both in conventional for...in loops and in comprehensions.

#Items can be deleted from the mutable collection types using relevant
#methods such as list.pop() and set.discard(), or using del, for example,
#del d[k] to delete an item with key k from dictionary d.

#Python's use of object references makes assignment extremely efficient, but it
#also means that objects are not copied (in memory) when the assignment operator (=)
#is used. We saw differences between shallow and deep copying, and later on saw
#how lists can be shallow-copied using a slice of the entire list, L[:], and
#how dictionaries can be shallow-copied using the dict.copy() method.
#Any copyable object can be copied using functions from the copy module, with
#copy.copy() performing a shallow copy, and copy.deepcopy() performing a deep copy.

#We introduced Python's highly optimized sorted() function. This function is used
#a lot in Python programming, b/c Python does not provide any instrinsically
#ordered collection data types, so WHEN we need to iterate over collections
#in sorted order, we use sorted().

#We introduced need to read in collection from files or write to collections to file.
#Full coverage of file handling is in Chapter 7.
#Chapter 11 offers additional means of providing data persistence.

#Next Chapter
control structures
exception handling
assert statement
creating custom functions --> versatile argument handling facilities


Exercises Chapter 3

1)#Modify the external_sites.py program to use a default dictionary. This is an easy
#change requiring an additional import, and changes just two other lines
external_sites_ans.py

#CODE HERE
external_sites.py
then
external_sites_ans.py


external_sites.py
#!/usr/bine/env python3
import sys

sites = {}
for filename in sys.argv[1:]:
    with open(filename) as file:
        for line in file:
            i = 0
            while True:
                site = None
                i = line.find("http://", i)
                if i > -1:
                    i += len("http://")
                    for j in range(i, len(line)):
                        if not (line[j].isalnum() or line[j] in ".-"):
                            site = line[i:j].lower()
                            break
                    if site and "." in site:
                        sites.setdefault(site, set()).add(filename)
                    i = j
                else:
                    break

for site in sorted(sites):
    print("{0} is referred to in:".format(site))
    for filename in sorted(sites[site], key=str.lower):
        print("     {0}".format(filename))


#CODE HERE
external_sites_ans.py
#!/usr/bine/env python3
import collections                                      #NEW
import sys

sites = collections.defaultdict(set)                    #CHANGED
for filename in sys.argv[1:]:
    with open(filename) as file:
        for line in file:
            i = 0
            while True:
                site = None
                i = line.find("http://", i)
                if i > -1:
                    i += len("http://")
                    for j in range(i, len(line)):
                        if not (line[j].isalnum() or line[j] in ".-"):
                            site = line[i:j].lower()
                            break
                    if site and "." in site:
                        sites[site].add(filename)       #CHANGED
                    i = j
                else:
                    break

for site in sorted(sites):
    print("{0} is referred to in:".format(site))
    for filename in sorted(sites[site], key=str.lower):
        print("     {0}".format(filename))




-----------1st EFFORT - posted on GitHub
#!/usr/bin/env python3
#external_sites_ans.py

import collections
import sys


sites = collections.defaultdict(set)
for filename in sys.argv[1:]:
    with open(filename) as file:
        for line in file:
            i = 0
            while True:
                site = None
                i = line.find("http://", i)
                if i > -1:
                    i += len("http://")
                    for j in range(i, len(line)):
                        if not (line[j].isalnum() or line[j] in ".-"):
                            site = line[i:j].lower()
                            break
                    if site and "." in site:
                        sites[site].add(filename)
                    i = j
                else:
                    break


for site in sorted(sites):
    print("{0} is referred to in:".format(site))
    for filename in sorted(sites[site], key=str.lower):
         print("    {0}".format(filename))
 -----------1st EFFORT - posted on GitHub



2)#Modify the uniquewords2.py program so that it outputs the words in frequency
#of occurences order rather than in alphabetical order. 
#You will need to iterate
#over the dictionary's items and create a tiny two-line function to extract
#each item's value and pass this function as sorted()'s key function.
#Also, the call to print() will need to changed appropriately. This is not difficult
#but it is slighly subtle.
unique-words_ans.py 

#CODE HERE
uniquewords1.py
then
uniquewords2.py 
then
uniquewords_ans.py 




#CODE HERE - OLD
uniquewords1.py
#!/usr/bin/env python3
#outputs words in alaphetical order (does not account for frequency)

import string
import sys

words = {}                             #create dictionary
strip = string.whitespace + string.punctuation + string.digits + "\"'"
for filename in sys.argv[1:]:
    with open(filename) as file:
        for line in file:
            for word in line.lower().split():
                word = word.strip(strip)
                if len(word) > 2:
                    words[word] = words.get(word, 0) + 1
for word in sorted(words):
    print("'{0}' occurs {1} times/counter".format(word, words[word]))


#Note difference from v1 to v2 to v3
#v1 - uses basic dict format. order words alaphetically. no freq noted.
#v2 - uses new dict format (defaultdict(int)). orders words with freq.
#v3 - TBD



#CODE HERE - NEW

#!/usr/bin/env python3
uniquewords2.py 
#same as uniquewords1.py but adds default dictionary

import collections
import string
import sys

words = collections.defaultdict(int)
strip = string.whitespace + string.punctuation + string.digits + "\"'"
for filename in sys.argv[1:]:
    with open(filename) as file:
        for line in file:
            for word in line.lower().split():
                word = word.strip(strip)
                if len(word) > 2:
                    words[word] += 1
for word in sorted(words):
    print("{0} occurs {1} times".format(word, words[word]))


-----------1st EFFORT - posted on GitHub
#!/usr/bin/env python3
#uniquewords2.py 
#same as uniquewords1.py but adds default dictionary

import collections
import string
import sys


words = collections.defaultdict(int)
strip = string.whitespace + string.punctuation + string.digits + "\"'"
for filename in sys.argv[1:]:
    with open(filename) as file:
        for line in file:
            for word in line.lower().split():
                word = word.strip(strip)
                if len(word) > 2:
                    words[word] += 1
for word in sorted(words):
    print("{0} occurs {1} times".format(word, words[word]))
-----------1st EFFORT - posted on GitHub



#CODE HERE
uniquewords_ans.py 
#!/usr/bin/env python3

import collections
import string
import sys


def by_value(item):
    return item[1]


words = collections.defaultdict(int)
strip = string.whitespace + string.punctuation + string.digits + "\"'"
for filename in sys.argv[1:]:
    with open(filename) as file:
        for line in file:
            for word in line.lower().split():
                word = word.strip(strip)
                if len(word) > 2:
                    words[word] += 1
for word, count in sorted(words.items(), key=by_value):
    print("{0} occurs {1} times".format(word, count))




-----------1st EFFORT - posted on GitHub
#!/usr/bin/env python3
#uniquewords_ans.py 

#execution python3 uniquewords_ans.py data/filename.txt
#same as uniquewords2.py but adds default dictionary and orders word frequency


import collections
import string
import sys


def by_value(item):
    return item[1]


words = collections.defaultdict(int)
strip = string.whitespace + string.punctuation + string.digits + "\"'"
for filename in sys.argv[1:]:
    with open(filename) as file:
        for line in file:
            for word in line.lower().split():
                word = word.strip(strip)
                if len(word) > 2:
                    words[word] += 1
for word, count in sorted(words.items(), key=by_value):
    print("{0} occurs {1} times".format(word, count))
-----------1st EFFORT - posted on GitHub



3)#Modify the 
generate_usernames.py program #so that it prints the details of two 
#users per line, limiting names to 17 characters and outputting a form feed
#character after every 64 lines, with the column titles printed at the start of
#every page. Here is a sample of the expected output:

Name              ID      Username     Name               ID      Username
----------------- ------  ------------ -----------------  ------  ------------
Aitkin, Shatha... (2370)  saitkin      Alderson, Nicole.  (8429)  naldeso
Allison, Karma... (8621)  kallison     Alwood, Kole E...  (2095)  kealwood
Annie, Neervana.. (2633)  nannie       Apperson, Lucyann  (7282)  leappers
#This is challenging. You will need to keep column titles in variables so
#that they can be printed when needed, and you will need to tweak the format
#specfications to accommodate the narrower names.

#One way to achieve pagination is to write all the output items to a list and
#then iterate over the list using striding to get the left hand and right hand
#items, using zip() to pair them up. 
#Longer sample data file is provided in
data/users2.txt
data/users_data.txt
#solution
generate_username_ans.py


#CODE HERE
generate_username.py
then
generate_username_ans.py


#CODE HERE
generate_username.py
#!/usr/bin/env python3

import collections
import sys

ID, FORENAME, MIDDLENAME, SURNAME, DEPARTMENT = range(5)

User = collections.namedtuple("User", "username forename middlename surname id")

def main():
    if len(sys.argv) == 1 or sys.argv[1] in {"-h", "--help"}:
        print("usage: {0} file1 [file2 [... fileN]]".format(sys.argv[0]))
        sys.exit()

    usernames = set()
    users = {}
    for filename in sys.argv[1:]:
        with open(filename, encoding="utf8") as file:
            for line in file:
                line = line.rstrip()
                if line:
                    user = process_line(line, usernames)
                    users[(user.surname.lower(), user.forename.lower(), user.id)] = user
    print_users(users)

def process_line(line, usernames):
    fields = line.split(":")
    username = generate_username(fields, usernames)
    user = User(username, fields[FORENAME], fields[MIDDLENAME], fields[SURNAME], fields[ID])
    return user 

def generate_username(fields, usernames):
    username = ((fields[FORENAME][0] + fields[MIDDLENAME][:1] + 
                 fields[SURNAME]).replace("-", "").replace("'", ""))
    username = original_name = uername[:8].lower()
    count = 1
    while username in usernames:
        username = "{0}{1}".format(original_name, count)
        count += 1
    usernames.add(username)
    return username

def print_users(users):
    namewidth = 32
    usernamewidth = 9

    print("{0:<{nw}} {1:^6} {2:{uw}}".format(
            "Name", "ID", "Username", nw=namewidth, uw=usernamewidth))
    print("{0:-<{nw}} {0:-<6} {0:-<{uw}}".format(
            "", nw=namewidth, uw=usernamewidth))

    for key in sorted(users):
        user = users[key]
        initial = ""
        if user.middlename:
            initial = " " + user.middlename[0]
        name = "{0.surname}, {0.forename}{1}".format(user, initial)
        print("{0:.<{nw}} {{1.id:4}} {1.username:{uw}}".format(
            name, user, nw=namewidth, uw=usernamewidth))


main()





#prints details of two users per line, limiting names to 17 characters and 
#outputting a form feed character after every 64 lines, 
#with the column titles printed at the start of every page

Name              ID      Username     Name               ID      Username
----------------- ------  ------------ -----------------  ------  ------------
Aitkin, Shatha... (2370)  saitkin      Alderson, Nicole.  (8429)  naldeso
Allison, Karma... (8621)  kallison     Alwood, Kole E...  (2095)  kealwood
Annie, Neervana.. (2633)  nannie       Apperson, Lucyann  (7282)  leappers

#column titles in variables so that they can be printed when needed
#and you will need to tweak the format specfications to accommodate the narrower names.
#achieve pagination is to write all the output items to a list and
#then iterate over the list using striding to get the left hand and right hand items, 
#using zip() to pair them up.



users_data.txt


1601:Albert:Lukas:Montgomery:Legal
3702:Albert:Lukas:Montgomery:Sales
3701:Albert:Lukas:Montgomery:Sales
3705:Albert:Lukas:Montgomery:Sales
3707:Albert:Lukas:Montgomery:Sales
4730:Nadelle::Landale:Warehousing
2343:Robert::Davis:Distribution
9834:Jimmuy::Dragonitte:Legal
5638:Mike::Newtonperson:Sales
5628:Mike::Newtonperson:Sales
5648:Mike::Newtonperson:Sales
1211:Jennifer::Romanite:Legal
1245:Mary::Liddell:Legal
8723:Bobby::Wednesdayite:Legal



#CODE HERE
generate_username_ans.py

-----------1st EFFORT - posted on GitHub
#!/usr/bin/env python3
#generate_usernames_ans.py
#text processing to create unique user id; ingest user names, dept and ID number

import collections
import sys

ID, FORENAME, MIDDLENAME, SURNAME, DEPARTMENT = range(5)

User = collections.namedtuple("User", "username forename middlename surname id")


def main():
    if len(sys.argv) == 1 or sys.argv[1] in {"-h" "--help"}:
        print("usage: {0} file1 [file2 [... fileN]]".format(sys.argv[0]))
        sys.exit()

    usernames = set()
    users = {}
    for filename in sys.argv[1:]:
        with open(filename, encoding="utf8") as file:
            for line in file:
                line = line.rstrip()
                if line:
                    user = process_line(line, usernames);
                    users[(user.surname.lower(), user.forename.lower(), user.id)] = user
    print_users(users)


def process_line(line, usernames):
    fields = line.split(":")
    username = generate_username(fields, usernames)
    user = User(username, fields[FORENAME], fields[MIDDLENAME], fields[SURNAME], fields[ID])
    return user   


def generate_username(fields, usernames):
    username = ((fields[FORENAME][0] + fields[MIDDLENAME][:1] + 
                fields[SURNAME]).replace("-", "").replace("'", ""))
    username = original_name = username[:8].lower()
    count = 1
    while username in usernames:
        username = "{0}{1}".format(original_name, count)
        count += 1
    usernames.add(username)
    return username


def by_surname_forename(user):
    return user.surname.lower(), user.forname.lower(), user.id


def print_users(users):
    namewidth = 17
    usernamewidth = 9
    columngap = " " * 2

    headline1 = "{0:<{nw}} {1:^6} {2:{uw}}".format("Name", "ID",
         "Username", nw=namewidth, uw=usernamewidth)
    headline2 = "{0:-<{nw}} {0:-<6} {0:-<{uw}}".format("", nw=namewidth, uw=usernamewidth)
    header = (headline1 + columngap + headline1 + "\n" + 
              headline2 + columngap + headline2)

    lines = []
    for key in sorted(users):
        user = users[key]
        initial = ""
        if user.middlename:
            initial = " " + user.middlename[0]
        name = "{0.surname}, {0.forename}{1}".format(user, initial)
        lines.append("{0:.<{nw}} ({1.id:4}) {1.username:{uw}}".format(name, user, 
                        nw=namewidth, uw=usernamewidth))

    lines_per_page = 64
    lino = 0
    for left, right in zip(lines[::2], lines[1::2]):
        if lino == 0:
            print(header)
        print(left + columngap + right)
        lino += 1
        if lino == lines_per_page:
            print("\f")
            lino = 0
    if lines[-1] != right:
        print(lines[-1])


main()
-----------1st EFFORT - posted on GitHub


Atuls-MBP:python_proginpython3 atulgolhar$ python3 test9_author_generate_usersnames_ans.py data/users_data.txt
Name                ID   Username   Name                ID   Username 
----------------- ------ ---------  ----------------- ------ ---------
Davis, Robert.... (2343) rdavis     Dragonitte, Jimmu (9834) jdragoni 
Landale, Nadelle. (4730) nlandale   Liddell, Mary.... (1245) mliddell 
Montgomery, Alber (1601) almontgo   Montgomery, Alber (3702) almontgo1
Newtonperson, Mik (5638) mnewtonp   Romanite, Jennife (1211) jromanit 
Wednesdayite, Bob (8723) bwednesd 


Atuls-MBP:python_proginpython3 atulgolhar$ python3 test1.py data/users_data.txt
Name                ID   Username   Name                ID   Username 
----------------- ------ ---------  ----------------- ------ ---------
Davis, Robert.... (2343) rdavis     Dragonitte, Jimmuy (9834) jdragoni 
Landale, Nadelle. (4730) nlandale   Liddell, Mary.... (1245) mliddell 
Montgomery, Albert L (1601) almontgo   Montgomery, Albert L (3701) almontgo2
Montgomery, Albert L (3702) almontgo1  Montgomery, Albert L (3705) almontgo3
Montgomery, Albert L (3707) almontgo4  Newtonperson, Mike (5628) mnewtonp1
Newtonperson, Mike (5638) mnewtonp   Newtonperson, Mike (5648) mnewtonp2
Romanite, Jennifer (1211) jromanit   Wednesdayite, Bobby (8723) bwednesd 
Atuls-MBP:python_proginpython3 atulgolhar$ 












#Reminder of topics<===========
===============================================================================================
CHAPTER: 4 Control Structures and Functions
CHAPTER BEGIN
===============================================================================================
Control Structures
    Conditional Branching 
    Looping 
Exception Handling
    Catching and Raising Exceptions 
    Custom Exceptions 
Custom Functions 
    Names and Docstrings
    Argument and Parameter Unpacking 
    Accessing Variables in the Global Scope 
    Lambda Functions 
    Assertions
Examples 
        make_html_skeleton.py 
Summary
Exercise - maintain lists of strings in files.

#CODE LISTING
checktags.py
digit_names.py
listkeeper.py
make_html_skeleton.py
noblanks.py
TextUtil.py --> see Chapter 5
Util.py 



===============
    Conditional Branching 
===============

#general syntax
if boolean_expression1:
    suite1
elif boolean_expression2:
    pass                      #Do nothing placeholder
elif boolean_expression3:
    suite3 
elif boolean_expressionN:
    suiteN 
else:
    else_suite

#Can reduce an if...else statment to a single line:
expression1 if boolean_expression1 else expression2

#One common programming pattern is set a variable to default value and then
#change the value if necessary due to request by user or to account for the
#platform on which the program is being run.

offset = 20
if not sys.platform.startswith("win"):
    offset = 10
#so here default is 20
#if windows platform then stay with 20
#if not win ie linux then switch to 10
#if not win ie apple then switch to 10

                        >>> offset = 20
                        >>> import sys
                        >>> if not sys.platform.startswith("win"):
                        ...     offset = 10
                        ... 
                        >>> offset
                        10
#same idea in one line
offset = 20 if sys.platform.startswith("win") else 10

#no parathensis are needed but using them avoids subtle trap
#example want to set width variable to 100 plus extra 10 if
#Margin is True
width = 100 + 10 if margin else 0     #BAD CODE
#when True then margin is 110 but if margin is False then width set to 0
#why? python sees 100 + 10 as part of expression1
expression1 if boolean_expression1 else expression2

                        >>> margin
                        True
                        >>> type(margin)
                        <class 'bool'>
                        >>> width = 100 + 10 if margin else 0
                        >>> width
                        110
                        >>> margin = False
                        >>> width = 100 + 10 if margin else 0
                        >>> width
                        0
#so better solution
width = 100 + (10 if margin else 0)   #default is now 100, and 10 more if True
#so here True --> 100 + 10 = 110
#so here False --> 100

                        >>> width = 100 + 10 if margin else 0
                        >>> width
                        110
                        >>> margin = False
                        >>> width = 100 + 10 if margin else 0
                        >>> width
                        0
                        >>> width = 100 + (10 if margin else 0)
                        >>> width
                        100
                        >>> margin = False
                        >>> width = 100 + (10 if margin else 0)
                        >>> width
                        100

#parenthesis improve message printed for users
print( "".format () )
print( "{0} file{1}".format( (count if count !=0 else "no"), "s" if count != 1 else "" ) )
#output will be
"no files", "1 file", "2 files", "3 files"      #more professional impression



#Reminder of topics<===========
CHAPTER 4 Control Structures and Functions

Control Structures
    Conditional Branching 
    Looping 
Exception Handling
    Catching and Raising Exceptions 
    Custom Exceptions 
Custom Functions 
    Names and Docstrings
    Argument and Parameter Unpacking 
    Accessing Variables in the Global Scope 
    Lambda Functions 
    Assertions
Examples 
        make_html_skeleton.py 
Summary
Exercise - maintain lists of strings in files.


#CODE LISTING
checktags.py
digit_names.py
listkeeper.py
make_html_skeleton.py
noblanks.py
TextUtil.py --> see Chapter 5
Util.py 


===============
    Looping  
===============

while loop 
for...in loop

while Loops
#general syntax

while boolean_expression1:
    while_suite
else:
    else_suite

continue statement
#inside the while block suite, if a continue statement is executed, control is then
#immediately returned to the top of the loop, and the boolean_expression1 is
#evaluated again. 
#NOTE
#1)If the loop is not terminated normally, any optional else clause suite is skipped.
#2)If the loop is terminated normally, then the else clause is executed.

#else suite clause is NOT executed if
    #1)if loop is broken out of due to a break statement
    #2)if return statement gets executed
    #3)if an exception is raised --> here python looks for 
#suitable exception handler (see next section)

#else clause behavior is the same for
    #1)while loop
    #2)for...in loop
    #3)try...except loop

#Lets look at else clause in action now
str.index() and list.index() 
#methods return the index position of given string or item
#or they will raise a ValueError exception if the string or item is not found.
str.find()
#does the same thing but on failure it returns an index -1 as opposed to throwing an exception.
#there is no equivalent method for lists but we can create a function to do this:
def list_find(st, target):
    index = 0
    while index < len(lst):
        if lst[index] == target:
            break
        index += 1
    else:
    index = -1
    return index

#This function searches the given list looking for the target.
#If the target is found then the break statement terminates the loop, thus causing
#the appropriate index position to be returned.
#If the target is not found, the loop runs to completion and terminates normally.
#After normal termination, the else suite is executed and the index position is set
#to -1 and returned.


for...in loop
#full syntax of the for...in loop also includes an optional else clause

for expression in iterable:
    for_suite
else:
    else_suite

#The expression is normally either a single variable or sequence of variables like a tuple
#If a tuple or list is used for the expression, each item is unpacked into the 
#expression's items.

#If a continue statement is executed inside the for...in loop's suite, control
#is immediately passed to the top of the loop and the next iteration begins.
#If the loop runs to completion it terminates, and any else suite is then executed.
#If the loop is broken out of (due to a break or return statement) then control
#is immediately passsed to the staement FOLLOWING the loop and any else statement is skipped.
#If an exception occurs, then Python skips the else clause and looks for a suitable
#exception handler (see next section).

#Example of for...in loop version of the list_find() function
def list_find(lst, target):
    for index, x in enumerate(lst):
        if x == target:
            break
        else:
            index = -1
        return index
#As this code snippet implies, the variables created inside the for...in loop's
#expression continue to exist after the loop has terminated. Like all local
#variables, they cease to exist at the end of their enclosing scope.


#Reminder of topics<===========
CHAPTER 4 Control Structures and Functions

Control Structures
    Conditional Branching 
    Looping 
Exception Handling
    Catching and Raising Exceptions 
    Custom Exceptions 
Custom Functions 
    Names and Docstrings
    Argument and Parameter Unpacking 
    Accessing Variables in the Global Scope 
    Lambda Functions 
    Assertions
Examples 
        make_html_skeleton.py 
Summary
Exercise - maintain lists of strings in files.


#CODE LISTING
checktags.py
digit_names.py
listkeeper.py
make_html_skeleton.py
noblanks.py
TextUtil.py --> see Chapter 5
Util.py 

===============
Exception Handling
===============


===============
    Catching and Raising Exceptions 
===============

#Exceptions are caught using try...except blocks with general syntax
try:
    try_suite
except exception_group1 as variable1:
    except_suite1
except exception_group2 as variable2:
    except_suite2
except exception_group3 as variable3:
    except_suite3
...
except exception_groupN as variableN:
    except_suiteN
else:                                  #Optional block
    else_suite
finally:                               #Optional block
    finally_suite
#There must be at least one except block.
#Else block suite is executed when try block suite finished normally.
#Finally block is always executed at the end.
#Each clouse's exception group can be single exception or parenthesized tuple of expressions.
#For each exception group, the variable part is optional.

#Example
Python Exception Heirarchy

                        object
                          ^
                      BaseException
                          ^
                       Exception
                          ^
ArithmeticError     EnvironmentError    EOFError    LookupError            ValueError
                            ^                              ^
                    IOError OSError                 IndexError KeyError

#Example of incorrect use
>>> try:
...     x = d[5]
... except LookupError:                       #WRONG ORDER
...     print("Lookup error occured")
... except KeyError:
...     print("Invalid key used")
... 
Lookup error occured
>>>
#here dictionary d has no item with key 5, we would want the most specific
#exception KeyError to be raised, rather than the more general LookupError exception.
#But here the KeyError except block will NEVER be reached.
#If a KeyError is raised, the LookupError except block will match it b/c
#LookupError is a base class of KeyError --> why? b/c LookupError appears higher than
#KeyError within the base class of KeyError or said another way that
#LoopupError appears higher than KeyError in the exception heirarchy.
#So when using multiple except blocks, we must always order them 
#from most specific (ie lowest in the heirarchy) to least specific (highest in heirachy)

>>> try:                        #pg165
...     x = d[k/n]
... except Exception:
...     print("Something bad happened")
... 
Something bad happened
>>>
#Bad practice to raise a general Exception b/c too broad thus masking logical errors.
#here we may intended to catch KeyErrors but if n is 0 we unintentionally and silently
#caught a ZeroDivisionError exception.

>>> try:
...     x = d[k/n]
... except:
...     print("Something bad happened")
... 
Something bad happened
#same Bad practice only really broad. Never do it.

#If none of the except blocks match the exception, Python will work its way up the call
#stack looking for a suitable exception handler. If none is found, then the program will
#terminate and print the exception and traceback on the console.

#final version of the list_find() function using exception handling
def list_find(lst, target):
    try:
        index = lst.index(target)
    except ValueError:
        index = -1
    return index
#here we effectively use the try...except block to turn an exception into a return value.
#Same approach can also be used to catch one kind of exception and raise another instead.

#Python offers a simpler try...finally block which is sometimes useful
try:
    try_suite
finally:
    finally_suite
#no matter what happens in the try block suite, the finally block's suite will be
#excuted. Also the with statement used with a context manager (Chapter 8) can be used
#to achieve a similar effect to using a try...finally block.

#One common pattern of use for try...except...finally blocks is for handling
#file errors. See noblanks.py as example of this.
#Example noblanks.py program reads a list of filenames on the command line, and for each
#one produces another file with the same name, but with its extension changed to .nb and
#with the same contents except for no blank lines.
noblanks.py         #pg 166
#here is the program's read_data() function
def read_data(filename):
    lines = []
    fh = None
    try:
        fh = open(filename, encoding="utf-8")
        for line in fh:
            if line.strip():
                lines.append(line)
    except (IOError, OSError) as err:
        print(err)
        return []
    finally:
        if fh is not None:
            fh.close()
    return lines
#We set the file object fh to None b/c it is possible that open() call will fail
#in which case nothing will be assigned to fh (so it stays None) and
#an exception will be raised.
#If one of the exceptions we have specifed does occur (IOError or OSError)
#then after printing the error message, we return an empty list.
#But note that BEFORE returning, the finally block will then be executed and 
#then the exception is passed up the call stack, 
#noting that there is no return value since the function finished as a result
#of the unhandled exception, and in this case, since there is no suitable block to 
#catch the encoding error exception, the program will terminate and print a 
#traceback.

#We could have written the except clause less verbosely
    except EnvironmentError as err:
        print(err)    
        return []
#Note that this works b/c EnvironmentError is the base class for both IOError and OSError.

#In chapter 8, we see a more compact idiom for ensuring that files are closed safely,
#which does NOT require a finally block.


#CODE HERE
noblanks.py



-----------1st EFFORT - posted on GitHub
#!/usr/bin/env python3
#noblanks.py
#ingest text file and writes corresponding .nb files with no blanks.

import os
import sys

def read_data(filename):
    lines = []
    fh = None
    try:
        fh = open(filename, encoding="utf8")
        for line in fh:
            if line.strip():
                lines.append(line)
    except (IOError, OSError) as err:
        print(err)
        return []
    finally:
        if fh is not None:
            fh.close()
    return lines


def write_data(lines, filename):
    fh = None
    try:
        fh = open(filename, "w", encoding="utf8")
        for line in lines:
            fh.write(line)
    except EnvironmentError as err:
        print(err)
    finally:
        if fh is not None:
            fh.close()


if len(sys.argv) < 2:
    print("usage: noblanks.py infile1 [infile2 [... infileN]]")
    sys.exit()


for filename in sys.argv[1:]:
    lines = read_data(filename)
    if lines:
        write_data(lines, os.path.splitext(filename)[0] + ".nb")
-----------1st EFFORT - posted on GitHub



#Reminder of topics<===========
CHAPTER 4 Control Structures and Functions

Control Structures
    Conditional Branching 
    Looping 
Exception Handling
    Catching and Raising Exceptions 
    Custom Exceptions 
Custom Functions 
    Names and Docstrings
    Argument and Parameter Unpacking 
    Accessing Variables in the Global Scope 
    Lambda Functions 
    Assertions
Examples 
        make_html_skeleton.py 
Summary
Exercise - maintain lists of strings in files.


#CODE LISTING
checktags.py
digit_names.py
listkeeper.py
make_html_skeleton.py
noblanks.py
TextUtil.py --> see Chapter 5
Util.py 


===============
    Raising Exceptions 
===============
#Exceptions provide useful means to change flow of control.
#We can take advantage of this by either using built-in exceptions or creating our own.

#Two syntaxes for raising exceptions:
raise exception(args)
raise

===============
    Custom Exceptions
===============

#Custom Exceptions are custom data types (classes). Creating classes is covered in Chapter 6
#but we will show syntax here
class exceptionName(BaseException): pass

#the base class should be Exception or a class that inherits from Exception.

#One use of custom exceptions is to break out of deeply nested loops.
#Example
#we have a table object that holds records (rows) which holds fields (columns) which
#have multiple values (items), so we could search for particular value with code like this:
found False
for row, record in enumerate(table):
    for column, field in enumerate(record):
        for index, item in enumerate(field):
            if item == target:
                found = True
                break
        if found:
            break
    if found:
        break
if found:
    print("found at ({0} {1} {2})".format(row, column, index))
else:
    print("not found")


#these 15 lines of code are complicated by the fact we must break out of each loop
#separately. An alternative solution is to use a custom exception:

class FoundException(Exception): pass

try:
    for row, record in enumerate(table):
        for column, field in enumerate(record):
            for index, item in enumerate(field):
                if item == target:
                    raise FoundException()
except FoundException:
    print("found at ({0} {1} {2})".format(row, column, index))
else:
    print("not found")



#code cut down to 11 lines, much easier to read. If the item is found we raise
#our custom exception and thus the except block's suite is executed and the 
#else block is skipped. And if the item is not found, no exception is raised and
#so the else suite is executed at the end.

#Lets look at another example to see some of the different ways to exception handling
#can be done. All the snippets are taken from the
checktags.py
#program, a program that reads all the HTML files it is given on the command line
#and performs some simple tests to verify that the tags begin with "<" and end with 
#">" and that entities are correctly formed. The program defines four custom exceptions:
class InvalidEntityError(Exception): pass
class InvalidNumericEntityError(InvalidEntityError): pass
class InvalidAlphaEntityError(InvalidEntityError): pass
class InvalidTagContentError(Exception): pass
#the second and third exceptions inherit from the first.
#The parse() function that uses the exceptions is more than 70 lines long, so we
#will only show those parts that are relevant to the exception-handling:
fh = None
try:
    fh = open(filename, encoding="utf-8")
    errors = False
    for lino, line in enumerate(fh, start=1):
        for column, c in enumerate(line, start=1):
        try:
            ...
#the code beings conventionally setting the file object to None and putting
#all the file handling work in a try block.
#The program reads the file line by line and read each line character by character.
#Notice that have two try blocks. 
#Outer one is used to handle file object exceptions
#Inner one is used to handle parsing exceptions
        ...
        elif state == PARSING_ENTITY:
            if c == ";":
                if entity.startswith("#"):
                    if frozenset(entity[1:]) - HEXDIGITS:
                        raise InvalidNumericEntityError()
                elif not entity.isalpha():
                    raise InvalidAlphaEntityError()
        ...
#The function has various states, for example, after reading an ampersand (&) it enters
#the PARSING_ENTITY state, and stores the characters between (but excluding) the
#ampersand and semicolon in the entity string.

#The part of the code shown here handles the case when a semicolon has been found while
#reading an entity. If the entity is numeric (of the form "&#", with hexadecimal digits
#and then ";" for example "&#20AC;") we convert the numeric part of it into a set and
#take away from the set all the hexadecimal digits; if anything is left at least one
#invalid character was present and we raise a custom exception. If the entity is
#alphabetic (of the form "&" with letters and then ";" for example "&copy;") then we
#raise a custom exception if any of its letters are not alphabetic.

          ...
        except (InvalidEntityError, InvalidTagContentError) as err:
            if isinstance(err, InvalidNumericEntityError):
                error = "invalid numeric entity"
            elif isinstance(err, InvalidAlphaEntityError):
                error = "invalid alphabetic entity"

            elif isinstance(err, InvalidTagContentError):
                error = "invalid tag"
            print("ERROR {0} in {1} on line {2} column {3}".format(error, filename, lino, column))
            if skip_on_first_error:
                raise
        ...
#if a parsing exception is raised we catch it in this except block.
#By using the InvalidEntityError base class, we catch both InvalidNumericEntityError
#and InvalidAlphaEntityError exceptions. We then use instance() to check
#which type of exception occurred, and to set the error message accordingly.
#The built-in isinstance() function return True if its first argument is the same type
#as the type (or one of that type's base types) given as its second argument.
#We could have used a separate except block for each of the three custom parsing
#exeptions, but in this case combining them means that we avoided repeating the
#last four lines (from the print() call to raise) in each one.
#The program has two modes of use. 
#If skip_on_first_error is False, the program continues checking a file even 
#after a parsing error has occurred; this can lead to mulitple error messages 
#being output for each file. 
#If skip_on_first_error is True, one a parsing error has occurred, after 
#the (one and only) error message is printed, raise is called to reraise the 
#parsing exception and the outer (per-file) try block is left to catch it.
        ...
        elif state == PARSING_ENTITY:
            raise EOFError("missing ';' at end of " + filename)
        ...
#at the end of parsing a file, we need to check to see whether we have been left
#in the middle of an entity. If we have, we raise an EOFError, the built-in end of
#file exception, but give it our own message text. We could just as easily have raised
#a custom exception.
        except (InvalidEntityError, InvalidTagContentError):
            pass    # Already handled
        except EOFError as err:
            print("ERROR unexpected EOF:", err)
        except EnvironmentError as err:
            print(err)
        finally:
            if fh is not None:
                fh.close()
#for the outer try block we have used separate except blocks since the behavior we want
#varies.
#If we have a parsing exception, we know that an error message has already
#been output and the purpose is simply to break out of reading the file and to move
#on to the next file, so we dont need to do anything in the exception handler. 
#If we get an EOFError it could be caused by a genuine premature end of file or it could
#be the result of us raising the exception ourselves. 
#In either case, we print an error message, and the exception's text. 
#If an EnvironmentError occurs (ie if an IOError or an OSError occurs), 
#we simply print its message. 
#And finally, no matter what, if the file was opened, we close it.


#CODE HERE
#DETAIL
checktags.py

-----------1st EFFORT - posted on GitHub
#!/usr/bin/env python3
#checktags.py
#reads all the HTML files it is given on the command line
#and performs simple tests to verify that the tags begin "<" and 
#end with ">" and that entities are correctly formed.

import string
import sys


class InvalidEntityError(Exception): pass 
class InvalidNumericEntityError(InvalidEntityError): pass 
class InvalidAlphaEntityError(InvalidEntityError): pass 
class InvalidTagContentError(Exception): pass 


def parse(filename, skip_on_first_error=False):
    HEXDIGITS = frozenset("0123456789ABDCEFabcdef")
    NORMAL, PARSING_TAG, PARSING_ENTITY = range(3)
    state = NORMAL
    entity = ""
    fh = None
    try:
        fh = open(filename, encoding="utf8")
        errors = False
        for lino, line in enumerate(fh, start=1):
            for column, c in enumerate(line, start=1):
                try:
                    if state == NORMAL:
                        if c == "<":
                            state = PARSING_TAG
                        elif c == "&":
                            entity = ""
                            state = PARSING_ENTITY
                    elif state == PARSING_TAG:
                        if c == ">":
                            state = NORMAL
                        elif c =="<":
                            raise InvalidTagContentError()
                    elif state == PARSING_ENTITY:
                        if c == ";":
                            if entity.startswith("#"):
                                if frozneset(entity[1:]) - HEXDIGITS:
                                    raise InvalidNumericEntityError()
                            elif not entity.isalpha():
                                raise InvalidAlphaEntityError()
                            entity = ""
                            state = NORMAL
                        else:
                            if entity.startswith("#"):
                                if c not in HEXDIGITS:
                                    raise InvalidNumericEntityError()
                            elif (entity and c not in string.ascii_letters):
                                raise InvalidAlphaEntityError()
                            entity += c
                except (InvalidEntityError, InvalidTagContentError) as err:
                    if isinstance(err, InvalidNumericEntityError):
                        error = "invalid numeric entity"
                    elif isinstance(err, InvalidAlphaEntityError):
                        error = "invald alphabetic entity"
                    elif isinstance(err, InvalidTagContentError):
                        error = "invalid tag"
                    print("ERROR {0} in {1} on line {2} column {3}".
                            format(error, filename, lino, column))
                    if skip_on_first_error:
                        raise
                    entity = ""
                    state = NORMAL
                    errors = True
        if state == PARSING_TAG:
            raise EOFError("missing '>' at end of " + filename)
        elif state == PARSING_ENTITY:
            raise EORError("missing ';' at end of " + filename)
        if not errors:
            print("OK", filename)
    except (InvalidEntityError, InvalidTagContentError):
        pass #Already handled
    except EORError as err:
        print("ERROR unexpected EOF:", err)
    except EnvironmentError as err:
        print(err)
    finally:
        if fh is not None:
            fh.close()


if len(sys.argv) < 2:
    print("usage: checktags.py infile1 [infile2 [... infileN]]")
    sys.exit()

for filename in sys.argv[1:]:
    parse(filename)
-----------1st EFFORT - posted on GitHub



#Reminder of topics<===========
CHAPTER 4 Control Structures and Functions

Control Structures
    Conditional Branching 
    Looping 
Exception Handling
    Catching and Raising Exceptions 
    Custom Exceptions 
Custom Functions 
    Names and Docstrings
    Argument and Parameter Unpacking 
    Accessing Variables in the Global Scope 
    Lambda Functions 
    Assertions
Examples 
        make_html_skeleton.py 
Summary
Exercise - maintain lists of strings in files.


#CODE LISTING
checktags.py
digit_names.py
listkeeper.py
make_html_skeleton.py
noblanks.py
TextUtil.py --> see Chapter 5
Util.py 


===============
Custom Functions 
===============

#Custom Functions are a means by which we can package up and parameterize functionality.
#Four kinds of functions can be created in Python
#1 global functions
#2 local functions
#3 lambda functions 
#4 methods 

#Every function we have created so far has been a global function. Global objects
#(including functions) are accessible to any code in the same module (ie same .py file) in
#which the object is created. Global objects can also be accessed from other modules (see 
#next Chapter).

#Local functions (also called nested functions) are functions that are defined inside
#other functions. These local functions are visible only to the function where they
#are defined. They are especially useful for creating small helper functions that have no
#use elsewhere. We will first show them in Chapter 7.

#Go to Python online documentation for extensively more info
docs.python.org
#skim the Global Module Index and the Library Reference to see what
#standard library offers
#help is also available in the interpreter --> call help() with the module or data type
#as the argument --> help(str), help(dict.update), help(os) assuming the module has
#been imported ALREADY.

#Once you are familiar with Python, it is good to be reminded what attributes (ie what methods)
#a data type provides --> use the dir() function to find this --> dir(str), dir(os).
#Lambda functions are expressions so they can be created at their point of use but
#they are much more limited than normal functions.
#Methods are functions that are associated with a particular data type and can used ONLY
#in conjunction with the data type --> see Chapter 6 when covering OOP.
#Python provides many built-in functions and the standard library and third party libraries
#add 100s more.

#general syntax to creating a global or local function is  (pg 173)

def functionName(parameters):
    suite

#Parameters are optional. If there are more one, written as sequence of comma-separated
#identifiers or as a sequence of identifier=value pairs.
#for example
#function that calculates the area of a triangle using heron's formula
def heron(a, b, c):
    s =(a + b + c) / 2
    return math.sqrt(s * (s - a) * (s - b) * (s - c))

                        >>> def heron(a, b, c):
                        ...     s = (a + b + c) / 2
                        ...     return math.sqrt(s * (s - a) * (s - b) * (s - c))
                        ... 
                        >>> heron(4, 7, 8)
                        13.997767679169419

#inside the function, each parameter a,b,c is initialized with the corresponding
#value that was passed as an argument. When the function is called, we must supply
#all of the arguments. If we give too many or too few arguments then a TypeError
#exception is raised. When we do this type of call, we are using positional arguments
#b/c each argument passed is set as the value of the parameter in the corresponding
#position.

#Every function in Python returns a value, although it is perfectly acceptable 
#and common to ignore the return value. The return value is either a single value
#or a tuple of values, and the values returned can be collections, so there are no
#practical limitations on what we can return. We can leave a function at any point
#by using the return statement. If we use return with no arguments, or if we dont
#have a return statement at all, the function will return None. In Chapter 6 we will
#cover yield statements which can be used instead of return in certain kinds of functions.


ATUL - practical issues
1 putting import statment inside module implies that the library is NOT inside interpreter
thus need to import all libraries separately from within interpreter

2 print statement needs end=' ' to print on same line
                        print(b)            #prints vertically
                        print(b, end=' ')   #prints horizontally  

                        >>> import test1
                        >>> import string
                        >>> test1.fib1(40)
                        1 2 3 5 8 13 21 34 55 ()






#Some functions have parameters for which there can be a sensible default. For example
#here is a function that counts the letters in a string, defaulting to the ASCII letters

def letter_count(text, letters=string.ascii_letters):
    letters = frozenset(letters)
    count = 0
    for char in text:
        if char in letters:
            count += 1
    return count
#We have specified a default value for the letters parameter by using the 
#parameter=default syntax. This allows us to call letter_count() with just 
#one argument. For example letter_count("Maggie and Hopey")
#so here inside the function this string will be used as text with defailt set to
#string.ascii_letters. We can chanage the default using an extra positional argument
#letter_count("Maggie and Hopey", "aeiouAEIOU") or using a keyword argument such as
#letter_count("Maggie and Hopey", letters="aeiouAEIOU")

#keyword positional argument explained
#parameter syntax does not permit us to follow parameters with default values if those
#parameters dont have default definitions.
def bad(a, b=1, c):   #bad code
#using keyword arguments in the form of name=value
#example --> function that returns the string it is given or if it is longer thatn the 
#specified length, it returns a shortened version with an indicator added:
def shorten(text, length=25, indicator="..."):
    if len(text) > length:
        text = text[:length - len(indictor)] + indicator
    return text
#Examples
#1) Default values were supplied for length and indicator, so they can be omitted.
>>> shorten("The Road")
'The Road'

#2) and 3) we use keyword arguments for both specified parameters so order does not matter.
>>> shorten(length=7, text="The Road")
'The ...'
>>> shorten(text="The Road", length=7)
'The ...'

#Positional argument must preceed Keyword argument
#4) and #5 we mix and redefine keyword arguments but need to maintin the non-keyword order
>>> shorten("The Road", indicator="&", length=7)
'The Ro&'
>>> shorten("The Road", 7, "&")
'The Ro&'

#Note must include "keyword argument" 
>>> shorten("The Road", length=8, "&")
  File "<stdin>", line 1
SyntaxError: positional argument follows keyword argument
>>> shorten("The Road", length=8, indicator="&")
'The Road'

#Mandatory parameter vs optional parameter difference?
#parameter with a default is optional (b/c Python can use default value)
#parameter without no default is mandatory (b/c Python can NOT guess)

#Careful use of default parameter values can make code much cleaner.
#by using mixture of keyword and positional arguments we can be free to write code
#that is much cleaner to read including boolean arguments
open(filename, encoding="utf-8")                      #easer to read
open(filename, "r", None, "utf-8", None, None, True)  #remember all these? Bad Code

#when default values are given, they are created at the time the def statement is
#excuted (ie when the function is created), not when the fucntion is called.
#for immutable arguments like numbers and strings, this does not matter
#for mutable arguments, this is a subtle trap

def append_if_even(x, lst=[]):    #WRONG  (pg 175)
    if x % 2 == 0:
        lst.append(x)
    return lst
#this is WRONG b/c the lst parameter is created when the function is created and
#lst will refer to a new empty list. But if the function is called with only 1 parameter
#then the default list will created using the values for lst back when the function itself
#was created so NO new list is created. This is not what we want. We expect a new empty
#list to be created EACH time the function is called with no second argument.

#corrected version of the append_if_even() function
def append_if_even(x, lst=None):
    if lst is None:
        lst = []
    if x % 2 == 0:
        lst.append(x)
    return lst
#here we create a new list every time the function is called without a list argument.
#And if a list argument is given, we use it.
#And if no list argument is given, lst gets assigned None.
#SO NOTE this uses the CORRECT idiom (rule) for default mutable arguments:
def append_if_even(x, lst=None):
    if lst is None:
        lst = []
    if x % 2== 0:
        lst.append(x)
    return lst
#so here we create a new list every time the function is called without a list argument.
#And if a list argument is given, we use it, just the same as the previous version of the
#function.
#This idiom of having a default of None and creating a fresh object should be used for
#dictionaries, lists, sets, and any other mutable data types that we want to use as
#default arguments.

#slightly shorter version of the same function --> using a conditional expression can
#save a line of code for each parameter that has a mutable default argument
def append_if_even(x, lst=None):
    lst = [] if lst is None else lst 
    if x % 2== 0:
        lst.append(x)
    return lst


#Reminder of topics<===========
CHAPTER 4 Control Structures and Functions

Control Structures
    Conditional Branching 
    Looping 
Exception Handling
    Catching and Raising Exceptions 
    Custom Exceptions 
Custom Functions 
    Names and Docstrings
    Argument and Parameter Unpacking 
    Accessing Variables in the Global Scope 
    Lambda Functions 
    Assertions
Examples 
        make_html_skeleton.py 
Summary
Exercise - maintain lists of strings in files.


#CODE LISTING
checktags.py
digit_names.py
listkeeper.py
make_html_skeleton.py
noblanks.py
TextUtil.py --> see Chapter 5
Util.py 


===============
    Names and Docstrings
===============
#using good names for functions and its parameters goes a long way toward making the
#purpose clear to others

#Rule of Thumb
#1)Use a naming scheme. Use it consistently. UPPERCASE for constants. TitleCase for
#classes, camelCase for GUI functions and methods (Chapter 13), and 
#lowercase or lowercase_with_underscores for everything else.
#2)For all names, avoid abbreviations, unless they are both standardized and widely used.
#3)Be proportional with variable and parameter names: x is good for an x-coordinate. i is
#fine for a loop counter. The name should describe the data's meaning rather than its type
#so amount_due is better than money.
#4)Functions and methods should have names that say what they do or what they return.
#examples of #4
def find(l, s, i=0):              #BAD
def linear_search(l, s, i=0):     #BAD
def first_index_of(sorted_name_list, name, start=0):  #GOOD
#all three functions return the index position of the first occurrence of a name in a list 
#of names, starting from the given starting index and using an algorithm that assumes the
#list if already sorted.
#note for second BAD example --> what happens if the internal search mechanism was changed
#from a linear search to a binary search. This name will confuse the code maintainers.

#none of the three example functions have any way of indicating what happens if the name
#is not found --> do they return a -1 or do they raise an exception? This needs to be 
#documented for users of the function.

docstring 
#We can add documentation to any function using a docstring.
#This is simply a string that comes immediately after the def line and before the 
#function's code proper begins.
#here is the shorten() function reproduced in full

def shorten(text, length=25, indicator="..."):
    """Returns text or a truncated copy with the indicator added

    text is any string; length is the maximum length of the returned
    string (including any indicator); indicator is the string added at
    the end to indicate that the text has been shortened

    >>> shorten("The Road")
    'The Road'
    >>> shorten("No Country for Old Men", 20)
    'No Country for Ol...'
    >>> shorten("Cities of the Plain", 15, "*")
    'Cities of the *'
    """

    if len(text) > length:
        text = text[:length - len(indicator)] + indictor
    return text

#NOTE it is not unusual for a function's documentation to be longer that the function
#itself. One convention is to make the first line of the docstring a brief one-line
#description, then have a blank lkne followed by a full description, and then to 
#reproduce some examples as they would appear if typed in interactively.
#In Chapter 5, we will see how examples in function documentation can be used to 
#provide unit tests.



#Reminder of topics<===========
CHAPTER 4 Control Structures and Functions

Control Structures
    Conditional Branching 
    Looping 
Exception Handling
    Catching and Raising Exceptions 
    Custom Exceptions 
Custom Functions 
    Names and Docstrings
    Argument and Parameter Unpacking 
    Accessing Variables in the Global Scope 
    Lambda Functions 
    Assertions
Examples 
        make_html_skeleton.py 
Summary
Exercise - maintain lists of strings in files.


#CODE LISTING
checktags.py
digit_names.py
listkeeper.py
make_html_skeleton.py
noblanks.py
TextUtil.py --> see Chapter 5
Util.py 


===============
    Argument and Parameter Unpacking 
===============
#From Chapter 3, we saw sequence unpacking operator * to supply positional arguments.
#if we wanted to compute the area of a triangle and had lengths of sides in a list
#could make a call like
heron(sides[0], sides[1], sides[2])
#or simply unpack the list with a simpler call
heron(*sides)

#And if the list (or other sequence) has more items than the function has parameters,
#we can use slicing to extract exactly the right number of arguments.

#We can also use the sequence unpacking operator in a function's parameter list
#which is useful when we want to create functions that can take a variable number
#of positional arguments such as the product() function
def product(*args):
    result = 1
    for arg in args:
        result *= arg 
    return result
    #this function has one parameter called args
    #having the * in front means that insde the function, the args parameter will be a
    #tuple with its items set to however many positional arguments are given.
    #Some examples
    product(1, 2, 3, 4)
    product(5, 3, 8)
    product(11)

>>> def product(*args):
...     result = 1
...     for arg in args:
...     
  
...             result *= arg
...     return result
... 
>>> product
<function product at 0x1011b8400>
>>> type(product)
<class 'function'>
>>> product(1,2,3,4)
24
>>> product(5,3,8)
120
>>> product(11)
11

#We can have keyword arguments following positional arguments.
def sum_of_powers(*args, power=1):
    result = 0
    for arg in args:
        result += arg ** power 
    return result
#this function can be called with just positional arguments
sum_of_powers(1, 3, 5)
>>> sum_of_powers
<function sum_of_powers at 0x1011b8488>
>>> type(sum_of_powers)
<class 'function'>
>>> sum_of_powers(1,3,5)
9
#or can be called with BOTH positional AND keyword arguments
sum_of_powers(1,3,5, power=2)
>>> sum_of_powers(1,3,5, power=2)
35

#It is also possible to use * as a parameter itself.
#Why? this is used to signal that there can be NO positional arguments after the *
#even thought keywords are allowed.
#here is a modified version of heron() that takes exactly three positional arguments
#and has one optional keyword argument.


#function that calculates the area of a triangle using heron's formula
#original
def heron(a, b, c):
    s =(a + b + c) / 2
    return math.sqrt(s * (s - a) * (s - b) * (s - c))

                        NOTE - underlying source code must be IN SCOPE
                        #!/usr/bin/env python3
                        #heron formula = area of triangle

                        #import math

                        def heron(a, b, c):
                            s =(a + b + c) / 2
                            return math.sqrt(s * (s - a) * (s - b) * (s - c))

                        >>> import test     #import from source 1 = test.py
                        >>> import math     #import from source 2 = web (ERROR) NOT IN SCOPE
                        >>> test.heron(3,4,5)
                        Traceback (most recent call last):
                          File "<stdin>", line 1, in <module>
                          File "/Users/atulgolhar/Projects/Python_ProgInPython3/test.py", line 8, in heron
                            return math.sqrt(s * (s - a) * (s - b) * (s - c))
                        NameError: name 'math' is not defined

#modified
def heron2(a, b, c, *, units="meters"):
    s =(a + b + c) / 2
    area = math.sqrt(s * (s - a) * (s - b) * (s - c))
    return "{0} {1}".format(area, units)

>>> import math
>>> def heron2(a, b, c, *, units="meters"):
...     s = (a+b+c) / 2
...     area = math.sqrt(s * (s-a) * (s-b) * (s-c))
...     return "{0} {1}".format(area, units)
... 
>>> heron2
<function heron2 at 0x1010dbae8>
>>> type(heron2)
<class 'function'>
>>> heron2(25, 24, 7)
'84.0 meters'
>>> heron2(41, 9, 40, units="inchesAtul")
'180.0 inchesAtul'

>>> heron2(41, 9, 40, units="inchesAtul")
'180.0 inchesAtul'
>>> heron2(41, 9, 40, units="inches")
'180.0 inches'
>>> heron2(41, 9, 40, "inches")
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: heron2() takes 3 positional arguments but 4 were given
#note here TypeError raised b/c we attempted to pass a 4th argument 
#but function only takes 3.

#Note by making * the first parameter we can prevent any positional arguments
#from being used and force callers to use keyword arguments.
def print_setup(*, paper="Letter", copies=1, color=False):
  pass
#this allows us to call print_setup() with no arguments, and accept the defaults.
#or we can change some or all of the defaults, for example
print_setup(paper="A4", color=True)

#If we attempted to use positional arguments here, then we get a TypeError raised
print_setup("A4")

#Mapping Unpacking Operator
#just as we can unpack a sequence to populate a function's positional arguments, we
#can also unpack a mapping using the mapping unpacking operator called **
#we can use ** to pass a dictionary to the print_setup() function
options = dict(paper="A4", color=True)
print_setup(**options)
#here the dictionary's key-value pairs are unpacked with each key's value 
#being assigned to the parameter whose name is the same as the key.
#Any argument for which the dictionary has no corresponding item is set to
#its default value, BUT if there is no default value, then TypeError is raised.

#Can also use the mapping unpacking operator with parameters. This allows us to
#create functions that will accept many keyword arguments as are given.
#Example --> here is an add_person_details() function that takes Social Security
#number and surname positional arguments, and any number of keyword arguments:
def add_person_details(ssn, surname, **kwargs):
    print(""SSN = ", ssn")
    print("    surname =", surname)
    for key in sorted(kwargs):
        print("     {0} = {1}".format(key, kwargs[key]))
#This function could be called with just two positional arguments, or with
#additional information, for example, 
add_person_details(83272171, "Luther", forename+"Lexis", age=47)
#this provides us a lot of flexibility
#we can accept both a variable number of positional arguments and a
#variable number of keyword arguments such as in-->
#BASIC
def print_args(*args, **kwargs):
    for i, arg in enumerate(args):
        print("".format())
    for key in kwargs:
        print("".format())
#DETAILED
def print_args(*args, **kwargs):
    for i, arg in enumerate(args):
        print("positional argument {0} = {1}".format(i, arg))
    for key in kwargs:
        print("keyword argument {0} = {1}".format(key, kwargs[key]))
#this function just prints the arguments it is given.
#It can be called with no arguments, or with any number of positional
#and keyword arguments.


#Reminder of topics<===========
CHAPTER 4 Control Structures and Functions

Control Structures
    Conditional Branching 
    Looping 
Exception Handling
    Catching and Raising Exceptions 
    Custom Exceptions 
Custom Functions 
    Names and Docstrings
    Argument and Parameter Unpacking 
    Accessing Variables in the Global Scope 
    Lambda Functions 
    Assertions
Examples 
        make_html_skeleton.py 
Summary
Exercise - maintain lists of strings in files.


#CODE LISTING
checktags.py
digit_names.py
listkeeper.py
make_html_skeleton.py
noblanks.py
TextUtil.py --> see Chapter 5
Util.py 


===============
    Accessing Variables in the Global Scope 
===============
#it is sometimes covenient to have a few global variables that are accessed by
#various functions in the program. This is usually okay for "constants" but is
#NOT good practive for variables (although for short one-off programs it is not
#always unreasonable.)


digit_names.py
#Takes an optional language ("en" or "fr") and a number on the command line and
#outputs the names of the digits it is given. So if invoked with "123" on command
#line will produce output "one two three".
#The program has three global variables:
Language = "en"
ENGLISH = {0: "zero", 1: "one", 2: "two", 3: "three", 4: "four", 5: "five",
            6: "six",  7: "seven", 8: "eight", 9: "nine"}
FRENCH = {0: "zero", 1: "un", 2: "deux", 3: "trois", 4: "quatre", 5: "cinq",
            6: "six",  7: "sept", 8: "huit", 9: "neuf"}
#we followed convention that all uppercase variable names indicate constants
#set defauil to English
#Python relies on programmes to create constants.
#elsewhere in the program we access the language variable and us it to choose 
#the appropriate dictionary to use:
def print_digits(digits):
    dictionary = ENGLISH if Language == "en" else FRENCH
    for digit in digits:
        print(dictionary[int(digit)], end=" ")
    print()
#when python encounters the Language variable in this function it looks in
#local scope first (=inside the function) and does NOT find it. So then 
#it looks in the global scope next (inside the .py file) and finds it there.

end=" " #keyword explained as part of the print function call:
#the print() function accepts any number of positional arguments
#and has three keyword arguments 
sep
end 
file 
#all the keyword arguments have defaults -->
#sep parameter's default is a space. If two or more positional arguments are given
#each is printed with the sep in between
#but if there is just one positional argument, then this parameter does nothing.
#end parameter's default is \n which a newline printed at the end of calls to print.
#file parameter's default is sys.stdout --> standard output stream which is 
#usally the console.

#any of the keyword arguments can be given the values we want instead of using the
#defaults.
#For example
#file can be set to a file object that is open for writing or appending.
#both sep and end can be set to other strings, including the empty string.

#If we need to print several items on the same line, one common pattern is to 
#print the items using print() calls where end is set to a suitable separator,
#and then at the end to call print() with no arguments, since this just prints
#a newline.
#For a coding example, see the print_digits() function just ABOVE this.


#Here is the program code main() function
#BASIC
def main():
    if len() == 1 or sys.argv[1] in {}:
        print("".format())
        sys.exit()

    args = sys.argv[1]
    if args[0] in {}:
        global Language
        Language = args.pop()
    print_digits(args.pop())

#DETAILED
def main():
    if len(sys.argv) == 1 or sys.argv[1] in {"-h", "--help"}:
        print("usage: {0} [en|fr] number".format(sys.argv[0]))
        sys.exit()

    args = sys.argv[1:]
    if args[0] in {"en", "fr"}:
        global Language
        Language = args.pop(0)
    print_digits(args.pop(0))
#what stands out here is the use of global statement.
#this statement is used to tell python that a variable exists at the global (file) scope,
#and that assignments to the variable should be applied to the global variable, rather
#than cause a local variable of the SAME name to be created.

#if we did not use the global statement the program would run, BUT when python
#encounted the Language variable in the if statement, it would look for it in the
#local (function) scope, and not finding it would create a NEW lcoal variable called
#Langauage, leaving the global Language UNCHAGED. This subtle bug would show up
#as an error only when the program was run with the "fr" argument. Why then?
#b/c then the local Language variable would be created and set to "fr", but the
#global Language variable used in the print_digits() function would remain
#unchanged as "en".

#So for non-trivial programs, it is best to use global variables except as
#constants, in which case there is no need to use the global statement.
ATUL - MAKE SURE you understand this last issue.

                        #ERROR 
                        Atuls-MBP:python_proginpython3 atulgolhar$ python3
                        Python 3.5.1 (v3.5.1:37a07cee5969, Dec  5 2015, 21:12:44) 
                        [GCC 4.2.1 (Apple Inc. build 5666) (dot 3)] on darwin
                        Type "help", "copyright", "credits" or "license" for more information.
                        >>> import test
                        usage:  [en|fr] number

                        #CORRECT
                        Atuls-MBP:python_proginpython3 atulgolhar$ python3 test.py
                        usage: test.py [en|fr] number

                        Atuls-MBP:python_proginpython3 atulgolhar$ python3 test.py en 3
                        three 
                        Atuls-MBP:python_proginpython3 atulgolhar$ python3 test.py fr 3
                        trois 

                        NOTE - if try to do SAME thing from interpreter, get an ERROR
                        >>> import test en 3
                          File "<stdin>", line 1
                            import test en 3
                                         ^
                        SyntaxError: invalid syntax


#CODE HERE
digit_names.py


-----------1st EFFORT - posted on GitHub
#!/usr/bin/env python3
#digit_names.py
#usage: from CLI filename language number

import sys

language = "en"

ENGLISH = {}

Language = "en"
ENGLISH = {0: "zero", 1: "one", 2: "two", 3: "three", 4: "four", 5: "five",
            6: "six",  7: "seven", 8: "eight", 9: "nine"}
FRENCH = {0: "zero", 1: "un", 2: "deux", 3: "trois", 4: "quatre", 5: "cinq",
            6: "six",  7: "sept", 8: "huit", 9: "neuf"}

def main():
    if len(sys.argv) == 1 or sys.argv[1] in {"-h", "--help"}:
        print("usage: {0} [en|fr] number".format(sys.argv[0]))
        sys.exit()

    args = sys.argv[1:]
    if args[0] in {"en", "fr"}:
        global Language
        Language = args.pop(0)
    print_digits(args.pop(0))

def print_digits(digits):
    dictionary = ENGLISH if Language == "en" else FRENCH
    for digit in digits:
        print(dictionary[int(digit)], end=" ")
    print()

main()
-----------1st EFFORT - posted on GitHub




#Reminder of topics<===========
CHAPTER 4 Control Structures and Functions

Control Structures
    Conditional Branching 
    Looping 
Exception Handling
    Catching and Raising Exceptions 
    Custom Exceptions 
Custom Functions 
    Names and Docstrings
    Argument and Parameter Unpacking 
    Accessing Variables in the Global Scope 
    Lambda Functions 
    Assertions
Examples 
        make_html_skeleton.py 
Summary
Exercise - maintain lists of strings in files.


#CODE LISTING
checktags.py
digit_names.py
listkeeper.py
make_html_skeleton.py
noblanks.py
TextUtil.py --> see Chapter 5
Util.py 

===============
    Lambda Functions 
===============
#lambda functions are created using the following syntax
lambda parameters: expression 

#Parameters are optional and if supplied are normally just comma-separated variables
#names (ie positional arguments)
#The expression can NOT contain branches or loops but yes conditional expressions OK and 
#cannot have a return or yield statement.
#Result of a lambda function is an anonymous function.
#When lambda is called, it returns the result of computing the expression as its result.
#If expression is a tuple, it should be enclosed in paraentheses.

s = lambda x: "" if x == 1 else "s"
                        >>> s = lambda x: "" if x == 1 else "s"
                        >>> s
                        <function <lambda> at 0x1011b86a8>
                        >>> s(2)
                        's'
                        >>> s(1)
                        ''
#the lambda expression s returns an anonymous function which we assign to the variable s
#Any callable variable can be called using parentheses so given the count of files
#processed in some operation we could output a message using the s() function like this:
print("".format())        #BASIC
print("{0} file{1} processed".format(count, s(count)))        #DETAIL

#when use Lambda functions? often used as the key function for the built-in sorted() function
#and for the list.sort() method
#Example
#suppose we have a list of elements as 3-tuples of (group, number, name) --> natural ordering
#and we wanted to sort this list in various ways. Here is an example of how
elements = [(), (), (), ()]       #BASIC
elements = [(2, 12, "Mg"), (1, 11, "Na"), (1, 3, "Li"), (2, 4, "Be")]       #DETAIL

#Now sort this list:
>>> elements = [(2, 12, "Mg"), (1, 11, "Na"), (1, 3, "Li"), (2, 4, "Be")]
>>> sorted(elements)
[(1, 3, 'Li'), (1, 11, 'Na'), (2, 4, 'Be'), (2, 12, 'Mg')]
#so here we can provide a key function alter the sort order.
#To sort by number and name, rather than natural ordering of the group
#we could write a tiny function such as
def ignore0(e): return e[1], e[2]
#this would be provided as the key function
#Creating lots of little functions like this is inconvenient:
def ignore0(e): return f[1], f[2]
def ignore0(e): return g[1], g[2]
def ignore0(e): return h[1], h[2]
#so, frequently used alternatives are a lambda function like this
elements.sort(key=lamdba e:())  #BASIC
elements.sort(key=lamdba e:(e[1], e[2]))  #DETAIL
#more elaborate version offers sorting in case-insensitive name, number order

#Example. Two equal ways to create function that calculates the area of triangle
area = lambda b, h: 0.5 * b * h
#or
def area(b, h):
  return 0.5 * b * h
#note that we can use this call for both code snippets
area(6,5)

                        >>> type(area)
                        <class 'function'>
                        >>> area = lambda b, h: 0.5 * b * h
                        >>> area(6,5)
                        15.0
                        >>> def area(b,h):
                        ...     return 0.5*b*h
                        ... 
                        >>> area(2,3)
                        3.0

#Creating default dictionaries using lambda
#from chapter 3, if we access a default dictionary using a nonexistent key, then a
#suitable item IS CREATED with the given key and with the default value.
#Examples
minus_one_dict = collections.defaultdict(lambda: -1)
point_zero_dict = collections.defaultdict(lambda: (0,0))
message_dict = collections.defaultdict(lambda: "No message available")
#so here if we access minus_one_dict with a nonexistent key, then a new item will
#be created with that given key and value of -1.
#similarly for point_zero_dict then the nonexistent key will have value of the tuuple (0,0)
#similarly for message_dict then the nonexistent key will have string



#Reminder of topics<===========
CHAPTER 4 Control Structures and Functions

Control Structures
    Conditional Branching 
    Looping 
Exception Handling
    Catching and Raising Exceptions 
    Custom Exceptions 
Custom Functions 
    Names and Docstrings
    Argument and Parameter Unpacking 
    Accessing Variables in the Global Scope 
    Lambda Functions 
    Assertions
Examples 
        make_html_skeleton.py 
Summary
Exercise - maintain lists of strings in files.


#CODE LISTING
checktags.py
digit_names.py
listkeeper.py
make_html_skeleton.py
noblanks.py
TextUtil.py --> see Chapter 5
Util.py 

===============
    Assertions
===============
#what happens if a function receives arguments with invalid data?
#what if we make implementation mistake of an algorithm and perform inaccurate computation?
#worst outcome is a silent error --> to avoid this WRITE A TEST (See Chapter 5)
#another way is to state preconditions and postconditions then indicate an error if not met.
#Ideal solution: do both --> use preconditions, postconditions and use tests.

preconditions and postconditions

#use this syntax
assert boolean_expression1, optional_expression2
#If the boolean_expression1 evaluates to False then an AssertionError exception is raised.
#Useful to provide error messages.
#Note assertions are designed for developers, not end users.
#Problems that occur in normal program use such as missing files or invalid command-line
#arguments should be handled by other means such as providing an error or log message.

#Here are two snippets of product() function. Both versions require that the arguments
#passed to them are nonzero, and both consider a call with a 0 argument to be a coding error.
#1st code snippet
def product(*args):                   #pessimistic
    assert all(args), "0 argument"      #checking all INCOMING arguments 
    result = 1                          #why? check is BEFORE computation
    for arg in args:
        result *= arg
    return result

#2nd code snippet
def product(*args):                   #optimistic
    result = 1
    for arg in args:
        result *= arg
    assert result, "0 argument"         #only checks OUTGOING result argument
    return result                       #why? check is AFTER computation

#code snippet #1
                        >>> def product(*args):
                        ...     assert all(args), "0 argument"
                        ...     result = 1
                        ...     for arg in args:
                        ...     
                          
                        ...             result *= arg
                        ...     
                          
                        ...     return result
                        ... 
                        >>> product(2,3,4)
                        24
                        >>> product(0,2,3,4)
                        Traceback (most recent call last):
                            File "<stdin>", line 1, in <module>
                            File "<stdin>", line 2, in product
                        AssertionError: 0 argument
                        
                        Atuls-MBP:python_proginpython3 atulgolhar$ python3
                        Python 3.5.1 (v3.5.1:37a07cee5969, Dec  5 2015, 21:12:44) 
                        [GCC 4.2.1 (Apple Inc. build 5666) (dot 3)] on darwin
                        Type "help", "copyright", "credits" or "license" for more information.
                        >>> import test
                        >>> test.product(2,3,5)
                        30
ATUL - to execute this code
#can NOT execute from Bash b/c no code snippet __name__ = "__main__:"
#can NOT execute from Bash b/c no sys.argv[1] code 
#can YES execute from Interpreter via import test then test.product(2,3,5)
#can YES execute from Interpreter by typing function directly into interpreter

#code snippet #2
                        >>> def product_optimistic(*args):
                        ...     result = 1
                        ...     for arg in args:
                        ...     
                            
                        ...             result *= arg
                        ...     assert result, "0 argument"
                        ...     return result
                        ... 
                        >>> product_optimistic(3,4,5)
                        60
                        >>> product_optimistic(2,3,4,5)
                        120
                        >>> product_optimistic(2,0,4,5)
                        Traceback (most recent call last):
                          File "<stdin>", line 1, in <module>
                          File "<stdin>", line 5, in product_optimistic
                        AssertionError: 0 argument
                        >>> 
#ATUL - NOTE - same error message here!

#so here, if one of these product() functions is called with a 0 argument then an
#AssertionError exception is raised. The output is written to the error stream
#which is sys.stderr which is usually the console.
#Python automatically provides a traceback that gives the
#filename, function, line number, and error message we specified.
#at runtime, we can tell Python not to execute assert statements by throwing them
#away at runtime --> how? run the program at the command line with -0 option
python3 -0 program.py
#Another approach is to set the PYTHONOPTIMIZE environment variable to 0.
#Also, if the docstrings are of no use to our users (and normally they would NOT be
#of use to them), then we can use the -00 option which in effect strips out both
#the assert statements and docstrings. But note that there is NO environment variable
#for setting this option. So some developers take a simplier approach: they produce a
#copy of their program with all the assert statements commented out, and providing
#this passes their tests, they release the assertion-free version.

Example make_html_skeleton.py

#we now draw together some of the techniques covered in this chapter and show in the
#context of a complete example program.
#Very small web sites are often created and maintained by hand
#One way to make this effort slightly more convenient is to have a program that can
#generate skeleton HTML files that can later be fleshed out with content.
#The make_html_skeleton.py program is an interactive program that prompts the user
#for various details and then creates a skeleton HTML file.
#The program's main() function has a loop so that users can create skeleton after
#skeleton, and it retains the common data (ie copyright information) so that users
#do not have to type it more than once.

make_html_skeleton.py

#Transcript of typical interaction:
Make HTML skeleton
Enter you name (for copyright): Harold Pinter 
Enter copyright year [2008]: 2009
Enter filename: career-synopsis
Enter title: Carrer Synopsis 
Enter description (optional): synopsis of the career of Harold Painter
Enter a keyword (optional): playwright
Enter a keyword (optional): actor
Enter a keyword (optional): activist
Enter a keyword (optional):
Enter the stylesheet filename (optional): style
Saved skeleton career-synopsis.html

Create another (y/n)? [y]:

Make HTML Skeleton

Enter you name (for copyright) [Harold Pinter]:
Enter copyright year [2009]:
Enter filename:
Cancelled

Create another (y/n)? n 

#note that for the second skeleton, the name and year had as their defaults
#the values entered previously, so they did not need to be retyped. But no
#default for the filename is provided, so when that was not given the skeleton
#was cancelled.

#Now lets look at the code

import datetime
import xml.sax.saxutils

#datetime module provides some simple functions for creating datetime.date
#and datetime.time objects. The xml.sax.saxutils module has useful
#xml.sax.saxutils.escape() function that takes a string and returns an equivalent
#string with the special HTML characters ("&", "<", and ">") in their escaped
#forms ("&amp;", "&lt;", "&gt;").

#Three global strings are defined; these are used as templates.

COPYRIGHT_TEMPLATE = "Copyright (c) {0} {1}. All rights reserved."

STYLESHEET_TEMPLATE('<link rel="stylesheet" type="text.css" '
                      'media="all" href="{0}" />\n')

HTML_TEMPLATE = """<?xml version="1.0"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" \
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://ww.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<title>{title}</title>
<!-- {copyright} -->
<meta name="Description" content="{description}" />
<meta name="Keywords" content="{keywords}" />
<meta equiv="content-type" content="text/html; charset=utf-8" />
{stylesheet}\
</head>
<body>

</body>
</html>
"""
#these strings will be used as templates in conjunction with the str.format() method.
#In the case HTML_TEMPLATE we have used names rather than index {0} and {1} are used as
#positions for the field while also using 
#names, for example, {title} {copyright} {description} {keywords}.
#We will see shortly that we must use keyword arguments to provide values for these.

class CancelledError(Exception): pass
#one custom exception is defined; and we will see it in use when we look at a couple of
#the program's functions.

#The program's main() function is used to set some initial information, and to provide
#a loop. On each iteration, the user has the chance to enter some information for the
#HTML page they want generated, and after each one they are given the chance to finish.

#BASIC
def main():
    information = dict(name=None, year=datetime.date.today().year, filename=None, title=None, description=None, keywords=None, stylesheet=None)
    while True:
        try:
            print()
            populate_information()
            make_html_skeleton()
        except CancelledError:
            print()
        if(get_string().lower not in {}):
            break

#DETAIL
def main():
    information = dict(name=None, year=datetime.date.today().year, filename=None, 
        title=None, description=None, keywords=None, stylesheet=None)
    while True:
        try:
            print("\nMake HTML Skeleton\n")
            populate_information(information)
            make_html_skeleton(**information)       #unpacking the information dictionary
        except CancelledError:
            print("Cancelled")
        if(get_string("\nCreate another (y/n)?", default="y").lower() not in {"y", "yes"}):
            break       #so if y then skip this break and loop again
                        #so if n then hit this break line which says break loop

#datetime.date.today() function returns datetime.date object that holds today's date
#We just want the year attribute.
#All other items are set to None since there are no sensible defaults that can be set.
#Inside the while loop, program prints a title "\nMake HTML Skeleton\n" then 
#calls the populate_information() function with argument information dictionary.
#this dictionary is updated INSIDE populate_information() function.

#Next, make_html_skeleton() function is called and takes a number of arguments.
#But rather than give explicit values for each argument, we have simply unpacked the 
#information dictionary.
#If the user cancels, for example, by not providing mandatory information, then
#the program prints out "Cancelled".
#At the end of each iteration (whether Cancelled or not), the user is asked whether 
#they want to create another skeleton. If they do not, we break out of the loop.
#And then program terminates.

#BASIC
def populate_information(information):
    name = get_string()
    if not name:
        raise CancelledError()
    year = get_integer()
    if year == 0:
        raise CancelledError()
    filename = get_string()
    if not filename:
        raise CancelledError()
    if not filename.endswith():
        filename += ".html"
    ...
    information.update()

#DETAIL
def populate_information(information):
    name = get_string("Enter you name (for copyright)", "name", information["name"])
    if not name:
        raise CancelledError()
    year = get_integer("Enter copyright year", "year", information["year"], 2000, datetime.date.today().year +1, True)
    if year == 0:
        raise CancelledError()
    filename = get_string("Enter filename", "filename")
    if not filename:
        raise CancelledError()
    if not filename.endswith((".htm", ".html")):
        filename += ".html"
    ...
    information.update(name=name, year=year, filename=filename, title=title, description=description, keywords=keywords, stylesheet=stylesheet)


#We have omitted the code for getting the title and description texts, HTML keywords,
#and the stylesheet file. All of them use the get_string() function that we will look
#at shortly. It is sufficient to note that this function takes a message prompt, the
#"name" of the relevant variable (for use in error messages), and an optional default
#value.  Similarly, get_integer() function takes a message prompt, variable name, 
#default value, minimum and maximum values, and whether 0 is allowed.

#At the end we update the information dictionary with the new values using keyword
#arguments. For each key=value pair the key is the name of a key in the dictionary
#whose value will be replaced with the given value and in this case each value is a 
#variable with the same name as the corresponding key in the dictionary.
#This function has no explicit return value so it returns None. 
#It may also be terminated if a CancelError exception is raised, in which case the 
#exception is passed up the call stack to main() and handled there.

#We will look at the make_html_skeleton() function in two parts.
#BASIC
def make_html_skeleton():
    copyright = COPYRIGHT_TEMPLATE.format()
    title = xml.sax.saxutils.escape()
    description = xml.sax.saxutils.escape()
    keywords = "".join() if keywords else ""
    stylesheet = ()
    html = HTML_TEMPLATE.format()

#DETAIL
def make_html_skeleton(year, name, title, description, keywords, stylesheet, filename):
    copyright = COPYRIGHT_TEMPLATE.format(year, xml.sax.saxutils.escape(name))
    title = xml.sax.saxutils.escape(title)
    description = xml.sax.saxutils.escape(description)
    keywords = ",".join(xml.sax.saxutils.escape(k) for k in keywords]) if keywords else ""
    stylesheet = (STYLESHEET_TEMPLATE.format(stylesheet) if stylesheet else "")
    html = HTML_TEMPLATE.format(title=title, copyright=copyright, description=description, keywords=keywords, stylesheet=stylesheet)

#To get the copyright text we call str.format() on the COPYRIGHT_TEMPLATE, 
#supplying the year and name (suitable HTML escaped) as positional arguments
#to replace {0} and {1}. For the title and description we produce HTML escaped
#copies of their texts.
#For the HTML keywords we have two cases to deal with, and we distinguish them
#using a conditional expression. If no keywords have been entered, we set the 
#keywords string to be empty. Otherwise we use a list comprehension to 
#iterate over all the keywords to produce a new list of strings, with each
#one being HTML escaped. This list is THEN joined into a single string with a 
#comma separating each item using str.join()
#The stylesheet text is created in a similar way to the copyright text, but 
#within the context of a conditional expression so that the text is the empty string
#if no stylesheet is specified.
#The html text is created from the HTML_TEMPLATE, with keyword arguments used to
#provide the data for the replacement fields rather than the positional arguments
#used for the other template strings.

    fh = none
    try:
        fh = open(filename, "w", encoding="utf-8")
        fh.write(html)
    except EnvironmentError as err:
        print("ERROR", err)
    else:
        print("Saved skeleton", filename)
    finally:
        if fh is not None:
            fh.close()
#Once the HTML has been prepared we write it to the file with the given filename.
#We inform the user that the skeleton has been saved - or of the error message if
#something went wrong. As usual we use a finally clause to ensure that the file 
#is closed if it was opened.

def get_string(message, name="string", default=None, minimum_length=0, maxwidth_length=80):
    message += ": " if default is None else " [{0}]: ".format(default)
    while True:
        try:
            line = input(message)
            if not line:
                if default is not None:
                    return default
                if minimum_length == 0:
                    return ""
                else:
                    raise ValueError("{0} may not be empty".format(name))
            if not (minimum_length <= len(line) <= maximum_length):
                raise ValueError()
            return line
        except ValueError as err:
            print("ERROR", err)
#This function has one mandatory argument, message, and four optional arguments.
#BOOKMARK TOPIC 
#If a default value is given we include it in the message string so that the
#user can see the default they would get if they just press Enter without
#typing any text. 
#The rest of the function is enclosed in an infinite loop.
#The loop can be broken out of by the user entering a valid string or by accepting
#the default (if given) by the just pressing Enter.
#The user could also break out of the loop, and indeed out of the entire program, by
#typing Ctrl+C --> this would cause a KeyboardInterrupt exception to be raised, and 
#since this is not handled by any of the program's exception handlers, would cause
#the program to terminate and print a traceback. Should we leave such a loophole?
#If we dont, and there is a bug in our program, we could leave the user stuck in an infinite
#loop with no way out except to kill the process. Unless there is a very strong 
#reason to prevent Ctrl+C from terminating a program, it should not be caught by
#any exception handler.

#Notice that this function is not specific to the make_html_skeleton.py program.
#It could be reused in mamy interactive programs of this type. Such reuse
#could be achieved by copying and pasting, but that would lead to maintenance 
#headaches. In the next chapter, we will see how to create custom modules
#with functionality that can be shared across any number of programs.

def get_integer(message, name="integer", default=None, minimum=0, maximum=100, allow_zero=True):
  ...
#This function is so similar in structure to the get_string() function that 
#it would add nothing to reproduce it here. (It is included in the source code that
#accompanies this book). This allow_zero parameter can be useful when 0 is not a
#valid value but where we want to permit one invalid value to signify that the
#user has cancelled. Another approach would be to pass an invalid default value
#and if that is returned, then take it to mean that the user has cancelled.
#The last statement in the program is simply a call to main()
#overall the program is slightly more than 150 lines and shows several features
# of the Python language introduced in the last 2 chapters.




#CODE HERE
make_html_skeleton.py


TERMINAL


Atuls-MBP:python_proginpython3 atulgolhar$ python3 test.py

Make HTML Skeleton

Enter your name (for copyright): Joe Smith
Enter copyright year [2016]: 1999
ERROR year must be between 2000 and 2017 inclusive (or 0)
Enter copyright year [2016]: 2001
Enter filename: x.py
Enter title: title_of_my_new_thing
Enter description (optional): no long description here, just a short blog
Enter a keyword (optional): long
Enter a keyword (optional): no  
Enter a keyword (optional): 
Enter the stylesheet filename (optional): 
Saved skeleton x.py.html

Create another (y/n)? [y]: n





OUTPUT 

x.py.html

<?xml version="1.0"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<title>title_of_my_new_thing</title>
<!-- Copyright (c) 2001 Joe Smith. All rights reserved. -->
<meta name="Description" content="no long description here, just a short blog" />
<meta name="Keywords" content="long,no" />
<meta equiv="content-type" content="text/html; charset=utf-8" />
</head>
<body>

</body>
</html>




#!/usr/bin/env python3
#make_html_skeleton.py
#usage: generates skeleton HTML framwork file where content can be added later

#transcript of typical interaction:
"""
Make HTML skeleton
Enter you name (for copyright): Harold Pinter 
Enter copyright year [2008]: 2009
Enter filename: career-synopsis
Enter title: Carrer Synopsis 
Enter description (optional): synopsis of the career of Harold Painter
Enter a keyword (optional): playwright
Enter a keyword (optional): actor
Enter a keyword (optional): activist
Enter a keyword (optional):
Enter the stylesheet filename (optional): style
Saved skeleton career-synopsis.html

Create another (y/n)? [y]:

Make HTML Skeleton

Enter you name (for copyright) [Harold Pinter]:
Enter copyright year [2009]:
Enter filename:
Cancelled

Create another (y/n)? n 
"""


import datetime
import xml.sax.saxutils


COPYRIGHT_TEMPLATE = "Copyright (c) {0} {1}. All rights reserved."

STYLESHEET_TEMPLATE = ('<link rel="stylesheet" type="text/css" '
                       'media="all" href="{0}" />\n')

HTML_TEMPLATE = """<?xml version="1.0"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" \
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<title>{title}</title>
<!-- {copyright} -->
<meta name="Description" content="{description}" />
<meta name="Keywords" content="{keywords}" />
<meta equiv="content-type" content="text/html; charset=utf-8" />
{stylesheet}\
</head>
<body>

</body>
</html>
"""

class CancelledError(Exception): pass


def main():
    information = dict(name=None, year=datetime.date.today().year,
                       filename=None, title=None, description=None,
                       keywords=None, stylesheet=None)
    while True:
        try:
            print("\nMake HTML Skeleton\n")
            populate_information(information)
            make_html_skeleton(**information)
        except CancelledError:
            print("Cancelled")
        if (get_string("\nCreate another (y/n)?", default="y").lower()
            not in {"y", "yes"}):
            break


def populate_information(information):
    name = get_string("Enter your name (for copyright)", "name",
                      information["name"])
    if not name:
        raise CancelledError()
    year = get_integer("Enter copyright year", "year",
                       information["year"], 2000,
                       datetime.date.today().year + 1, True)
    if year == 0:
        raise CancelledError()
    filename = get_string("Enter filename", "filename")
    if not filename:
        raise CancelledError()
    if not filename.endswith((".htm", ".html")):
        filename += ".html"
    title = get_string("Enter title", "title")
    if not title:
        raise CancelledError()
    description = get_string("Enter description (optional)",
                             "description")
    keywords = []
    while True:
        keyword = get_string("Enter a keyword (optional)", "keyword")
        if keyword:
            keywords.append(keyword)
        else:
            break
    stylesheet = get_string("Enter the stylesheet filename "
                            "(optional)", "stylesheet")
    if stylesheet and not stylesheet.endswith(".css"):
        stylesheet += ".css"
    information.update(name=name, year=year, filename=filename,
                       title=title, description=description,
                       keywords=keywords, stylesheet=stylesheet)


def make_html_skeleton(year, name, title, description, keywords,
                       stylesheet, filename):
    copyright = COPYRIGHT_TEMPLATE.format(year,
                                    xml.sax.saxutils.escape(name))
    title = xml.sax.saxutils.escape(title)
    description = xml.sax.saxutils.escape(description)
    keywords = ",".join([xml.sax.saxutils.escape(k)
                         for k in keywords]) if keywords else ""
    stylesheet = (STYLESHEET_TEMPLATE.format(stylesheet)
                  if stylesheet else "")
    html = HTML_TEMPLATE.format(**locals())
    fh = None
    try:
        fh = open(filename, "w", encoding="utf8")
        fh.write(html)
    except EnvironmentError as err:
        print("ERROR", err)
    else:
        print("Saved skeleton", filename)
    finally:
        if fh is not None:
            fh.close()


def get_string(message, name="string", default=None,
               minimum_length=0, maximum_length=80):
    message += ": " if default is None else " [{0}]: ".format(default)
    while True:
        try:
            line = input(message)
            if not line:
                if default is not None:
                    return default
                if minimum_length == 0:
                    return ""
                else:
                    raise ValueError("{0} may not be empty".format(
                                     name))
            if not (minimum_length <= len(line) <= maximum_length):
                raise ValueError("{name} must have at least "
                        "{minimum_length} and at most "
                        "{maximum_length} characters".format(
                        **locals()))
            return line
        except ValueError as err:
            print("ERROR", err)


def get_integer(message, name="integer", default=None, minimum=0,
                maximum=100, allow_zero=True):

    class RangeError(Exception): pass

    message += ": " if default is None else " [{0}]: ".format(default)
    while True:
        try:
            line = input(message)
            if not line and default is not None:
                return default
            i = int(line)
            if i == 0:
                if allow_zero:
                    return i
                else:
                    raise RangeError("{0} may not be 0".format(name))
            if not (minimum <= i <= maximum):
                raise RangeError("{name} must be between {minimum} "
                        "and {maximum} inclusive{0}".format(
                        " (or 0)" if allow_zero else "", **locals()))
            return i
        except RangeError as err:
            print("ERROR", err)
        except ValueError as err:
            print("ERROR {0} must be an integer".format(name))


main()










#Reminder of topics<===========
CHAPTER 4 Control Structures and Functions

Control Structures
    Conditional Branching 
    Looping 
Exception Handling
    Catching and Raising Exceptions 
    Custom Exceptions 
Custom Functions 
    Names and Docstrings
    Argument and Parameter Unpacking 
    Accessing Variables in the Global Scope 
    Lambda Functions 
    Assertions
Examples 
        make_html_skeleton.py 
Summary
Exercise - maintain lists of strings in files.


#CODE LISTING
checktags.py
digit_names.py
listkeeper.py
make_html_skeleton.py
noblanks.py
TextUtil.py --> see Chapter 5
Util.py 


===============
Summary Chapter 4
===============

#covered complete syntax for all Python's control structures.
#Most of the chapter was devoted to custom functions. We saw how to create functions.
#And presened rules of thumb for naming functions and their parameters.
#Also swa how to provide documentation for functions.
#Python's versatile parameter syntax and argument passing were covered in detail
#including both fixed and variable numbers of positional and keyword arguments, 
#default values for arguments of both immutable and mutable data types.
#We also briefly recapped sequence unpacking with * and showed how to do 
#mapping unpacking with **.

#If we need to assign a new value to a global variable inside a function, we
#can do so by declaring that the variable is global, thereby preventing Python
#from creating a local variables and assigning to that. In general, though, it is
#best to use global variables only for constants.

#Lambda functions are often used as key functions, or in other contexts where
#functions must be passed as parameters. This chapter showed how to create lamdba
#functions, both as anonymous functions and as a means of creating small named
#one-line functions by assigning them to a variable.

#Covered use of the assert statement. This statement is very useful for specifying
#the preconditions and postconditions that we expect to be true on every use of a 
#function, and can be a real aid to robust programming and bug hunting.

#We covered all the fundamentals of creating functions, but other techniques are 
#available to us. These include creating dynamic functions (creating functions 
#at runtime, possibly with implementations that differ depending on circumstances) Chapter 5
#local (nested) functions --> Chapter 7 and
#recursive functions, generator functions and others in Chapter 8

#Although python has a considerable amount of built-in functionality, and a very
#extensive standard library, it is still likely that we will write some functions
#that would be useful in many of the program we develop.
#Copying and pasting such functions would lead to maintenance nightmares, but
#fortuneately Python provides a clean easy to use solution --> custom modules --> 
#Chapter 5. We will learn how to create our own custom modules with our own 
#functions inside them. We will also see how import functionality from the 
#standard library and from our own modules, and will briefly review what the 
#standard library has to offer so that we can avoid reinventing the wheel.


#Reminder of topics<===========
CHAPTER 4 Control Structures and Functions

Control Structures
    Conditional Branching 
    Looping 
Exception Handling
    Catching and Raising Exceptions 
    Custom Exceptions 
Custom Functions 
    Names and Docstrings
    Argument and Parameter Unpacking 
    Accessing Variables in the Global Scope 
    Lambda Functions 
    Assertions
Examples 
        make_html_skeleton.py 
Summary
Exercise - maintain lists of strings in files.


#CODE LISTING
checktags.py
digit_names.py
listkeeper.py
make_html_skeleton.py
noblanks.py
TextUtil.py --> see Chapter 5
Util.py 


===============
Exercise Chapter 4
===============

#(only 1 program to write)
#Model solution is less than 200 lines of code
listkeeper.py

#two additional
TextUtil.py --> see Chapter 5
Util.py --> appears to not be anywhere in the current text



#Write an interactive program that maintains lists of strings in files
#When the program is run, it should create a list of all the files in the current
#directory that have the .lst extension.
#Use os.listdir(".") to get all the files and filter out those that dont have
#the .lst extension. 
#If there are no matching files then program should prompt
#the user to enter a filename -- adding the .lst extension if the user does not
#enter it. 
#If there are one or more .lst files they should be printed as a numbered
#list starting from 1. 
#The user should be asked to enter the number of the file
#they want to load, or 0, in which case they should be asked to gie a filename
#for the new file.

#If an existing file was specified its items should be read. If the file is empty,
#or if a new file was specified, the program should show a message, "no items are
#in the list".

#If there are no items, two options should be offered: "Add" and "Quit"
#One the list has one or more items, the list should be shown with each item
#numbered from 1, and the options offered should be "Add", "Delete", "Save"
#unless already saved, and "Quit". If the user chooses "Quit" and there are
#unsaved changes they should be given the chance to save.

#Keep the main() function fairly small (less than 30 lines) and use it to provide
#the program's main loop. Write a function to get the new or existing filename 
#(and in the latter case to load the items), and a function to prsent the options
#and get the user's choice of option. Also write functions to add an item,
#delete an item, print a list (or either items or filenames), load the list, and
#save the list. Either copy the get_string() and get_integer() functions from
#make_html_skeleton.py or write your own versions.

#When printing the list or the filenames, print the item numbers using a field
#width of 1 if there are less that ten items, or 2 if there are less than 100 items,
#and of 3 otherwise.

#Keep the items in case-insensitive alphabetical order, and keep track of whether
# the list is "dirty" (has unsaved changes). Offer the "Save" option only if
#the list is dirty and ask the user whether they want to save unsaved changes
#when the quit only if the list is dirty. Adding or deleting an item will make
#the list dirty; saving the list will make it clean again.

#Here is a transcript of a session with the program (with most blank removed, and
#without the "List Keeper" title shown above the list each time):

  Choose filename: movies

  --no items are in the list--
  [A]dd  [Q]uit  [a]: a 
  Add item: Love Actually

  1: Love Actually
  [A]dd [D]elete [S]ave [Q]uit [a]: a
  Add item: About a Boy

  1: About a Boy
  2: Love Actually 
  [A]dd [D]elete [S]ave [Q]uit [a]:
  Add item: Alien 

  1: About a Boy
  2: Alien 
  3: Love Actually
  [A]dd [D]elete [S]ave [Q]uit [a]: k

  ERROR: invalid choice--enter one of the 'AaDdSsQq'
  Press Enter to continue...
  [A]dd [D]elete [S]ave [Q]uit [a]: d 
  Delete item number (or 0 to cancel): 2

  1: About a Boy
  2: Love Actually
  [A]dd [D]elete [S]ave [Q]uit [a]: s 
  Saved 2 items to movies.lst
  Press Enter to continue...

  1: About a Boy
  2: Love Actually
  [A]dd [D]elete [Q]uit [a]:
  Add item: Four Weddings and a Funeral

  1: About a Boy
  2: Four Weddings and a Funeral
  3: Love Actually
  [A]dd [D]elete [S]ave [Q]uit [a]: q 
  Save unsaved changes (y/n) [y]:
  Saved 3 items to movies.lst







#Model solution is in and is less than 200 lines of code
listkeeper.py


#!/usr/bin/env python3
#listkeeper.py
#description HERE



import os


YES = frozenset({"y", "Y", "yes", "Yes", "YES"})


def main():
    dirty = False
    items = []

    filename, items = choose_file()
    if not filename:
        print("Cancelled")
        return

    while True:
        print("\nList Keeper\n")
        print_list(items)
        choice = get_choice(items, dirty)

        if choice in "Aa":
            dirty = add_item(items, dirty)
        elif choice in "Dd":
            dirty = delete_item(items, dirty)
        elif choice in "Ss":
            dirty = save_list(filename, items)
        elif choice in "Qq":
            if (dirty and (get_string("Save unsaved changes (y/n)",
                                      "yes/no", "y") in YES)):
                save_list(filename, items, True)
            break


def choose_file():
    enter_filename = False
    print("\nList Keeper\n")
    files = [x for x in os.listdir(".") if x.endswith(".lst")]
    if not files:
        enter_filename = True
    if not enter_filename:
        print_list(files)
        index = get_integer("Specify file's number (or 0 to create "
                            "a new one)", "number", maximum=len(files),
                            allow_zero=True)
        if index == 0:
            enter_filename = True
        else:
            filename = files[index - 1]
            items = load_list(filename)
    if enter_filename:
        filename = get_string("Choose filename", "filename")
        if not filename.endswith(".lst"):
            filename += ".lst"
        items = []
    return filename, items



def print_list(items):
    if not items:
        print("-- no items are in the list --")
    else:
        width = 1 if len(items) < 10 else 2 if len(items) < 100 else 3
        for i, item in enumerate(items):
            print("{0:{width}}: {item}".format(i + 1, **locals()))
    print()


def get_choice(items, dirty):
    while True:
        if items:
            if dirty:
                menu = "[A]dd  [D]elete  [S]ave  [Q]uit"
                valid_choices = "AaDdSsQq"
            else:
                menu = "[A]dd  [D]elete  [Q]uit"
                valid_choices = "AaDdQq"
        else:
            menu = "[A]dd  [Q]uit"
            valid_choices = "AaQq"
        choice = get_string(menu, "choice", "a")

        if choice not in valid_choices:
            print("ERROR: invalid choice--enter one of '{0}'".format(
                  valid_choices))
            input("Press Enter to continue...")
        else:
            return choice


def add_item(items, dirty):
    item = get_string("Add item", "item")
    if item:
        items.append(item)
        items.sort(key=str.lower)
        return True
    return dirty


def delete_item(items, dirty):
    index = get_integer("Delete item number (or 0 to cancel)",
                        "number", maximum=len(items), allow_zero=True)
    if index != 0:
        del items[index - 1]
        return True
    return dirty


def load_list(filename):
    items = []
    fh = None
    try:
        for line in open(filename, encoding="utf8"):
            items.append(line.rstrip())
    except EnvironmentError as err:
        print("ERROR: failed to load {0}: {1}".format(filename, err))
        return []
    finally:
        if fh is not None:
            fh.close()
    return items


def save_list(filename, items, terminating=False):
    fh = None
    try:
        fh = open(filename, "w", encoding="utf8")
        fh.write("\n".join(items))
        fh.write("\n")
    except EnvironmentError as err:
        print("ERROR: failed to save {0}: {1}".format(filename, err))
        return True
    else:
        print("Saved {0} item{1} to {2}".format(len(items),
              ("s" if len(items) != 1 else ""), filename))
        if not terminating:
            input("Press Enter to continue...")
        return False
    finally:
        if fh is not None:
            fh.close()


def get_string(message, name="string", default=None,
               minimum_length=0, maximum_length=80):
    message += ": " if default is None else " [{0}]: ".format(default)
    while True:
        try:
            line = input(message)
            if not line:
                if default is not None:
                    return default
                if minimum_length == 0:
                    return ""
                else:
                    raise ValueError("{0} may not be empty".format(
                                     name))
            if not (minimum_length <= len(line) <= maximum_length):
                raise ValueError("{name} must have at least "
                        "{minimum_length} and at most "
                        "{maximum_length} characters".format(
                        **locals()))
            return line
        except ValueError as err:
            print("ERROR", err)


def get_integer(message, name="integer", default=None, minimum=0,
                maximum=100, allow_zero=True):

    class RangeError(Exception): pass

    message += ": " if default is None else " [{0}]: ".format(default)
    while True:
        try:
            line = input(message)
            if not line and default is not None:
                return default
            i = int(line)
            if i == 0:
                if allow_zero:
                    return i
                else:
                    raise RangeError("{0} may not be 0".format(name))
            if not (minimum <= i <= maximum):
                raise RangeError("{name} must be between {minimum} "
                        "and {maximum} inclusive{0}".format(
                        " (or 0)" if allow_zero else "", **locals()))
            return i
        except RangeError as err:
            print("ERROR", err)
        except ValueError as err:
            print("ERROR {0} must be an integer".format(name))


main()





-----------1st EFFORT - posted on GitHub
#!/usr/bin/env python3
#listkeeper.py
#creates list of all files in current directory with .lst extension


import os


YES = frozenset({"y", "Y", "yes", "YES"})


def main():
    dirty = False
    items = []

    filename, items = choose_file()
    if not filename:
        print("Cancelled")
        return

    while True:
        print("\nList Keeper\n")
        print_list(items)                       
        choice = get_choice(items, dirty)           

        if choice in "Aa":
            dirty = add_item(items, dirty)          
        elif choice in "Dd":
            dirty = delete_item(items, dirty)       
        elif choice in "Ss":
            dirty = save_list(filename, items)      #HERE
        elif choice in "Qq":
            if (dirty and (get_string("Save unsaved changes (y/n)", "yes/no", "y") in YES)):
                save_list(filename, items, True)
            break


def choose_file():
    enter_filename = False
    print("\nList Keeper\n")
    files = [x for x in os.listdir(".") if x.endswith(".lst")]
    if not files:
        enter_filename = True
    if not enter_filename:
        print_list(files)
        index = get_integer("Specify file's numbers (or 0 to create a new one)", 
            "number", maximum=len(files), allow_zero=True)
        if index == 0:
            enter_filename = True
        else:
            filename = files[index - 1]
            items = load_list(filename)
    if enter_filename:
        filename = get_string("Choose filename", "filename")
        if not filename.endswith(".lst"):
            filename += ".lst"
        items = []
    return filename, items



def print_list(items):
    if not items:
        print("-- no items are in the list --")
    else:
        width = 1 if len(items) < 10 else 2 if len(items) < 100 else 3
        for i, item in enumerate(items):
            print("{0:{width}}: {item}".format(i + 1, **locals()))
    print()


def get_choice(items, dirty):
    while True:
        if items:
            if dirty:
                menu = "[A]dd [D]elete [S]ave [Q]uit"
                valid_choices = "AaDdSsQq"
            else:
                menu = "[A]dd [D]elete [Q]uit"
                valid_choices = "AaDdQq"
        else:
            menu = "[A]dd [Q]uit"
            valid_choices = "AaQq"
        choice = get_string(menu, "choice", "a")

        if choice not in valid_choices:
            print("ERROR: invalid choice --- enter one of '{}'".format(valid_choices))
            input("Press Enter to continue...")
        else:
            return choice


def add_item(items, dirty):
    item = get_string("Add item", "item")
    if item:
        items.append(item)
        items.sort(key=str.lower)
        return True
    return dirty


def delete_item(items, dirty):
    item = get_string("Delete item number (or 0 to cancel)", "number", maximum=len(items), allow_zero=True)
    if index != 0:
        del items[index - 1]
        return True 
    return dirty


def load_list():
    items = []
    fh = None
    try:
        for line in open(filename, encoding="utf8"):
            items.append(line.rstrip())
    except EnvironmentError as err:
        print("ERROR: failed to load {0}: {1}".format(filename, err))
        return []
    finally:
        if fh is not None:
            fh.close()
    return items


def save_list(filename, items, terminating=False):
    fh = None
    try:
        fh = open(filename, "w", encoding="utf8")
        fh.write("\n".join(items))
        fh.write("\n")
    except EnvironmentError as err:
        print("ERROR: failed to save {0}: {1}".format(filename, err))
        return True
    else:
        print("Saved {0} item{1} to {2}".format(len(items), ("s" if len(items) != 1 else ""), filename))
        if not terminating:
            input("Press Enter to continue...")
        return False
    finally:
        if fh is not None:
            fh.close()
    



def get_string(message, name="string", default=None, minimum_length=0, maximum_length=80):
    message += ": " if default is None else "[{0}]".format(default)
    while True:
        try:
            line = input(message)
            if not line:
                if default is not None:
                    return default
                if minimum_length == 0:
                    return ""
                else:
                    raise ValueError("{0}may not be empty".format(name))
            if not (minimum_length <= len(line) <= maximum_length):
                raise ValueError("[name} must have at least {minimum_length} and at most {maximum_length} characters".format(**locals()))
            return line
        except ValueError as err:
            print("ERROR", err)


main()
-----------1st EFFORT - posted on GitHub









BOOKMARK HERE
#Reminder of topics<===========
===============================================================================================
CHAPTER: 5 Modules
CHAPTER BEGIN
===============================================================================================

Modules and Packages
    Packages
    Custom Modules
        TextUtil Module
        CharGrid Module
Overview of Python Standard library
    String Handling
        io.StringIO Class
    Command-Line Programming
        optparse Module 
    Mathematics and Numbers
        heapq Module
    Times and Dates
        calendar, datetime, and time Module  
    Algorithms and Collection Data Types 
    File Formats, Encodings, and Data Persistence 
        base64 Module 
        tarfile Module 
    File, Directory, and Process Handling 
        os and os.path Modules
    Networking and Internet Programming 
    XML
        xml.etree.ElementTree Module 
    Other Modules
Summary
Exercises 


#CODE LISTING HERE

TextUtil.py --> see Chapter 5
Util.py --> see Chapter 5

base64image.py
capture.py
CharGrid.py
convert-incidents.py
csv2html2_opt.py
finddup.py
Graphics/__init__.py
Graphics/Bmp.py
Graphics/Jpeg.py
Graphics/Png.py
Graphics/Tiff.py
Graphics/Vector/__init__.py
Graphics/Vector/Eps.py
Graphics/Vector/Svg.py
Graphics/Xpm.py
ls.py
untar.py 


===============
Modules
===============
#Whereas functions allow us to parcel up pieces of code so that they can be resused
#throughout a program, modules provide a means of collecting sets of functions (as well
#custom data types) together so that they can be used by any number of programs.
#Python also has facilities for creating packages --> these are modules that are grouped
#together usually b/c their modules provide related functionality or b/c they depend
#upon each other.

#First we cover syntaxes for 
importing functionality from modules and packages
#whether from the standard library, or from our own custom modules and packages.
#This section then goes onto to show to create custom packages and custom modules.
#Two custom module examples are shown, the first introductory and the second
#illustrating how to handle many of the practical issues that arise, such as 
#platform independence and testing.

#The second section provides a brief overview of Python's standard library. It is important
#to be aware of what the library has to offer, since using predefined functionality
#makes programming much faster than creating everything from scratch. Also many of the 
#standard library's modules are widely used, well tested, and robust. In addition, a few
#small examples are used to illustrate some common use cases. And cross-references are
#provided for modules covered in other chapters.

===============
Modules and Packages
===============
#A Python module is a .py file
#A module can contain any Python code we want.
#All the programs we have written so far have been contained in a single .py file and
#so they are modules as well as programs. Key difference is that .py programs are 
#designed to be run, whereas modules are designed to be imported and used by programs.

#Not all modules have associated .py files. For example, the sys module is built into
#Python and some modules are written in other languages (most commonly C).
#However much of Python's library is written in Python so for example if we write
import collections 
#we can create named tuples by calling
collections.namedtuple()
#and the functionality we are accessing is in the collections.py module file.
#It makes no difference to our programs what language a module is written in, since
#all modules are imported and used in the same way.

#Several syntaxes can be used when importing. For example
import importable
import importable1, importable2, ..., importableN
import importable as preferred_name

#Here importable is usually a module such as collections, but could be a package or a
#module in a package, in which case each part is separated with a dot .
#for example os.path ---> package.module

#The first two syntaxes are the safest b/c they avoid the possibiity of having
#name conflicts, since they force us to always use fully qualified names.
#The third syntax allows us to give a name of our choice to the package or
#module we are importing, theoretically this could lead to name clashes, but in
#practice the as syntax is used to avoid them. Renaming is particularly useful
#when experimenting with different implementations of a module. For example,
#if we had two modules MyModuleA and MyModuleB that had the same API, we could
#write import MyModuleA as MyModule in a program, and later on seemlessly switch
#to using import MyModuleB as MyModule.

#Where to locate import statements? Common practice to put all import statements
#at the beginning of .py files, after the shebang line, and after the module's
#documentation.
#So order is:
import standard library modules first
import third-party library modules second
import our own custom modules third 

BOOKMARK HERE TOPIC

#other import syntaxes
from importable import object as preferred_name
from importable import object1, object2, ... objectN
from importable import (object1, object2, object3, object4, object5, ... objectN)
from importable import *
#note that these syntaxes can cause name conflicts since they make the imported
#objects (variable, functions, data types, or modules) directly accessible.
#If we want to use the from...object syntax to import lots of objects, we can use
#multiple lines either by escaping each newline except the last, or by enclosing
#the object names in parenteses, as the the third syntax illustrates.

#The last syntax * means "import everything that is not private", which in practical
#terms means either that every object in the module is imported except for those
#whose names begin with a leading underscore, or if the module has 
#a global __all__ variable that holds a list of names, that all the objects
#named in the __all__ variable are imported.

#Here are a few examples
import os
print (os.path.basename(filename))    #safe fully qualified access

import os.path as path 
print(path.basename(filename))        #risk of name collision with path

from os import path
print(path.basename(filename))        #risk of name collision with parth

from os.path import basename
print(basename(filename))             #risk of name collision with basename

from os.path import *
print(basename(filename))             #risk of many name collisions

#The 
from importable import * 
#syntax imports all the objects from the module
#or all the modules from the package) --> this could be hundreds of names. In
#the case 
from.os import * #--> almost 40 names are imported, including 
dirname, exists and split   #any of which might be the names we would prefer 
#to use for our own variables or functions.

#For example, if we wrote
from os.path import dirname
#we can conveniently call dirname() without qualification. But if further on in our
#code we write
dirname = "."  #the the object reference dirname will now be bound to the string
"." # instead of to the dirname() function, so if we try calling dirname() will get
#a TypeError exception b/c dirname now refers to a string and strings are not callable.

#In view of the potential for name collisions the
import * #syntax creates, some programming teams specify in their guidelines that only
import importable #syntax may be used. However, certain large packages, particularly GUI
#libraries are often imported this way because they have large numbers of functions
#and classes (custom data types) that can be tedious to out by hand.

#A question that naturally arises is, how does Python know where to look for the modules
#and packages that are imported? The built-in sys module has a list called sys.path
#that holds a list of directories that consistute the Python path. The first directory
#is the directory that contains the program itself, even if the program was invoked
#from another directory. If the PYTHONPATH environment variable is set, the paths specified
#in it are the next ones in the list, and the final paths are those needed to access Python's
#standard library --> these are set when Python is installed.

#When we first import a module, if it isnt built-in, Python looks for the module
#in each path listed in 
sys.path #in turn. One consequence of this is that we created a module or program
#with the same name as one of Python's library modules, ours will be found first, 
#inevitably causing problems. To avoid this, never create a program or module with
#the same name as one of Python's library's top-level directories or modules, unless
#you are providing yoru own implementation of that module and are deliberately overriding it.
#A top-level module one whose .py file is in one of the directories in the Python path,
#rather than in one of those directories' subdirectories. For example, on Windows, the Python
#path usally includes a directory called C:\Python30\Lib
#So on that platform we should not create a module called Lib.py nor a module with the 
#same name as any of the modules in the C:\Python30\Lib directory.

#One quick way to check whether a module name is in use is try to import the module.
#This can be done at the console by calling the interpreter with the -c commmand
#line option. -c means execute code. Followed by an import statement.
#For example, if we want to see whether there is a module called Music.py (or a top-level
#directory in the Python path called Music), we can type the following at the console
python -c "import Music"
#If we get an ImportError exception then we know that no module or top-level directory
#of that name is in use; any other output (or none) means that the name is taken.
#Unfortunatly, this does not guarantee that the name will always be okay, since we
#might later on install a third-party Python package or module that has a conflicting
#name, although in practice this is a very rare problem.

#For example, if we created a module file called os.py then it would conflict with
#the library's os module. But if we created a module file called path.py then this
#would okay since it would be imported as the path module whereas the library module
#would be imported as os.path
#In this book, we use an uppercase letter for the first letter of custom
#module filenames. This avoids name conflicts (at least on Unix) b/c standard
#library module filenamees are lowercase.

#A program might import some modules which in turn import modules of their own
#inclding some that have already been imported. This does not cause any problems.
#Whenever a module is imported Python first checks to see whetehr it has already been
#imported. If it has not, then Python executes the module's byte-code complied code,
#thereby creating the variables, functions, and other objects it provides, and 
#internally records that the module has been imported. At every subsequent import
#of the module Python will detect that the module has already been imported
#and will do nothing.

#When Python needs a module's byte-code compiled code, it generate it automatically
#this differs from say Java where compiling to byte code must be done explicitly.
#First Python looks for a file with the same name as the module's .py file but
#with the extension .pyo --> this is an optimized byte-code compiled version
#of the module. If there is no .pyo file (or if it is older than the .py file
#that is if it is out of date), then Python looks for a file with the extension .pyc
#this is the nonoptimized byte-code compiled version of the module. If Python
#finds an up-to-date byte-code compiled version of the module, it loads it, otherwise
#Python loads the .py file and compiles a byte-code compiled version. Either way
#Python ends up with the module in memory in byte-code compiled form.

#If Python has to byte-compile the .py file, it saves a .pyc version (or .pyo if -O
#was specified on Python's command line, or is set in the PYTHONOPTIMIZE environment
#variable), providing the directory is writable. Saving byte code can be avoided by using
#the -B command line option or by setting the PYTHONDONTWRITEBYCODE environment variable.

#Using byte-code compiled files leads to faster start-up times since the interpreter
#only has to load and run the code, rather than load, compile (save if possible) and
#run the code. Runtimes are not affected though. When Python is installed, the 
#standard library modules are usually byte-code compiled as part of the installation process.


#Reminder of topics<===========
CHAPTER 5 Modules

Modules and Packages
    Packages
    Custom Modules
        TextUtil Module
        CharGrid Module
Overview of Python Standard library
    String Handling
        io.StringIO Class
    Command-Line Programming
        optparse Module 
    Mathematics and Numbers
        heapq Module
    Times and Dates
        calendar, datetime, and time Module  
    Algorithms and Collection Data Types 
    File Formats, Encodings, and Data Persistence 
        base64 Module 
        tarfile Module 
    File, Directory, and Process Handling 
        os and os.path Modules
    Networking and Internet Programming 
    XML
        xml.etree.ElementTree Module 
    Other Modules
Summary
Exercises 


===============
    Packages
===============
# a package is simply a directory that contains a set of modules and a file called
__init__.py
#Suppose for example that we had a fictious set of module files for reading and 
#writing various graphics file formats, such as Bmp.py, Jpeg.py, Png.py, Tiff.py
#and Xpm.py, all of which provided the functions load(), save(), and so on.
#see Python Imaging Library at www.pythonware.com/products/pil
#We could keep the modules in the same directory as our program, but for a large
#program that uses scores of custom modules the graphics modules will be dispersed.
#By putting them in their own subdirectory, say Graphics, they can be kept together.
#And if we put an empty __init__.py file the Graphics directory along with them
#then the directory will become a package:
Graphics/
    __init__.py         #empty file, enabling directory to become a package
    Bmp.py
    Jpeg.py
    Png.py
    Tiff.py 
    Xpm.py
#As long as the Graphics directory is a subdirectory inside our program's directory
#or is in the Python path, we can import any of these modules and make use of them.
#We must be careful to ensure that our top level module name (Graphics) is not the
#same as any top level name in the standard library so as to avoid name conflicts.
#(On Unix this is easily done by starting with an uppercase letter since all of
#the standard library's modules have lowercase names.) Here is how we can import
#and use our module:
import Graphics.Bmp 
image = Graphics.Bmp.load("bashful.bmp")
#For short programs some programmers prefer to use shorter names, and Python makes
#this possible using two slightly different approaches:
#Approach1
import Graphics.Jpeg as Jpeg  #imported Jpeg module directly from Graphics package
image = jpeg.load("doc.jpeg") #refer to it simply as Jpeg rather than using its 
                              #fully qualified name of Graphics.Jpeg
#Approach2
from Graphics import Png      #imported Png module directly from Graphics package
image = Png.load("dopey.png")
#this syntax from...import makes Png module directly accessible

#We are not obliged to use the original pacakage names in our code.
from Graphics import Tiff as picture  #using Tiff module but renaming it inside our program
image = picture.load("grumpy.tiff")

#In some situations it is convenient to load in all of a package's modules using a single
#statement. To do this we must edit the package's 
__init__.py #file to contain a statement which specifies which modules we want loaded. This
#statement must assign a list of module names to the special variable
__all__

#for examples here is the necessary line for the Graphics/__init.py file
__all__ = ["Bmp", "Jpeg", "Png", "Tiff", "Xpm"]
#that is all that is required, although we are free to put any other code we like in the
__init__.py #file. 

#So now we can write a different kind of import statement:
from Graphics import *
image = Xpm.load("sleepy.xpm")
#so here the from package import * syntax directly imports all the modules names in
#the __all__ list. So, after this import, not only is the Xpm module directly accessible,
#but so are all the others.

#As noted earlier, this syntax can also be applied to a module, that is,
from module import *  #in which case all the functions, variables, and other objects
#defined in the module (apart from those whose names begin with a leading underscore) will
#be imported. If we want to control excactly what is imported when the 
from module import *  #syntax is used, we can define an 
__all__  #list in the module itself, in which case doing 
from module import *  #will only import those objets named in the __all__ list.

#Nesting packages
#so far we have shown only one level of nesting, but Python allows us to nest packages
#as deeply as we like. So we could have a subdirectory inside the Graphics directory,
#say Vector, with module files inside that, such as Eps.py and Svg.py

Graphics/
    __init__.py
    Bmp.py
    Jpeg.py
    Png.py
    Tiff.py
    Vector/
        __init__.py  #for the Vector directory to be a package it must have __init__.py inside
        Eps.py
        Svg.py
    Xpm.py
#and as noted earlier, Vector directory could be empty or could have an __all__ list as a
#convenience for programmers who want to import using
from Graphics.Vector import *

BOOKMARK HERE TOPIC

#to access a nested package, we just build on the syntax we have already used
import Graphics.Vector.Eps 
image = Graphics.Vector.Eps.load("sneezy.eps")
#the fully qualified name is rather long, so some programmers try to keep their
#module heirarchies fairly flat to avoid this.
import Graphics.Vector.Svg as Svg
image = Svg.load("snow.svg")
#remember that we can always use own short name for a module, as we have done here,
#although this does increase the risk of having a name conflict.


#Reminder of topics<===========
CHAPTER 5 Modules

Modules and Packages
    Packages
    Custom Modules
        TextUtil Module
        CharGrid Module
Overview of Python Standard library
    String Handling
        io.StringIO Class
    Command-Line Programming
        optparse Module 
    Mathematics and Numbers
        heapq Module
    Times and Dates
        calendar, datetime, and time Module  
    Algorithms and Collection Data Types 
    File Formats, Encodings, and Data Persistence 
        base64 Module 
        tarfile Module 
    File, Directory, and Process Handling 
        os and os.path Modules
    Networking and Internet Programming 
    XML
        xml.etree.ElementTree Module 
    Other Modules
Summary
Exercises 


===============
    Custom Modules              #pg 202
===============
#since modules are just .py files, they can be created without formality.
#In this section we look at two custom modules:

#Custom Module #1 TextUtil located in the TextUtil.py file contains just three functions:
is_balanced() #returns True if the string it is passed has balanced paraentheses 
shorten() #returns text or a truncated copy with the indicator added
simplify() #can strip spurious whitespace and other characters from a string
#Note that within this section, we will also see how to execute the code in
#docstrings as unit tests

#for example 
>>> shorten("The Road", indicator="&", length=7)
'The Ro&'
>>> shorten("The Road", indicator="&", length=2)
'T&'
>>> shorten("The Road", indicator="&", length=3)
'Th&'


#Custom Module #2 CharGrid in the CharGrid.py file
#this holds a grid of characters and allows us to draw lines, rectangles and text onto
#grid and to render the grid on the console. This module shows some techniques that we have
#not seen before and is more typical of larger, more complex modules.


#Reminder of topics<===========
CHAPTER 5 Modules

Modules and Packages
    Packages
    Custom Modules
        TextUtil Module
        CharGrid Module
Overview of Python Standard library
    String Handling
        io.StringIO Class
    Command-Line Programming
        optparse Module 
    Mathematics and Numbers
        heapq Module
    Times and Dates
        calendar, datetime, and time Module  
    Algorithms and Collection Data Types 
    File Formats, Encodings, and Data Persistence 
        base64 Module 
        tarfile Module 
    File, Directory, and Process Handling 
        os and os.path Modules
    Networking and Internet Programming 
    XML
        xml.etree.ElementTree Module 
    Other Modules
Summary
Exercises 


===============
        TextUtil Module
===============
#structure of this module and most others differs a little from programs.
#first line is a shebang line, next comments
#next triple quoted string = docstring provides an overview of the module's contents often
#including some usage examples.

is_balanced(:("Python (is (not (lisp))))")
>>> True 

def simplify(text, whitespacing=string.whitespace, delete=""):
    """Returns the text with multiple spaces reduced to single spaces

    The whitespace parameter is a string of characters, each of which
    is considered to be a space.
    If delete is not empty it should be a string, in which case any
    characters in the delete string are excluded form the resultant
    string.

    >>> simplify("  this    and\n that\t too")
    'this and that too'
    >>> simplify("  Washington   D.C.\n")
    'Washington D.C.'
    >>> simplify("  Washington   D.C.\n", delete=",;:.")
    'Washington DC'
    >>> simplify(" disemvoweled ", delete="aeiou")
    'dsmvwld'
    """

    result = []
    word = ""
    for char in text:       #interated over
        if char in delete:    #skip deleted characters
            continue            #skip deleted characters
        elif char in whitespace:
            if word:
                result.append(word)
                word = ""
        else:
            word += char 
    if word:
        result.append(word)
    return " ".join(result)

#After the def line, comes docstring laid out conventionally with the single line
#description, blank line, further description, and then some written examples as
#though they were typed interactively.
#b/c quoted strings are inside docstrings, we must either escape the backslashes
#inside them or do what we did here --> use raw triple strings quoted string.

#the result list is used to "hold" words, ie strings that have no whitespaces or 
#deleted characters.
#The given text is iterated over character by character and deleted characters
#are skipped. If whitespace is encountered and word exists then add that word
#to result list thus, otherwise the whitespace is skipped.
#any other character is added to the word being built up.
#At the end a single string is returned and joined by a single space between words.

#code without docstring:
def is_balanced(text, brackets="()[]{}<>"):
    counts = {}                 #dictionary for opening characters
    left_for_right = {}         #dictionary for closing characters
    for left, right in zip(brackets[::2], brackets[1::2]):
        assert left != right, "the bracket characters must differ"
        counts[left] = 0
        left_for_right[right] = left
    for c in text:
        if c in counts:
            counts[c] += 1
        elif c in left_for_right:
            left = left_for_right[c]
            if counts[left] == 0:
                return False
            counts[left] -= 1
    return not any(counts.values())
#This function build TWO dictionaries --> counts and left_for_right.
#counts dictionary's keys are the opening characters ( "(", "[", "{", "<" ) and its 
#values are integers.
#The left_for_right dictionary's keys are the closing characterss ( ")", "}", "]", ">" ) 
#and its values are the corresponding opening characters.
#Once the dictionaries are set up, then the function iterates character by character
#over the text. Whenever an opening character is encounterd, then its corresponding count
#is incremented. Similarly, when a closing character is encountered, the function finds
#out what the corresponding opening character is.
#If the count for that character is 0 then it means that we have reached one closing
#character TOO MANY so can immediately return False, otherwise, we the relevant
#count is decremented.
#At the very end, the count should be 0 if all the pairs are balanced, so if any
#of them is not 0, the function returns False, otherwise the function returns True.

#Up to this point, everything has been much like any other .py file.
#If TextUtil.py was a program, there would be some more functions and at the end
#a single call to one of the functions to start off the processing.
#BUT since this is a module that is intended to be imported, defining functions
#are sufficient. And so any program can import TextUtil and make use of it:

import TextUtil
text = "    a    puzzling   conundrum      "
text = TextUtil.simplify(text)      #text = 'a puzzling conundrum'

#If we want TextUtil module to be available to a particular program, we just need to
#put TextUtil.py in the same directory as the program.
#If we want TextUtil to be available to ALL of our programs, then a few approaches exist:
    #Approach1 - put the module in the Python distribution's site-packages dictionary.
    # C:\Python30\Lib\site-packages on Windows but varies on Mac OS and Unixes. This
    #directory is in the Python path, so any module that is here will always be found.
    Approach2# - to create a directory specifically for the custom modules we want to use
    #for all our programs, and to set the PYTHONPATH environment variable to this directory.
    #Approach3 - to put the module in the local site-packages subdirectory called
    # %APPDATA%/Python/Python30/site-packages on Windows or
    # ~/.local/lib/python3.0/site-packages on Mac OS and Unix.
    #Approaches 2 and 3 have the additional benefit of keeping our code separate from
    #the official installation.

#Having the TextUtil module is nice but we may have many programs using it. To be more
#confident that it works, a simple check is to execute the examples in the docstrings
#and make sure they product the expected results. This can be done by just adding 3 lines
#to the end of the module's .py file
if __name__ == "__main__":
    import doctest
    doctest.testmod()
#so here, whenever a module is imported, then Python creates a variable for the module
#called __name__ and stores the module's name in this variable. A module's name
#is simply the name of its .py file but without the extension. So here when the
#module is imported __name__ will have the value = "TextUtil" and so if condition 
#will not be met so last two lines will NOT be executed. This means that these last three
#lines of code have no cost when the module is imported.

#Whenever a .py file is run, Python creates a variable for the program called
# __name__ and sets it to the string "__main__" so if we were to run TextUtil.py
#as though it were a program, Python will (proacticely) set __name__ to __main__ and the 
#if condition will, therefore, evaluate to True thus the last two lines will be executed.

#The doctest.testmod() function uses Python's 
introspection features #to discover all the functions in the module and their docstrings, 
#and attempts to execute all the docstring code snippets it finds. 
#Running a module like this produces output only if there are errors. 
#This can be disconcerting at first since it doesn't look like anything
#happened at all, but if we pass a command-line flag of -v we will get output like this:

  Trying:
    is_balanced("(Python (is (not (lisp))))")
  Expecting:
    True
  ok
  ...     #NOTE LOTS OF LINES WERE OMITTED HERE
  Trying 
    simplify("  disemvoweled ",  delete ="aeiou")
  Expecting
    'dsmvwld'
  ok
  4 items passed all tests:
    3 tests in __main__
    5 tests in __main__.is_balanced
    3 tests in __main__.shorten
    4 tests in __main__.simplify
  15 tests in 4 items.
  15 passed and 0 failed.
  Test passed.

# ... --> is the ellipsis to indicate lots of lines were omitted. If there are
#functions (or classes or methods) that dont have tests, these are listed when
#the -v option is used. Notice that the doctest module found the tests in the
#module's docstring as well as those in the function's docstrings.

#Examples in docstrings that can be executed as tests are called 
doctests
#Note that when we write doctests, we are able to call simplify() and other
#functions as unqualified (since the doctests occur inside the module itself).
#Outside the module, assuming we have done import TextUtil, we must use the
qualified names#, for example, TextUtil.is_balanced()

BOOKMARK HERE TOPIC
#Next section will go through tests in detail such as test cases for invalid data 
#causing exceptions
#Also address issues when creating modules, module initialization, accounting for
#platform differences, and ensuring that if the 
from module import * #syntax is used, only the objects we want to be made public
#are actually imported into the importing program or module.


BOOKMARK HERE
#CODE HERE
TextUtil.py 

-----------1st EFFORT - posted on GitHub
#!/usr/bin/env python3
#TextUtil.py 

"""
This module provides five generic string manipulation functions.

>>> is_balanced("(Python (is (not (lisp))))")
True
>>> shorten("The Crossing", 10)
'The Cro...'
>>> simplify(" some    text    with  spurious  whitespace  ")
'some text with spurious whitespace'
>>> def insert_at
>>> def dummy_insert_at
"""

import string


def is_balanced(text, brackets="()[]{}<>"):
    """Returns True if all the brackets in the text are balanced

    For each pair of brackets, the left and right bracket characters
    must be different.

    >>> is_balanced("no brackets at all")
    True
    >>> is_balanced("<b>bold</b>")
    True
    >>> is_balanced("[<b>(some {thing}) goes</b>]")
    True
    >>> is_balanced("<b>[not (where {it}) is}]</b>")
    False
    >>> is_balanced("(not (<tag>(like) (anything)</tag>)")
    False
    """
    counts = {}
    left_for_right = {}
    for left, right in zip(brackets[::2], brackets[1::2]):
        assert left != right, "the bracket characters must differ"
        counts[left] = 0
        left_for_right[right] = left
    for c in text:
        if c in counts:
            counts[c] += 1
        elif c in left_for_right:
            left = left_for_right[c]
            if counts[left] == 0:
                return False
            counts[left] -= 1
    return not any(counts.values())


def shorten(text, length=25, indicator="..."):
    """Returns text or a truncated copy with the indicator added

    text is any string; length is the maximum length of the returned
    string (including any indicator); indicator is the string added at
    the end to indicate that the text has been shortened

    >>> shorten("Second Variety")
    'Second Variety'
    >>> shorten("Voices from the Street", 17)
    'Voices from th...'
    >>> shorten("Radio Free Albemuth", 10, "*")
    'Radio Fre*'
    """
    if len(text) > length:
        text = text[:length - len(indicator)] + indicator
    return text


def simplify(text, whitespace=string.whitespace, delete=""):
    r"""Returns the text with multiple spaces reduced to single spaces

    The whitespace parameter is a string of characters, each of which
    is considered to be a space.
    If delete is not empty it should be a string, in which case any
    characters in the delete string are excluded from the resultant
    string.

    >>> simplify(" this    and\n that\t too")
    'this and that too'
    >>> simplify("  Washington   D.C.\n")
    'Washington D.C.'
    >>> simplify("  Washington   D.C.\n", delete=",;:.")
    'Washington DC'
    >>> simplify(" disemvoweled ", delete="aeiou")
    'dsmvwld'
    """
    result = []
    word = ""
    for char in text:
        if char in delete:
            continue
        elif char in whitespace:
            if word:
                result.append(word)
                word = ""
        else:
            word += char
    if word:
        result.append(word)
    return " ".join(result)


def insert_at(string, position, insert):
    """Returns a copy of string with insert inserted at the position

    >>> string = "ABCDE"
    >>> result = []
    >>> for i in range(-2, len(string) + 2):
    ...     result.append(insert_at(string, i, "-"))
    >>> result[:5]
    ['ABC-DE', 'ABCD-E', '-ABCDE', 'A-BCDE', 'AB-CDE']
    >>> result[5:]
    ['ABC-DE', 'ABCD-E', 'ABCDE-', 'ABCDE-']
    """
    return string[:position] + insert + string[position:]


def dummy_insert_at(string, position, insert):
    """Returns a copy of string with insert inserted at the position

    >>> string = "ABCDE"
    >>> result = []
    >>> for i in range(-2, len(string) + 2):
    ...     result.append(insert_at(string, i, "-"))
    >>> result[:5]
    ['ABC-DE', 'ABCD-E', '-ABCDE', 'A-BCDE', 'AB-CDE']
    >>> result[5:]
    ['ABC-DE', 'ABCD-E', 'ABCDE-', 'ABCDE-']
    """
    return string


if __name__ == "__main__":
    import doctest
    doctest.testmod()
-----------1st EFFORT - posted on GitHub



-----------1st EFFORT - posted on GitHub
#!/usr/bin/env python3
#Util.py 

"""
This module provides some general utility functions:
- complete_comparisons()
- equal_float() improved version with slightly different API
- s()
- logged()
- positive_result()
- bounded()
- is_unicode_punctuation()
- int2base36()
>>> file = os.path.join(tempfile.gettempdir(), "logged.log")
>>> @logged
... def discounted_price(price, percentage, make_integer=False):
...     result = price * ((100 - percentage) / 100)
...     if not (0 < result <= price):
...         raise ValueError("invalid price")
...     return result if not make_integer else int(round(result))
>>> discounted_price(100, 10)
90.0
>>> discounted_price(210, 5, make_integer=True)
200
>>> discounted_price(210, 14, True)
181
>>> discounted_price(210, 5)
199.5
>>> discounted_price(210, -8)
Traceback (most recent call last):
...
ValueError: invalid price
>>> @logged
... def f(a=10): return a**2
>>> f()
100
>>> f(20)
400
>>> f(a=12)
144
>>> #if os.path.exists(file): os.remove(file)
>>> @strictly_typed
... def discriminant(a : float, b : float, c : float) -> float:
...     return (b ** 2) - (4 * a * c)
>>> discriminant(4.0, 3.0, 2.0)
-23.0
>>> discriminant(a=4.0, b=3.0, c=2.0)
-23.0
>>> discriminant(a=4.0, b=3.0, c=2)
Traceback (most recent call last):
...
AssertionError: expected argument 'c' of <class 'float'> got <class 'int'>
>>> @strictly_typed
... def fail1(a : float, b : float, c : float):
...     return (b ** 2) - (4 * a * c)
Traceback (most recent call last):
...
AssertionError: missing type for return value
>>> @strictly_typed
... def fail2(a : float, b, c : float) -> float:
...     return (b ** 2) - (4 * a * c)
Traceback (most recent call last):
...
AssertionError: missing type for parameter 'b'
>>> @strictly_typed
... def fail3(a : float, b : float, c : float) -> float:
...     return int((b ** 2) - (4 * a * c))
>>> fail3(a=4.0, b=3.0, c=2.0)
Traceback (most recent call last):
...
AssertionError: expected return of <class 'float'> got <class 'int'>
"""

import functools
import inspect
import logging
import os
import string
import sys
import tempfile
import unicodedata


def complete_comparisons(cls):
    """A class decorator that completes a class's comparisons operators.
    The decorated class will have the operators <, <=, ==, !=, >=, >,
    assuming it already has <, and ideally == too. If the class doesn't
    even have < an assertion error is raised.
    >>> @complete_comparisons
    ... class AClass(): pass
    Traceback (most recent call last):
    ...
    AssertionError: AClass must define < and ideally ==
    >>> @complete_comparisons
    ... class Lt():
    ...     def __init__(self, x=""):
    ...         self.x = x
    ...     def __str__(self):
    ...         return self.x
    ...     def __lt__(self, other):
    ...         return str(self) < str(other) 
    >>> a = Lt("a")
    >>> b = Lt("b")
    >>> b2 = Lt("b")
    >>> (a < b, a <= b, a == b, a !=b, a >= b, a > b)
    (True, True, False, True, False, False)
    >>> (b < b2, b <= b2, b == b2, b != b2, b >= b2, b > b2)
    (False, True, True, False, True, False)
    >>> @complete_comparisons
    ... class LtEq():
    ...     def __init__(self, x=""):
    ...         self.x = x
    ...     def __str__(self):
    ...         return self.x
    ...     def __lt__(self, other):
    ...         return str(self) < str(other) 
    ...     def __eq__(self, other):
    ...         return str(self) == str(other) 
    >>> a = LtEq("a")
    >>> b = LtEq("b")
    >>> b2 = LtEq("b")
    >>> (a < b, a <= b, a == b, a !=b, a >= b, a > b)
    (True, True, False, True, False, False)
    >>> (b < b2, b <= b2, b == b2, b != b2, b >= b2, b > b2)
    (False, True, True, False, True, False)
    """
    assert cls.__lt__ is not object.__lt__, (
            "{0} must define < and ideally ==".format(cls.__name__))
    if cls.__eq__ is object.__eq__:
        cls.__eq__ = lambda self, other: (not
                (cls.__lt__(self, other) or cls.__lt__(other, self)))
    cls.__ne__ = lambda self, other: not cls.__eq__(self, other)
    cls.__gt__ = lambda self, other: cls.__lt__(other, self)
    cls.__le__ = lambda self, other: not cls.__lt__(other, self)
    cls.__ge__ = lambda self, other: not cls.__lt__(self, other)
    return cls


def delegate(attribute_name, method_names):
    """Passes the call to the attribute called attribute_name for
    every method listed in method_names.
    (See SortedListP.py for an example.)
    """
    def decorator(cls):
        nonlocal attribute_name
        if attribute_name.startswith("__"):
            attribute_name = "_" + cls.__name__ + attribute_name
        for name in method_names:
            setattr(cls, name, eval("lambda self, *a, **kw: "
                                    "self.{0}.{1}(*a, **kw)".format(
                                    attribute_name, name)))
        return cls
    return decorator


def equal_float(a, b, decimals=None):
    """Returns True if a and b are equal to the limits of the machine's
    accuracy or to the specified number of decimal places if specified
    >>> equal_float(.1, .1), equal_float(.000000000001, .000000000001)
    (True, True)
    >>> equal_float(.00000000000101, .00000000000102, 13)
    True
    >>> equal_float(.00000000000101, .00000000000102)
    False
    >>> equal_float(.00000000000101, .00000000000102, 9)
    True
    """
    if decimals is not None:
        a = round(a, decimals)
        b = round(b, decimals)
    return abs(a - b) <= (sys.float_info.epsilon * min(abs(a), abs(b)))


def equal_float_old(a, b, epsilon=None):
    """Returns True if a and b are equal to the limits of the machine's
    accuracy or to the limit of epsilon if given
    >>> equal_float_old(.1, .1), equal_float_old(.000000000001, .000000000001)
    (True, True)
    >>> equal_float_old(.00000000000101, .00000000000102, .0000000000001)
    True
    >>> equal_float_old(.00000000000101, .00000000000102)
    False
    """
    if epsilon is None:
        return abs(a - b) <= (sys.float_info.epsilon * min(abs(a), abs(b)))
    return abs(a - b) <= epsilon


s = lambda x: "" if x == 1 else "s"
s.__doc__ = "Returns 's' for quantities other than 1"


def positive_result(function):
    @functools.wraps(function)
    def wrapper(*args, **kwargs):
        result = function(*args, **kwargs)
        assert result >= 0, function.__name__ + "() result isn't >= 0"
        return result
    return wrapper


@positive_result
def discriminant(a, b, c):
    """
    >>> discriminant(1, 2, 3)
    Traceback (most recent call last):
    ...
    AssertionError: discriminant() result isn't >= 0
    >>> discriminant(3, 4, 1)
    4
    >>> discriminant.__name__
    'discriminant'
    """
    return (b ** 2) - (4 * a * c)


def bounded(minimum, maximum):
    def decorator(function):
        @functools.wraps(function)
        def wrapper(*args, **kwargs):
            result = function(*args, **kwargs)
            if result < minimum:
                return minimum
            elif result > maximum:
                return maximum
            return result
        return wrapper
    return decorator


@bounded(0, 100)
def percent(amount, total):
    """
    >>> percent(512, 4096)
    12.5
    >>> percent(811, 700)
    100
    >>> percent(-7, 91)
    0
    """
    return (amount / total) * 100


def strictly_typed(function):
    annotations = function.__annotations__
    arg_spec = inspect.getfullargspec(function)

    assert "return" in annotations, "missing type for return value"
    for arg in arg_spec.args + arg_spec.kwonlyargs:
        assert arg in annotations, ("missing type for parameter '" +
                                    arg + "'")
    @functools.wraps(function)
    def wrapper(*args, **kwargs):
        for name, arg in (list(zip(arg_spec.args, args)) +
                          list(kwargs.items())):
            assert isinstance(arg, annotations[name]), (
                    "expected argument '{0}' of {1} got {2}".format(
                    name, annotations[name], type(arg)))
        result = function(*args, **kwargs)
        assert isinstance(result, annotations["return"]), (
                    "expected return of {0} got {1}".format(
                    annotations["return"], type(result)))
        return result
    return wrapper


if __debug__:
    logger = logging.getLogger("Logger")
    logger.setLevel(logging.DEBUG)
    handler = logging.FileHandler(os.path.join(
                                tempfile.gettempdir(), "logged.log"))
    logger.addHandler(handler)

    def logged(function):
        @functools.wraps(function)
        def wrapper(*args, **kwargs):
            log = "called: " + function.__name__ + "("
            log += ", ".join(["{0!r}".format(a) for a in args] +
                             ["{0!s}={1!r}".format(k, v)
                              for k, v in kwargs.items()])
            result = exception = None
            try:
                result = function(*args, **kwargs)
                return result
            except Exception as err:
                exception = err
            finally:
                log += ((") -> " + str(result)) if exception is None
                        else ") {0}: {1}".format(type(exception),
                                                 exception))
                logger.debug(log)
                if exception is not None:
                    raise exception
        return wrapper
else:
    def logged(function):
        return function


def is_unicode_punctuation(s : str) -> bool:
    """ >>> is_unicode_punctuation("No way!")
    False
    >>> is_unicode_punctuation("@!?*")
    True
    >>> is_unicode_punctuation("@!?*X")
    False
    """
    for c in s:
        if unicodedata.category(c)[0] != "P":
            return False
    return True


def int2base36(integer):
    """Returns integer as a base 36 string
    Use int(string, 36) to do the reverse conversion.
    >>> int2base36(0)
    '0'
    >>> int2base36(35), int("Z", 36)
    ('Z', 35)
    >>> int2base36(36), int("10", 36)
    ('10', 36)
    >>> int2base36(37), int("11", 36)
    ('11', 37)
    >>> int2base36(98712374), int("1MRQYE", 36)
    ('1MRQYE', 98712374)
    >>> int2base36(825170), int("HOPE", 36)
    ('HOPE', 825170)
    """
    DIGITS = string.digits + string.ascii_uppercase
    digits = []
    while integer >= 36:
        integer, modulus = divmod(integer, 36)
        digits.append(DIGITS[modulus])
    digits.append(DIGITS[integer])
    return "".join(reversed(digits))


if __name__ == "__main__":
    import doctest
    doctest.testmod()
-----------1st EFFORT - posted on GitHub




#Reminder of topics<===========
CHAPTER 5 Modules

Modules and Packages
    Packages
    Custom Modules
        TextUtil Module
        CharGrid Module
Overview of Python Standard library
    String Handling
        io.StringIO Class
    Command-Line Programming
        optparse Module 
    Mathematics and Numbers
        heapq Module
    Times and Dates
        calendar, datetime, and time Module  
    Algorithms and Collection Data Types 
    File Formats, Encodings, and Data Persistence 
        base64 Module 
        tarfile Module 
    File, Directory, and Process Handling 
        os and os.path Modules
    Networking and Internet Programming 
    XML
        xml.etree.ElementTree Module 
    Other Modules
Summary
Exercises 


===============
        CharGrid Module
===============
#CharGrid module holds a grid of characters in memory and provides functionality
#to draw lines, rectangles, and text on grid and for rendering the grid onto the console.
#Here are the module's docstring objects:
>>> resize(14, 50)
>>> add_rectangle(0, 0, *get_size())
>>> add_vertical_line(5, 10, 13)
>>> add_vertical_line(2, 9, 12, "!")
>>> add_horizontal_line(3, 10, 20, "+")
>>> add_rectangle(0, 0, 5, 5, "%")
>>> add_rectangle(5, 7, 12, 40, "#", True)
>>> add_rectangle(7, 9, 10, 38, " ")
>>> add_text(8, 10, "This is the CharGrid module")
>>> add_text(1, 32, "Pleasantville", "@")
>>> add_rectangle(6, 42, 11, 46, fill=True)
>>> render(False)
#The CharGrid.add_rectangle() function takes at least four arguments, the top
#left corner row and column, the bottom right corner row and column.
#The character used to draw the outline can be given as a 5th argument, and a 
#Boolean indicating whether the rectangle should be filled (with the same character
#as the outline) as a 6th argument.
#The first time we call it, we pass the 3rd and 4th arguments by unpacking the 2-tuple
#(width, height) and which is returned by the CharGrid.get_sized() function.

#By default, the CharGrid.render() function clears the screen before printing the grid,
#but this can be prevented by passing False as we have done before. Here is the grid that
#results from the preceeding doctests:
%%%%********************************************
%  %                           @@@@@@@@@@@@@@@ *
%  %                           @Pleasantville@ *
%  %  +++++++++++              @@@@@@@@@@@@@@@ *
%%%%                                           *
*     #################################        *
*     #################################  ****  *
*     ##                             ##  ****  *
*     ## This is the CharGrid module ##  ****  *
*     ##                             ##  ****  *
* !   #################################  ****  *
* ! | #################################        *
*   |                                          *
************************************************

#module code is here
#begins sameas TextUtil module

#shebang line
#copy and license comments
#module docstring that describes the module and has the doctests quoted
#The the code proper begins with two imports
import sys
import subprocess #(see Chapter 9 for details)

#next is two error handling policies in place
#several functions have a char parameter whose actual argument must always be a 
#string containing exactly one character; a violation of this requirement is 
#considered to be fatal coding error, so asset statements are used to verify
#its length.
#But passing out-of-range row or column numbers is considered erroneous but normal
#so custom exceptions are raised when this happens.
class RangeError(Exception): pass
class RowRangeError(RangeError): pass
class ColumnRangeError(RangeError): pass

#None of the functions in the module that raise an exception ever raise a RangeError;
#they always raise the specific exception depending on whether an out-of-range row or
#column was given. But by using a heirachy, we give users of the module the choice of
#catching the specific exception, or to catch either of them by catching their RangeError
#base class. Note also that inside doctests the exception names are used as they appear
#here, but if the module is imported with import CharGrid, the exception names are, of course,
#CharGrid.RangeError, CharGrid.RowRangeError, and CharGrid.ColumnRangeError.

  _CHAR_ASSERT_TEMPLATE = ("char must be a single character: '{0}' is too long")
  _max_rows = 25
  _max_columns = 80
  _grid = []
  _background_char = " "
#here we define some private data for internal use by the module.
BOOKMARK HERE TOPIC
#We use leading underscores so that if the module is importing using 
from CharGrid import *  #then none of these variables will be imported.
#An alternative approach would be to set an __all__ list
#The _CHAR_ASSERT_TEMPLATE is a string for use with the str.format() function wherein we
#will see it used to give error messages in assert statements.
#We will discuss other variables as we encounter them

if sys.platform.startswith("win"):          #DYNAMICALLY create a def statement
    def clear_screen():
        subprocess.call(["cmd.exe", "/C", "cls"])
else:
    def clear_screen():
        subprocess.call(["clear"])
    clear_screen.__doc__ = """Clears the screen using the underlying \ window
    system's clear screen command"""
#This means of clearing the console screen is platform dependent. On Windows we must
#excute the cmd.exe program with appropriate arguments and on most Unix systems we
#execute the clear program. The subprocess module's subprocess.call() function lets us
#run an external program, so we can use it to clear the screen in the appropriate
#platform specific way. The sys.platform string holds the name of the operating system
#the program is running on, for example "win32" or "linux2". So one way of handling
#the platform differences would be to have a single clear_screen() function like this:
    def clear_screen():
        command = (["clear" if not sys.platform.startswith("win") else ["cmd.exe", "/C", "cls"])
        subprocess.call(command)

#The disadvantage of this approach is that eventhough we know the platform can not change
#while the program is running, we perform the check every time the function is called.

#To avoid checking which platform the program is being run on every time the
#clear_screen() function is called, we have created a platform-specific clear_screen()
#function once when the module is imported, and from then on we always use it. This is
#possible b/c the def statement is a Python statement like any other; so when the 
#interpreter reaches the if statement it executes either the first or the second def statement, 
DYNAMMICALLY #creating one or the other clear_screen() function. Since the
#function is not defined inside another function (or inside a class as will see in the next
#chapter), it is still a global function, accessible like any other function in the module.
#global function vs class function explained here above paragraph

#After creating the function, we explicitly set its docstring; this avoids us having to 
#write the same docstring in two places, and also illustrates that a docstring is simply
#one of the attributes of a function. Other attributes include the function's module and
#its name.

def resize(max_rows, max_columns, char=None):
    """Changes the size of the grid, wiping out the contents and
    changing the background if the background char is not None
    """
    assert max_rows > 0 and max_columns > 0, "too small"
    global _grid, _max_rows, _max_columns, _background_char
    if char is not None:
        assert len(char) == 1, _CHAR_ASSERT_TEMPLATE.format(char)
        _background_char = char
    _max_rows = max_rows
    _max_columns = max_columns
    _grid = [[_background_char for column in range(_max_columns)] for row in range(_max_rows)]
#This function uses an assert statement to enforce the policy that it is a coding
#error to attempt to resize the grid smaller than 1x1. If a background character is
#specified an assert is used to guarantee that it is a string of exactly one character;
#if it is not, the assertion error message is the _CHAR_ASSERT_TEMPLATE's text with
#the {0} replaced with the given char string.

                        >>> x = 10
                        >>> y = 5
                        >>> assert x > 9 and y > 4, "too small"
                        >>> x=4
                        >>> assert x > 9 and y > 4, "too small"
                        Traceback (most recent call last):
                          File "<stdin>", line 1, in <module>
                        AssertionError: too small

#Unfortunately, we must use global statement because we need to update a number of 
global variables #inside this function. This is something that using an
#object-oriented approach can help us avoid. See Chapter 6.
BOOKMARK HERE TOPIC

#The _grid is created using a 
list comprehension inside a list comprehenion
#Using list replication such as [[char] * columns] * rows will NOT work b/c the inner
#list will be shared (shallow copied). We could have used nested for...in loops instead:
_grid = []
for row in range(_max_rows):
    _grid.append([])
    for column in range(_max_columns):
        _grid[-1].append(_background_char)
#This code is arguably tricker to understand that the list comprehension, and is much
#longer.

#We will review just one of the drawing functions to give a flavor of how the drawing is
#done, since our primary concern is with the implementation of the module. Here is the 
#add_horizontal_line() function, split into two parts;
def add_horizontal_line(row, column0, column1, char="-"):
    """Adds a horiztonal line to the grid using the given char 

    >>> add_horizontal_line(8, 20, 25, "=")
    >>> char_at(8, 20) == char_at(8,24) == "="
    True
    >>> add_horizontal_line(31, 11, 12)
    Traceback (most recent call last):
    ...
    RowRangeError
    """

doctest exception Traceback ellipsis
#the docstring has two tests, one that is expected to work and another that is expected
#to raise an exception. When dealing with exceptions in doctests the pattern is to
#specify the "Traceback" line since that is always the same and tells the doctest
#module an exception is expected, then to use an ellipsis to stand for the intervening
#lines which will vary, and ending with the exception line we expect to get.
#The char_at() function is one those provided by the module; it returns the
#character at the given row and column position in the grid.

    assert len(char) == 1, _CHAR_ASSERT_TEMPLATE.format(char)
    try:
        for column in range(column0, column1):
            _grid[row][column] = char
    except IndexError:
        if not 0 <= row <= _max_rows:
            raise RowRangeError()
        raise ColumnRangeError()
#this code begins with the same character length check that is used in the resize() function.
#Rather then explicitly checking the row and column arguments, the function works by
#assuming that the arguments are valid. If an IndexError exception occurs b/c a nonexistant
#row or column is accessed, we catch the exception and raise the appropriate module-
#specific exception in its place. This style of programming is known colloquially as
#"its easier to ask forgiveness than permission", and is generally considered more 
#Pythonic than "look before you leap", wherein checks are made in advance.
#Relying on exceptions to be raised rather than checking in advance is more efficient
#when exceptions are rare. (Assertions dont count as "look before you leap" b/c they 
#should never occur -- and are often commented out -- in deployed code.)

#Almost at the end of the module, after all the functions have been defined, there is
#a single call to resize():
resize(_max_rows, _max_columns)
#this call initializes the grid to the default size (25x80) and ensures that code
#that imports the module can safely make use of it immediately. Without this call,
#every time the module was imported, the importing program or module would have to call
#resize() to initialize the grid, forcing programmers to remember that fact and also
#multiple initializations.

if __name__ == "__main__":
    import doctest
    doctest.testmod()
#these last three lines of the module are the standard ones for modules that
#use the doctest module to check their doctests.

#The CharGrid module has an important failing --> it supports only a single character
#grid. One solution to this would be to hold a collection of grids in the module,
#but that would mean that users of the module would have to provide a key or index
#with every function call to identify which grid they were referring to. In cases
#where multiple instances of an object are required, a better solution is to create a
#module that defines a class (a custom data type), since we can create as many class 
#instances (objects of the data type) as we like. An additional benefit of creating
#a class is that we should be able to avoid using the global statement by storing
#class (static) data. See next Chapter 6 on OOP.





-----------1st EFFORT - posted on GitHub
#!/usr/bin/env python3
#CharGrid.py 

"""
This module provides functionality for writing characters on a grid.

The module provides functions for adding horizontal and vertical lines,
and for (optionally filled) rectangles, and for (optionally boxed) text.

All char arguments must be strings of length 1; these are guarded by
assertions. If out of range row or column values are given, the
appropriate exception, RowRangeError or ColumnRangeError will
be raised---use the RangeError exception if you want to catch either.

>>> resize(14, 50)
>>> add_rectangle(0, 0, *get_size())
>>> add_vertical_line(5, 10, 13)
>>> add_vertical_line(2, 9, 12, "!")
>>> add_horizontal_line(3, 10, 20, "+")
>>> add_rectangle(0, 0, 5, 5, "%")
>>> add_rectangle(5, 7, 12, 40, "#", True)
>>> add_rectangle(7, 9, 10, 38, " ")
>>> add_text(8, 10, "This is the CharGrid module")
>>> add_text(1, 32, "Pleasantville", "@")
>>> add_rectangle(6, 42, 11, 46, fill=True)
>>> render(False)
%%%%%*********************************************
%   %                           @@@@@@@@@@@@@@@  *
%   %                           @Pleasantville@  *
%   %     ++++++++++            @@@@@@@@@@@@@@@  *
%%%%%                                            *
*      #################################         *
*      #################################  ****   *
*      ##                             ##  ****   *
*      ## This is the CharGrid module ##  ****   *
* !    ##                             ##  ****   *
* !  | #################################  ****   *
* !  | #################################         *
*    |                                           *
**************************************************
"""

import subprocess
import sys


class RangeError(Exception): pass
class RowRangeError(RangeError): pass
class ColumnRangeError(RangeError): pass


_CHAR_ASSERT_TEMPLATE = ("char must be a single character: '{0}' "
                         "is too long")
_max_rows = 25
_max_columns = 80
_grid = []
_background_char = " "


if sys.platform.startswith("win"): 
    def clear_screen():
        subprocess.call(["cmd.exe", "/C", "cls"])
else:
    def clear_screen():
        subprocess.call(["clear"])
clear_screen.__doc__ = """Clears the screen using the underlying \
window system's clear screen command"""


def char_at(row, column):
    """Returns the character at the given position

    This is really just for debugging.

    >>> char_at(0, 0)
    '%'
    >>> char_at(4, 11)
    ' '
    >>> char_at(32, 24)
    Traceback (most recent call last):
    ...
    RowRangeError
    """
    try:
        return _grid[row][column]
    except IndexError:
        if not 0 <= row <= _max_rows:
            raise RowRangeError()
        raise ColumnRangeError()


def set_background(char=" "):
    """Sets the background character

    >>> set_background("$")
    >>> char_at(0, 0)
    '%'
    >>> char_at(4, 24)
    '$'
    >>> set_background("<>")
    Traceback (most recent call last):
    ...
    AssertionError: char must be a single character: '<>' is too long
    >>> set_background(" ")
    """
    assert len(char) == 1, _CHAR_ASSERT_TEMPLATE.format(char)
    global _background_char
    old_background_char = _background_char
    _background_char = char
    for row in range(_max_rows):
        for column in range(_max_columns):
            if _grid[row][column] == old_background_char:
                _grid[row][column] = _background_char


def add_vertical_line(column, row0, row1, char="|"):
    """Adds a vertical line to the grid using the given char

    >>> add_vertical_line(5, 2, 10, "&")
    >>> char_at(2, 5) == char_at(3, 5) == "&"
    True
    >>> add_vertical_line(85, 1, 2)
    Traceback (most recent call last):
    ...
    ColumnRangeError
    """
    assert len(char) == 1, _CHAR_ASSERT_TEMPLATE.format(char)
    try:
        for row in range(row0, row1):
            _grid[row][column] = char
    except IndexError:
        if not 0 <= row <= _max_rows:
            raise RowRangeError()
        raise ColumnRangeError()
    

def add_horizontal_line(row, column0, column1, char="-"):
    """Adds a horizontal line to the grid using the given char

    >>> add_horizontal_line(8, 20, 25, "=")
    >>> char_at(8, 20) == char_at(8, 24) == "="
    True
    >>> add_horizontal_line(31, 11, 12)
    Traceback (most recent call last):
    ...
    RowRangeError
    """
    assert len(char) == 1, _CHAR_ASSERT_TEMPLATE.format(char)
    try:
        for column in range(column0, column1):
            _grid[row][column] = char
    except IndexError:
        if not 0 <= row <= _max_rows:
            raise RowRangeError()
        raise ColumnRangeError()
    

def add_rectangle(row0, column0, row1, column1, char="*", fill=False):
    """Adds a rectangle to the grid using the given char for the
    outline
    
    If filled is True, fills the rectangle with the given char.

    >>> add_rectangle(10, 30, 14, 35, "^", True)
    >>> char_at(10, 30) == char_at(12, 32) == "^"
    True
    >>> add_rectangle(10, 30, 14, 35, "!")
    >>> char_at(10, 30) == char_at(13, 34) == "!"
    True
    >>> add_rectangle(10, 30, 14, 95, "x")
    Traceback (most recent call last):
    ...
    ColumnRangeError
    >>> add_rectangle(10, 30, 14, 95)
    Traceback (most recent call last):
    ...
    ColumnRangeError
    """
    if not fill:
        add_vertical_line(column0, row0, row1, char)
        add_vertical_line(column1 - 1, row0, row1, char)
        add_horizontal_line(row0, column0, column1, char)
        add_horizontal_line(row1 - 1, column0, column1, char)
    else:
        assert len(char) == 1, _CHAR_ASSERT_TEMPLATE.format(char)
        try:
            for row in range(row0, row1):
                for column in range(column0, column1):
                    _grid[row][column] = char
        except IndexError:
            if not 0 <= row <= _max_rows:
                raise RowRangeError()
            raise ColumnRangeError()


def add_text(row, column, text, char=None):
    """Adds a string of text to the grid
    
    If char is not None, draws a box around the text with
    the given char. The box's top-left corner is one row above
    and one column left of the given row and column and extends
    to encompass the text.

    >>> add_text(6, 15, "Alpha Beta")
    >>> char_at(6, 15) == "A"
    True
    >>> char_at(6, 19) == char_at(6, 24) == "a"
    True
    >>> add_text(11, 22, "Gamma", ":")
    >>> char_at(12, 23) == "G"
    True
    >>> char_at(12, 24) == char_at(12, 27) == "a"
    True
    >>> char_at(11, 24) == char_at(13, 27) == ":"
    True
    >>> add_text(10, 89, "Delta")
    Traceback (most recent call last):
    ...
    ColumnRangeError
    >>> add_text(110, 8, "Epsison", "O")
    Traceback (most recent call last):
    ...
    RowRangeError
    """
    try:
        if char is None:
            for i, column in enumerate(range(column,
                                             column + len(text))):
                _grid[row][column] = text[i]
        else:
            assert len(char) == 1, _CHAR_ASSERT_TEMPLATE.format(char)
            row0 = row
            row1 = row0 + 3
            column0 = column
            column1 = column0 + len(text) + 2
            add_rectangle(row0, column0, row1, column1, char)
            row = row0 + 1
            for i, column in enumerate(range(column0 + 1,
                                             column1 - 1)):
                _grid[row][column] = text[i]
    except IndexError:
        if not 0 <= row <= _max_rows:
            raise RowRangeError()
        raise ColumnRangeError()


def render(clear=True):
    """Renders the grid onto the console and clears the grid
    """
    if clear:
        clear_screen()
    for row in range(_max_rows):
        print("".join(_grid[row]))
        for column in range(_max_columns):
            _grid[row][column] == _background_char


def get_size():
    """Returns the size of the grid

    >>> get_size()
    (14, 50)
    """
    return _max_rows, _max_columns


def resize(max_rows, max_columns, char=None):
    """Changes the size of the grid, wiping out the contents and
    changing the background if the background char is not None
    """
    assert max_rows > 0 and max_columns > 0, "too small"
    global _grid, _max_rows, _max_columns, _background_char
    if char is not None:
        assert len(char) == 1, _CHAR_ASSERT_TEMPLATE.format(char)
        _background_char = char
    _max_rows = max_rows
    _max_columns = max_columns
    _grid = [[_background_char for column in range(_max_columns)]
             for row in range(_max_rows)]

    
resize(_max_rows, _max_columns)


if __name__ == "__main__":
    import doctest
    doctest.testmod()
-----------1st EFFORT - posted on GitHub




#Reminder of topics<===========
CHAPTER 5 Modules

Modules and Packages
    Packages
    Custom Modules
        TextUtil Module
        CharGrid Module
Overview of Python Standard library
    String Handling
        io.StringIO Class
    Command-Line Programming
        optparse Module 
    Mathematics and Numbers
        heapq Module
    Times and Dates
        calendar, datetime, and time Module  
    Algorithms and Collection Data Types 
    File Formats, Encodings, and Data Persistence 
        base64 Module 
        tarfile Module 
    File, Directory, and Process Handling 
        os and os.path Modules
    Networking and Internet Programming 
    XML
        xml.etree.ElementTree Module 
    Other Modules
Summary
Exercises 


===============
Overview of Python Standard library
===============
#generally described as batteries included . Over 200 packages available.
#here we take a thematic approach to explaining landscape.

===============
    String Handling
===============
string module
                        >>> import string
                        >>> 
                        >>> import textwrap
#useful constants are string.ascii_letters and string.hexdigits
#provides string.Formatter class which we can subclass to provide custom string formatters.
#textwrap module can be used to wrap lines of text to a specific width and to minimize
#indentation.
                        >>> import struct 
#The struct module provides functions for packing and unpacking numbers, Booleans, and 
#strings to and from byte objects using their binary representations. This can be useful
#when handling data to be sent or received from low level libraries written in C.
#The struct and textwrap modules are used by the convert-incidents.py program in Chapter 7.
                        >>> import difflib
#The difflab module provides classes and methods for comparing sequences, such as strings,
#and is able to produce output both in standard "diff" formats and in HTML.

#Python's most powerful string handling module is the re (regular expression) module
#see Chapter 12

#The io.StringIO class can provide a string-like object that behaves like an in-memory
#text file. This can be convenient if we want to use the same code that writes to a file
#to write to a string.

#Example io.StringIO class
#Python provides two different ways of writing text to files
#One way is to use a file object's write() method, and the other is use the print() function
#with the file keyword argument set to a file object that is open for writing.
#Example

print("An error message", file=sys.stdout)          #buffered 
sys.stdout.write("Another error message\n")         #unbuffered
#both lines of text are printed to sys.stdout which is a file object that represents the
#standard output stream only in that the second is unbuffered. Python autmoatically
#creates and opens sys.stdin, sys.stdout, and sys.stderr at program start-up.
#The print() function adds a newline by default, although we can stop this by giving
#the end keyword argument set to an empty string.

#In some situation it is useful to be able to capture into a string the output that is 
#intended to go to a file. This can be achieved using the io.StringIO class which
#provides an object that can be used just like a file object, but which holds any 
#data writing to it in a string. If the io.StringIO object is given an initial string
#it can also be read as though it were a file.

#We can access io.StringIO if we do
import io  
#and we can use to capture output destined for a file object such as sys.stdout:
sys.stdout = io.StringIO()
#If this line is put at the beginning of a program, after the imports but before any
#use is made of sys.stdout then any text that is sent to sys.stdout will actually be 
#sent to the io.StringIO file-like object which this line has created and which has
#replaced the standard sys.stdout file object. Now when the print() and sys.stdout.write()
#lines shown earlier are executed, their output will go to the io.StringIO object
#instead of the console. (At any time we can restore the original sys.stdout with the
#statement sys.stdout = sys.__stdout__    
#We can obtain all the strings that have been written to the io.StringIO object by calling
io.StringIO.getvalue()  #function, in this case by calling
sys.stdout.getvalue()  #the return value is a string containing all the lines that have 
#been written. This string could be printed, or saved to a log or sent over a network
#connection like any other string. We will see another example of io.StringIO in this Chap.

#Reminder of topics<===========
CHAPTER 5 Modules

Modules and Packages
    Packages
    Custom Modules
        TextUtil Module
        CharGrid Module
Overview of Python Standard library
    String Handling
        io.StringIO Class
    Command-Line Programming
        optparse Module 
    Mathematics and Numbers
        heapq Module
    Times and Dates
        calendar, datetime, and time Module  
    Algorithms and Collection Data Types 
    File Formats, Encodings, and Data Persistence 
        base64 Module 
        tarfile Module 
    File, Directory, and Process Handling 
        os and os.path Modules
    Networking and Internet Programming 
    XML
        xml.etree.ElementTree Module 
    Other Modules
Summary
Exercises 



===============
    Command-Line Programming
===============
#If we need a program to be able to process text that may have been redirected
#in the console or that my be in files listed on the command line, we can use
#the fileinput module's
fileinput.input() #function which iterates over all the lines redirected from
#the console (if any) and over all the lines in the files listed on the command line
#as one continuous sequence of lines. The module can report the current filename and
#line number at any time using 
fileinput.filename() #and
fileinput.lineno()
#and can handle some compressed files.

#Two separate modiules are provided for handling command-line options, 
optparse #module is newer and more powerful
getopt #module is popular b/c it is simple to use and has been around long time

#Example optparse Module
#in Chapter 2 we described 
csv2html.py program #and in that chapter's exercises, we
#proposed extending the program to accept the command line arguments "maxwidth" taking
#an integer and "format" taking a string. (SEE MODEL SOLUTION NEXT)

#The model solution is here
csv2html2_opt.py 
#!/usr/bin/env python3


import sys
import sys.sax.saxutils

def main():
    maxwidth, format = process_options()
    if maxwidth is not None:
        print_start()
        count = 0
        while True:
            try:
                line = input()
                if count == 0:
                    color = "lightgreen"
                elif count % 2:
                    color = "white"
                else:
                    color = "lightyellow"
                print_line(line, color, maxwidth, format)
                count += 1
            except EOFError:
                break
        print_end()

def process_options():
    maxwidth_arg = "maxwidth"
    format_arg = "format="
    maxwidth = 100
    format = ".0f"
    for arg in sys.argv[1:]:
        if arg in ["-h", "--help"]:
            print("""\
usage:
csv2html.py [maxwidth=int] [format=str] < infile.csv > outfile.html

maxwidth is an optional integer; if specified, it sets the maximum
number of characters that can be output for string fields,
otehrwie a default of {0} characters is used.

format is the format to use for numbers; if not specified it
defaults to "{1}".""".format(maxwidth, format))
            return None, None
        elif arg.startswith(maxwidth_arg):
            try:
                maxwidth = int(arg[len(maxwidth_arg):])
            except ValueError:
                pass
        elif arg.startswith(format_arg):
            format = arg[len(format_arg):]
    return maxwidth, format

def print_line(line, color, maxwidth, format):
    print("<tr bgcolor='{0}'>".format(color))
    numberFormat = "<td align='right'>{{0:{0}}}</td>".format(format)
    fields = extract_fields(line)
    for field in fields:
        if not field:
            print("<td></td>")
        else:
            number = field.replace(",", "")
            try:
                x = float(number)
                print(numberFormat.format(x))
            except ValueError:
                field = field.title()
                field = field.replace(" And ", " and ")
                if len(field) <= maxwidth:
                    field = xml.sax.saxutils.escape(field)
                else:
                    field = "{0} ...".format(xml.sax.saxutils.escape(field[:maxwidth]))
                print("<td>{0}</td>".format(field))
    print("</tr")


def extract_fields(line):
    fields = []
    field = ""
    quote = None
    for c in line:
        if c in "\"'":
            if quote is None:
                qoute = c 
            elif quote == c:
                quote = None 
            else:
                field += c 
            continue
        if quote is None and c == ",":
            fields.append(field)
            field = ""
        else:
            fields.append(field)
    return fields

def print_end():
    print("</table>")

main()

#so here back to text
#the model solution (above) has a 26 line function to process the arguments. Here is
#the start of the main() function for csv2html._opt.py which is a version of the 
#program that uses the optparse module to handle the command line arguments rather 
#than a custom function:

import optparse

def main():
    parser = optparse.OptionParser()
    parser.add_option(  "-w",
                        "--maxwidth",
                        dest="maxwidth", 
                        type="int",
                        help=("the maximum number of characters that can be output "
                                "to string fields [default: %default"))
    parser.add_option(  "-f",
                        "--format",
                        dest="format",
                        help=("the format used for outputting numbers "
                                "[default: %default]"))
    parser.set_defaults(maxwidth=100, format=".0f")
    opts, args = parser.parse_args()
#only 9 new lines of code are needed, plus the import optparse statement
#note do NOT need to explicitly provide -h and --help options; these are
#handled by the optparse module to produce a suitable usage message using
#texts from the help keyword arguments, and with and "%default" text replaced
#with the option's default value.

#Notice also that the options now use the conventional Unix style of having both
#short and long option names that start with a hyphen. Short names are convenient
#for interactive use at the console; long names are more understandable when used
#in shell scripts.
#Example setting maximum width to 80 we can use any of the following
#  -w80, -w 80, --width=80, or --width 80

#After the command line is parsed, the options are available using the
dest #names, for example
opts.maxwidth #and
opts.format
#Any command line arguments that have not been processed (usually filenames) are in the 
#args list.

#If an error occurs when parsing the command line, the optparse parser will call
#sys.exit(2) which leads to a clean program termination and returns 2 to the
#operating system as the program's result value.
#Conventionally, a return value of 2 signifies a usage error, 1 signifies any other
#kind of error, and 0 means success. When sys.exit() is called with no argument
#it returns 0 to the operating system.

#Reminder of topics<===========
CHAPTER 5 Modules

Modules and Packages
    Packages
    Custom Modules
        TextUtil Module
        CharGrid Module
Overview of Python Standard library
    String Handling
        io.StringIO Class
    Command-Line Programming
        optparse Module 
    Mathematics and Numbers
        heapq Module
    Times and Dates
        calendar, datetime, and time Module  
    Algorithms and Collection Data Types 
    File Formats, Encodings, and Data Persistence 
        base64 Module 
        tarfile Module 
    File, Directory, and Process Handling 
        os and os.path Modules
    Networking and Internet Programming 
    XML
        xml.etree.ElementTree Module 
    Other Modules
Summary
Exercises 


===============
    Mathematics and Numbers
===============
heapq module
#In addition to the built-in int, float, and complex numbers, the library also 
#provides the 
decimal.Decimal #and
fractions.Fraction #numbers
#Three numberic libraries are available
math #for standard mathematical functions
cmath #for complex number mathematical functions
random #which provides many functions for random number generation (see Chapter 2).

#Python's numeric abstract base classes (classes that can be inherited from BUT
#that can NOT be used directly) are in the 
numbers #module
#are useful for checking that an object, say x is any kind of number using
isinstance(x, numbers.Number)
#or is a specific kind of number, for example, 
isinstance(x, numbers.Rational) #or
isinstance(x, numbers.Integral)

#For scientific and engineering programming, 
NumPy #package is useful. It provides highly efficient n-dimensional arrays, 
#basic linear algebra functions and Fourier transforms, and tools for integration 
#with C, C++ and Fortran code. The 
SciPy 
#package incorporates NumPy and extends it to modules for statistical computing, 
#signal and image processing, genetic algorithms, and much more. See www.scipy.org



#Reminder of topics<===========
CHAPTER 5 Modules

Modules and Packages
    Packages
    Custom Modules
        TextUtil Module
        CharGrid Module
Overview of Python Standard library
    String Handling
        io.StringIO Class
    Command-Line Programming
        optparse Module 
    Mathematics and Numbers
        heapq Module
    Times and Dates
        calendar, datetime, and time Module  
    Algorithms and Collection Data Types 
    File Formats, Encodings, and Data Persistence 
        base64 Module 
        tarfile Module 
    File, Directory, and Process Handling 
        os and os.path Modules
    Networking and Internet Programming 
    XML
        xml.etree.ElementTree Module 
    Other Modules
Summary
Exercises 


===============
    Times and Dates 
===============
#not simple, very complex topic
datetime.datetime class #can handle time zones
dateutil #from www.labix.org/python-dateutil and
mxDateTime #from www.egenix.com/products/python/mxBase/mxDateTime

time module #hanles timestamps
#Example of the calendar, datetime, and time Modules
#objects of type datetime.datetime are usually created programmatically
#whereas objects that hold UTC date/times are usually received from external
#sources, such as file timestamps. Some examples are:
                        import calendar, datetime, time
                        moon_datetime_a = datetime.datetime(1969, 7, 20, 20, 17, 40)
                        moon_time = calendar.timegm(moon_datetime_a.utctimetuple())
                        moon_datetime_b = datetime.datetime.utcfromtimestamp(moon_time)
                        moon_datetime_a.isoformat()     #returns 
                        >>> moon_datetime_a.isoformat()
                        '1969-07-20T20:17:40'
                        moon_datetime_b.isoformat()     #returns 
                        >>> moon_datetime_b.isoformat()
                        '1969-07-20T20:17:40'
                        time.strftime("%Y-%m-%dT%H:%M:%S", time.gmtime(moon_time))
                        >>> time.strftime("%Y-%m-%dT%H:%M:%S", time.gmtime(moon_time))
                        '1969-07-20T20:17:40'
                        >>> 
#moon_datetime_a variable is of type datetime.datetime and holds the data and time
#that Apollo 11 landed on the moon.
#moon_time is of type int and hold the number of seconds since the landing


#Reminder of topics<===========
CHAPTER 5 Modules

Modules and Packages
    Packages
    Custom Modules
        TextUtil Module
        CharGrid Module
Overview of Python Standard library
    String Handling
        io.StringIO Class
    Command-Line Programming
        optparse Module 
    Mathematics and Numbers
        heapq Module
    Times and Dates
        calendar, datetime, and time Module  
    Algorithms and Collection Data Types 
    File Formats, Encodings, and Data Persistence 
        base64 Module 
        tarfile Module 
    File, Directory, and Process Handling 
        os and os.path Modules
    Networking and Internet Programming 
    XML
        xml.etree.ElementTree Module 
    Other Modules
Summary
Exercises 


===============
    Algorithms and Collection Data Types 
===============
bisect #module provides functions for searching sorted sequences such as sorted lists
#and for inserting items while preserving the sort order.
#this uses the binary search algorithm, so they are very fast.
heapq #module provides functions for turning a sequence such as a list into a heap
#heap = collection data type where the first item (at index position 0) is always
#the smallest item, and for inserting and removing items while keeping the sequence
#as a heap.

collections #package provides
collections.defaultdict #dictionary and
collections.namedtuple #collection data type (previously discussed)
collections.UserList #and
collections.UserDict #types, although subclassing the built-in and dict types is
#probably more common than using these types. Another type is 
collections.deque #which is similar to a list, but whereas a list is very fast for
#adding and removing items at the end, a collections.deque is very fast for
#adding and removing items both at the beginning and at the end.

#Python's non-numeric abstract base classes are also in the collections package.
#See Chapter 8

array #module provides the
array.array #sequence type that can store numbers or characterss in a very space
#efficient way. It has similar behavior to lists except that the type of object
#it can store is fixed when it is created, so unlike lists, it can NOT store
#objects of different types. NumPy also provides efficient arrays.

weakref #module provides functionality for creating weak references = behave like 
#normal object references except that if the only reference to an object is a weak
#reference, the object can still be scheduled for garbage collection.
#This prevents objects from being kept in memory simply b/c we have a reference to them

#Example
heapq #module provides functionality to convert a list into a heap and for adding/removing
#items from the heap while preserving the heap property.
#heap is binary tree that respects the heap property = first item (at index position 0)
#is always the smallest item.
#create a heap from scratch
import heapq
heap = []
heapq.heappush(heap, (5, "rest"))
heapq.heappush(heap, (2, "work"))
heapq.heappush(heap, (4, "study"))

                        >>> import heapq
                        >>> heap = []
                        >>> heapq.heappush(heap, (5, "rest"))
                        >>> heapq.heappush(heap, (2, "work"))
                        >>> heapq.heappush(heap, (4, "study"))
                        >>> heap
                        [(2, 'work'), (5, 'rest'), (4, 'study')]
                        >>> 

BOOKMARK HERE TOPIC
#if we already have a list, we can turn it into a heap with
heapq.heapify(alist)
#this will do any necessary reordering in-place.
#the smallest item can be removed from the heap using 
heapq.heappop(heap)

for x in heapq.merge([1, 3, 5, 8], [2, 4, 7], [0, 1, 6, 8, 9]):
    print(x, end=" ")

                        >>> heap
                        [(2, 'work'), (5, 'rest'), (4, 'study')]
                        >>> for x in heapq.merge([1, 3, 5, 8], [2, 4, 7], [0, 1, 6, 8, 9]):
                        ...     print(x, end=" ")
                        ... 
                        0 1 1 2 3 4 5 6 7 8 8 9 >>> 

heapq.merge()
#function takes any number of sorted iterables as arguments and returns an iterator
#that iterates over all the items from all the iterables in order.



#Reminder of topics<===========
CHAPTER 5 Modules

Modules and Packages
    Packages
    Custom Modules
        TextUtil Module
        CharGrid Module
Overview of Python Standard library
    String Handling
        io.StringIO Class
    Command-Line Programming
        optparse Module 
    Mathematics and Numbers
        heapq Module
    Times and Dates
        calendar, datetime, and time Module  
    Algorithms and Collection Data Types 
    File Formats, Encodings, and Data Persistence 
        base64 Module 
        tarfile Module 
    File, Directory, and Process Handling 
        os and os.path Modules
    Networking and Internet Programming 
    XML
        xml.etree.ElementTree Module 
    Other Modules
Summary
Exercises 


===============
    File Formats, Encodings, and Data Persistence 
===============
base64 #module has functions for reading and writing using Base16, Base32, and Base64
#encodings specified in RFC 3548
quopri #module has functions reading and writing "quoted printable" format. See RFC 1521
#and is used for MIME data (Multipurpose Internet Mail Extensions).
uu #module has functions for reading and writing uuencoded data.
xdrlib #module has functions for external data reprsentation standards RFC 1832

#modules are also provided for reading and writing archive files in the most popular 
#formats.
bz2 #module handles .bz2 files
gzip #module handles .gz files
tarfile #module handles .tar, .tar.gz, .tgz, .tar.bz2 files 
zipfile #module handles .zip files

#audio format support
aifc #module for AIFF (Audio Interchange File Format)
wave #module for uncompressed .wav files
audioop #module for audio data
sndhdr #module provides functions to determine what kind of sound data is stored
#in a file and some of its properties, such as the sampling rate.

configparser #module for format for configuration files is RFC 822
csv #module for read/writing csv data or tab-delimited data including idiosyncracies.

#data persistence provided by
pickle #module used to store and retrieve arbitrary Python objects (including entire
#collections) to and from disk. See Chapter 7
DBM #support --> these are like dictionaries except that their items are stored on disk
#rather than in memory, and both their keys and values must be byte objects or strings.
shelve #module Chapter 11 is used to provide DBM files with string keys and arbitrary
#Python objects as values.
#Chapter 11 covers DBM module, Python's database API, and using built-in SQLite database

#Example base64 module
base64image.py
#used mostly for handling binary data that is embedded in emails such as ASCII text.
#can also be used to store binary data inside .py files

#first step is to get the binary data into base64 format. 
import base64
import os
left_align_png = os.path.join(os.path.dirname(__file__), "data/left_align.png")
#Here we assume that the base64 module has been imported and that the path 
#and filename of a .png file are in the variable left_align_png

binary = open(left_align_png, "rb").read()
ascii_text = ""
for i, c in enumerate(base64.b64encode(binary)):
    if i and i % 68 == 0:
        ascii_text += "\\\n"
    ascii_text += chr(c)
#this code snippet reads the file in binary mode ie "rb" and converts it to a Base64
#string of ASCII characters. 
#Alternative way to code this
with open(left_align_png, "rb") as file:
    binary = file.read()
#Every 68th character a backslash-newline combination is added. Why? 
#this limits the width of the lines of ASCII characters to 68, but
#ensures that when the data is read back the newlines will be ignored b/c the 
#backslash will escape them. The ASCII text obtained like this can get stored
#as a byte literal in a .py file, for example:
LEFT_ALIGN_PNG = b"""\
iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAABGdBTUEAALGPC/xhBQAA\
AAlwSFlzAAALEgAACxIB0t1+/AAAAUBJREFUeJztlrFKw0AYx38RhzyCY/oUqVskm5tE\
cBQEFynkEcQXKBS6SKDg2KG46ChmbJ7CjL5BXKQd7gvlzgRbm3An+ofj7rsj933587/7\
n8ciBICkUL0Z94Qw8gE46DXLFvDMichfaHH+kXSb0WDYKQZWNnI7xcB2uBNN3OpaidMR\
AC+TqRZ/3p8AUA1fASjyqfadfQYCGZT9a6CRbesMHIbXVwCU2cwDCGSh3HNjUxM1LiTf\
PJsBDjDgpTKY7K+BnU7UH/YCAw4wsHGnfy/4GVpeUL/HC4byB8v+NeCoFyzjUxkWjRWG\
0ZFazd9lpr4nurkfrDNg7U0YpyM37oGvOE5UE1xK+x6+tN1gnYEuNKCdnsG56t+e5LQY\
bmquu8PAmVT2+CwVV6rCyA9UfFMCkI+bN6p18tCWqcUzrDOwBh2zVCR+JZVeAAAAAElF\
TkSuQmCC"""
#here we omitted most of the lines as indicated by the ellipsis.
#The data can be converted back to its original binary form like this.
binary = base64.b64decode(LEFT_ALIGN_PNG)
#The binary data could be written to a file using 
open(filename, "wb").write(binary)
#Keeping binary data in .py files is much less compact than keeping it in its
#original form, but can be useful if we want to provide a program that requires
#some binary data as a single .py file.


-----------1st EFFORT - posted on GitHub
BOOKMARK HERE TOPIC - posted but not sure how it works

#!/usr/bin/env python3
#base64image.py

import base64
import os

left_align_png = os.path.join(os.path.dirname(__file__),
                              "data/left_align.png")
with open(left_align_png, "rb") as file:
    binary = file.read()
ascii_text = ""
for i, c in enumerate(base64.b64encode(binary)):
    if i and i % 68 == 0:
        ascii_text += "\\\n"
    ascii_text += chr(c)

LEFT_ALIGN_PNG = b"""\
iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAABGdBTUEAALGPC/xhBQAA\
AAlwSFlzAAALEgAACxIB0t1+/AAAAUBJREFUeJztlrFKw0AYx38RhzyCY/oUqVskm5tE\
cBQEFynkEcQXKBS6SKDg2KG46ChmbJ7CjL5BXKQd7gvlzgRbm3An+ofj7rsj933587/7\
n8ciBICkUL0Z94Qw8gE46DXLFvDMichfaHH+kXSb0WDYKQZWNnI7xcB2uBNN3OpaidMR\
AC+TqRZ/3p8AUA1fASjyqfadfQYCGZT9a6CRbesMHIbXVwCU2cwDCGSh3HNjUxM1LiTf\
PJsBDjDgpTKY7K+BnU7UH/YCAw4wsHGnfy/4GVpeUL/HC4byB8v+NeCoFyzjUxkWjRWG\
0ZFazd9lpr4nurkfrDNg7U0YpyM37oGvOE5UE1xK+x6+tN1gnYEuNKCdnsG56t+e5LQY\
bmquu8PAmVT2+CwVV6rCyA9UfFMCkI+bN6p18tCWqcUzrDOwBh2zVCR+JZVeAAAAAElF\
TkSuQmCC"""

assert (bytes(ascii_text.replace("\\\n", ""), encoding="ascii") ==
        LEFT_ALIGN_PNG)

binary = base64.b64decode(LEFT_ALIGN_PNG)
with open(left_align_png, "wb") as file:
    file.write(binary)
print("saved", left_align_png)
-----------1st EFFORT - posted on GitHub






#Example tarfile module
#most versions of Windows do not come with support for .tar format that is so
#widely used in Unix. Easily rectified using Python's tarfile module which can 
#create and unpack .tar and .tar.gz archives (known as tarballs) and with the 
#right libraries installed, .tar.bz2 archives.
#The untar.py program can unpack tarballs using the tarfile module; here we 
#will just show some key extracts
BZ2_AVAILABLE = True
try:
    import bz2
except ImportError:
    BZ2_AVAILABLE = False
#the bz2 module is used to handle the bzip2 compression format, but importing it
#will fail if Python was built without access to the bzip2 library.
#The Python binary for Windows is always built with bzip2 compression built-in; it is
#only on some Unix builds that it might be absent.
#We account for the possibility that the module is not available using a try..except block
#and keep a Boolean variable that we can refer to later (although we dont show that code)
UNTRUSTED_PREFIXES = tuple(["/", "\\"] + [c + ":" for c in string.ascii_letters])
#this statement creates the tuple ('/', '\', 'A:', 'B:','C:', ..., 'Z:', 'a:','b:', ...'z:')
#Any filename in the tarball being unpacked that begins with one of these is suspect b/c
#tarballs should NOT use absolute paths since then they risk overwritting system files,
#so as a precaution we will not unpack any file whose name starts with one of
#these prefixes.

def untar(archive):
    tar = None
    try:
        tar = tarfile.open(archive)
        for member in tar.getmembers():
            if member.name.startswith(UNTRUSTED_PREFIXES):
                print("untrusted prefix, ignoring", member.name)
            elif ".." in member.name:
                print("suspect path, ignoring", member.name)
            else:
                tar.extract(member)
                print("unpacked", member.name)
    except (tarfile.TarError, EnvironmentError) as err:
        error(err)
    finally:
        if tar is not None:
            tar.close()
#Each file in a tarball is called a member. The tarfile.getmembers() function
#returns a list of tarfile.TarInfo objects, one for each member.
#the member's filename, including its path, is in the tarfileTarInfo.name attribute.
#if the name begins with an untrusted prefix or contains .. in its path, we output
#an error message; otherwise, we call tarfile.extract() to save the member to disk.
#tarfile module has its own set of custom exceptions, but we have taken the simplistic
#approach that if any exception occurs we output the error message and finish
def error(message, exit_status=1):
    print(mesage)
    sys.exit(exit_status)
#here we quoted the error() function just for completeness. The unquoted main() function
#print a usage message if -h or --help is given; otherwise, it performs some
#basic checks before calling untar() with the tarball's filename.



-----------1st EFFORT - posted on GitHub
#!/usr/bin/env python3
# Useful on Windows where tar isn't supplied as standard

BZ2_AVAILABLE = True
try:
    import bz2
except ImportError:
    BZ2_AVAILABLE = False
import os
import string
import sys
import tarfile


UNTRUSTED_PREFIXES = tuple(["/", "\\"] +
        [c + ":" for c in string.ascii_letters])


def main():
    if len(sys.argv) != 2 or sys.argv[1] in {"-h", "--help"}:
        error("usage: untar.py archive.{{tar,{0}tar.gz}}".format(
              "tar.bz2," if BZ2_AVAILABLE else ""), 2)

    archive = sys.argv[1]
    if not archive.lower().endswith((".tar", ".tar.gz", ".tar.bz2")):
        error("{0} doesn't appear to be a tarball".format(archive))
    if not BZ2_AVAILABLE and archive.lower().endswith(".bz2"):
        error("bzip2 decompression is not available")
    if not os.path.exists(archive):
        error("{0} doesn't appear to exist".format(archive))
    untar(archive)


def untar(archive):
    tar = None
    try:
        tar = tarfile.open(archive)
        for member in tar.getmembers():
            if member.name.startswith(UNTRUSTED_PREFIXES):
                print("untrusted prefix, ignoring", member.name)
            elif ".." in member.name:
                print("suspect path, ignoring", member.name)
            else:
                tar.extract(member)
                print("unpacked", member.name)
    except (tarfile.TarError, EnvironmentError) as err:
        error(err)
    finally:
        if tar is not None:
            tar.close()


def error(message, exit_status=1):
    print(message)
    sys.exit(exit_status)


main()
-----------1st EFFORT - posted on GitHub




#Reminder of topics<===========
CHAPTER 5 Modules

Modules and Packages
    Packages
    Custom Modules
        TextUtil Module
        CharGrid Module
Overview of Python Standard library
    String Handling
        io.StringIO Class
    Command-Line Programming
        optparse Module 
    Mathematics and Numbers
        heapq Module
    Times and Dates
        calendar, datetime, and time Module  
    Algorithms and Collection Data Types 
    File Formats, Encodings, and Data Persistence 
        base64 Module 
        tarfile Module 
    File, Directory, and Process Handling 
        os and os.path Modules
    Networking and Internet Programming 
    XML
        xml.etree.ElementTree Module 
    Other Modules
Summary
Exercises 


===============
    File, Directory, and Process Handling 
===============
shutil #module provides high level functions for file and directory handling including
shutil.copy()       #for copying files
shutil.copytree()   #for copying entire directory trees
shutil.move()       #for moving directory trees
shutil.rmtree()     #for removing entire directory trees including nonempty ones

#temporary files and directories should be creating used the 
tempfile #module which provides the necessary functions, for example,
tempfile.mkstemp() #creates the temporaries in the most secure manner possible.

filecmp #module can be used to compare files with the
filecmp.cmp() #function
filecmp.cmpfiles() #to compare entire directories

BOOKMARK HERE TOPIC
#one very powerful and effective use of Python programs is to orchestrtte the running
#of other programs. This can be done using the
subprocess #module which can start other processes, communicate with them using pipes,
#and retrieve their results. See Chapter 10
#An even MORE powerful alternative is to use the
multiprocessing #module which provides extensive facilities for offloading work
#to multiple processes and for accumulating results, and can often be used as an
#alternative to multithreading.

os #module provides platform independent access to operating system functionality.
os.environ #variable holds a mapping object whose items are environment variable
#names and their values. The program's working directory is provided by
os.getcwd() #the program's working directory and can be changed to 
os.chdir() #change the working directory
#also provides low-level file descriptor based file handling
os.access() #function can be used to determine whether a file exists or whether
#it is readible or writeable
os.listdir() #function returns a list of the entries (ie files and directories but
#excluding the . and .. entries).
os.stat() #function returns various items of information about a file or directory
#such as its mode, access time, and size
os.mkdir() #create directories
os.makedirs() #function that creates intermediate directories
os.rmdir() #function to remove directories
os.removedirs() #function to remove directory trees that contain only empty directories
os.remove() #function to remove file or directories
os.rename() #function to rename file or directories
os.walk() #function iterates over an entire directory tree, retrieveing the name of
#every file and directory in turn.

#os also provides many low-level platform specific functions for example
#to work with file descriptors, and to fork (only on Unix systems), spawn, etc.

os.path #module provides a mixture of string manipulation of paths, and some file
#system convenience functions.
os.path.abspath() #function returns the absolute path of its argument with 
#redundant path separators and elements removed.
os.path.split() #function returns a 2-tuple with 1st element containing the path and 
#2nd element is filename (which will be empty if path with no filename was given)
os.path.basename() #function is 1st part of os.path.split()
os.path.dirname() #function is 2nd part of os.path.split()
os.path.splitext() #function to split path name into two parts
os.path.join() #function take any number of path strings and returns a single path 
#using the platform specific path separator.

os.stat() #module provides several pieces of info about a file or directory
os.path.exists() #function
os.path.getsize() #function
os.path.isfile() #function
os.path.isdir() #function

mimetypes #module for MIME types (Multipurpose Internet Mail Extensions)

#Example os and os.path Modules
#to create a dictionary where each key is a filename including its path and
#each value is the timestamp (seconds since epoch) when the file was last modified
#only for those in the given path:

date_from_name = {}
for name in os.listdir(path):
    fullname = os.path.join(path, name)
    if os.path.isfile(fullname):
        date_from_name[fullname] = os.path.getmtime(fulltime)
#this code is simple
#BUT can only be used for files in a single directory

#what if we need to traverse entire directory tree? then use
os.walk() #function
#code snippet from 
finddup.py #program
#is here
#this code snippet creates a dictionary where each key is a 2-tuple (file size, filename)
#where the filename excludes the path, and where each value is a list of the full
#filenames that match their key's filemane and have the same file size:

data = collections.defaultdict(list)

for root, dirs, files in os.walk(path):
    for filename in files:
        fullname = os.path.join(root, filename)
        key = (os.path.getsize(fullname), filename)
        data[key].append(fullname)
#Note a much more sophisticated find duplicates program
findduplicates-t.py #uses multiple threads and MD5 checksums is in Chapter 9
#Back to our code snippet, for each directory os.walk() returns the root and two lists
#one of the subdirectories in the directory and the other of the files in the directory.
#To get the full path for a filename we need to combine just the root and the filename.
#Notice taht we do not have to recurse into the subdirectories ourselves b/c os.walk()
#does this for us. Once the data is gathered, we can iterate over it to produce a report
#of possible duplicate files:
#BASIC
for size filename in sorted(data):
    names = data[(size, filename)]
    if len(names) > 1:
        print("" "".format())
        for name in names:
            print("".format())

#DETAIL
for size filename in sorted(data):
    names = data[(size, filename)]
    if len(names) > 1:
        print("{0} ({1} bytes) may be duplicated " 
                "({2} files):".format(filename ,size, len(names)))
        for name in names:
            print("\t{0}".format(name))

#b/c the dictionary keys are (size, filename) tuples, we dont need to use a key 
#function to get the data sorted in size order. If any (size, filename) tuple has
#more than one filename in its list, these might be duplicates.

...
shell32.dll (8460288 bytes) may be duplicated (2 files):
"           \windows\system32\shell32.dll                       "
"           \windows\system32\dllcache\shell32.dll              "

#this is the last item taken from the 3,282 lines of output produced by running
#finddup.py \windows on a Windows XP system.



#Reminder of topics<===========
CHAPTER 5 Modules

Modules and Packages
    Packages
    Custom Modules
        TextUtil Module
        CharGrid Module
Overview of Python Standard library
    String Handling
        io.StringIO Class
    Command-Line Programming
        optparse Module 
    Mathematics and Numbers
        heapq Module
    Times and Dates
        calendar, datetime, and time Module  
    Algorithms and Collection Data Types 
    File Formats, Encodings, and Data Persistence 
        base64 Module 
        tarfile Module 
    File, Directory, and Process Handling 
        os and os.path Modules
    Networking and Internet Programming 
    XML
        xml.etree.ElementTree Module 
    Other Modules
Summary
Exercises 


BOOKMARK HERE LEFT OFF
===============
    Networking and Internet Programming 
===============
#packages and modules for networking and internet programming are a major part
#of Python's standard library. At the lowest level, the 
socket #module provides the most fundamental network functionality, with functions
#for creating sockets, doing DNS (Domain Name System) lookups, and handling IP addresses.
#Encrypted and authenticated sockets can be set up using the 
ssl #module.
socketserver #module provides TCP (Transmission Control Protocal) and UDP (User
#Datagram Protocal) servers. These servers can handle requests directly or can create
#a separate process (by forking) or a separate thread to handle each request.
#Asynchronous client and server socket handling can be achieved using the
asyncore #module and the higher level 
aynchat #module that is built on top of it.

#Python has defined the WSGI (Web Server Gateway Interface) to provide a standard
#interface between web servers and web applications written in Python. In support
#of the standard the
wsgiref #package provides a reference implementation of WSGI that has modules for
#providing WSGI-compliant HTTP servers, and for handling response header and CGI
#Common Gateway Interface) scripts. In addition, the 
http.server #module provides and HTTP server which can be given a request
#handler (a standard one is provided), to run CGI scripts.
http.cookies #module provides functions for managing cookies
http.cookiejar #module provides functions for managing cookies
cgi #module offers CGI script support
cgitb #module offers CGI script support
http.client #module offers client access to HTTP requests

urllib #package's modules offer higher-level and easier URL convenient access
urllib.parse #module
urllib.request #module
urllib.response #module
urllib.error #module
urllib.robotparser #module

#Example
#grabbing a file from the internet is as simple as
fh = urllib.request.urlopen("http://www.python.org/index.html")
html = fh.read().decode("utf-8")
#here the urllib.request.urlopen() function returns an object that behaves much like
#a file object opened in read binary mode.
#here we retrieve the web site's index.html file as a bytes object and store it
#as a string in the html variable. It is also possible to grab files and store
#them in local files with the
urllib.request.urlretrieve() #function

#HTML, XHTML and URL documents can be parsed using the
html.parser #module
urrlib.parse #module
#robots.txt #files can be parsed with the 
urllib.robotparser #module
#Data that is represented using JSON (JavaScript Object Notation) can be read and written
json #modole

#XML-RPC (Remote Procedure Call) provides support
#(as opposed to HTML server and client support)
xmlrpc.client #module
xmlrpc.server #module

ftplib #module offers additional client functionality for FTP (File Transport Protocol)
nntplib #module for the NNTP (Network News Transport Protocol)
telnetlib #module for TELNET

smtpd #module provides an SMTP (Simple Mail Transport Protocol) server
smtplib #module provides the email client modules
imaplib #module for IMAP4 (Internet Message Access Protocol)
poplib #module for POP3 (Post Office Protocol)
mailbox #module for various formats
email #module for individual messages

#Twisted provides a comprehensive 3rd party networking library
www.twistedmatrix.com
#other 3rd party programming libraries
www.djangoproject.com  #for creating web applications
www.turbogeats.org #for creating web applications

www.plone.org #for providing complete web frameworks and CMS (content management systems)
www.zope.org #for providing complete web frameworks and CMS (content management systems)



#Reminder of topics<===========
CHAPTER 5 Modules

Modules and Packages
    Packages
    Custom Modules
        TextUtil Module
        CharGrid Module
Overview of Python Standard library
    String Handling
        io.StringIO Class
    Command-Line Programming
        optparse Module 
    Mathematics and Numbers
        heapq Module
    Times and Dates
        calendar, datetime, and time Module  
    Algorithms and Collection Data Types 
    File Formats, Encodings, and Data Persistence 
        base64 Module 
        tarfile Module 
    File, Directory, and Process Handling 
        os and os.path Modules
    Networking and Internet Programming 
    XML
        xml.etree.ElementTree Module 
    Other Modules
Summary
Exercises 


===============
    XML 
===============
#two widely used approach to parsing XML documents.
#Approach1) is DOM (Document Object Model)
#Approach2) is SAX (Simple API for XML)

xml.dom #module provides a DOM parser
xml.dom.minidom #module

xml.sax #module provides SAX parser
xml.sax.saxutils #module for its xml.sax.saxutils.escape #function 
#to XML escape "&", "<", and ">"
xml.sax.saxutils.quoteattr() #function that does same thing but additionally escapes
#quotes to make the text suitable for a tag's attribute
xml.sax.saxutils.unescape() #function to do the opposite conversion

#two other parsers are available
xml.parsers.expat #module used to parse XML documents with expat (assuming expat library
#is available
xml.etree.ElementTree #module to parse XML documents using a kind of dictionary/list
#interface. 
#note by default, the DOM and element tree parsers themselves use the expat parser
#under the hood.
#all of this is covered in Chapter 7

Example xml.etree.ElementTree Module
#Python's DOM and SAX parsers provide the APIs that experienced XML programmers are
#used to, and the 
xml.etree.ElementTree #module offers a more Pythonic approach to parsing and writing XML
#the element tree module was recently added to Python library so many readers may not be
#familier with it.
#short example here and Chapter 7 gives more detailed coding using DOM and SAX

BOOKMARK HERE NOAA
#NOAA National Oceanic and Atmospheric Administration web site provides wide variety of
#data, including XML file listing US weather stations with 20,000+ lines long and 2000+
#actual weather station locations.
#typical entry is

<station>
    <station_id>KBOS</station_id>
    <state>MA</state>
    <station_name>Boston, Logan International Airport</station_name>
    ...
    <xml_url>http://weather.gov/data/current_obs/KBOS.xml</xml_url>
</station>
#file is cut down for presentation purposes. File is 840K in size, and so its 
#compressed using gzip to 72K. BUT the element tree parser requires either a 
#filename or file object to be read, but we cannot give it to the compressed site
#since that will just appear to be random binary data.
#We can solve this in two initial steps:
binary = gzip.open(filename).read()
fh = io.StringIO(binary.decode("utf8"))
#the gzip module's gzip.open() function is similar to the built-in open() except
#that it reads gzip-compressed files (those with extension .gz) as raw binary data.
#We need the data available as a file that the element tree parser can work with, so
#we use the bytes.decode() method to convert the binary data to a string using UTF-8
#encoding (which is what the XML file uses), and we create a file-like 
io.StringIO #object with the string containing the entire XML file as its data.

tree = xml.etree.ElementTree.ElementTree()
root = tree.parse(fh)
stations = []
for element in tree.getiterator("station_name"):
    stations.append(element.text)
#Here we create a new xml.etree.ElementTree.ElementTree object and give it a
#file object from which to read XML we want it to parse.
#As far as the element tree parser is concerned, it has been passed a file object
#open for reading, although in fact it is reading a string inside an io.StringIO object.
#We want to extract the names of all the weather stations, and this is easily achieved
#using the xml.etree.ElementTree.ElementTree.getiterator() method which returns
#an iterator that returns all the xml.etree.ElementTree.ElementTree objects that
#have the given tag name.
#We just use the element's text attribute to retrieve the text.
#Like os.walk(), we dont have to do any recursion ourselves; the iterator method
#does that for us.
#Nor do we have to specify a tag, in which case the iterator will return every element
#in the entire XML document.


===============
    Other Modules 
===============
#there about 200 packages and modules in the standard library.

#Unit testing framework
unittest #module that a Python version of the Java JUnit test framework
doctest #module also provides some basic integration with unittest module
#other 3rd party testing frameworks are
py.test #from codespeaknet/py/dist/
nose #from www.somethingaboutorange.com/mrl/projects/nose

#Noninteractive applications such as servers often report problems by writing
#to log files.
logging #module provides a uniform interface for logging, and in addition to being
#able to log to files, it can log using HTTP GET or POST requests
#or using email or sockets.

#Introspection and code manipulation (beyond scope of this book)
pprint #module has functions for "pretty printing" Python objects including collection
#data types, which is somethimes useful for debugging
#see Chapter 8 for simple use of the
inspect #module that introspects live objects

#Creating threaded applications
threading #module
queue #module provides three different kinds of thread-safe queues. See Chapter 9

#GUI programming
#Python has no native support for GUI programming but several GUI libaries for 
#creating abstract base classes.  See Chapter 8

#Copy
copy #module provides
copy.copy() #function
copy.deepcopy() #funtion
#see Chapter 3

#Access to Foreign Functions = functions located in shared libraries
#such as .dll files on Windows, .dylib files on Mac OS, and .so files on Linux is avaible by
ctypes #module
#this also provides a C API, so it is possible to create custom data types and functions
#in C and make these available to Python.
#both ctypes module and Python's C API are beyond the scope of this book.

Global Module Index
#before writing anything from scracth it is worth checking Python documentation's Global
#Module Index to see whether a suitable module is available.
#Failing this, then next check
Python Package Index #at
pypi.python.org/pypi #which contains several thousand Python add-ons ranging from
#small one-file modules all the way up to large library and framework packages
#containing anything from scores to hundreds of modules.

===============
Summary Chapter 5 Modules
===============
#Introduced various syntaxes for importing packages, modules, and objects inside modules.
#many programmers ony the import importable syntax so as to avoid name clashes and
#must be careful not to give a program or module the same name as top level Python
#module or directory.

#Also discussed were Python packages. These are simple directories with an __init__.py
#file and one or more .py modules inside them. The __init__.py file can be empty, but
#to support the from importable import * syntax, we can create al __all__ special variable
#in the __init__.py file set to a list of module names. We can also put any common
#initialization code in the __init__.py file. It was noted that packages can be nested
#simply by creating subdirectories and having each of these contain its own __init__.py file.

#Two custom modules were described.
#First just provided a few functions and had very simple doctests.
#Second was more elaborate with its own exceptions, the use of dynamic function creation
#to create a function wiht a platform-specific implemenation, private global data, a call
#to an initialization function, and more eloborate doctests.

#About half the chapter was devoted to a high level overview of Python's standard library.
#Several string handling modules were mentioned and a couple of io.StringIO examples
#were presented. One example showed how to write text to a file using either the built-in
#print() fucntion of a file object's write() method, and how to use an io.StringIO object
#in place of a real file. In previous chapters we handled command line options by reading
#sys.argv ourselves, but in the coverage of the library's support for command-line 
#programming we introducted the optparse module which gretly simplifies command-line
#argument handling, and so we will use this module extensively from now on.

#Mention was made of Python's excellent support for numbers, and the library's numeric 
#types and its three modules of mathematical fucntions, as well as the support for 
#scientific and engineering mathematics provided by the SciPy project. Both library
#and 3rd party date/time handling classes were briefly described and examples of how
#to obtain the current date/time and how to convert between datetime.datetime and
#the number of seconds since the epoch were shown. Also discussed were the additional
#collection data types and the algorithms for working with ordered sequences that the
#standard library provides, along with some examples of using the heapq module's functions.

#The modules that support various file encoding (besides character encodings) were 
#discussed, as well as the modules for packing and unpackgin the most popular archieve
#formats, and those that have support for audio data. An example showing how to use
#the Base64 encoding to store binary data in .py files was given, and also a program
#to unpack tarballs. Considerable support is provided for handling directories and
#files --- and all of this is abstracted into platform independent functions. Examples
#were shown for creating a dictionary with filename keys and last modified timestamp
#values, and for doing a recursive search of a directory to identify possible duplicate
#files based on their name and size.

#A large part of the library is devoted to networking and Internet programming.
#We briefly surveyed what is available, from raw sockets (including encrypted
#sockets), to TCP and UDP servers, to HTTP servers and support for the WSGI.
#Also mentioned were the modules for handling cookies, CGI scripts, and HTTP data,
#and for parsing HTML, XHTML, and URLs. Other modules that were mentioned included
#those for handling higher level protocols such as FTP and NNTP, as well the email
#client and server support using SMTP and client support for IMAP4 and POP3.

#XML support is comprehensive for writing and parsing including DOM, SAX, element
#tree parsers and the expat module. See example using element tree module.

===============
Exercise Chapter 5 BOOKMARK HERE
=======
=======
#write a program to show directory listings, rathar like the dir command in Windows
#or ls in Unix.
#Benefit to doing this is that we can build in the defaults we prefer and can use
#the same program on all platforms without having to remember the differences 
#betwee dir and ls.
#Create a program that supports the following interface:

Usage: ls.py [options] [path1 [path2 [path3 [... pathN]]]]

The paths are optional; if not given . is used.

Options:
    -h, --help          show this help message and exit
    -H, --hidden        show hidden files [default: off]
    -m, --modified      show last modified date/time [default: off]
    -o ORDER, --order=ORDER
                        order by ('name', 'n', 'modified', 'm', 'size', 's')
                        [dfault: name]
    -r, --recursive     recurse into subdirectories [default: off]
    -s, --sizes         show sizes [default: off]

#(this output has been modified to fit the book page's width)

#Here is an example of output on a small directory using the command line
ls.py -ms -os misc/:

2007-04-10 15:49:01             322     misc/chars.pyw
2007-08-01 11:24:57            1,039    misc/pfa-bug.pyw
2007-10-12 09:00:27            2,445    misc/test.lout
2007-04-10 15:50:31            2,848    misc/chars/.png
2007-02-11 14:17:03           12,184    misc/abstract.pdf
2007-02-05 14:22:38          109,788    misc/klmqtintro.lyx
2007-12-13 12:01:14        1,359,950    misc/tracking/pdf
                                        misc/phonelog

7 files, 1 directory 

#We used option grouping in the command line (optparse handles thia automatically
#for us), but the same could have been achieved using separate options, for example
ls.py -m =s -os misc/
#or by even more grouping
ls.py -msos misc/
#or by using long options
ls.py --modified --sizes --order=size misc/
#or any combination of these. Note that we define a "hidden" file or directory as
#one whose name begins with a dot (.)

#This exercise is quite challenging. You will need to read the optparse documentation
#to see how to provide options that set a True value and how to offer a fixed list of
#choices. If the user sets the recursive option you will need to process the files (but
#not the directories) using os.walk(); otherwise, you will have to use os.listdir()
#and process both files and directories yourself.

#One rather tricky aspect is avoiding hidden directories when recursing. They can be
#cut out of os.walk()'s dir list -- and therefore skipped by os.walk() -- by modifying
#that list. But be careful not to assign to the dirs variable itself, since that won't
#change the list it refers to but will simply (and uselessly) replace it; the approach
#used in the module solution is to assign to a slice of the whole list, that is,
dirs[:] = [dir for dir in dirs if not dir.statswith(".")]

#The best way to get grouping characters in the file sizes is to import the
locale #module, call
locale.setlocale() #to get the user's default locale, and then use a format
#character. Overall, ls.py #is about 130 lines split over four functions.

#CODE HERE
ls.py #is about 130 lines split over four functions.

ANSWER
#DETAIL

-----------1st EFFORT - posted on GitHub
#!/usr/bin/env python3
#ls.py 
#shows directory listings like ls in UNIX and dir in Windows

import locale
locale.setlocale(locale.LC_ALL, "")

import datetime
import optparse
import os

def main():
    counts = [0, 0]
    opts, paths = process_options()
    if not opts.recursive:
        filenames = []
        dirnames = []
        for path in paths:
            if os.path.isfile(path):
                filenames.append(path)
                continue
            for name in os.listdir(path):
                if not opts.hidden and name.startswith("."):
                    continue
                fullname = os.path.join(path, name)
                if fullname.startswith("./"):
                    fullname = fullname[2:]
                if os.path.isfile(fullname):
                    filenames.append(fullname)
                else:
                    dirnames.append(fullname)
        counts[0] += len(filenames)
        counts[1] += len(dirnames)
        process_lists(opts, filenames, dirnames)
    else:
        for path in paths:
            for root, dirs, files in os.walk(path):
                if not opts.hidden:
                    dirs[:] = [dir for dir in dirs if not dir.startswith(".")]
                filenames = []
                for name in files:
                    if not opts.hidden and name.startswith("."):
                        continue
                    fullname = os.path.join(root, name)
                    if fullname.startswith("./"):
                        fullname = fullname[2:]
                    filenames.append(fullname)
                counts[0] += len(filenames)
                counts[1] += len(dirs)
                process_lists(opts, filenames, [])
    print("{0} file{1}, {2} director{3}".format(
          "{0:n}".format(counts[0]) if counts[0] else "no",
          "s" if counts[0] != 1 else "",
          "{0:n}".format(counts[1]) if counts[1] else "no",
          "ies" if counts[1] != 1 else "y"))


def process_lists(opts, filenames, dirnames):
    keys_lines = []
    for name in filenames:
        modified = ""
        if opts.modified:
            try:
                modified = (datetime.datetime.fromtimestamp(os.path.getmtime(name)).isoformat(" ")[:19] + " ")
            except EnvironmentError:
                modified = "{0:>19}".format("unknown")
        size = ""
        if opts.sizes:
            try:
                size = "{0:>15n}  ".format(os.path.getsize(name))
            except EnvironmentError:
                size = "{0:>15}  ".format("unknown")
        if os.path.islink(name):
            name += " -> " + os.path.realpath(name)
        if opts.order in {"m", "modified"}:
            orderkey = modified
        elif opts.order in {"s", "size"}:
            orderkey = size
        else:
            orderkey = name
        keys_lines.append((orderkey, "{modified}{size}{name}".format(**locals())))
    size = "" if not opts.sizes else " " * 15
    modified = "" if not opts.modified else " " * 20
    for name in sorted(dirnames):
        keys_lines.append((name, modified + size + name + "/"))
    for key, line in sorted(keys_lines):
        print(line)


def process_options(): 
    usage = """ %prog [options] [path1 [path2 [...pathN]]]
    The paths are optional; if not given . is used """

    parser = optparse.OptionParser(usage=usage)
    parser.add_option("-H", "--hidden", dest="hidden", action="store_true", help=("show hidden files [default: off]"))
    parser.add_option("-m", "--modified", dest="modified", action="store_true", help=("show last modifed date/time [default: off]"))
    orderlist = ["name", "n", "modified", "m", "size", "s"]
    parser.add_option("-o", "--order", dest="order", choices=orderlist, help=("order by ({0}) [default: %default]".format(", ".join(["'" + x + "'" for x in orderlist]))))
    parser.add_option("-r", "--recursive", dest="recursive", action="store_true", help=("recurse into subdirectories [default: off]"))
    parser.add_option("-s", "--sizes", dest="sizes", action="store_true", help=("show sizes [default: off]"))
    parser.set_defaults(order=orderlist[0])
    opts, args = parser.parse_args()
    if not args:
        args = ["."]
    return opts, args


main()
-----------1st EFFORT - posted on GitHub






-----------1st EFFORT - posted on GitHub
#!/usr/bin/env python3
#capture.py

import io
import sys

sys.stdout = io.StringIO()

print("An error message", file=sys.stdout)
sys.stdout.write("Another error message\n")
print("Nothing has been printed on the console", file=sys.stdout)

error_strings = sys.stdout.getvalue()
sys.stdout = sys.__stdout__
print(error_strings)
-----------1st EFFORT - posted on GitHub






-----------1st EFFORT - posted on GitHub
#!/usr/bin/env python3
#findduplicates.py


import collections
import os
import sys


path = sys.argv[1] if len(sys.argv) > 1 else "."
data = collections.defaultdict(list)

for root, dirs, files in os.walk(path):
    for filename in files:
        fullname = os.path.join(root, filename)
        key = (os.path.getsize(fullname), filename)
        data[key].append(fullname)

for size, filename in sorted(data):
    names = data[(size, filename)]
    if len(names) > 1:
        print("{filename} ({size} bytes) may be duplicated "
              "({0} files):".format(len(names), **locals()))
        for name in names:
            print("\t{0}".format(name))
-----------1st EFFORT - posted on GitHub







#Reminder of topics<===========
===============================================================================================
CHAPTER: 6 OOP - Object Oriented Programming
CHAPTER BEGIN
===============================================================================================

OO Approach
    OO Concepts and Terminology
Custom Classes
    Attributes and Methods
    Inheritance and Polymorphism
    Using Properties to Control Attribute Access
    Creating Complete and Fully Integrated Data Types
        Creating Data Types from Scratch (ANSWER PART 1)
        Creating Data Types from Other Data Types (ASSWER PART 2)
Custom Collection Classes 
    Creating Classes That Aggregate Collections 
    Creating Collection Classes Using Aggregration 
    Creating Collection Classes Using Inheritance
Summary
Exercises 
#1
#2
#3
#4

#CODE LISTING HERE
Account.py
Circle.py
fuzzybool.py
FuzzyBoolAlt.py
Image.py
Image_ans.py
Shape.py
Shape_ans.py
ShapeAlt.py
ShapeAlt_ans.py
SortedDict.py
SortedList.py 
---
SortedListMeta.py


#up to now our programming style has been strictly procedural
#1st section here covers problems arising from procedural programming that OOP can solve,
#explain approach and then terminology.
#2nd section covers creating custom data types that hold single items
#3rd section covers creating custom data tupes holding any objects of any type
#advanced material in Chapter 8

===============
OO Approach
===============

--------
Bob Martin - SOLID Principles of Object Oriented and AGILE Design

OO Agile - bad code symptoms
RIGID       rigidity depend upon each other in undesirable ways
FRAGILE     fragility depend upon data strucutre in undesirable ways
COUPLED     tight coupling not desirable
thus 
manage dependency - managing dependencies

OO is about managing dependencies by selecting re-inverting key dependencies in 
    your archetecture so that you can prevent rigidity, fragility and non-reusability

OO - 3 main ideas
0 encapsulated --> variables were put into header files, allowing data visibility (no no)
                    private, public and protected idea born
1/2 inherited --> simulated, but not convenient 
     polymorphism --> if have poliymoriphic dispath then dont need pointers to functions

read write open close seek 
polimorphism means dont need pointers to functions
policymoprihis allows you to point AGAINST the FLOW OF CONTROL thus have absolute control
        over your dependency structure thus allowing you to AVOID writing fragile, rigidi 
        and non-resuable modules

if have pointers, then needed a table to hold those relationsihps and needed to load that table


OO weakens encapsulation, and replaced with publicp/private/protected

Class Design Principles

S   SRP     Single Responsibility Principle - a class should have only one reason to change
                    reasons to change = report without dot anymore 
                    dont want calculations vs formatting vs database changes to impact each other
O   OCP     Open / Closed Principle
                    Open for extension but closed for modification 
                    so its behavior can be extended (by polymorphic calls)
                    but closed for changes to the old code

                    immobilty - reusable part not properly decoupled from goop
                    so high level policy does NOT know about low level details
                    ordering - customers want circles drawn on top of squares
                    but customers didnt know this prior to implementing it
                    --> go out to customers early as poosibls and ask for what changes
                    AND ONLY THEN build the abstractions into the archetecture

L   LSP     Liskov Substitution Principle
                    derived classes must be usuable through the base class interface, without
                    the need for the user to know the difference ie simple polymorphism

                    rectangle square problem

I   ISP     Interface Substitution Principle 

D   DIP     Dependency Inversion Principle
--------




#problem of purely procedural approach
#example: need to represent circles
circle = (11, 60, 8)
#(x, y, radius) or (radius, x, y)? not clear
#procedural approach means we can access elements by index position only
#so if we have two functions
distance_from_origin(x, y, radius) #and
edge_distance_from_origin(x, y, radius)
#then must use tuple unpacking to call them with a circle tuple:
distance = distance_from_origin(*circle[:2])
distance = edge_distance_from_origin(*circle)
#but both of these assume circle tuples are of the form (x, y, radius).

#ATUL But what if using different argument order? ie (y, x, radius) or (radius, x, y)?
#so use named attributes vs index order attributes

#can solve the problem of knowing element order and of using tuple unpacking by using
#a named tuple:
import collections
Circle = collections.namedtuple("Circle", "x y radius")
circle = Circle(13, 84, 9)
distance = distance_from_origin(circle.x, circle.y)
#this allows us to create Circle 3-tuples with named attributes. Which makes function
#calls easier to understand b/c now we can access elements using their names.

#Unfortunately, problems still remain:
#how to stop an invalid circle input? --> negative radius.
#Notice we did not raise any exception when defining Circle. Need to go back and redo?
#Also can have two errors here b/c (1 ) the error will ONLY be noticed if we call
#edge_distance_from_origin() function 
#and (2) then only if that function actually checks for a negative radius.
#Thus this inability to validate when creating an object is probably the worst aspect
#of taking a purely procedural approach.

#If we want circles to be mutable to resize them then we can use
collections.namedtuple._replace() method
circle = circle._replace(radius=12)
#note nothing to stop us from setting invalid data.
#note if the circles needed lots of changes, then we may use a mutable data type --> list
circle = [36, 77, 8]
#But still no protection from inputting invalid data.
#And best we can do about accessing elements by name is to create some constants allowing
#us to write
circle[RADIUS] = 5
#But using a list brings additional problems for example we can legitimately call
circle = dict(x=36, y=77, radius=8)
#but again there is no way to ensure a valid radius and no way to prevent inappropriate
#methods from being called.


#Reminder of topics<===========
CHAPTER 6 OOP - Object Oriented Programming

OO Approach
    OO Concepts and Terminology
Custom Classes
    Attributes and Methods
    Inheritance and Polymorphism
    Using Properties to Control Attribute Access
    Creating Complete and Fully Integrated Data Types
        Creating Data Types from Scratch (ANSWER PART 1)
        Creating Data Types from Other Data Types (ASSWER PART 2)
Custom Collection Classes 
    Creating Classes That Aggregate Collections 
    Creating Collection Classes Using Aggregration 
    Creating Collection Classes Using Inheritance
Summary
Exercises 

#CODE LISTING HERE
Account.py
Circle.py
fuzzybool.py
FuzzyBoolAlt.py
Image.py
Image_ans.py
Shape.py
Shape_ans.py
ShapeAlt.py
ShapeAlt_ans.py
SortedDict.py
SortedList.py 
---
SortedListMeta.py


===============
    OO Concepts and Terminology
===============
#what we need is some way to package the data, restrict the methods that can be applied 
#to the data so that only valid operations are possible.
#how? create a custom Circle data type.

#first preliminaries and terminology
#most classes encapsulate data and the methods that can be applied onto that data
#special methods --> __add__() 
#special methods always begin and end with two underscores and are PREDEFINED.
#example; to create a class that supports concatenation + and the len() function,
#then we just implehlepment the 
__add__() # and
__len__() #into our class

#objects have attributes --> methods are callable attributes.
#Data attributes are normally implemented as 
instance variables # --> = variables that are unique to a particular object.
#we will see examples of how to provide data attributes as
properties # --> = property is an item of object data that is accessed list an instance
#variable but where thes accesses are handled by methods behind the scenes.
#properties make it easier to do data validation.

#Inside a method (which is just a function whose first argumenbt is the instance
#on which it is called to operate), several kinds of variables are potentially accessible.
#Explain:
#Object's instance variables can be accessed by qualifying their name with the instance itself.
#Local variables can be created inside the method; these are accessed without qualification.
#Class variables (or static variables) are accessed by qualifying their name with the class name.
#Global variables (or module variables) are accessed without qualification.

#Namespace = mapping from names to objects.
#modules are namespaces. For example, after the statement
import math #we can access objects in the math module by qualifying their name with their
#namespace for example
math.pi
math.sin()
#classes and objects are namespaces
#for example
z = complex(1, 2)
#and z object's namespaces have two attributes which we can access
z.real
z.imag                      BOOKMARK HERE

#Advantage of OOP --> can specialize a class via 
inheritence of attributes (such as data and methods)
can add or replace methods
can add instance variables
can subclass any Python class #great advantage thus can use tried and tested classes
can pass objects of our new class to functions and methods

base class = super class 
subclass = derived class 
#any method in subclass can be overridden

can dynamically bind a method = dynamic method binding = Polymorphism
#if need to call the base class version of a method inside a reimplemented method, we
#can do so by using the built-in 
super() function

Duck typing #--> if we want to call certain methods on an object, it does NOT matter
#what class the object is from, what does matter is that object has the methods we
#want to call.

Aggregration is also called composition #--> a class includes one or more instance
#variables that are from other classes.  Aggregation is used to model a "has-a" relationship.

#Python does not provide
overloading #--> two methods with same name but with different parameter lists in the same class
access control #--> no bulletproof mechanisms to enforce data privacy.
#but if we create attributes with two leading underscores, then Python will prevent
#unintentional access --> see Chapter 8 Name Mangling.



#Reminder of topics<===========
CHAPTER 6 OOP - Object Oriented Programming

OO Approach
    OO Concepts and Terminology
Custom Classes
    Attributes and Methods
    Inheritance and Polymorphism
    Using Properties to Control Attribute Access
    Creating Complete and Fully Integrated Data Types
        Creating Data Types from Scratch (ANSWER PART 1)
        Creating Data Types from Other Data Types (ASSWER PART 2)
Custom Collection Classes 
    Creating Classes That Aggregate Collections 
    Creating Collection Classes Using Aggregration 
    Creating Collection Classes Using Inheritance
Summary
Exercises 

#CODE LISTING HERE
Account.py
Circle.py
fuzzybool.py
FuzzyBoolAlt.py
Image.py
Image_ans.py
Shape.py
Shape_ans.py
ShapeAlt.py
ShapeAlt_ans.py
SortedDict.py
SortedList.py 
---
SortedListMeta.py


===============
Custom Classes
===============
#syntax for creating custom classes

class className:
    suite

class className(base_classes):
    suite


===============
    Attributes and Methods
===============


################################################
Point class inheritance hierachy

object  <----------   Point               
                         x               #ATTRIBUTES
                         y               #ATTRIBUTES
------------         -------------------                                    
__new__()             #   __newer__()                           1
__init__()                __init__()          BOLD      3
                          distance_from_origin()            2
__eq__()                  __eq__()            BOLD      3
__repr__()                __repr__()          BOLD      3
__str__()                 __str__()           BOLD      3

#inherited                  1
implemented                 2
reimplemented BOLD          3
################################################


#start with simple class Point that holds (x, y) coordinate
#DONT need to execute code class Point b/c its ALREADY located within PyPi

class Point:

    def __init__(self, x=0, y=0):
        self.x = x
        self.y = y 

    def distance_from_origin(self):
        return math.hypot(self.x, self.y)

    def __eq__(self, other):
        return self.x == other.x and self.y == other.y

    def __repr__(self):
        return "Point({0.x!r}, {0.y!r})".format(self)

    def __str__(self):
        return "({0.x!r}, {0.y!r})".format(self)

#since no base classes are specified, Point is direct subclass of object.
#This is just as if we had written 
class Point(object)

#before discussing each method, lets see examples in action:
import Shape
a = Shape.Point()
repr(a)
b = Shape.Point(3, 4)
str(b)
b.distance_from_origin()
b.x = -19
str(b)
a == b, a != b
            >>> import Shape
            >>> a = Shape.Point()
            >>> repr(a)
            'Point(0, 0)'
            >>> b = Shape.Point(3,4)
            >>> str(b)
            '(3, 4)'
            >>> type(b)
            <class 'Shape.Point'>
            >>> type(str(b))
            <class 'str'>
            >>> b.distance_from_origin()
            5.0
            >>> a
            Point(0, 0)
            >>> b
            Point(3, 4)
            >>> b.x = -19
            >>> str(b)
            '(-19, 4)'
            >>> a == b, a != b
            (False, True)


            ---DONT NEED THIS---
            #CODE HERE
            #NOTE to implement on laptop need to
            #1) using IDE create Shape.py file and save in pwd.
            #2) import math

            #!/usr/bin/env python3

            import math

            class Point:

                def __init__(self, x=0, y=0):                          #Method1
                    self.x = x                  #Data Attribute1
                    self.y = y                  #Data Attribute2

                def distance_from_origin(self):                        #Method2
                    return math.hypot(self.x, self.y)

                def __eq__(self, other):                               #Method3
                    return self.x == other.x and self.y == other.y

                def __repr__(self):                                    #Method4
                    return "Point({0.x!r}, {0.y!r})".format(self)

                def __str__(self):                                     #Method5
                    return "({0.x!r}, {0.y!r})".format(self)

            >>> import Shape
            >>> a = Shape.Point()
            >>> repr(a)
            'Point(0, 0)'
            >>> b = Shape.Point(3,4)
            >>> str(b)
            '(3, 4)'
            >>> b.distance_from_origin()
            5.0
            >>> b.x = -19
            >>> str(b)
            '(-19, 4)'
            >>> a == b, a != b
            (False, True)
            >>> 
            ---DONT NEED THIS---


#NOTES
#Python automatically supplies the first arugment in method calls = it is an
#object reference to the object ITSELF. By convention, the parameter is called
self 
#by typing it out, we have absolute clarity.

#No need to reimplement methods in a subclass b/c if the base class has been 
#implemented, then its all good.

#If we call a method on an object and the object's class does NOT have an 
#implementation of that method, then Python will automatically go through the
#object's base classes, and their base classes, and so on, etc, until it finds
#the method. If at this point, the method is not actually found then Python raises
#an AttributeError exception.

#Now lets discuss each method (5 total)

#Method1
   def __init__(self, x=0, y=0):                          #Method1
        self.x = x                  #Data Attribute1
        self.y = y                  #Data Attribute2
#self explanatory.

#Method2
    def distance_from_origin(self):                        #Method2
        return math.hypot(self.x, self.y)
#this is a conventional method that performs a computation based upon the
#object's instance variables.
#common to have very short methods
#common to have only the object they are called on as an argument, since
#often all the data the method needs is available inside the object.

#Method3
    def __eq__(self, other):                               #Method3
        return self.x == other.x and self.y == other.y
#this method performs a computation based on the object's instance variables.
#default behavior is that all custom classes support == operator and the 
#comparison always returns False. We can override this behavior by 
#reimplementing the __eq__() special method as we have done here.
#By default, all instances of custom classes are hashable, so hash() can be
#called on them and they can be used as dicitonary keys and sorted in sets.
#But if we reimplement __eq__() then the instances are no longer hashable.
#This is fixable using a
FuzzyBool #class --> see later this Chapter.
#Special Method --> comparison of them
Special Method          Usage           Description
____________________    ___________     ________________________________________________
__lt__(self, other)     x < y           returns True   
__le__(self, other)     x <= y
__eq__(self, other)     x == y 
__ne__(self, other)     x != y 
__ge__(self, other)     x >= y
__gt__(self, other)     x > y 
#need to avoid inappropriate comparisons so few approaches here
#1) use an assertion
assert isinstance(other, Point)
#2) raise a TypeError to indicate that comparisons between the two types are not
#supported, for example
if not isinstance(other, Point): raise TypeError()
#3)most Pythonic: 
if not isinstance(other, Point): return NotImplemented  #so here if NotImplemented
#is in fact returned, then Python will then try calling 
other.__eq__(self) #to see whether the
other #type supports the comparison with the 
Point #type, and if there is no such method or if that method also returns
NotImplemented #then Python will give up and raise a 
TypeError #exception.
#Note that only reimplementations of the comparison special methods listed in Table 6.1
#may return NotImplemented

#Method4
    def __repr__(self):                                    #Method4
        return "Point({0.x!r}, {0.y!r})".format(self)
#this built-in repr() function calls the __repr__() SPECIAL METHOD for the object
#that it is given and returns a result.
#what is returned? a string which is one of two kinds:
#kind1 is where the string returned can be evaluated using the built-in eval() function
#to produce an object equivalent to the one repr() was called upon.
#kind2 is where THIS IS NOT POSSIBLE. See example later this chapter.
BOOKMARK HERE TOPIC
#How do we go from a Point object to a string and back to a Point object?
            >>> import Shape
            >>> p = Shape.Point(3, 9)
            >>> repr(p)
            'Point(3, 9)'
#we must give the module name when executing 
eval() #if we used 
import Shape
#This would not be needed if we had done the import differently, for example, 
from Shape import Point 

            >>> from Shape import Point
            >>> dir()
            ['Point', '__builtins__', '__doc__', '__loader__', '__name__', '__package__', '__spec__']
            >>> help(Point)

#Python provides every object with a few private attribuates, one of which is
__module__
#which is a string that holds the object's module name which is here is Shape
>>> q = eval(p.__module__ + "." + repr(p))
>>> repr(q)
'Point(3, 9)'
#so note here we have two equal outcomes but the path is DIFFERENT.
            >>> import Shape
            >>> p = Shape.Point(3,9)
            >>> repr(p)
            'Point(3, 9)'
            >>> q = eval(p.__module__ + "." + repr(p))
            >>> repr(q)
            'Point(3, 9)'
            >>> p
            Point(3, 9)
            >>> q
            Point(3, 9)
            >>> type(p)
            <class 'Shape.Point'>
            >>> type(q)
            <class 'Shape.Point'>
            >>> x = "foo"
            >>> repr(x)
            "'foo'"
#New topic
#Method5
    def __str__(self):                                     #Method5
        return "({0.x!r}, {0.y!r})".format(self)
#result here is intended to be understandable to human readers and is NOT expected
#to be suitable for passing to the eval() function.

#Summary of this section -- the Point class holds an (x, y) coordinate.
#Next see to to create a custom Circle class, inheriting from Point so that we
#do NOT have to duplicate the code for the x and y attributes or for the
#distance_from_origin() method.

            >>> help(Shape.Point)

            class Point(builtins.object)
             |  Methods defined here:
             |  
             |  __eq__(self, other)
             |      Return self==value.
             |  
             |  __init__(self, x=0, y=0)
             |      Initialize self.  See help(type(self)) for accurate signature.
             |  
             |  __repr__(self)
             |      Return repr(self).
             |  
             |  __str__(self)
             |      Return str(self).
             |  
             |  distance_from_origin(self)
             |  
             |  ----------------------------------------------------------------------
             |  Data descriptors defined here:
             |  
             |  __dict__
             |      dictionary for instance variables (if defined)
             |  
             |  __weakref__
             |      list of weak references to the object (if defined)
             |  
             |  ----------------------------------------------------------------------
             |  Data and other attributes defined here:
             |  
             |  __hash__ = None

            >>> p = Shape.Point(3,9)
            >>> p
            Point(3, 9)
            >>> repr(p)
            'Point(3, 9)'
            >>> p.__repr__()
            'Point(3, 9)'
            >>> p.__str__()
            '(3, 9)'
            >>> p.x
            3
            >>> p.y
            9

            >>> p.__init__()
            >>> p
            Point(0, 0)
            >>> p.__repr__()
            'Point(0, 0)'

            >>> type(p)
            <class 'Shape.Point'>
            >>> type(Shape)
            <class 'module'>
            >>> type(Point)
            <class 'type'>
            >>> p
            Point(3, 9)


#Reminder of topics<===========
CHAPTER 6 OOP - Object Oriented Programming

OO Approach
    OO Concepts and Terminology
Custom Classes
    Attributes and Methods
    Inheritance and Polymorphism
    Using Properties to Control Attribute Access
    Creating Complete and Fully Integrated Data Types
        Creating Data Types from Scratch (ANSWER PART 1)
        Creating Data Types from Other Data Types (ASSWER PART 2)
Custom Collection Classes 
    Creating Classes That Aggregate Collections 
    Creating Collection Classes Using Aggregration 
    Creating Collection Classes Using Inheritance
Summary
Exercises 

#CODE LISTING HERE
Account.py
Circle.py
fuzzybool.py
FuzzyBoolAlt.py
Image.py
Image_ans.py
Shape.py
Shape_ans.py
ShapeAlt.py
ShapeAlt_ans.py
SortedDict.py
SortedList.py 
---
SortedListMeta.py



===============
    Inheritance and Polymorphism
===============
#Circle class builds on the Point class using inheritance.
#Circle class adds one additional data attribute (radius), and three new methods
#also implements a few of Point's methods

#This is an inheritance tree showing inheritance heirarchy
################################################
Point class inheritance hierachy

object  <----------   Point <-------------------------    Circle              
                         x     #new attribute               x
                         y     #new attribute               y
                                                            radius  #new attribute
------------         -------------------                --------------------------                       
__new__()             #   __new__()                         __new__()     
__init__()                __init__()BOLD                    __init__()BOLD
__eq__()                  distance_from_origin()     #      distance_from_origin()
__repr__()                __eq__()BOLD                      edge_distance_from_origin()
__str__()                 __repr__()BOLD                    area()
                          __str__()BOLD                     circumference()
                                                            __eq__()BOLD
                                                            __repr__()BOLD
                                                            __str__()BOLD
#inherited (ATUL -- Ah, ok, now I get it!)
implemented
reimplemented BOLD #ATUL we use super() to reimplement, with super() meaning supercede!
################################################


#complete class definition CODE HERE
class Circle(Point):

    def __init__(self, radius, x=0, y=0):
        super().__init__(x, y)
        self.radius = radius 

    def edge_distance_from_origin(self):
        return abs(self.distance_from_origin() - self.radius)       #Inheritance here

    def area(self):
        return math.pi * (self.radius ** 2)

    def circumference(self):
        return 2 * math.pi * self.radius

    def __eq__(self, other):
        return self.radius == other.radius and super().__eq__(other)

    def __repr__(self):
        return "Circle({0.radius!r}, {0.x!r}, {0.y!r})".format(self)

    def __str__(self):
        return repr(self)
#Inheritance is achieved simply by listing the classes we want our class to inherit
#in the class line 
#(this idea of in the class --> see Chapt 8 for multiple inheritance, adbstract 
#base types, and other advanced OOP techniques)

#Inside __init__() we use super() to call the base class's __init__() method
#why? this creates and initializes the self.x and self.y attributes. Why does this 
#matter? For now, users of the class are allowed to submit invalid data such as -2 for
#the radius. See next section on how to prevent this by making attributes more robust
#using properties.

#area() and circumference() methods are straightforward
#edge_distance_from_origin() method calls distance_from_origin() method 
#Since the Circle class does NOT provide an implementation of distance_from_origin()
#method, then the Point base class WILL BE FOUND AND USED. 
#ATUL - This is by default given how Python built. See help(Shape)
#Contrast this (prior paragraph) with the reimplementation of the __eq__() method.
#ATUL - Ah, ok.

#Reimplementation of the __eq__() --> this method compares this circle's radius with
#the other circle's radius ------ and if they are equal than it EXPLICITLY calls
#the base class's __eq__() method USING super(). Why does this matter?
#if we did NOT use super() then we would have INFINITE recursion b/c it (ie Circle.__eq__()
#would keep calling itself. 
The use of super() is LIKE A HOOK TAKING IT OUT OF THIS class 
and into the inherited based class of Point. Also notice that we do NOT have to pass
self argument in the super() call b/c Python automatically passes it for us.


#Some usage examples (and so need full Shape.py module)
-----------1st EFFORT - posted on GitHub
#!/usr/bin/env python3
#Shape_basic.py

import math

class Point:

    def __init__(self, x=0, y=0):
        self.x = x
        self.y = y 

    def distance_from_origin(self):
        return math.hypot(self.x, self.y)

    def __eq__(self, other):
        return self.x == other.x and self.y == other.y

    def __repr__(self):
        return "Point({0.x!r}, {0.y!r})".format(self)

    def __str__(self):
        return "({0.x!r}, {0.y!r})".format(self)


class Circle(Point):

    def __init__(self, radius, x=0, y=0):
        super().__init__(x, y)
        self.radius = radius 

    def edge_distance_from_origin(self):
        return abs(self.distance_from_origin() - self.radius)

    def area(self):
        return math.pi * (self.radius ** 2)

    def circumference(self):
        return 2 * math.pi * self.radius

    def __eq__(self, other):
        return self.radius == other.radius and super().__eq__(other)   #super() used here
                                                                       #which requires
                                                                       #reimplementation
    def __repr__(self):
        return "Circle({0.radius!r}, {0.x!r}, {0.y!r})".format(self)

    def __str__(self):
        return repr(self)
-----------1st EFFORT - posted on GitHub

#original examples and test
            >>> import Shape
            >>> a = Shape.Point()
            >>> repr(a)
            'Point(0, 0)'
            >>> b = Shape.Point(3,4)
            >>> str(b)
            '(3, 4)'
            >>> b.distance_from_origin()
            5.0
            >>> b.x = -19
            >>> str(b)
            '(-19, 4)'
            >>> a == b, a != b
            (False, True)

#then new example and test
            >>> p = Shape.Point(28, 45)
            >>> c = Shape.Circle(5, 28, 45)
            >>> p.distance_from_origin()
            53.0
            >>> c.distance_from_origin()
            53.0


            ATUL using new python3 implementation
            >>> import math
            >>> help(math)

            >>> help(math.hypot)

            >>> x = 3
            >>> y = 4
            >>> z = math.hypot(x, y)
            >>> z
            5.0


#now we can call distance_from_origin() method on a Point or a Circle
#since Circle exists and stands in for Point
#How?
#if we call distance_from_origin() via Point then we do it  DIRECTLY
#if we call distance_from_origin() via Circle then we do it INDIRECTLY via polymorphism
#or also called inheritance.
ATUL polymorphism, inheritance heirachy
Shape
        Point 
                Circle

#Polymorphism means that any object of a given class can be used as though it were
#an object of any of its base class's class. (WORDED PRECISELY HERE)
#so this is why when we create a subclass we need to 
#(1) implement ONLY the ADDITIONAL NEW methods we need and 
#(2) reimplement only those EXISTING methods we want to replace.
#and (3) when reimplementing, we can use super() inside the reimplementation

#Example of point (3) here
#when reimplementing in Circle class the following methods __eq__(), __repr__(), and 
#__str__() we need to include super() so that the data returned is in fact from Circle class.
#If we did not use super() then we would be accessing data from Point class (ie wrong data).
There is an new attribute in Circle class --> radius so
#Circle has an additional attribute ie radius within its __init__() method and __eq__() method 
#and so we must reimplement this.

#now Point and Circle classes are complete (as we need them to be).
#we could provide additional methods if needed such as 
copy a Point or Circle #but no method does this so far, so lets add it now
#how?
#import the copy module and use copy.copy() function 
#no need to use copy.deepcopy() for Point and Circle objects since they contain only
#immutable instance variables.


#Reminder of topics<===========
CHAPTER 6 OOP - Object Oriented Programming

OO Approach
    OO Concepts and Terminology
Custom Classes
    Attributes and Methods
    Inheritance and Polymorphism
    Using Properties to Control Attribute Access
    Creating Complete and Fully Integrated Data Types
        Creating Data Types from Scratch (ANSWER PART 1)
        Creating Data Types from Other Data Types (ASSWER PART 2)
Custom Collection Classes 
    Creating Classes That Aggregate Collections 
    Creating Collection Classes Using Aggregration 
    Creating Collection Classes Using Inheritance
Summary
Exercises 

#CODE LISTING HERE
Account.py
Circle.py
fuzzybool.py
FuzzyBoolAlt.py
Image.py
Image_ans.py
Shape.py
Shape_ans.py
ShapeAlt.py
ShapeAlt_ans.py
SortedDict.py
SortedList.py 
---
SortedListMeta.py


BOOKMARK HERE

===============
    Using Properties to Control Attribute Access
===============
#in ShapeAlt.py, alternative implementation of Point and Circle are provided and
ShapeAlt.py 
#all the methods mentioned here are provided as properties. This allows us to write
#code like this
circle = Shape.Circle(5, 28, 45)

            >>> circle = Shape.Circle(5, 28, 45)
            >>> circle
            Circle(5, 28, 45)
            >>> circle.radius
            5
            >>> circle.x
            28
            >>> circle.y
            45


            >>> circle.edge_distance_from_origin
            <bound method Circle.edge_distance_from_origin of Circle(5, 28, 45)>

            #I created ShapeAlt.py and saved within pwd
            >>> import ShapeAlt as Shape

#here are the implementations for the getter methods for the ShapeAlt.Circle class's
#area and edge_distance_from_origin properties:

@property
def area(self):
    return math.pi * (self.raduis ** 2)

@property
def edge_distance_from_origin(self):
    return abs(self.distance_from_origin - self.radius)
#here we have only provided getters thus the properties are read only.
#Code for the area property is the same as for the previous area() method

    def area(self):
        return math.pi * (self.radius ** 2)
    area = property(area)


#CODE FROM BEFORE

def area(self):
    return math.pi * (self.radius ** 2)

def edge_distance_from_origin(self):
    return abs(self.distance_from_origin() - self.radius)

#vs NEW CODE 

@property           #so just adding this new line @property
def edge_distance_from_origin(self):
    return abs(self.distance_from_origin - self.radius)

#what is the difference? now it calls the base class's 
distance_from_origin PROPERTY --> so not from class Circle, but from class Point = base class
#instead of calling the 
distance_from_origin METHOD
#so difference is that 
property decorator #is used.
#Decorators are discussed in detain in Chapter 8. For now, just assume its syntax.
#decorator is indicated by its 
@ symbol
#Decorator = is a function that takes a function or method as its argument and returns
#a decorated version (ie a version of the function or method that is modified in some way.)

property() 
#property decorator function is built-in and takes up to 4 arguments:
getter function, setter function, deleter function, and a docstring
#effect of using @property is SAME as calling 
#property() function with just 1 argument which is the getter function

#we could have created area property like this (CUMBERSOME CODE)
def area(self):
    return math.pi * (self.radius ** 2)
area = property(area)   #<------ CLUNKY code

#BETTER CODE
@property
def area(self):
    return math.pi * (self.raduis ** 2)

#from previous section, we noted that STILL no validation is performed on Circle's radius 
#attribute, but YES can STILL provide validation by making radius a property
#How?
#no need to change Circle.__init__() #method

#Pythonic programmers normally use properties rather than explicit getters and setters 
#(eg getRadius() and setRadius() ) b/c its so easy to change a data attribute into a
#property WITHOUT affecting the use of the class.
#How? need to turn an attribute into a readable/writable property by creating 
#a private attribute where the data is actually held and supply the getter and setter methods.
#Here it is:

@property 
def radius(self):
    """ docstring is here"""
    return self.__radius
@radius.setter
def radius(self, radius):
    assert radius > 0, "radius must be nonzero and non-negative"
    self.__radius = radius 

#NOTES
#ATUL --> the assert statement is the actual validation check on the input
#Use assert statement to ensure nonzero and non-negative radius and to store the 
#value in the private attribute self.__radius
#Notice that getter (and setter if needed but not included here) all have the same name.
#What distinguishes them? the decorator
#Decorator will rename it so that no name conflict occurs.

#At first, this decorator may look strange. Every property that is created has a 
#getter, setter, and deleter attribute, so once the radius property is created using
@property
#then the
radius.getter
radius.setter
radius.deleter
#attributes all become available.
#The radius.getter is set to the getter method by the @property decorator.
#Note that the other two are set up by Python (automatically) so that they do
#nothing unless they are used as decorators.
#Why set up to do nothing? so the attribute can not be written to or deleted unless explictly
#requested by the coder.
#Now, if they are used as decorators, then they in effect will replace themselves with
#the method they are used to decorate.

#Note initializer method syntax ------>
#(as presented by author)
Circle.__init__()

    def __init__(self, radius, x=0, y=0):
        super().__init__(x, y)
        self.radius = radius 

#ATUL code presented here
class Circle(Point):

    def __init__(self, radius, x=0, y=0):
        super().__init__(x, y)
        self.radius = radius 

#------>this method include the statement 
self.radius = radius
#Why? this will call the radius property's setter, so if an INVALID radius in inputted
#when a Circle is created, then an AssertError exception will be raised.
#Similarly, if an attempt is made to set an existing Circle's radius to an invalid value,
#then again the setter will be called and an exception is raised.
#Note the docstring --> the docstring includes doctests to test that the exception
#is correctly raised in these cases.

#Full radius's getter, setter, and docstring are here:

@property
def radius(self):
    """ The circle's radius

    >>> circle = Circle(-2)
    Traceback (most recent call last):
    ...
    AssertionError: radius must be nonzero and non-negative
    >>> circle = Circle(4)
    >>> circle.radius = -1
    Traceback (most recent call last):
    ...
    AssertionError: radius must be nonzero and non-negative
    >>>circle.radius = 6
    """
    return self.__radius

    @radius.setter
    def radius(self, radius):
        assert radius > 0, "radius must be nonzero and non-negative"
        self.__radius = radius

#Both the Point and Circle types are custom data types that have sufficent functionality
#to be useful. Most data types that we are likely to create are like this, but
#occasionally it is necessary to create a custom data type that is complete in every
#respect. We will see examples in next subsection.





@property
def radius(self):
    """ 
    """
    return self.__radius

    @radius.setter
    def radius(self, radius):
        assert radius > 0, "radius must be nonzero and non-negative"
        self.__radius = radius








#Reminder of topics<===========
CHAPTER 6 OOP - Object Oriented Programming

OO Approach
    OO Concepts and Terminology
Custom Classes
    Attributes and Methods
    Inheritance and Polymorphism
    Using Properties to Control Attribute Access
    Creating Complete and Fully Integrated Data Types
        Creating Data Types from Scratch (ANSWER PART 1)
        Creating Data Types from Other Data Types (ASSWER PART 2)
Custom Collection Classes 
    Creating Classes That Aggregate Collections 
    Creating Collection Classes Using Aggregration 
    Creating Collection Classes Using Inheritance
Summary
Exercises 


#CODE LISTING HERE
Account.py
Circle.py
fuzzybool.py
FuzzyBoolAlt.py
Image.py
Image_ans.py
Shape.py
Shape_ans.py
ShapeAlt.py
ShapeAlt_ans.py
SortedDict.py
SortedList.py 
---
SortedListMeta.py



===============
    Creating Complete and Fully Integrated Data Types
===============
#ATUL - lets 1st describe the problem and solution approach

#When creating a complete data type, then 2 possibilites are open to us.
#1) to create the data type from scratch
#2) to inherit from an existing similar data type which means REIMPLEMENTING those methods
#we want to behave differently and UNIMPLEMENTING those methods we dont want at all.

#We will implement
fuzzybool
#data type from scratch and then in subsubsection after that we will implement the same
#type but will use inheritance to reduce the work needed.

#The built-in bool type is two-valued (True and False) but in some areas of AI (Artifical
#Intelligence), fuzzy booleans are used. In our implementations, we will use floating
#point values with 0.0 denoting False and 1.0 denoting True.
#so 0.5 means 50 percent true, 0.25 means 25 percent true.
#Usage examples that will work the same with both implementations
a = fuzzybool.FuzzyBool(.875)
b = fuzzybool.FuzzyBool(.25)
a >= b                              #returns True
bool(a), bool(b)                    #returns (True, False)
-a                                  #returns FuzzyBool (0.125)
a & b                               #returns FuzzyBool(0.25)
b |= fuzzybool.FuzzyBool(.5)        #b is now: FuzzyBool(0.5)
"a={0:.1%} b={1:.0%}".format(a, b)  #returns 'a=87.5% b=50%'

#We want the FuzzyBool type to support the complete set of comparison operators 
#(< <= == != >= >) and the three basic logical operations, not(~), and (&), and or (|).
#In addition to the logical operations, we want to provide a couple of other logical
#methods such as
conjunction() #and
disjunction() #that take as many FuzzyBools as we like and return the appropriate 
#resultant FuzzyBool.
#And to complete the data type, we want to provide conversions to types
#bool, int, float, and str, and have an eval() able representational form.
#The final requirements are that (1) FuzzyBool supports str.format() format specifications,
#(2) that FuzzyBool can be used as dictionary keys or as members of sets, and (3) that
#FuzzyBool are immutable but with the provision of augmented assignment operators (&= and
# |=) to ensure that they are convenient to use.

#Notes
#Table 6.1 lists the comparison special methods
#Table 6.2 lists the fundamental special methods
#Table 6.3 lists the numeric special methods which include bitwise operators (~, & and |)
#which FuzzyBool use for their logical operators, and also arithmetic operators such as
# + and - which FuzzyBool does not implement because they are inappropriate. 


#Reminder of topics<===========
CHAPTER 6 OOP - Object Oriented Programming

OO Approach
    OO Concepts and Terminology
Custom Classes
    Attributes and Methods
    Inheritance and Polymorphism
    Using Properties to Control Attribute Access
    Creating Complete and Fully Integrated Data Types
        Creating Data Types from Scratch (ANSWER PART 1)
        Creating Data Types from Other Data Types (ASSWER PART 2)
Custom Collection Classes 
    Creating Classes That Aggregate Collections 
    Creating Collection Classes Using Aggregration 
    Creating Collection Classes Using Inheritance
Summary
Exercises 


===============
        Creating Data Types from Scratch (ANSWER PART 1)
===============
#to create the FuzzyBool from scratch means we must provide an attribute to hold the
#FuzzyBool; value and all the methods that we require.

#Here are the class line and the initializer (taken from fuzzybool.py)

class FuzzyBool:
    def __init__(self, value=0.0):
        self.__value = value if 0.0 <= value <= 1.0 else 0.0
#we made the value attribute PRIVATE b/c we want FuzzyBool to behave like immutables,
#so allowing access to the attribute would be wrong.
#also, if an out of range value is given, then we force it to take a fail-safe value
#of 0.0 which is False.
#Note, in the previous subsection's ShapeAlt.Circle class we used stricter policy,
#raising an exception if an invalid radius value was used when creating a new
#Circle object.
#ATUL so here no forced exception is used, rather just use default of 0.0
#FuzzyBool inheritance hierarchy or inheritance tree

################################################ Figure 6.4
FuzzyBool class inheritance hierachy

object  <----------   FuzzyBool 
                         __value     #attribute
------------         -------------------            
__new__()             #   __new__()               
__init__()                __init__()  BOLD
__eq__()                  __eq__()    BOLD
__repr__()                __repr__()  BOLD
__str__()                 __str__()   BOLD
__hash__                  __hash__()  BOLD
__format__                __format__()BOLD
                          __bool__()
                          __float__()
                          __invert__()                          
                          __and__()
                          __iand__()
                          conjunction()     #static
#inherited
implemented
reimplemented BOLD
################################################

#The simplest logical operator is logical NOT, for which we use bitwise inversion operator ~
def __invert__(self):
    return FuzzyBool(1.0 - self.__value)

#Now just list Table 6.2 and talk about __del__() Special Method

#Table 6.2 Fundamental Special Methods
Special Method                  Usage           Description

__bool__(self)                  bool(x)         If provided, returns truth value for x
                                                Useful for x is ...

__format__(self, format_spec)   "{0}".format(x) Provides str.format() support for custom classes

__hash__(self)                  hash(x)         If provided, x can be used as a dictionary key
                                                or held in a set

__init__(self, args)            x = X(args)     Called when an object is initialized

__new__(cls, args)              x = X(args)     Called when an object is created

__repr__(self)                  repr(x)         Returns a string representation of x 
                                                where possible eval(repr(x)) == x

__repr__(self)                  ascii(x)        Returns a string representation of x using 
                                                ASCII characters 

__str__(self)                                   Returns a human comprehensible string
                                                representation of x 

#New idea explained
__del__(self)
#this special method is called when an object is destroyed. It may never be called, 
#even at program termination. Furthermore, when we write del x, then all that happens 
#is that the object reference x is deleted and the count of how many object references
#refer to the object that was referred to by x is decreased by 1. Only when this count
#reaches 0 is __del__() likely to be called, but Python offers no guarantee that it will
#ever be called. In view of this, __del__() is very rarely reimplemented. None of the 
#examples in this book reimplements it. And it should not be used to free up resources,
#so it is not suitable to be used for closing files, disconnecting network connections, 
#or disconnecting database connections. Python provides two separate mechanisms for
#ensuring that resouces are properly released:
#One is use a try...finally block (see before and in Chapter 7)
#Other is to use a context object in conjunction with a with statement (Chapter 8).

#Now back to explanation
#The bitwise logical AND operator (&) is provided by the 
__and__()
# special method, and
#the in-place version (&=) is provided by 
__iand__()
#see here for code:
def __and__(self, other):       #called bitwise logical AND operator
    return FuzzyBool(min(self.__value, other.__value))

def __iand__(self, other):      #called bitwise in-place version &= operator
    self.__value = min(self.__value ,other.__value)        #also called AUGMENTED ASSIGNMENT
    return self
#The bitwise AND operator returns a new FuzzyBool based on this one and the other one.
return FuzzyBool

#The augmented assignment operator (in-place) version update the PRIVATE value.
self.__value
#Matters b/c? strictly speaking, this is not immutable behavior, but it DOES match
#the behavior of some other Python immutables, such as int, where for example, using +=
#looks like the left hand operand is being changed but in fact it is re-bound to refer to
#a new int object that holds the result of the addition, although in this case no 
#rebinding is needed b/c we really do change the FuzzyBool itself.
#The reason we return self is to support the chaining of operations.

#We could also implement 
__rand__()  #this method is called when self and other are of different types and
#and the __and__() method is not implemented for that particular pair of types. This is not
#needed for the FuzzyBool class. Most of the special methods for binary operators have
#both "i" (in-place) and "r" (reflect, that is, swap operands) versions.

#We have not shown the implementations for 
__or__() #which provides the bitwise | operator 
#or shown
__ior__() #which provides the in-place |= operator, since both are the same as the 
#equivalent AND methods except that we take the maximum value instead of the minimum
#value of SELF and OTHER.

def __repr__(self):
    return ("{0}({1})".format(self.__class__.__name__, self.__value))
#We have created an eval()-able representational form. For example, 
#given f = FuzzyBool.FuzzyBool(.75) then repr(f) will produce the string 'FuzzyBool(0.75)'

#All objects that have some special attributes automatically supplied by Python, one of
#which is called
__class__  #which is a reference to the object's class. All classes have a private
__name__  #attribute, again provided automatically. We have used these attributes to 
#provide the class name used for the representation form. This means that if the 
#FuzzyBool class is subclasses just to add extra methods, then the inherited __repr__()
#method will work correctly WITHOUT needed to be reimplemented, since it will
#pick up the subclass's class name.

def __str__(self):
    return str(self.__value)
#For the string form, we just return the floating-point value formatted as a string.
#We do NOT have to ue super() to avoid infinite recursion b/c we call str() on the
self.__value #attribute, not on the instance itself.

def __bool__(self):
    return self.__value > 0.5

def __int__(self):
    return round(self.__value)

def __float__(self):
    return self.__value
#The __bool__() special method converts the instance to a Boolean, so it must always 
#return either True or False.
#The __int__() special method provides integer conversion. We have used the built-in
#round() function b/c int() simply truncates (so would return 0 for any FuzzyBool value
#except 1.0).
#Floating-point conversion is easy b/c the value is already a floating-point number.

def __lt__(self, other):
    return self.__value < other.__value

def __eq__(self, other):
    return self.__value == other.__value
#To provide the complete set of comparisons (< <= == != >= >) it is necessary to
#implement at least three of them (< <= and +==) since Python can 
#infer > from <, != from ==, and >= from <=. We have shown only two representative
#methods here since all of them are very similar.
#(in fact we implemented only the __lt__() and __eq__() methods here
#the other comparison methods were automatically generated and we will see this
#happens in Chapter 8).

Numeric and Bitwise Special Methods

Special Method              Usage
-----------------------     --------------------
__abs__(self)               abs(x)                  __complex(self)         complex(x)
__float__(self)             float(x)                __int__(self)           int(x)
__index__(self)             bin(x) oct(x) hex(x)    __round__(self, digits) round(x, digits)
__pos__(self)               +x                      __neg__(self)           -x
__add__(self, other)        x + y                   __sub__(self, other)    x - y
__iadd__(self, other)       x += y                  __isub__(self, other)   x -= y
__radd__(self, other)       y + x                   __rsub__(self, other)   y - x 
__mul__(self, other)        x * y                   __mod__(self, other)    x % y
__imul__(self, other)       x *= y                  __imod__(self, other)   x %= y
__rmul__(self, other)       y * x                   __rmod__(self, other)   y % x
__floordiv__(self, other)   x // y                  __truediv__(self, other)    x / y
__ifloordiv__(self, other)  x //= y                 __itruediv__(self, other)   x /= y
__rfloordiv__(self, other)  y // x                  __rtruediv__(self, other)   y / x
__divmod__(self, other)     divmod(x, y)            __rdivmod__(self, other)    divmod(y, x)
__pow__(self, other)        x ** y                  __and__(self, other)    x & y
__ipow__(self, other)       x **= y                 __iand__(self, other)   x &= y
__rpow__(self, other)       y ** x                  __rand__(self, other)   y & x
__xor__(self, other)        x ^ y                   __or__(self, other)     x | y
__ixor__(self, other)       x ^= y                  __ior__(self, other)    x |= y
__rxor__(self, other)       y ^ x                   __ror__(self, other)    y | x
__lshift__(self, other)     x << y                  __rshift__(self, other) x >> y
__ilshift__(self, other)    x <<= y                 __irshift__(self, other) x >>= Y
__rlshift__(self, other)    y << x                  __rrshift__(self, other) y >> x
                                                    __invert__(self)        ~x

def __hash__(self):
    return hash(id(self))
#By default, instances of custom classes support operator == (which always returns False)
#and are hashable (so can be dictionary keys and can be added to sets). But if we
#reimplement the __eq__() special method to provide proper equality testing,
#then those instances are no longer hashable. This can be fixed by providing a
__hash__()  #special method as we have done here.

#Python provides hash functions for strings, numbers, frozen sets, and other classes.
#Here we have simply used the built-in hash() function (which can operate on any
#type which has a __hash__() special method), and given it the object's unique ID
#from which to calculate the hash. (Note that we can NOT use the private self.__value
#since that can change as a result of augmented assignment, whereas an object's hash
#value must never change.)

#The built-in 
id()  #function returns a unique integer for the object it is given as its argument. This
#integer is usually the object's address in memory, but all that we can assume is that no
#two objects have the same ID. Behind the scenes the 
is #operator uses the
id() #function to determine whether two object references refer to the same object.

def __format__(self, format_spec):
    return format(self.__value, format_spec)
#The built-in format() function is only really needed in class definitions. It takes a
#single object and an optional format specification and returns a string with the object
#suitably formatted.

#When an object is used in a format string, the object's __format__() method is called
#with the object and the format specification as arguments. The method returns the 
#instance suitably formatted as we saw earlier.

#All the built-in classes already have suitable __format__() methods; here we make use of
#the float.__format__() method by passing the floating-point value and the format string
#we have been given. We could have achieved exactly the same thing like this:
def __format__(self, format_spec):
    return self.__value.__format__(format_spec)
#Using the format() function requires a tiny bit less typing and is clearer to read.
#Nothing forces us to use the format() function at all, so we could INVENT our own format
#specification language and interpret it inside the __format__() method, as long as we
#return a string.

@staticmethod
def conjunction(*fuzzies):
    return FuzzyBool(min([float(x) for x in fuzzies]))
#The built-in staticmethod() is designed to be used as a decorator as we have done here.
#Static methods are simply methods that do NOT get self or any other first argument
#specially passed by Python.

#The & operator can be chained, so given FuzzyBool's f, g, h, we can get the conjunction
#of all of them by writing
f & g & h
#This works fine for small numbers of FuzzyBools, but if we have a dozen or more then it
#starts to become inefficient since each & represents a function call. With the method
#given here, we can achieve the same thing using a single function call of 
FuzzyBool.FuzzyBool.conjunction(f, g, h)
#This can be written more concisely using a FuzzyBool instance, but since static methods
#do NOT get self, if we call one using an instance and we want to process that instance, 
#then we must pass it ourselves. For example, 
f.conjunction(f, g, h)

#We have not shown the corresponding
disjunction() #method since it differs only in name and that it uses
max() #rather than min()

#Some Python programmers consider the use of static methods to be unPythonic and use them
#only if they converted code from another language (such as C++ or Java), or if they
#have a method that does not use self. In Python, rather using static methods, it is usually
#better to create a module function instead, as well see in the next subsubsection, or a 
#class method, as will see in the last section.

#In similar vein, createing a variable inside a class definition but outside any method
#creates a static (class) variable. For constants, it is usually more convenient to use
#private module globals, but class variables can often be useful for sharing data
#among all of a class's instances.

#We have NOW completed the implementation of FuzzyBool class "from scratch". We have had
#to implement 15 methods (17 if had done the minimum of all four comparison operators) and
#have implemented two static methods. In the following subsubsection, we will show an
#alternative implementation, this time based upon the 
inheritance of float.  #It involves the reimplementations of just 8 methods and the 
#implementation of 2 module functions -- and the UNIMPLEMENTATION of 32 methods.

#In most OO languages, inheritance is used to create new classes that have all the
#methods and attributes of the classes they inherit, as well as the additional
#methods and attributes that we want the new class to have. Python fully supports this,
#allowing us to add new methods, or to reimplement inherited methods so as to modify 
#their behavior. 
#BUT in addition, Python allows us to effectively unimplment methods, that is, to make 
#the new class behave as though it does NOT have some of the methods that it inherits.
#Doing this might not appeal to OO purists since it breaks polymorphism, 
#but in Python at least, it can occasionally be a useful technique.

BOOKMARK HERE TOPIC

#CODE HERE
fuzzybool.py

#!/usr/bin/env python3

"""implements an immutable FuzzyBool data type that can only have values in the
interval [0.0, 1.0] and which supports the basic logical operations not (~), and (&), and 
or (|) using fuzzy logic.
"""
import Util

@Util.complete_comparisons
class FuzzyBool:
    def __init__(self, value=0.0):
        self.__value = value if 0.0 <= value <= 1.0 else 0.0

    def __invert__(self):
        return FuzzyBool(1.0 - self.__value)

    def __and__(self, other):
        return FuzzyBool(min(self.__value, other.__value))

    def __iand__(self, other):
        self.__value = min(self.__value, other.__value)
        return self

    @staticmethod
    def conjunctions(*fuzzies):
        return FuzzyBool(min([float(x) for x in fuzzies]))

    def __or__(self, other):
        return FuzzyBool(max(self.__value, other.__value))

    def __ior__(self, other):
        self.__value = max(self.__value, other.__value)
        return self

    @@staticmethod
    def disjunction(*fuzzies):
        return FuzzyBool(max([float(x) for x in fuzzies]))

    def __repr__(self):
        return ("{0}({1})".format(self.__class__.__name__, self.__value))

    def __str__(self):
        return str(self.__value)

    def __bool__(self):
        return self.__value > 0.5

    def __int__(self):
        return round(self.__value)

    def __float__(self):
        return self.__value

    def __lt__(self, other): 
        return self.__value < other.__value

    def __eq__(self, other):
        return self.__value == other.__value

    def __hash__(self):
        return hash(id(self))

    def __format__(self, format_spec):
        return format(self.__value, format_spec)

if __name__ == "__main__":
    import doctest
    doctest.testmod()

#ATUL - need to include comments for each method
#DONE






>>> from fuzzybool import FuzzyBool
>>> f = FuzzyBool()
>>> g = FuzzyBool(.5)
>>> h = FuzzyBool(3.75)
>>> f, g, h
(FuzzyBool(0.0), FuzzyBool(0.5), FuzzyBool(0.0))
>>> h = ~h
>>> print(f, g, h)
0.0 0.5 1.0
>>> f = FuzzyBool(0.2)
>>> f < g
True
>>> h >= g
True
>>> f + g
Traceback (most recent call last):
...
TypeError: unsupported operand type(s) for +: 'FuzzyBool' and 'FuzzyBool'
>>> int(h), int(g)
(1, 0)
>>> d = {f : 1, g : 2, h : 3}
>>> d[g]
2


-----------1st EFFORT - posted on GitHub
#!/usr/bin/env python3
#fuzzybool.py


"""
Implements an immutable FuzzyBool data type that can only have values in
the interval [0.0, 1.0] and which supports the basic logical operations
not (~), and (&), and or (|) using fuzzy logic.

>>> from FuzzyBool_module import FuzzyBool
>>> f = FuzzyBool()
>>> g = FuzzyBool(.5)
>>> h = FuzzyBool(3.75)
>>> f, g, h
(FuzzyBool(0.0), FuzzyBool(0.5), FuzzyBool(0.0))
>>> h = ~h
>>> print(f, g, h)
0.0 0.5 1.0
>>> f = FuzzyBool(0.2)
>>> f < g
True
>>> h >= g
True
>>> f + g
Traceback (most recent call last):
...
TypeError: unsupported operand type(s) for +: 'FuzzyBool' and 'FuzzyBool'
>>> int(h), int(g)
(1, 0)
>>> d = {f : 1, g : 2, h : 3}
>>> d[g]
2
"""

import Util


@Util.complete_comparisons # Superceded by functools.total_ordering
class FuzzyBool:

    def __init__(self, value=0.0):
        """
        >>> f = FuzzyBool()
        >>> g = FuzzyBool(.5)
        >>> h = FuzzyBool(3.75)
        >>> f, g, h
        (FuzzyBool(0.0), FuzzyBool(0.5), FuzzyBool(0.0))
        """
        self.__value = value if 0.0 <= value <= 1.0 else 0.0


    def __invert__(self):
        """Returns the logical not of this FuzzyBool

        >>> f = FuzzyBool(0.125)
        >>> ~f
        FuzzyBool(0.875)
        >>> ~FuzzyBool()
        FuzzyBool(1.0)
        >>> ~FuzzyBool(1)
        FuzzyBool(0.0)
        """
        return FuzzyBool(1.0 - self.__value)


    def __and__(self, other):
        """Returns the logical and of this FuzzyBool and the other one

        >>> FuzzyBool(0.5) & FuzzyBool(0.6)
        FuzzyBool(0.5)
        """
        return FuzzyBool(min(self.__value, other.__value))


    def __iand__(self, other):
        """Applies logical and to this FuzzyBool with the other one

        >>> f = FuzzyBool(0.5)
        >>> f &= FuzzyBool(0.6)
        >>> f
        FuzzyBool(0.5)
        """
        self.__value = min(self.__value, other.__value)
        return self


    @staticmethod
    def conjunction(*fuzzies):
        """Returns the logical and of all the FuzzyBools

        >>> FuzzyBool.conjunction(FuzzyBool(0.5), FuzzyBool(0.6), 0.2, 0.125)
        FuzzyBool(0.125)
        """
        return FuzzyBool(min([float(x) for x in fuzzies]))


    def __or__(self, other):
        """Returns the logical or of this FuzzyBool and the other one

        >>> FuzzyBool(0.5) | FuzzyBool(0.75)
        FuzzyBool(0.75)
        """
        return FuzzyBool(max(self.__value, other.__value))


    def __ior__(self, other):
        """Applies logical or to this FuzzyBool with the other one

        >>> f = FuzzyBool(0.5)
        >>> f |= FuzzyBool(0.75)
        >>> f
        FuzzyBool(0.75)
        """
        self.__value = max(self.__value, other.__value)
        return self


    @staticmethod
    def disjunction(*fuzzies):
        """Returns the logical or of all the FuzzyBools

        >>> FuzzyBool.disjunction(FuzzyBool(0.5), FuzzyBool(0.75), 0.2, 0.1)
        FuzzyBool(0.75)
        """
        return FuzzyBool(max([float(x) for x in fuzzies]))


    def __repr__(self):
        """
        >>> f = FuzzyBool(0.5)
        >>> repr(f)
        'FuzzyBool(0.5)'
        """
        return ("{0}({1})".format(self.__class__.__name__,
                                  self.__value))


    def __str__(self):
        """
        >>> f = FuzzyBool(0.5)
        >>> str(f)
        '0.5'
        """
        return str(self.__value)


    def __bool__(self):
        """
        >>> f = FuzzyBool(.3)
        >>> g = FuzzyBool(.51)
        >>> bool(f), bool(g)
        (False, True)
        """
        return self.__value > 0.5


    def __int__(self):
        return round(self.__value)


    def __float__(self):
        return self.__value


    def __lt__(self, other):
        return self.__value < other.__value


    def __eq__(self, other):
        return self.__value == other.__value


    def __hash__(self):
        return hash(id(self))


    def __format__(self, format_spec):
        """
        >>> f = FuzzyBool(.875)
        >>> "{0:.0%}".format(f)
        '88%'
        >>> "{0:.1%}".format(f)
        '87.5%'
        """
        return format(self.__value, format_spec)


if __name__ == "__main__":
    import doctest
    doctest.testmod()

-----------1st EFFORT - posted on GitHub








#Reminder of topics<===========
CHAPTER 6 OOP - Object Oriented Programming

OO Approach
    OO Concepts and Terminology
Custom Classes
    Attributes and Methods
    Inheritance and Polymorphism
    Using Properties to Control Attribute Access
    Creating Complete and Fully Integrated Data Types
        Creating Data Types from Scratch (ANSWER PART 1)
        Creating Data Types from Other Data Types (ASSWER PART 2)
Custom Collection Classes 
    Creating Classes That Aggregate Collections 
    Creating Collection Classes Using Aggregration 
    Creating Collection Classes Using Inheritance
Summary
Exercises 


#CODE LISTING HERE
Account.py
Circle.py
fuzzyBbol.py
FuzzyBoolAlt.py
Image.py
Image_ans.py
Shape.py
Shape_ans.py
ShapeAlt.py
ShapeAlt_ans.py
SortedDict.py
SortedList.py 
---
SortedListMeta.py


===============
        Creating Data Types from Other Data Types (ASSWER PART 2)
===============




#CODE HERE
fuzzyboolalt.py


#The fuzzyboolalt.py has one immeidate difference from the original version:
#instead of providing static methods for conjunction() and disjunction(), we provide
#them as
module functions #for example NEW WAY

def conjuction(*fuzzies):
    return FuzzyBool(min(fuzzies))

#vs previous way:  OLD WAY

@staticmethod
def conjunctions(*fuzzies):
    return FuzzyBool(min([float(x) for x in fuzzies]))

#why does this matter?
#code is much simpler b/c fuzzyboolalt.FuzzyBool objects are float SUBCLASSES NOW, so they
#can be used directly in place of a float without needing any conversion. See tree below
#for comparison

################################################ Figure 6.4
FuzzyBool class inheritance hierachy

object  <----------   FuzzyBool 
                         __value     #attribute
------------         -------------------            
__new__()             #   __new__()               
__init__()                __init__()          reimplemented
__eq__()                  __eq__()            reimplemented
__repr__()                __repr__()          reimplemented
__str__()                 __str__()           reimplemented
__hash__                  __hash__()          reimplemented
__format__                __format__()        reimplemented
                          __bool__()
                          __float__()
                          __invert__()                          
                          __and__()
                          __iand__()
                          conjunction()     #static
#inherited
implemented
reimplemented BOLD
################################################

################################################ Figure 6.4
FuzzyBool class inheritance hierachy

object  <----------        float                             <----------   FuzzyBool 
------------         -------------------                    -------------------            
__new__()                 __new__()        reimplemented    __new__()       reimplemented
__init__()             #  __init__()                        __init__()      inherited
__eq__()                  __eq__()         reimplemented  # __eq__()        inherited
__repr__()                __repr__()       reimplemented    __repr__()      reimplemented
__str__()                 __str__()        reimplemented  # __str__()       inherited
__hash__                  __hash__()       reimplemented  # __hash__()      inherited
__format__                __format__()     reimplemented  # __format__()    inherited
                                                            __bool__()      reimplemented

                                                          # __invert__()    implemented
                                                          # __and__()       implemented
                                                          # __iand__()      implemented

#inherited
implemented
reimplemented BOLD
################################################

#now accessing the function is also cleaner than before. Instead of having to specify
#both the module and the class (or using an instance), we can now just write
fuzzyboolalt.conjunction()

#new method for FuzzyBool's class line and its __new__() method:

class FuzzyBool(float):
    def __new__(cls, value=0.0):
        return super().__new__(cls, value if 0.0 <= value <= 1.0 else 0.0)
#When we create a new class it is usually MUTABLE and relies on
object.__new__() #to create the RAW unitialized object. But in the case of IMMUTABLE classes
#we need to DO the creation AND initalization in ONE step since once an immutable object
#has been created, it CAN NOT be changed -->thus create AND initialize in ONE step

#The __new__() method is called before any object has been created (since object creation
#is what __new__() does), so it can NOT have a self object passed to it since one does NOT
#yet exist. In fact, __new__() is a CLASS METHOD.
Class Method # --> = these are similar to normal methods except that they are called on
#the class rather than on an instance and Python supplies as their first argument the 
#class that they are called upon. The variable name cls for class is just a convention, in
#the same way that self is the conventional name for the object itself.

#So when we write 
f = FuzzyBool(0.7)  #, under the hood Python calls 
FuzzyBool.__new__(FuzzyBool, 0.7) # to create the new object, say fuzzy and then calls
fuzzy.__init__() #to do any further initialization, and finally returns an object 
#reference to the fuzzy object. It is this object reference that f is set to.
#Most of __new__()'s work is passed on to the base class implementation:
object.__new__()
#all we do is make sure that the value is within the range.

#Class methods are set up by using the built-in
classmethod() #function used as a decorator. But as a convenience, we do NOT have to bother
#writing @classmethod before def __new__() b/c Python ALREADY knows that this method is
#always a class method.
#We do need to use the decorator if we want to create other class methods and
#for this see next chapter's final section.

#Now that we have seen a class method, we can clarify the different kinds of methods
#that Python provides. 
Class methods #have their first argument added by Python
#and it is the method's class; 
normal method #have their first argumet added by Python
#and it is the instance that the method was called on; and 
static methods #have NO first argument added.
#All the kinds of methods get any arguments we pass onto to them
#so for class and normal methods --> this would be their second and subsequent methods
#so for static methods --> this would be their first and subsequent methods

def __invert__(self):
    return FuzzyBool(1.0 - float(self))
#This method is used to provide support for the bitwise NOT operator (~) just like before.
#Notice that instead of accessing a private attribute that holds the FuzzyBool value
#we just use self directly here. Why? b/c it inherits float which means that a FuzzyBool
#can be used whenever a float is expected --> providing none of FuzzyBool's unimplmented
#methods are used of course.

def __and__(self, other):
    return FuzzyBool(min(self, other))

def __iand__(self, other):
    return FuzzyBool(min(self, other))
#same logic for these two methods, but code is subtly different.
#just like __invert__() method, we can use self and other as though they were floats.
#We have omitted the OR versions since they differ only in their names
__or__()
__ior__()
#and that __or__() and __ior__() both use max() rather than min()

            ATUL
            def __or__(self, other):
                return FuzzyBool(max(self, other))

            def __iand__(self, other):
                return FuzzyBool(max(self, other))


def __repr__(self):
    return ("{0}({1})".format(self.__class__.__name__, super().__repr__()))
#We must implement the 
__repr__() #method since the base class version 
float.__repr__() #just returns the number as a string, whereas we need the class name to 
#make the representation eval()-able.
            
            self.__class__.__name__

#For the str.format()'s second argument, we can NOT just pass self b/c that will result
#in an infinite recursion of calls to this __repr__() method, so instead we call
#the base class implmentation.

            super().__repr__()

#We dont have to implement __str__() method b/c the base class version float.__str__() is
#sufficient and will be used in the absence of a FuzzyBool.__str__() reimplementation.

def __bool__(self):
    return self >0.5

def __int__(self):
    return round(self)
#When a float is used in a Boolean context, it is False if its value is 0.0 and
#True otherwise. But this is not the appropriate behavior for FuzzyBools so we need
#to reimplement this method. Similarly, using int(self) would simply truncate, turning
#everything but 1.0 into 0, so here we use round() to produce 0s for values up to 0.5
#and 1 for values up to and including the maximum of 1.0

#We have not reimplemented the __hash__() method, the __format__() method, or any of
#the other methods that are used to provide the comparison operators, since all those
#provided by the float base class work correctly for FuzzyBools. Why? see Figure 6.4
################################################ Figure 6.4
FuzzyBool class inheritance hierachy

object  <----------        float                             <----------   FuzzyBool 
------------         -------------------                    -------------------            
__new__()                 __new__()        reimplemented    __new__()       reimplemented
__init__()             #  __init__()                        __init__()      inherited
__eq__()                  __eq__()         reimplemented  # __eq__()        inherited
__repr__()                __repr__()       reimplemented    __repr__()      reimplemented
__str__()                 __str__()        reimplemented  # __str__()       inherited
__hash__                  __hash__()       reimplemented  # __hash__()      inherited
__format__                __format__()     reimplemented  # __format__()    inherited
                                                            __bool__()      reimplemented

                                                          # __invert__()    implemented
                                                          # __and__()       implemented
                                                          # __iand__()      implemented

#inherited
implemented
reimplemented BOLD
################################################


#So far, the methods we have reimplemented provide a complete implementation of the 
#FuzzyBool class --- and have required far LESS code than the implementation presented
#in the previous subsubsection. However, this new FuzzyBool class has now inherited
#more than 30 methods which dont make sense for FuzzyBools. For example, none of the
#basic numeric and bitwiese shift operators (+ - * ? << >> etc) can be sensibly applied
#to FuzzyBools. So here is how we could begin to UNIMPLEMENT addition:
def __add__(self, other):
    raise NotImplementedError()
#we would also need to write same code for __iadd__() and __radd__() methods 
#to completed prevent addition.

            def __iadd__(self, other):
                raise NotImplementedError()

            def __radd__():
                raise NotImplementedError()

#Note that the 
NotImplementedError #is a standard exception and is different from the built-in
NotImplemented object
#An alternative to raising a NotImplementedError exception, especially if we want to
#more closely mimic the behavior of Python's built-in classes, is to raise a TypeError.
#Here is how we can make FuzzyBool.__add__() behave just like built-in classes that are
#faced with an invalid operation:
add __add__(self, other):
raise TypeError(
                "unsupported operand type(s) for +: "
                "'{0}' and '{1}' "
                .format(self.__class__.__name__, other.__class__.__name__)
                )

#For unary operations, we want to unimplement in a way that mimics the behavior of 
#built-in types, the code is slightly easier:
def __neg__(self):
    raise TypeError(
                    "bad operand type for unary -: '{0}' "
                    .format(self.__class__.__name__)
                    )

#For comparison operators, there is a much simpler idiom --> to umimplement ==, we use
def __neg__(self, other):
    return NotImplemented

#If a method implementing a comparison operator (< <= == != >= >) returns the built-in
#NotImplemented object, and an attempt is made to use the method, then Python will 
#first try the reverse comparison by swapping the operands (in case the other object
#has a suitable comparison method since the self object does not), and if that does NOT
#work then Python raises a TypeError exception with a message explaining that the 
#operation is not supported for operands of the types used. But for all the 
#noncomparison methods that we dont want, we must raise either a NonImplementedError
#or a TypeError exception as we did for the __add__() and __neg__() methods
#shown earlier.

#It would be tedious to unimplement every method we dont want as we have done here, 
#although it does work and has the virtue of being easy to understand. So now we look
#at more advanced techniques for unimplementing methods.

#Here is the code for unimplementing the two unary operations we dont want:
for name, operator in (("__neg__", "-"), ("__index__", "index()")):
    message = ("bad operand type for unary {0}: '{{self}}'"
                .format(operator))
    exec("def {0}(self): raise TypeError(\" {1} \")".format(self=self.__class__.__.name__).format(name, message))
#the built-in exec() fuction dynamically executes the code passed to
#it form the object it is given. In this case we have given it a string, but
#it is also possible to pass some other kinds of objects. By default, the code is 
#excuted in the context of the enclosing scope, in this case within the
#definition of the FuzzyBool class, so the def statements that are executed
#create FuzzyBool methods which is what we want. The code is executed just once, 
#when the FuzzyBoolALt module is imported. Here is the code that is generated
#for the first tuple ("__neg__", "-"):
def __neg__(self):
    raise TypeError("bad operand type for unary -: '{self}'".format(self=self.__class__.__name__))

#We have made the exception and error message match those that Python uses for its own
#types. The code for handling binary methods and n-ary functions (such as pow()) follows
#a similar pattern but with a different error message. For completeness, here is the code
#we have used:

for name, operator in(
    ("__xor__", "^"), ("__ixor__", "^="),
    ("__add__", "+"), ("__iadd__", "+="), ("__radd__", "+"),
    ("__sub__", "-"), ("__isub__", "-="), ("__rsub", "-"),
    ("mul", "*"), ("imul", "*="), ("rmul", "*"),
    ("__pow__", "**"), ("__ipow__", "**="), ("__rpow__", ""),
    ("__floordiv__", "//"), ("__ifloordiv__", "//="), ("__rfloordiv__", "//"),
    ("__truediv__", "/"), ("__itruediv__", "/="), ("__rtruediv__", "/"),
    ("__divmod__", "divmod()"), ("__rdivmod__", "divmod()"),
    ("__mod__", "%"), ("__imod__", "%="), ("__rmod__", "%"),
    ("__lshift", "<<"), ("__ilshift__", "<<="), ("__rlshift__", "<<"),
    ("__rshift__", ">>"), ("__irshift__", ">>="), ("__rrshift__", ">>")):
    message = ("unsupported operand type(s) for {0}: "
        "'{{self}}'{{join}} {{args}}".format(operator))
    #exec("def {0}(self): raise TypeError(" {1} ".format(self=self.__class__.__name__))".format(name, message))
    exec("def {0}(self, *args):\n"
        "    types = [\"'\" + arg.__class__.__name__ + \"'\" "
        "for arg in args]\n"
        "    raise TypeError(\"{1}\".format("
        "self=self.__class__.__name__, "
        "join=(\" and\" if len(args) == 1 else \", \, "
        "args=\", \".join(types)))".format(name, message)

#this code is slightly more complicated than before b/c for binary operators, 
#we must output messages where the two types are listed as type1 and type2, but
#for three or more types we must list them at type1, type2, type3 to mimic
#the built-in behavior.
#Here is the code that is generated for the first tuple ("__xor__", "^"):
def __xor__(self, *args):
    types = ["'" + args.__class__.__name__ + "'" for arg in args]
    raise TypeError("unsupported operand type(s) for ^: "
                    "'{self}'{join} {args}".format(
                    self=self.__class__.__name__,
                    join=(" and" if len(args) == 1 else ","),
                    args=", ".join(types)))
#The two for...in loop blocks we have used here can be simply cut and pasted,
#and then we can add or remove unary operators and methods from the first
#one and binary or n-ary operators and methods from the second one to
#unimplement whatever methods are not required.

#With this last peice of code in place, if we had two FuzzyBools, f and g,
#and tried to add them using f + g, we would get a TypeError exception with
#the message "unsupported operand types(s) for =:'FuzzyBool' and 'FuzzyBool'
#which is exactly the behavior we want.

#Creating clases the way we did for the FIRST FuzzyBool implementation is 
#much more common and is sufficient for almost every purpose. However if
#we need to create an immutable class, the way to do it is to reimplement
object.__new__() #having inherited one of Python's immutable types such as
float, int, str, or tuple #and then implement all the other methods we need.
#The disadvantage of doing this is that we may need to unimplement some
#methods which breaks polymorphism, so in most cases using aggregation
#as we in the first FuzzyBool implementation is a much BETTER approach.










#CODE HERE
fuzzyboolalt_module.py

-----------1st EFFORT - posted on GitHub
#!/usr/bin/env python3
#fuzzyboolalt_module.py

"""
Implements an immutable FuzzyBool data type that can only have values in
the interval [0.0, 1.0] and which supports the basic logical operations
not (~), and (&), and or (|) using fuzzy logic.

Tests of inherited methods
>>> f = FuzzyBool()
>>> g = FuzzyBool(.5)
>>> h = FuzzyBool(3.75)
>>> print(f, g, h)
0.0 0.5 0.0
>>> h = ~h
>>> f = FuzzyBool(0.2)
>>> f < g
True
>>> h >= g
True
>>> f + g
Traceback (most recent call last):
...
TypeError: unsupported operand type(s) for +: 'FuzzyBool' and 'FuzzyBool'
>>> -f
Traceback (most recent call last):
...
TypeError: bad operand type for unary -: 'FuzzyBool'
>>> int(h), int(g), int(FuzzyBool(0.51))
(1, 0, 1)
>>> f = FuzzyBool(0.5)
>>> str(f)
'0.5'
"""


def conjunction(*fuzzies):
    """Returns the logical and of all the FuzzyBools

    >>> conjunction(FuzzyBool(0.5), FuzzyBool(0.6), 0.2, 0.125)
    FuzzyBool(0.125)
    """
    return FuzzyBool(min(fuzzies))


def disjunction(*fuzzies):
    """Returns the logical or of all the FuzzyBools

    >>> disjunction(FuzzyBool(0.5), FuzzyBool(0.75), 0.2, 0.1)
    FuzzyBool(0.75)
    """
    return FuzzyBool(max(fuzzies))


class FuzzyBool(float):

    def __new__(cls, value=0.0):
        """
        >>> f = FuzzyBool()
        >>> g = FuzzyBool(.5)
        >>> h = FuzzyBool(3.75)
        >>> f, g, h
        (FuzzyBool(0.0), FuzzyBool(0.5), FuzzyBool(0.0))
        """
        return super().__new__(cls,
                value if 0.0 <= value <= 1.0 else 0.0)


    def __invert__(self):
        """Returns the logical not of this FuzzyBool

        >>> f = FuzzyBool(0.125)
        >>> ~f
        FuzzyBool(0.875)
        >>> ~FuzzyBool()
        FuzzyBool(1.0)
        >>> ~FuzzyBool(1)
        FuzzyBool(0.0)
        """
        return FuzzyBool(1.0 - float(self))


    def __and__(self, other):
        """Returns the logical and of this FuzzyBool and the other one

        >>> FuzzyBool(0.5) & FuzzyBool(0.6)
        FuzzyBool(0.5)
        """
        return FuzzyBool(min(self, other))


    def __iand__(self, other):
        """Applies logical and to this FuzzyBool with the other one

        >>> f = FuzzyBool(0.5)
        >>> f &= FuzzyBool(0.6)
        >>> f
        FuzzyBool(0.5)
        """
        return FuzzyBool(min(self, other))


    def __or__(self, other):
        """Returns the logical or of this FuzzyBool and the other one

        >>> FuzzyBool(0.5) | FuzzyBool(0.75)
        FuzzyBool(0.75)
        """
        return FuzzyBool(max(self, other))


    def __ior__(self, other):
        """Applies logical or to this FuzzyBool with the other one

        >>> f = FuzzyBool(0.5)
        >>> f |= FuzzyBool(0.75)
        >>> f
        FuzzyBool(0.75)
        """
        return FuzzyBool(max(self, other))


    def __repr__(self):
        """
        >>> f = FuzzyBool(0.5)
        >>> repr(f)
        'FuzzyBool(0.5)'
        """
        return ("{0}({1})".format(self.__class__.__name__,
                                  super().__repr__()))


    def __bool__(self):
        """
        >>> f = FuzzyBool(.3)
        >>> g = FuzzyBool(.51)
        >>> bool(f), bool(g)
        (False, True)
        """
        return self > 0.5


    def __int__(self):
        """
        >>> f = FuzzyBool(.3)
        >>> g = FuzzyBool(.51)
        >>> int(f), int(g)
        (0, 1)
        """
        return round(self)


    for name, operator in (("__neg__", "-"),
                           ("__index__", "index()")):
        message = ("bad operand type for unary {0}: '{{self}}'"
                   .format(operator))
        exec("def {0}(self): raise TypeError(\"{1}\".format("
             "self=self.__class__.__name__))".format(name, message))

    for name, operator in (("__xor__", "^"), ("__ixor__", "^="),
            ("__add__", "+"), ("__iadd__", "+="), ("__radd__", "+"),
            ("__sub__", "-"), ("__isub__", "-="), ("__rsub__", "-"),
            ("__mul__", "*"), ("__imul__", "*="), ("__rmul__", "*"),
            ("__pow__", "**"), ("__ipow__", "**="),
            ("__rpow__", "**"), ("__floordiv__", "//"),
            ("__ifloordiv__", "//="), ("__rfloordiv__", "//"),
            ("__truediv__", "/"), ("__itruediv__", "/="),
            ("__rtruediv__", "/"), ("__divmod__", "divmod()"),
            ("__rdivmod__", "divmod()"), ("__mod__", "%"),
            ("__imod__", "%="), ("__rmod__", "%"),
            ("__lshift__", "<<"), ("__ilshift__", "<<="),
            ("__rlshift__", "<<"), ("__rshift__", ">>"),
            ("__irshift__", ">>="), ("__rrshift__", ">>")):
        message = ("unsupported operand type(s) for {0}: "
                   "'{{self}}'{{join}} {{args}}".format(operator))
        exec("def {0}(self, *args):\n"
             "    types = [\"'\" + arg.__class__.__name__ + \"'\" "
             "for arg in args]\n"
             "    raise TypeError(\"{1}\".format("
             "self=self.__class__.__name__, "
             "join=(\" and\" if len(args) == 1 else \",\"),"
             "args=\", \".join(types)))".format(name, message))


if __name__ == "__main__":
    import doctest
    doctest.testmod()
-----------1st EFFORT - posted on GitHub












#Reminder of topics<===========
CHAPTER 6 OOP - Object Oriented Programming

OO Approach
    OO Concepts and Terminology
Custom Classes
    Attributes and Methods
    Inheritance and Polymorphism
    Using Properties to Control Attribute Access
    Creating Complete and Fully Integrated Data Types
        Creating Data Types from Scratch (ANSWER PART 1)
        Creating Data Types from Other Data Types (ASSWER PART 2)
Custom Collection Classes 
    Creating Classes That Aggregate Collections 
    Creating Collection Classes Using Aggregration 
    Creating Collection Classes Using Inheritance
Summary
Exercises 

#CODE LISTING HERE
Account.py
Circle.py
fuzzybool.py
FuzzyBoolAlt.py
Image.py
Image_ans.py
Shape.py
Shape_ans.py
ShapeAlt.py
ShapeAlt_ans.py
SortedDict.py
SortedList.py 
---
SortedListMeta.py


===============
Custom Collection Classes 
===============
#Here we look at custom classes that are responsible for large amounts of data.
#First class we review is Image that holds image data --> this class is typical 
#of many data-holding custom classes in that it not only provides in-memory 
#access to its data, but also has methods for saving and loading the data to and 
#from disk.
#Second and Third classes we will review, SortedList and SortedDict are
#designed to fill a rare and surprising gap in Python's standard library
#for intrinsically sorted collection data types.

===============
    Creating Custom Classes That Aggregate Collections 
===============
#a simple way of representing a 2D color image is as a two-dimensional array
#with each array element being a color. So to represent a 100 x 100 image, we
#must store 10000 colors. For the image class (in the file Image.py), we will
#take potentially more efficient approach.
#An Image stores a single background color, plus the colors of those points
#in the image that differ from the background color. This is done by using a 
#dictionary as a kind of sparse array, with each key being an (x,y) coordinate
#and the corresponding value being the color of that point. If we had a 100 x 100
#image and half its points are the background color, we would need to store only
#5000 + 1 colors, a considerable saving in memory.

#The Image.py module follows what should now be a familar pattern: it starts with
#a shebang line, then copyright info in comments, then a module docstring with
#some doctests, and then the imports, in case of os and pickle modules.
#We will briefly cover the use of the pickle module when we cover saving and
#loading images. After the imports, we create some custom exception classes:
class ImageError(Exception): pass
class CoordinatedError(Exception): pass
#We have shown only the first two exception classes, the others (LoadError, 
#SaveError, ExportError, and NoFilenameError) are all created the same way and
#all inherit from ImageError. Users of the Image class can choose to test for any
#of the specific exceptions, or just for the base class ImageError exception.

#The rest of the module consists of the Image class and at the end of the standard
#three lines for running the module's doctests. Before looking at the class and
#its methods, lets look at how it can be used:
border_color = "#FF000"     #red
square_color = "0000FF"     #blue
width, height = 240, 60
midx, midy = width // 2, height = // 2
image = Image.Image(width, height, "square_eye.img")
for x in range(width):
    for y in range(height):
        if x < 5 or x >= width -5 or y < 5 or y >= height - 5:
            image[x,y] = border_color
        elif midx - 20 < x < midx + 20 and midy - 20 < y < midy + 20:
            image[x,y] = square_color
image.save()
image.export("square_eye.xpm")
#Notice that we can use the 
item access operator [] #for setting colors in the image. Brackets can also be used for
#getting or deleting (effectively setting to the background color) the color at a
#particular (x,y) coordinate.
#The coordinates passed as a single tuple object (thanks to the comma separator), which
#is the same as if we wrote the code image[(x,y)].  Achieving this kind of seemless
#syntax intergration is easy in Python, as we just have to implement the appropriate
#special methods, which in the case of the item access operator are:
__getitem__(), __setitem__(), and __delitem__()

#The Image class uses HTML style hexadecimal strings to represent colors. The background
#color must be set when the image is created; otherwise, it defaults to white. The Image
#class saves and loads images in its own custom format, but it can also export in the 
#.xpm format which is understood by many image processing applications
#See figure 6.6 on page 263 for a screen shot photo of the image produced by the
#code snippet above.

#We will now review the Image class's methods, starting with the class line and initializer
class Image:
    def __init__(self, widith, height, filename="", background="#FFFFFF"):
        self.filename = filename
        self.__background = background
        self.__data = {}
        self.__width = width
        self.__height = height
        self.__colors = {self.__background}
#when an Image is created, the user (ie class's user) must provide a width and height,
#but the filename and background color are optional since defaults are provided.
#The self.__data dictionary's keys are (x,y) coordinates and its values are color
#strings. The self.__colors set is initialized with the background color; it is 
#used to keep track of unique colors used by the image.

#All the data attributes are private except for the filename, so we must provide
#a means by which users of the class can access them. This is easily done using
#properties. (Note in Chapter 8 we see a complete different approach to
#providing attribute access, using special methods such as __getattr() 
#and __setattr() #which very useful in SOME circumstances.
    @property
    def background(self):
        return self.__background

    @property
    def width(self):
        return self.__width

    @property
    def height(self):
        return self.__height 

    @property
    def colors(self):
        return set(self.__colors)
#When returning a data attribute from an object, we need to be aware of whether
#the attribute is of an immutable or mutable type. It is always safe to return
#immutable attributes since they cant be changed, but for mutable attributes
#we must consider some trade-offs. Returning a reference to a mutable attribute
#is very fast and efficient b/c no copying takes place, but it also means that 
#the called now has access to the object's internal state and might change it
#in a way that invalidates the object ---> so one policy to consider is to 
#always return a copy of mutable data attributes, unless 
#profiling shows a significant negative effect on performance.
#(In this case, an alternative to keeping the set of unique colors would be to return
set(self.__data.values() | {self.__background})
#whenever the set of colors was needed).

    def __getitem__(self, coordinate):
        assert len(coordinate) == 2, "coordinate should be 2-tuple"
        if (not (0 <= coordinate[0] < self.width) or not (0 <= coordinate[1] < self.height) ):
            raise CoordinateError(str(coordinate))
        return self.__data.get(tuple(coordinate), self.__background)
#This method returns the color for a given coordinate using the item access operator []

#We have choosen to apply two policies for item access.
#First policy is that a precondition for using an item access method is that 
#the coordinate it is passed is a sequence of length 2 (usually a 2-tuple), and 
#we use an assertion to ensure this.
#Second policy is that many coordinate values are accepted, but if either is out of
#range, then we raise a custom exception.

#We have used the dict.get() method with a default value of the background color to
#retrieve the color for the given coordinate. This ensures that if the color has
#never been set for the coordinate the background color is correctly returned
#instead of a KeyError exception being raised.


#The special methods for the item access operators and some other collection-relevant
#special methods are listed in Table 6.4 here
################################################ Table 6.4
Collection Special Methods

Special Method              Usage               Description
--------------------      ------------------    ---------------------------------------
__contains__(self, x)       x in y              #Returns True if x is in sequence y or
                                                #if x is a key in mapping y 
__delitem__(self, k)        del y[k]            #Deletes the k-th item of sequence y or
                                                #the item with key k in mapping y 
__getitem__(self, k)        y[k]                #Returns the k-th item of sequence y
                                                #or the value for key k in mapping y
__iter__(self)              for x in y: pass    #Returns an iterator for sequence y's
                                                #items or mapping y's keys
__len__(self)               len(y)              #Returns the number of items in y

__reversed__(self)          reversed(y)         #Returns a backward iterator for sequence y's
                                                #items or mapping k's keys
__setitem__(self, k, v)     y[l] = v            #Sets the k-th item of sequence y or the 
                                                #value for key k in mapping y, to v
################################################


    def __setitem__(self, coordinate, color):
        assert len(coordinate) == 2, "coordinate should be a 2-tuple"
        if (not(0 <= coordinate[0] < self.width) or not(0 <= coordinate[1] < self.height)):
            raise CoordinateError(str(coordinate))
        if color == self.__background:
            self.__data.pop(tuple(coordinate), None)
        else:
            self.__data[tuple(coordinate)] = color
            self.__colors.add(color)

#If the user sets a coordinate's value to the background color we can simply delete
#the corresponding dictionary item since any coordinate not in the dictionary is
#assumed to have the background color. We must use
dict.pop() #and give a dummy second argument rather than use
del #b/c doing so avoids a KeyError being raised if the key (coordinate) is not in
#the dictionary.
#If the color is different from the background color, we set it for the given 
#coordinate and add it to the set of the unique colors used by the image.

    def __delitem__(self, coordinate):
        assert len(coordinate) == 2, "coordinate should be a 2-tuple"
        if (not(0 <= coordinate[0] < self.width) or not(0 <= coordinate[1] < self. hieght)):
            raise CoordinateError(str(coordinate))
        self.__data.pop(tuple(coordinate), None)

#If a coordinate's color is deleted the effect is to make that coordinate's color
#the background color. Again we use dict.pop() to remove the item since it will 
#work correctly whether or not an item with the given coordinate is in the dictionary.

#We have not provided a 
__len__() #implementation since it does not make sense for a two-dimensional object.
#Also, we can not provide a representational form since an Image can not be created
#fully formed just by calling Image(), so we do not provide __repr__() or __str__()
#implementations either. If a user calls repr() or str() on an Image object, then
#the object.__repr__() base class implementation will return a suitable string, for
#example '<Image.Image object at 0x9x794ac>'. This is a standard format used for
#non-eval() objects. The hexadecimal number is the object's ID --> this is unique
#normally it is the object's address in memory but may be transient.

#We want users of the Image class to be able to save and load their image data, so we
#have provided two methods, save() and load() to carry out these tasks.
#We have chosen to save the data by pickling it.
pickling 
#In Pythonic, pickling is a way of serializing a Python object --> converting into a 
#sequence of bytes, or into a string. Why? the pickled object can be a collection 
#data type, such as a list or dictionary, and even if the pickled object has other
#objects inside it (including other collections), the whole lot will be pickled WITHOUT
#duplicating objects that occur more than once.

#A pickle can be read back directly into a Python variable so no need to parse or do
#additional interpretation ourselves. So using pickles is ideal for saving and loading
#ad hoc collections of data, especially for small programs and for personal use.
#However, pickles have no security mechanism (no encryption, no digital signature) so
#loading a pickle that comes from an untrusted source could be dangerous. In view of this
#its best to not use them for personal use. So it is best to create a custom file format
#that is specific to the program. In Chpater 7 we show how to read and write custom
#binary, text and XML file formats.

    def save(self, filename=None):
        if filename is not None:
            self.filename = filename
        if not self.filename:
            raise NoFilenameError()

        fh = None 
        try:
            data = [self.width, self.height, self.__background, self.__data]
            fh = open(self.filename, "wb")
            pickle.dump(data, fh, pickle.HIGHEST_PROTOCOL)
        except (EnvironmentError, pickle.PicklingError) as err:
            raise SaveError(str(err))
        finally:
            if fh is not None:
                fh.close()

#The first part of the function is concerned purely with the filename. If the Image
#object was created with no filename and no filename has been set since, then the save()
#method must be given an explicit filename (in which case it behaves as "save as" and
#sets the internally used filename.) If no filename is specified the current filename
#is used, and if there is no current filename and none is given an exception is raised.

#We create a list (data) to hold the objects we want to save, including the
#self.__data dictionary of coordinate-color items, but excluding the set of unique
#colors since that data can be reconstructed. Then we open the file to write in binary
#mode and call the pickle.dump() function to write the data object to the file. And
#that is it!

#The pickle module can serialize data using various formats (clalled protocals in the
#documenatation), with the one to use specified by the third argument to pickle.dump()
#Protocol 0 is ASCII and is useful for debugging. We have used protocol 3 which is
#pickle.HIGHEST_PROTOCOL which is a compact binary format which is why we had to
#open the file in binary mode. When reading pickles, no protocol is specified, so
#pickle.load() function is smart enougth to work out the protocol for itself.

    def load(self, filename=None):
        if filename is not None:
            self.filename = filename
        if no self.filename:
            raise NoFilenameError()

        fh = None
        try:
            fh = open(self.filename, "rb")
            data = pickle.load(fh)
            (self.__width, self.__height, self.__background, self.__data) = data
            self.__colors = (set(self.__data.values()) | {self.__background}
        except (EnvironmentError, pickle.UnpicklingError) as err:
            raise LoadError(str(err))
        finally:
            if fh is not None:
                fh.close()

#This function starts off the same as the save() function to get the filename of the 
#file to load. File must be opened in read binary mode, and the data is read using
#the single statement           data = pickle.load(fh)
#The data object is an exact reconstruction of the one we saved, so in this case
#it is a list with the width and height integers, the background color string, and
#the dictionary of coordinate-color items. We use tuple unpacking to assign each
#of the data lists's items to the appropriate variable, so any previously held image
#data is CORRECTLY lost. (ie old info is written over).
#The set of unique colors is reconstructed by making a set of all the colors in the
#coordinate-color dictionary and then adding the background color.

#pge 257
    def export(self, filename):
        if filename.lower().endswith(".xpm"):
            self.__export_xpm(filename)
        else:
            raise ExportError("unsupported export format: " + os.path.splitext(filename)[1])

#We have provided one generic export method that use the file extension to determine
#which private method to call -- or raises an exception for file formats that can NOT
#be exported. In this case, we only support saving to .xpm files (and then only for
#images with fewer than 8930 colors). We have not quoted the __export_xpm() method
#b/c it is not really relevant to this chapter's theme, but it is in the book's 
#source code.

#We have now completed our coverage of the custom Image class. This is typical of 
#those used to hold program-specific data, providing access to the data items it
#contains, the ability to save and load all its data to and from disk, and with
#only the essential methods it needs provided. In the next two subsectionn, we will
#see how to create two generic custom collection types that offer complete APIs.


#Reminder of topics<===========
CHAPTER 6 OOP - Object Oriented Programming

OO Approach
    OO Concepts and Terminology
Custom Classes
    Attributes and Methods
    Inheritance and Polymorphism
    Using Properties to Control Attribute Access
    Creating Complete and Fully Integrated Data Types
        Creating Data Types from Scratch (ANSWER PART 1)
        Creating Data Types from Other Data Types (ASSWER PART 2)
Custom Collection Classes 
    Creating Classes That Aggregate Collections 
    Creating Collection Classes Using Aggregration 
    Creating Collection Classes Using Inheritance
Summary
Exercises 


#CODE LISTING HERE
Account.py
Circle.py
fuzzybool.py
FuzzyBoolAlt.py
Image.py
Image_ans.py
Shape.py
Shape_ans.py
ShapeAlt.py
ShapeAlt_ans.py
SortedDict.py
SortedList.py 
---
SortedListMeta.py


===============
    Creating Custom Collection Classes Using Aggregration 
===============

#In this subsection we will develop a complete custom collection data type SortedList
#that holds a list of items in sorted order. The items are sorted using their less than
#operator (<), provided by the __lt__() special method, or by using a key function if
#one is given. The (custom) class tries to match the API of the built-in list class 
#to make IT as easy to learn and use as possible, but some methods can NOT sensibly 
#be provided for example using the concatenation operator (+) could result in items 
#being out of order, so we do not implement it.

#As always, when creating custom classes, we are faced with the choices of inheriting
#a class that is similar to the one we want to make, or creating a class from
#scratch and aggregating instances of any other classes we need inside it, or doing
#a mixture of both. For this subsection's SortedList we use aggregation (and 
#implicitly 
inherit object #of course), and for the following subsection's 
SortedDict #we will use both aggregation and inheritance (
inherit dict #).

#In Chapter 8, we will see that 
classes can YES make promises about the API they offer. #For example, 
a list provides the MutableSequence API #which means that it supports the 
in #operator, the 
iter() #and 
len() #built-in functions, and the item access operator 
[] #for getting, setting, and deleting items, and an 
insert() #method. Ths SortedList class implemented here does NOT support
#item setting and does NOT have an insert() method, 
so it does NOT provide a MutableSequence API. 
#If we were to create SortedList by inheriting list, the resultant
#class would claim to be a mutable sequence but would not have the complete API. In view of
THIS #the SortedList does NOT inherit list and so makes no promises about its API.
#On the other hand, the next subsection's 
SortedDict class YES supports #the complete
MutableMapping API #that the dict class provides, so we can make it a dict subclass.

#Here are some basic examples of using a SortedList
letters = SortedList.SortedList(("H", "c", "B", "G", "e"), str.lower)
# str(letters) == "['B', 'c', 'e', 'G', 'H']"
letters.add("G")
letters.add("f")
letters.add("A")    # str(letters) == "['A', 'B', 'c', 'e', 'f', 'G', 'G', 'H']"
letters[2]          # returns: 'c'

            >>> from test8 import SortedList
            >>> L = SortedList((5, 8, -1, 3, 4, 22))
            >>> list(L)
            [-1, 3, 4, 5, 8, 22]
            >>> L[2]
            4
            >>> L[4:8]      
            TypeError: use add() to insert a value and rely on the list to 
            put it in the right place
            >>> L.add(5)
            >>> L.add(5)
            >>> L.add(6)
            >>> list(L)
            [-1, 3, 4, 5, 5, 5, 6, 8, 22]

            letters = SortedList(("H", "c", "B", "G", "e"), str.lower)
            >>> letters
            <test8.SortedList object at 0x101819978>
            >>> print(letters)
            ['B', 'c', 'e', 'G', 'H']
            >>> letters.add("G")
            >>> letters.add("f")
            >>> letters.add("A")
            >>> print(letters)
            ['A', 'B', 'c', 'e', 'f', 'G', 'G', 'H']
            >>> letters[2]
            'c'

#ATUL BIG PICTURE
#A SortedList object aggregates (ie is composed of) two private attributes --> 
#a function called 
self.__key() #which is held as an object reference of self.__key
#and a list called 
self.__list

#The key function is passed as the second argument (or using the key keyword argument
#if no initial sequence is given.) If no key function is specified the following
#private module function is used:
_identity = lambda x: x      #this is the identity function: it simply returns 
#its argument unchanged, so when it is used as a SortedList's key function it 
#means that THE SORT KEY for each object in the list is THE OBJECT itself.

#The SortedList type does not allow the item access operator [] to change an item (so it
#does NOT implement the __setitem__() special method), nor does it provide the append()
#or extend() method since these might invalidate the ordering. Therefore, the only way to add
#items is to pass a sequence when the SortedList is created or to add them later using the
SortedList.add() #method. On the other hand, we can safely use the item access operator for
#getting or deleting the item at a given index position since neither operation affects the
#ordering, so both the 
__getitem__() #and 
__delitem__() #special methods are implemented (ie in the code).

#ATUL now detailed explanation
#We will now review the class method by method and line by line, starting as usual with the 
#class line and the initializer

    class SortedList:
        def __init__(self, sequence=None, key=None):
            self.__key = key or _identity               #explain_1
            assert hasattr(self.__key, "__call__")
            if sequence is None:
                self.__list = []                        #aggregation is here
            elif (isinstance(sequence, SortedList) and sequence.key == self.__key):
                self.__list = sequence.__list[:]        #shallow copy the sequence's list
            else:
                self.__list = sorted(list(sequence), key=self.__key)

#ATUL - explain_1 covers entire paragraph
#Since a function's name is an object reference (to its function), we can hold
#functions in variables just like any other object reference. Here the private
#self.__key variable holds a reference to the key function that was passed in, or to the
#identity function. The method's first statement relies on the fact that the 
or #operator returns its first operand if it is True in a Boolean context (which a non-None 
#key function is), or its second operand otherwise. A slightly longer but more obvious 
#alternative would have been 
self.__key = key if key is not None else _identity

#Once we have the key function, we use an assert TO ENSURE that it is callable. The built-in
hasattr() #function returns True if the object passed as its first argument has the attribute
#whose name is passed as its second argument. There are corresponding setattr() and 
#delattr() functions --> see Chapter 8. ALL CALLABLE objects, for example, functions and
#methods have a 
__call__ attribute.

#To make the creation of 
SortedLists #as similar as possible to the creation of 
lists
#we have an optional sequence argument that corresponds to the single optionarl argument
#that list() accepts. The SortedList class aggregates a list collection in the private variable
self.__list #and keeps the items in the aggregated list in sorted order using
#the given key function.
ATUL this is the AGGREGRATION part!

#The elif clause uses TYPE TESTING to see whether the given sequence is a SortedList and
#if that is the case then whether it has the same key function as this sorted list. If these
#conditions are met we simply shallow-copy the sequence's list without needing to sort it.
#If most key functions are created on the fly using lambda, even though two may have the
#same code, they will NOT compare as equal, so the efficiency gain may not be realized
#in practice.

        @property
        def key(self):
            return self.__key

#Once a sorted list is created its key function is NOW fixed, so we KEEP it as a private
#variable to prevent users from changing it. But some users may want get a reference
#to the key function (as we will see in the next subsection), and so we have made it
#accessible by providing the read-only key property.

        def add(self, value):
            index = self.__bisect_left(value)       #returns the required index position
            if index == len(self.__list):           #checks if new > all existing
                self.__list.append(value)           #append to end if so
            else: 
                self.__list.insert(index, value)    #insert at correct index position

#When this method is called the given value must be inserted into the private 
self.__list #in the correct position to preserve the list's order. The private
SortedList.__bisect_left() #method returns the required index position. If the new
#value is larger than any other value in the list then it must go at the end, so 
#the index position will be equal to the list's length. Note that list index positions go from
0 to len(L) - 1 #--> if this is the case then we append the new value.
#Otherwise, we insert the new value at the given index position, which will be at index
#position 0 if the new value is smaller than any other value in the list.

        def __bisect_left(self, value):             #STANFORD BOOKMARK HERE
            key = self.__key(value)
            left, right = 0, len(self.__list)
            while left < right:
                middle = (left + right) // 2
                if self.__key(self.__list[middle]) < key:
                    left = middle + 1
                else:
                    right = middle
            return left

#This private method calculates the index position where the given value belongs
#in the list, that is, the index position where the value is (if it is in the list),
#or where it should go (if it is not yet in the list). It computes the comparision key
#for the given value using the sorted list's key function, and compares the comparison
#key with the computed comparison keys of the items that the method examines. The
#algorithm used is 
binary search (also called binary chop) #which has excellent performance even on very
#large lists, for example, at most, 21 comparisons are required to find a value's
#position in a list of 1,000,000 items. #(NOTE that Python's bisect module 
#provides the bisect.bisect_left() function and some
#others, but at the time of this writing, none of the bisect module's functions
#can work with a key function.)
#Compare this with a 
plain unsorted list #which uses 
linear search #and needs an average of 500,000 comparisons and at worst 1,000,000
#comparisons to find a value in a list of 1,000,000 items.
 
        def remove(self, value):
            index = self.__bisect_left(value)
            if index < len(self.__list) and self.__list[index] == value:
                del self.__list[index]
            else:
                raise ValueError("{0}.remove(x): x not in list".format(self.__class__.__name__))

#This method is used to remove the first occurrence of the given value. It uses the
SortedList.__bisect_left() #method to find the index position where the value belongs
#and then tests to see whether that index position is within the list and that the item
#at that position is the same name as the given value. If the conditions are met the
#item is removed: otherwise, a ValueError exception is raised (which is what
#list.remove() does in the same circumstances).

        def remove_every(self, value):
            count = 0
            index = self.__bisect_left(value)
            while (index < len(self.__list) and self.__list[index] == value):
                del self.__list[index]
                count += 1
            return count

#This method is similar to the SortedList.remove() method, and is an extension
#of the list API. It starts off by finding the index position where the first
#occurrence of the value belongs in the list, and then loops as long as the index
#position is within the list and the item at the index position is the same as 
#the given value. The code is slightly subtle since at each iteration the matching
#item is deleted, and as a consequence, after each deletion the item at the index
#position is the item that followed the deleted item.

        def count(self, value):
            count = 0
            index = self.__bisect_left(value)
            while (index < len(self.__list) and self.__list[index] == value):
                index += 1
                count += 1
            return count

#This method returns the number of times the given value occurs in the list (which
#could be 0). It uses a very similar algorithm to SortedList.remove_every()
#only here we must increment the index position in each iteration.
#ATUL by "uses a very similar algoritm" means that the what the code tries to do is
#mirrored by the prior defition --> similar code, not exactly the same, but close.

        def index(self, value):                     #STANFORD BOOKMARK HERE
            index = self.__bisect_left(value)
            if index < len(self.__list) and self.__list[index] == value:
                return index
            raise ValueError("{0}.index(x): x not in list".format(self.__class__.__name__))

#Since a SortedList is ordered we can use a FAST BINARY SEARCH to find (or not find)
#the value in the list.

        def __delitem__(self, index):
            del self.__list[index]

#The __delitem__() special method provides support for the 
del L[n] syntax  #where L is a sorted list and n is an integer index position. We do NOT test 
#for an out-of-range index since if one is given, the 
self.__list[index] #call will raise an IndexError exception, which is the behavior we want.

        def __getitem__(self, index):
            return self.__list[index]

#This SPECIAL method provides support for the x = L[n] syntax, where L is a sorted list and
#n is an integer index position.

        def __setitem__(self, index, value):
            raise TypeError("use add() to insert a value and rely on the list "
                            "to put it in the right place")

#We dont the user to change an item at a given index position (so L[n] = x is DISALLOWED);
#otherwise, the sorted list's order might be invalidated. The TypeError exception is the
#one used to signify that an operation is NOT supported by a particular data type.

        def __iter__(self):
            return iter(self.__list)

#This method is easy to implement since we can just return an iterator to the private
#list using the built-in iter() function. This method is used to support the 
for value in iterable #syntax.

#Note that if a sequence is required, it is this method that is used. So to convert a
#SortedList, L, to a plain list we can call 
list(L) #and behind the scenes Python will call
SortedList.__iter__(L) #to provide the sequence that the 
list (L) #function requires.

        def __reversed__(self):
            return reversed(self.__list)

#This provides support for the built-in reversed() function so that we can write, for example
for value in reversed(iterable).

        def __contains__(self, value):
            index = self.__bisect_left(value)
            return (index < len(self.__list) and self.__list[index] == value)

#The 
__contains__() #method provides support for the 
in #operator. Once again we are able to use a FAST BINARY SEARCH rather than 
#the SLOW LINEAR SERACH used by a plain list.

        def clear(self):
            self.__list = []

        def pop(self, index=-1):
            return self.__list.pop(index)

        def __len__(self):
            return len(self.__list)

        def __str__(self):
            return str(self.__list)

#The
SortedList.clear() #method discards the existing list and replaces it with a new
#empty list. The 
SortedList.pop() #method removes and returns the item at the given index
#position, or raises an IndexError exception if the index is out of range. For the 
pop(), __len__(), #and
__str__() #methods, we simply pass on the work to the aggregrated 
self.__list #object.

#We do not reimplement the __repr__() special method, so the base class 
#object.__repr__() will be called when the user writes repr(L) and L is a SortedList.
#This will produce a string such as '<SortedList.SortedList object at 0x97e7cec>', 
#although the hexadecimal ID will vary. We can not provide a sensible __repr__()
#implemenation b/c we would need to give the key function and we can not represent a
#function object reference as an eval()-able string.

#We have not implemented the insert(), reverse(), or sort() method b/c none of them
#is appropriate. If any of them are called an AttributeError exception will be raised.

#If we copy a sorted list using the L[:] ideom we will get a plain list object, rather
#than a SortedList. Therefore, the easiest way to get a copy is to import the copy module 
#and use the copy,copy() function -- this is smart enough to copy a sorted list 
#(and instances of most other custom classes) without any help. However, we have 
#decided to provide an explicit copy() method:
 
        def copy(self):
            return SortedList(self, self.__key)

#By passing 
self #as the first argument, we ensure that self.__list is simply shallow-copied rather 
#than being copied and re-sorted. 
#(This is thanks to the __init__() method's type testing elif clause). 
#The theoretical performance advantage of copying this way is not avaiable 
#to the copy.copy() function, but we can easily make it available by adding this line:

        __copy__ = copy

#When copy.copy() is called, it tries to use the object's __copy__() special method, 
#falling back to its own code if one isnt provided. With this line in place
#copy.copy() will now use the SortedList.copy() method for sorted lists. 
#(It is also possible to provide a __deepcopy__() special method, but this is slightly 
#more involved. The copy module's online documentation has the details.)

#This now COMPLETES the implementation of the SortedList class. In the next subsection, 
#we will make use of a SortedList to provide a sorted list of keys for the SortedDict class.




-----------1st EFFORT - posted on GitHub
#!/usr/bin/env python3
#sortedlist.py

#Created a custom collection data type class SortedList to mimic
#the API of the built-in list class.

_identity = lambda x: x


class SortedList:

    def __init__(self, sequence=None, key=None):
        self.__key = key or _identity
        assert hasattr(self.__key, "__call__")
        if sequence is None:
            self.__list = []
        elif (isinstance(sequence, SortedList) and
              sequence.key == self.__key):
            self.__list = sequence.__list[:]
        else:
            self.__list = sorted(list(sequence), key=self.__key)


    @property
    def key(self):
        return self.__key


    def clear(self):
        self.__list = []


    def __bisect_left(self, value):
        key = self.__key(value)
        left, right = 0, len(self.__list)
        while left < right:
            middle = (left + right) // 2
            if self.__key(self.__list[middle]) < key:
                left = middle + 1
            else:
                right = middle
        return key, left


    def add(self, value):
        index = self.__bisect_left(value)[1]
        if index == len(self.__list):
            self.__list.append(value)
        else:
            self.__list.insert(index, value)


    def pop(self, index=-1):
        return self.__list.pop(index)


    def remove(self, value):
        key, index = self.__bisect_left(value)
        while (index < len(self.__list) and
                self.__key(self.__list[index]) == key):
            if self.__list[index] == value:
                del self.__list[index]
                return
            index += 1
        raise ValueError("{0}.remove(x): x not in list".format(
                            self.__class__.__name__))


    def remove_every(self, value):
        count = 0
        key, index = self.__bisect_left(value)
        while (index < len(self.__list) and
               self.__key(self.__list[index]) == key):
            del self.__list[index]
            count += 1
        return count


    def count(self, value):
        count = 0
        key, index = self.__bisect_left(value)
        while (index < len(self.__list) and
               self.__key(self.__list[index]) == key):
            index += 1
            count += 1
        return count


    def index(self, value):
        key, index = self.__bisect_left(value)
        if (index < len(self.__list) and
            self.__key(self.__list[index]) == key):
            return index
        raise ValueError("{0}.index(x): x not in list".format(
                         self.__class__.__name__))


    def __delitem__(self, index):
        del self.__list[index]
        

    def __getitem__(self, index):
        return self.__list[index]


    def __setitem__(self, index, value):
        raise TypeError("use add() to insert a value and rely on "
                        "the list to put it in the right place")


    def __iter__(self):
        return iter(self.__list)


    def __reversed__(self):
        return reversed(self.__list)


    def __contains__(self, value):
        key, index = self.__bisect_left(value)
        return (index < len(self.__list) and
                self.__key(self.__list[index]) == key)


    def __len__(self):
        return len(self.__list)


    def __str__(self):
        return str(self.__list)


    def copy(self):
        return SortedList(self, self.__key)
        
    __copy__ = copy

if __name__ == "__main__":
    import doctest
    doctest.testmod()
-----------1st EFFORT - posted on GitHub



-----------1st EFFORT - posted on GitHub
#!/usr/bin/env python3
#sortedlist.py

#Created a custom collection data type class SortedList to mimic
#the API of the built-in list class.


"""
>>> L = SortedList((5, 8, -1, 3, 4, 22))
>>> L[2] = 18 #doctest: +IGNORE_EXCEPTION_DETAIL
Traceback (most recent call last):
...
TypeError: use add() to insert a value and rely on the...
>>> list(L)
[-1, 3, 4, 5, 8, 22]
>>> L.add(5)
>>> L.add(5)
>>> L.add(6)
>>> list(L)
[-1, 3, 4, 5, 5, 5, 6, 8, 22]
>>> L.index(4)
2
>>> L.count(5), L.count(2)
(3, 0)
>>> L.insert(2, 9)
Traceback (most recent call last):
...
AttributeError: 'SortedList' object has no attribute 'insert'
>>> L.reverse()
Traceback (most recent call last):
...
AttributeError: 'SortedList' object has no attribute 'reverse'
>>> L.sort()
Traceback (most recent call last):
...
AttributeError: 'SortedList' object has no attribute 'sort'

>>> import collections
>>> isinstance(L, collections.Sequence)
False
"""

_identity = lambda x: x


class SortedList:

    def __init__(self, sequence=None, key=None):
        """Creates a SortedList that orders using < on the items,
        or on the results of using the given key function

        >>> L = SortedList()
        >>> print(L)
        []
        >>> L = SortedList((5, 8, -1, 3, 4, 22))
        >>> print(L)
        [-1, 3, 4, 5, 8, 22]
        >>> L = SortedList({9, 8, 7, 6, -1, -2})
        >>> print(L)
        [-2, -1, 6, 7, 8, 9]
        >>> L = SortedList([-5, 4, -3, 8, -2, 16, -1, 0, -3, 8])
        >>> print(L)
        [-5, -3, -3, -2, -1, 0, 4, 8, 8, 16]
        >>> L2 = SortedList(L)
        >>> print(L2)
        [-5, -3, -3, -2, -1, 0, 4, 8, 8, 16]
        >>> L = SortedList(("the", "quick", "brown", "fox", "jumped"))
        >>> print(L)
        ['brown', 'fox', 'jumped', 'quick', 'the']
        """
        self.__key = key or _identity
        assert hasattr(self.__key, "__call__")
        if sequence is None:
            self.__list = []
        elif (isinstance(sequence, SortedList) and
              sequence.key == self.__key):
            self.__list = sequence.__list[:]
        else:
            self.__list = sorted(list(sequence), key=self.__key)


    @property
    def key(self):
        """Return the key function used by this list
        """
        return self.__key


    def clear(self):
        """Clears the list

        >>> L = SortedList((5, 8, -1, 3, 4, 22))
        >>> print(L)
        [-1, 3, 4, 5, 8, 22]
        >>> L.clear()
        >>> print(L)
        []
        """
        self.__list = []


    def __bisect_left(self, value):
        """Returns value's key and its index position in the list
        (or where value belongs if it isn't in the list)
        """
        key = self.__key(value)
        left, right = 0, len(self.__list)
        while left < right:
            middle = (left + right) // 2
            if self.__key(self.__list[middle]) < key:
                left = middle + 1
            else:
                right = middle
        return key, left


    def add(self, value):
        """Adds a value to the list (duplicates are allowed)

        >>> L = SortedList((5, 8, -1, 3, 4, 22))
        >>> print(L)
        [-1, 3, 4, 5, 8, 22]
        >>> L.add(5)
        >>> L.add(5)
        >>> L.add(7)
        >>> L.add(-18)
        >>> L.add(99)
        >>> print(L)
        [-18, -1, 3, 4, 5, 5, 5, 7, 8, 22, 99]
        """
        index = self.__bisect_left(value)[1]
        if index == len(self.__list):
            self.__list.append(value)
        else:
            self.__list.insert(index, value)


    def pop(self, index=-1):
        """Removes and returns the item the given index

        >>> L = SortedList([-18, -1, 3, 4, 5, 5, 7, 8, 22, 99])
        >>> print(L)
        [-18, -1, 3, 4, 5, 5, 7, 8, 22, 99]
        >>> L.pop()
        99
        >>> L.pop(0)
        -18
        >>> L.pop(5)
        7
        >>> print(L)
        [-1, 3, 4, 5, 5, 8, 22]
        >>> L.pop(12)
        Traceback (most recent call last):
        ...
        IndexError: pop index out of range
        """
        return self.__list.pop(index)


    def remove(self, value):
        """Removes the first occurrence of value from the list

        >>> L = SortedList([-18, -1, 3, 4, 5, 5, 7, 8, 22, 99])
        >>> print(L)
        [-18, -1, 3, 4, 5, 5, 7, 8, 22, 99]
        >>> L.remove(20)
        Traceback (most recent call last):
        ...
        ValueError: SortedList.remove(x): x not in list
        >>> L.remove(5)
        >>> L.remove(-18)
        >>> L.remove(99)
        >>> print(L)
        [-1, 3, 4, 5, 7, 8, 22]
        >>> L = SortedList(["ABC", "X", "abc", "Abc"], lambda x: x.lower())
        >>> print(L)
        ['ABC', 'abc', 'Abc', 'X']
        >>> L.remove("Abca")
        Traceback (most recent call last):
        ...
        ValueError: SortedList.remove(x): x not in list
        >>> print(L)
        ['ABC', 'abc', 'Abc', 'X']
        >>> L.remove("Abc")
        >>> print(L)
        ['ABC', 'abc', 'X']
        >>> L.remove("ABC")
        >>> print(L)
        ['abc', 'X']
        >>> L.remove("X")
        >>> print(L)
        ['abc']
        >>> L.remove("abc")
        >>> print(L)
        []
        """
        key, index = self.__bisect_left(value)
        while (index < len(self.__list) and
                self.__key(self.__list[index]) == key):
            if self.__list[index] == value:
                del self.__list[index]
                return
            index += 1
        raise ValueError("{0}.remove(x): x not in list".format(
                            self.__class__.__name__))


    def remove_every(self, value):
        """Removes every occurrence of value from the list

        Returns the number of occurrences removed (which could be 0).
        >>> L = SortedList([5, 5, -18, -1, 3, 4, 5, 5, 7, 8, 22, 99])
        >>> L.add(5)
        >>> L.add(5)
        >>> print(L)
        [-18, -1, 3, 4, 5, 5, 5, 5, 5, 5, 7, 8, 22, 99]
        >>> L.remove_every(-3)
        0
        >>> L.remove_every(7)
        1
        >>> L.remove_every(5)
        6
        >>> print(L)
        [-18, -1, 3, 4, 8, 22, 99]
        >>> L = SortedList(["ABC", "X", "abc", "Abc"], lambda x: x.lower())
        >>> L.remove_every("abc")
        3
        """
        count = 0
        key, index = self.__bisect_left(value)
        while (index < len(self.__list) and
               self.__key(self.__list[index]) == key):
            del self.__list[index]
            count += 1
        return count


    def count(self, value):
        """Counts every occurrence of value in the list

        >>> L = SortedList([5, 5, -18, -1, 3, 4, 5, 5, 7, 8, 22, 99])
        >>> L.count(5)
        4
        >>> L.count(99)
        1
        >>> L.count(-17)
        0
        >>> L = SortedList(["ABC", "X", "abc", "Abc"], lambda x: x.lower())
        >>> L.count("abc")
        3
        """
        count = 0
        key, index = self.__bisect_left(value)
        while (index < len(self.__list) and
               self.__key(self.__list[index]) == key):
            index += 1
            count += 1
        return count


    def index(self, value):
        """Returns the index position of the first occurrence of value

        >>> L = SortedList([5, 5, -18, -1, 3, 4, 7, 8, 22, 99, 2, 1, 3])
        >>> L.index(5)
        7
        >>> L.index(0)
        Traceback (most recent call last):
        ...
        ValueError: SortedList.index(x): x not in list
        >>> L.index(99)
        12
        >>> L = SortedList(["ABC", "X", "abc", "Abc"], lambda x: x.lower())
        >>> print(L)
        ['ABC', 'abc', 'Abc', 'X']
        >>> L.index("x")
        3
        >>> L.index("abc")
        0
        """
        key, index = self.__bisect_left(value)
        if (index < len(self.__list) and
            self.__key(self.__list[index]) == key):
            return index
        raise ValueError("{0}.index(x): x not in list".format(
                         self.__class__.__name__))


    def __delitem__(self, index):
        """Deletes the value at the given index position

        >>> L = SortedList([9, -5, 3, -7, 8, 14, 0, 8, 3])
        >>> print(L)
        [-7, -5, 0, 3, 3, 8, 8, 9, 14]
        >>> del L[0]
        >>> del L[-1]
        >>> del L[5]
        >>> print(L)
        [-5, 0, 3, 3, 8, 9]
        >>> del L[25]
        Traceback (most recent call last):
        ...
        IndexError: list assignment index out of range
        >>> del L[-3:]
        >>> print(L)
        [-5, 0, 3]
        """
        del self.__list[index]
        

    def __getitem__(self, index):
        """Returns the value at the given index position

        >>> L = SortedList([9, -5, 3, -7, 8, 14, 0, 8, 3])
        >>> L[0], L[3], L[4], L[-1]
        (-7, 3, 3, 14)
        >>> L[15]
        Traceback (most recent call last):
        ...
        IndexError: list index out of range
        >>> L[:3]
        [-7, -5, 0]
        >>> L[4:8]
        [3, 8, 8, 9]
        """
        return self.__list[index]


    def __setitem__(self, index, value):
        raise TypeError("use add() to insert a value and rely on "
                        "the list to put it in the right place")


    def __iter__(self):
        """Returns an iterator for the list

        >>> L = SortedList([5, 5, -18, -1, 3, 4, 7, 8, 22, 99, 2, 1, 3])
        >>> result = []
        >>> for x in L:
        ...     result.append(x)
        >>> print(result)
        [-18, -1, 1, 2, 3, 3, 4, 5, 5, 7, 8, 22, 99]
        """
        return iter(self.__list)


    def __reversed__(self):
        """Returns a reverse iterator for the list

        >>> L = SortedList([5, 5, -18, -1, 3, 4, 7, 8, 22, 99, 2, 1, 3])
        >>> result = []
        >>> for x in reversed(L):
        ...     result.append(x)
        >>> print(result)
        [99, 22, 8, 7, 5, 5, 4, 3, 3, 2, 1, -1, -18]
        """
        return reversed(self.__list)


    def __contains__(self, value):
        """Returns True if value is in the list; otherwise returns False

        >>> L = SortedList([5, 5, -18, -1, 3, 4, 7, 8, 22, 99, 2, 1, 3])
        >>> 5 in L
        True
        >>> 0 in L
        False
        >>> 99 in L
        True
        >>> L = SortedList(["ABC", "X", "Abc"], lambda x: x.lower())
        >>> "abc" in L
        True
        >>> "x" in L
        True
        >>> "ZZ" in L
        False
        """
        key, index = self.__bisect_left(value)
        return (index < len(self.__list) and
                self.__key(self.__list[index]) == key)


    def __len__(self):
        """Returns the length of the list

        >>> L = SortedList([5, 5, -18, -1, 3, 4, 7, 8, 22, 99, 2, 1, 3])
        >>> len(L)
        13
        >>> L = SortedList()
        >>> len(L)
        0
        """
        return len(self.__list)


    def __str__(self):
        """Returns a human readable string version of the list; the
        result could be very long

        >>> L = SortedList([-1, 3, 4, 7, 8, 22, -9, 2, 1, 3])
        >>> str(L)
        '[-9, -1, 1, 2, 3, 3, 4, 7, 8, 22]'
        >>> L = SortedList()
        >>> str(L)
        '[]'
        >>> L = SortedList(("the", "quick", "brown", "fox", "jumped"))
        >>> str(L)
        "['brown', 'fox', 'jumped', 'quick', 'the']"
        """
        return str(self.__list)


    def copy(self):
        """Returns a shallow copy of the list with the same key function
        >>> L = SortedList([-1, 3, 4, 7, 8, 22, -9, 2, 1, 3])
        >>> m = L.copy()
        >>> str(m)
        '[-9, -1, 1, 2, 3, 3, 4, 7, 8, 22]'
        >>> m[:]
        [-9, -1, 1, 2, 3, 3, 4, 7, 8, 22]
        >>> import copy
        >>> n = copy.copy(L)
        >>> str(n)
        '[-9, -1, 1, 2, 3, 3, 4, 7, 8, 22]'
        """
        return SortedList(self, self.__key)
        
    __copy__ = copy

if __name__ == "__main__":
    import doctest
    doctest.testmod()
-----------1st EFFORT - posted on GitHub





#Reminder of topics<===========
CHAPTER 6 OOP - Object Oriented Programming

OO Approach
    OO Concepts and Terminology
Custom Classes
    Attributes and Methods
    Inheritance and Polymorphism
    Using Properties to Control Attribute Access
    Creating Complete and Fully Integrated Data Types
        Creating Data Types from Scratch (ANSWER PART 1)
        Creating Data Types from Other Data Types (ASSWER PART 2)
Custom Collection Classes 
    Creating Classes That Aggregate Collections 
    Creating Collection Classes Using Aggregration 
    Creating Collection Classes Using Inheritance
Summary
Exercises 


#CODE LISTING HERE
Account.py
Circle.py
fuzzybool.py
FuzzyBoolAlt.py
Image.py
Image_ans.py
Shape.py
Shape_ans.py
ShapeAlt.py
ShapeAlt_ans.py
SortedDict.py
SortedList.py 
---
SortedListMeta.py


===============
    Creating Custom Collection Classes Using Inheritance
===============

------ATUL--
#SortedDict.py
>>> import SortedDict

import sortedlist
SortedList = sortedlist

class SortedDict(dict):
------ATUL--

#pg 276
#The SortedDict class shown here attempts to mimic a dict as closely as possible. 
The major difference is that a SortedDict's keys are always ordered based on a specified key '
#function or on the identify function. SortedDict provides the same API as dict (except
#for having a non-eval()-able repr() ), plus two extra methods that make sense only for
#an ordered collection.
#Note that Python 3.1 introduced the
collections.OrderedDict #class which is DIFFERENT from
SortedDict #since it is insertion-ordered rather than key-ordered.

#Here are a few examples of use to give a flavor of how SortedDict works:
d = SortedDict.SortedDict(dict(s=1, A=2, y=6), str.lower)
d["z"] = 4
d["T"] = 5
del d["y"]
d["n"] = 3
d["A"] = 17
str(d)          # returns: "{'A': 17, 'n': 3, 's': 1, 'T': 5, 'z': 4}"
#The SortedDict implementation uses both aggregation and inheritance. The sorted list of
#keys is aggregated as an instance variable, whereas SortedDict class itself inherits
#the dict class. Start code review by looking at the class line and initializer, then 
#look at all of the other methods in turn.

class SortedDict(dict):
    def __init__(self, dictionary=None, key=None, **kwargs):
        dictionary = dicationary or {}
        super().__init__(dictionary)
        if kwargs:
            super().update(kwargs)
        self.__keys = SortedList.SortedList(super().keys(), key)
#The dict base class is specified in the class line.
#The initializer tries to mimic the dict() function but adds a second argument for 
#the key function.
#The super().__init__() call is used to initialize the SortedDict using the base class
dict.__init__() #method. Similarly, if keyword arguments have been used, we use the base class
dict.update() #method to add them to the dictionary. (Note that only one occurrence
#of any keyword argument is accepted, so none of the keys in the kwargs keyword arugments
#can be "dictionary" or "key").
#We keep a copy of all the dictionary's keys in a sorted list stored in the self.__keys
#variable. We pass the dictionary's keys to initialize the sorted list using the base
#class's dict.keys() method --> we must NOT use SortedDict.keys() b/c that relies on the
#self.__keys variable which will exist only AFTER the SortedList of keys has been
#created.

def update(self, dictionary=None, **kwargs):
    if dictionary is None:
        pass
    elif isinstance(dictionary, dict):
        super().update(dictionary)
    else:                                           #NOT A DICT
        for key, value in dictionary.items():
            super().__setitem__(key, value)
    if kwargs:
        super().update(kwargs)
    self.__keys = SortedList.SortedList(super().keys(), self.__keys.key)

#This method is used to update one dictionary's items with another dictionary's
#items, or with keyword arguments, or both. Items which exist only in the other
#dictionary are added to this one, and for items whose keys appear in BOTH
#dictionaries, the other dictionary's value replaces the original value. We have
#had to extend the behavior slightly in that we keep the original dictionary's key
#function, even if the other dictionary is a SortedDict.

#The updating is done in two phases. First we update the dictionary's items. If the
#given dictionary is a dict subclass (which includes SortedDict, of course), we use
#the base class dict.update() to perform the update --using the base class version
#is essential to avoid calling SortedDict.update() recursively and going into an
#infinite loop. If the dictionary is NOT A DICT, we iterate over the dictionary's
#items and set each key-value pair individually. 
#(If the dictionary object is not a dict and does not have an items() method then 
#an AttributeError exception will be quite rightly raised.) 
#If keyword arguments have been used we again call the base class update() method 
#to incorporate them.

#A consequence of the updating is that the 
self.__keys #list becomes out of date, so we replace it with a new SortedList with 
#the dictionary's keys (again obtained from the base class, since the SortedDict.keys() 
#method relies on the self.__keys list which we are in the process of updating), and 
#with the original sorted list's key function.

    @classmethod
    def fromkeys(cls, iterable, value=None, key=None):
        return cls({k: value for k in iterable}, key)

#ATUL - notice that its called 
dict.fromkeys() class method
---> how is it created? CLASSTYPE.METHODNAME() class method

#The dict API includes the dict.fromkeys() class method. This method is used to create
#a new dictionary based on an iterable. Each element in the iterable becomes a key, and
#each key's value is either None or the specified value.
#B/c this is a class method, the first argument is provided automatically by Python
#and is the class (ie cls). For a dict the class will be dict, and for a SortedDict it is
#SortedDict.  The return value is a dictionary of the given class. For example:
ATUL - try this in python interpreter:

            class MyDict(SortedDict.SortedDict): pass
            d = MyDict.fromkeys("VEINS", 3)
            str(d)      # returns: "{'E': 3, 'I': 3, 'N': 3, 'S': 3, 'V': 3}"
            d.__class__.__name__    # returns 'MyDict'

#So when inherited class methods are called, their cls variable is set to the
#correct class, just like when normal methods are called and their self variable
#is set to the current object. This is different from and better than using a static
#method b/c a static method is tied to a paticular class and does not know whether
#it is being executed in the context of its original class or in the context of a subclass.

    def __setitem__(self, key, value):
        if key not in self:
            self.__keys.add(key)
        return super().__setitem__(key, value)

#This method implements the 
d[key] = value #syntax. If the key isnt in the dictionary we add it to the list of
#keys, relying on the SortedList to put it in the right place. Then we call the base 
#class method, and return its result to the caller to support chaining, for example
x = d[key] = value

#Notice that in the if statement we check to see whether the key already exists in the 
#SortedDict by using 
not in self
#B/c SortedDict inherits dict, a SortedDict can be used wherever a dict is expected, and
#in this case, self is in fact a SortedDict. When we implemented dict methods in SortedDict, 
#if we need to call the base class implementation to get it do some of the work for us, 
#we must be careful to call the method using 
super() #as we do in this method's last statement; doing this prevents the reimplementation
#of the method from calling itself and going into infinite recursion.

#We do not reimplement the __getitem__() method since the base class version works fine
#and has no effect on the ordering of the keys.

    def __delitem__(self, key):
        try:
            self.__keys.remove(key)
        except ValueError:
            raise KeyError(key)
        return super().__delitem__(key)

#This method provides the 
del d[key] #syntax. If the key is not present the 
SortedList.remove() #call will raise a ValueError exception. If this occurs we CATCH the 
#exception and raise a KeyError exception INSTEAD so as to match the dict class's API.
#Otherwise, we return the result of calling the base class implementation to delete the
#item with the given key from the dictionary itself.

    def setdefault(self, key, value=None):
        if key not in self:
            self.__keys.add(key)
        return super().setdefault(key, value)

#This method returns the value for the given key if the key is in the dictionary;
#otherwise, it creates a new item with the given key and value and returns the value.
#For the SortedDict we must make sure that the key is added to the keys list if the key
#is not already in the dictionary.

    def pop(self, key, *args):
        if key not in self:
            if len(args) == 0:
                raise KeyError(key)
            return args[0]
        self.__keys.remove(key)
        return super().pop(key, args)

 #If the given key is in the dictionary this method returns the corresponding value
 #and removes the EXISTING key-value item from the dictionary. The key must also be
 #removed from the keys list.

 #The implementation is quite subtle b/c the pop() method must support TWO different
 #behaviors to match dict.pop().  
 #The first is
 d.pop(k) #here the value for key k is returned, or if there is no key k, then a KeyError
 #is raised. 
 #The second is 
 d.pop(k, value) #here the value for key k is returned, or if there is no key k, then
 value #(which could be None) is returned.

     def popitem(self):
        item = super().popitem()
        self.__keys.remove(item[0])
        return item

#The 
dict.popitem() #method removes and returns a random key-value itme form the 
#dictionary. We must call the base class version first since we dont know in
#advance which item will be removed. We remove the item's key from the keys list, 
#and then return the item.

    def clear(self):
        super().clear()
        self.__keys.clear()

#Here we clear all the dictionary's items and all the keys list's items.

    def values(self):
        for key in self.__keys:
            yield self[key]

    def items(self):
        for key in self.__keys:
            yield (key, self[key])

    def __iter__(self):
        return iter(self.__keys)

    keys = __iter__

#Dictionaries have four methods that return iterators:
dict.values() #for the dictionary's values
dict.items() #for the dicationary's key-value items
dict.keys() #for the keys, and the
__iter__() #special method that provides support for the iter(d) syntax, and
#operates on the keys.  (Actually, the base class version of these methods return
#dictionary views, but for most purposes the behavior of the iterators implemented
#here is the same).

#Since the __iter__() method and the keys() method have IDENTICAL behavior, instead
#of implementing keys(), we simply create an object reference called 
keys #and set it to refer to the 
__iter__() #method. With this in place, users of SortedDict can call
d.keys() #or
iter(d) #to get an iterator over a dictionary's keys, just the same as they can call
d.values() #to get an iterator over the dictionary's values.


###################################GRAY BOX#############
Generator Functions

#A generator function or generator method is one which contains a yield expression.
#When a generator function is called it returns an iterator. Values are extracted
#from the iterator one at a time by called its 
__next__() #method. At each call to 
__next__() #the generator function's 
yield #expression's value is returned (None if none is specified). If the generator 
#function finished or executes a 
return #then a 
StopIteration #exception is raised.

#In practice, we rarely call __next__() or catch a StopIteration. Instead, we just
#use a generator like any other iterable. Here are two almost equivalent functions.
#The left returns a list and right returns a generator:

            #Build and return a list
            def letter_range(a, z):
                result = [] 
                while ord(a) < ord(z):
                    result.append(a)
                    a = chr(ord(a) + 1)
                return result 

            #Return each value on demand  #ie returns a generator)
            def letter_range(a, z):
                while ord(a) < ord(z):
                    yield a               #note yield statement is the CLUE HERE
                    a = chr(ord(a) + 1)

#We can iterate over the result produced by either function using a for loop, for example
for letter in letter_range("m", "v"): 
    pass
#But if we want a list of the RESULTANT letters, although calling 
letter_range("m", "v") #is sufficient for the FIRST OR TOP function, 
#but for the for the second OR BOTTOM generator function we must use
list(letter_range("m", "v"))

#Generator functions and methods are covered in Chapter 8
################################################

#continue from above

#pg 281
#The values() and items() methods are generator methods. See GRAY BOX for explanation. 
#In both cases they iterate over the sorted keys list, so they always return 
#iterators that iterate in key order (with the key order depending on the key function 
#given to the initializer). For the items() and values() methods, the values are looked 
#up using d[k] syntax (which uses
dict.__getitem__() #under the hood) since we can treat self as a dict.

    def __repr__(self):
        return object.__repr__(self)

    def __str__(self):
        return ("{" + ", ".join(["{0!r}: {1!r}".format(k,v) for k,v in self.items()]) + "}")

#We cannot provide an eval()-able representation of a SortedDict b/c we can NOT produce
#an eval()-able representation of the key function. So for the 
__repr__() #reimplementation we bypass
dict.__repr__() #and instead call the ULTIMATE base class version
object.__repr__() #.This produces a string of the kind used for non-eval()-able 
#representation, for example, '<SortedDict.SortedDict object at 0xb71fff5c>'

#We have implemented the SortedDict.__str__() method ourselves b/c we want the output
#to show the items in key sorted order. The method could have been written like this instead:
    
    items = []
    for key, value in self.items():
        items.append("{0!r}: {1!r}".format(key, value))
    return "{" + ", ".join(items) + "}"

#Using a list comprehension is shorter and avoids the need for the temporary items variable.

#The base class methods
dict.get()
dict.__getitem__() #for the v = d[k] syntax
dict.__len__() #for len(d), and
dict.__contains__() #for x in d
#all work fine as they are and dont affect the key ordering, so we have not needed
#to reimplement them.

#The last dict method we must reimplement is copy():

    def copy(self):
        d = SortedDict()
        super(SortedDict d).update(self)
        d.__keys = self.__keys.copy()
        return d

#The easiest reimplementation is simply 
def copy(self): return SortedDict(self)
#We have chosen a slightly more complicated solution that avoids re-sorting the already
#sorted keys. We create an empty sorted dictionary, then update it with the items in the
#original sorted dictionary using the base class
dict.update() #to avoid the 
SortedDict.update() #reimplementation and replace the dictionary's 
self.__keys SortedList #with a shallow copy of the original one.

#When super() is called with no arguments it works on the base class and the self
#object. But we can make it work on ANY class and ANY object by passing in a class
#and an object EXPLICITLY. Using this syntax, the super() call works on the immediate
#BASE class it is given, so in this case, the code has the same effect as (and could be
#written as)
dict.updated(d, self)

#In view of the fact that Python's sort algorithm is very fast, and is particulary
#well optimized for PARTIALLY sorted lists the efficiency gain is likely to be
#little or nothing except for HUGE dictionaries. However, the implementation shows
#that at least in principle, a custom copy() method can be more efficient than
#using the
copy_of_x = ClassOfX(x) #idiom that Python's built-in types support. 
#And just as we did for SortedList, we set 
__copy__ = copy #so that the 
copy,copy() #function uses our custom copy method rather than its own code.

    def value_at(self, index):
        return self[self.__keys[index]]

    def set_value_at(self, index, value):
        self[self.__keys[index]] = value

#These two methods represent an extension to the dict API.
#Since UNLIKE a plain dict, a SortedDict is ORDERED, so it follows that the concept of
#key index positions is applicable. For example, the first item in the dictionary is
#at index position 0 and the last at position 
len(d) - 1
#Both of these methods operate on the dictionary item whose key is at the 
index-th #position in the sorted keys list. Thanks to inheritance, we can look up 
#values in the SortedDict using the item access operator [] applied directly to self, since 
self #is a
dict #. If an out-of-range index is given the methods then it raises an IndexError exception.

#We have now COMPLETED the implementation of the SortedDict class! It is not often
#that we need to create a complete generic collection classes like this but when we do,
#Python's special methods allow us to fully integrate our class so that its users
#can treat it like any of the built-in or standard library classes.


-----------1st EFFORT - posted on GitHub
#CODE HERE
SortedDict.py
#!/usr/bin/env python3
#SortedDict.py

"""A dictionary that is sorted by < over its keys or by < over
the result of the key function applied to the keys


>>> import SortedDict

These are tests for inherited methods that aren't reimplemented
>>> d = SortedDict.SortedDict(dict(s=1, A=2, y=6), str.lower)
>>> str(d)
"{'A': 2, 's': 1, 'y': 6}"
>>> d["z"]=4
>>> d["T"]=5
>>> str(d)
"{'A': 2, 's': 1, 'T': 5, 'y': 6, 'z': 4}"
>>> del d['y']
>>> str(d)
"{'A': 2, 's': 1, 'T': 5, 'z': 4}"
>>> d["n"]=3
>>> d["A"]=17
>>> str(d)
"{'A': 17, 'n': 3, 's': 1, 'T': 5, 'z': 4}"
>>> d = SortedDict.SortedDict(dict(s=1, a=2, n=3, i=4, t=5, y=6), str.lower)
>>> str(d)
"{'a': 2, 'i': 4, 'n': 3, 's': 1, 't': 5, 'y': 6}"
>>> d["i"]
4
>>> d["y"]
6
>>> d["z"]
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
KeyError: 'z'
>>> str(d)
"{'a': 2, 'i': 4, 'n': 3, 's': 1, 't': 5, 'y': 6}"
>>> d.get("X", 21)
21
>>> d.get("i")
4
>>> d = SortedDict.SortedDict(dict(s=1, a=2, n=3, i=4, t=5, y=6), str.lower)
>>> "a" in d
True
>>> "x" in d
False
>>> d = SortedDict.SortedDict(dict(s=1, a=2, n=3, i=4, t=5, y=6), str.lower)
>>> len(d)
6
>>> del d["n"]
>>> del d["y"]
>>> len(d)
4
>>> d.clear()
>>> len(d)
0
>>> d = SortedDict.SortedDict(dict(V=1, E=2, I=3, N=4, S=5))
>>> str(d)
"{'E': 2, 'I': 3, 'N': 4, 'S': 5, 'V': 1}"
"""


import sortedlist           #PEP compliant
SortedList = sortedlist     

class SortedDict(dict):

    def __init__(self, dictionary=None, key=None, **kwargs):
        """Initializes with a shallow copy of the given dictionary
        and/or with keyword key=value pairs and preserving order using
        the key function. All keys must be unique.

        key is a key function which defaults to the identity
        function if it is not specified

        >>> d = SortedDict(dict(s=1, a=2, n=3, i=4, t=5, y=6))
        >>> list(d.items())
        [('a', 2), ('i', 4), ('n', 3), ('s', 1), ('t', 5), ('y', 6)]
        >>> dict(SortedDict())
        {}
        >>> e = SortedDict(d)
        >>> list(e.items())
        [('a', 2), ('i', 4), ('n', 3), ('s', 1), ('t', 5), ('y', 6)]
        >>> dict(e)
        {'a': 2, 'i': 4, 's': 1, 't': 5, 'y': 6, 'n': 3}
        >>> f = SortedDict(key=str.lower, S=1, a=2, n=3, I=4, T=5, y=6)
        >>> dict(f)
        {'a': 2, 'I': 4, 'S': 1, 'T': 5, 'y': 6, 'n': 3}
        """
        dictionary = dictionary or {}
        super().__init__(dictionary)
        if kwargs:
            super().update(kwargs)
        self.__keys = SortedList.SortedList(super().keys(), key)


    def update(self, dictionary=None, **kwargs):
        """Updates this dictionary with another dictionary and/or with
        keyword key=value pairs and preserving order using this
        dictionary's key function

        >>> d = SortedDict(dict(s=1, a=2, n=3, i=4, t=5))
        >>> d.update(dict(a=4, z=-4))
        >>> list(d.items())
        [('a', 4), ('i', 4), ('n', 3), ('s', 1), ('t', 5), ('z', -4)]
        >>> del d["a"]
        >>> del d["i"]
        >>> d.update({'g': 9}, a=1, z=3)
        >>> list(d.items())
        [('a', 1), ('g', 9), ('n', 3), ('s', 1), ('t', 5), ('z', 3)]
        >>> e = SortedDict(dict(p=4, q=5))
        >>> del d["a"]
        >>> del d["n"]
        >>> e.update(d)
        >>> list(e.items())
        [('g', 9), ('p', 4), ('q', 5), ('s', 1), ('t', 5), ('z', 3)]
        >>> del d["s"]
        >>> del d["z"]
        >>> d.update(e)
        >>> list(d.items())
        [('g', 9), ('p', 4), ('q', 5), ('s', 1), ('t', 5), ('z', 3)]
        """
        if dictionary is None:
            pass
        elif isinstance(dictionary, dict):
            super().update(dictionary)
        else:
            for key, value in dictionary.items():
                super().__setitem__(key, value)
        if kwargs:
            super().update(kwargs)
        self.__keys = SortedList.SortedList(super().keys(),
                                            self.__keys.key)

    @classmethod
    def fromkeys(cls, iterable, value=None, key=None):
        """A class method that returns a SortedDict whose keys are
        from the iterable and each of whose values is value

        >>> d = SortedDict()
        >>> e = d.fromkeys("KYLIE", 21)
        >>> list(e.items())
        [('E', 21), ('I', 21), ('K', 21), ('L', 21), ('Y', 21)]
        >>> e = SortedDict.fromkeys("KYLIE", 21)
        >>> list(e.items())
        [('E', 21), ('I', 21), ('K', 21), ('L', 21), ('Y', 21)]
        """
        return cls({k: value for k in iterable}, key)


    def value_at(self, index):
        """Returns the index-th item's value

        >>> d = SortedDict(dict(s=1, a=2, n=3, i=4, t=5, y=6))
        >>> d.value_at(0)
        2
        >>> d.value_at(5)
        6
        >>> d.value_at(2)
        3
        >>> d.value_at(19)
        Traceback (most recent call last):
        ...
        IndexError: list index out of range
        """
        return self[self.__keys[index]]


    def set_value_at(self, index, value):
        """Sets the index-th item's value to the given value

        >>> d = SortedDict(dict(s=1, a=2, n=3, i=4, t=5, y=6))
        >>> d.value_at(5)
        6
        >>> d.set_value_at(5, 99)
        >>> d.value_at(5)
        99
        >>> d.set_value_at(19, 42)
        Traceback (most recent call last):
        ...
        IndexError: list index out of range
        """
        self[self.__keys[index]] = value


    def clear(self):
        """Removes every item from this SortedDict
        >>> d = SortedDict(dict(s=1, a=2, n=3, i=4, t=5, y=6))
        >>> len(d)
        6
        >>> d.clear()
        >>> len(d)
        0
        >>> d["m"] = 3
        >>> d["a"] = 5
        >>> d["z"] = 7
        >>> d["e"] = 9
        >>> list(d.keys())
        ['a', 'e', 'm', 'z']
        """
        super().clear()
        self.__keys.clear()


    def setdefault(self, key, value=None):
        """If key is in the dictionary, returns its value;
        otherwise adds the key with the given value which is also
        returned

        >>> d = SortedDict(dict(s=1, a=2, n=3, i=4, t=5, y=6))
        >>> d.setdefault("n", 99)
        3
        >>> list(d.values())
        [2, 4, 3, 1, 5, 6]
        >>> d.setdefault("r", -20)
        -20
        >>> list(d.items())[2:]
        [('n', 3), ('r', -20), ('s', 1), ('t', 5), ('y', 6)]
        >>> d.setdefault("@", -11)
        -11
        >>> d.setdefault("z", 99)
        99
        >>> d.setdefault("m", 50)
        50
        >>> list(d.keys())
        ['@', 'a', 'i', 'm', 'n', 'r', 's', 't', 'y', 'z']
        """
        if key not in self:
            self.__keys.add(key)
        return super().setdefault(key, value)


    def pop(self, key, *args):
        """If key is in the dictionary, returns its value and removes it
        from the dictionary. Otherwise returns arg if specified, or
        raises KeyError if there is no arg.

        >>> d = SortedDict(dict(s=1, a=2, n=3, i=4, t=5, y=6))
        >>> d.pop("n")
        3
        >>> "n" in d
        False
        >>> d.pop("q", 41)
        41
        >>> list(d.keys())
        ['a', 'i', 's', 't', 'y']
        >>> d.pop("a")
        2
        >>> d.pop("t")
        5
        >>> list(d.keys())
        ['i', 's', 'y']
        >>> d.pop("X")
        Traceback (most recent call last):
        ...
        KeyError: 'X'
        >>> d.pop("X", None)
        >>> d.pop("X", 1)
        1
        """
        if key not in self:
            if len(args) == 0:
                raise KeyError(key)
            return args[0]
        self.__keys.remove(key)
        return super().pop(key, args)


    def popitem(self):
        """Returns and removes an arbitrary item from the dictionary

        >>> d = SortedDict(dict(s=1, a=2, n=3, i=4, t=5, y=6))
        >>> len(d)
        6
        >>> item = d.popitem()
        >>> item = d.popitem()
        >>> item = d.popitem()
        >>> len(d)
        3
        """
        item = super().popitem()
        self.__keys.remove(item[0])
        return item


    def values(self):
        """Returns the dictionary's values in key order

        >>> d = SortedDict(dict(s=1, a=2, n=3, i=4, t=5, y=6))
        >>> list(d.values())
        [2, 4, 3, 1, 5, 6]
        """
        for key in self.__keys:
            yield self[key]


    def items(self):
        """Returns the dictionary's items in key order

        >>> d = SortedDict(dict(s=1, a=2, n=3, i=4, t=5, y=6))
        >>> list(d.items())
        [('a', 2), ('i', 4), ('n', 3), ('s', 1), ('t', 5), ('y', 6)]
        """
        for key in self.__keys:
            yield (key, self[key])


    def __iter__(self):
        """Returns an iterator over the dictionary's keys

        >>> d = SortedDict(dict(s=1, a=2, n=3, i=4, t=5, y=6))
        >>> list(d)
        ['a', 'i', 'n', 's', 't', 'y']
        >>> list(d.keys())
        ['a', 'i', 'n', 's', 't', 'y']
        """
        return iter(self.__keys)

    keys = __iter__


    def __delitem__(self, key):
        """Deletes the item with the given key from the dictionary

        >>> d = SortedDict(dict(s=1, a=2, n=3, i=4, t=5, y=6))
        >>> del d["s"]
        >>> del d["y"]
        >>> del d["a"]
        >>> list(d.keys())
        ['i', 'n', 't']
        >>> del d["X"]
        Traceback (most recent call last):
        ...
        KeyError: 'X'
        >>> d = SortedDict(dict(a=1, b=2, z=3))
        >>> list(d.keys())
        ['a', 'b', 'z']
        >>> del d["c"]
        Traceback (most recent call last):
        ...
        KeyError: 'c'
        >>> list(d.keys())
        ['a', 'b', 'z']
        """
        try:
            self.__keys.remove(key)
        except ValueError:
            raise KeyError(key)
        return super().__delitem__(key)


    def __setitem__(self, key, value):
        """If key is in the dictionary, sets its value to value;
        otherwise adds the key to the dictionary with the given value

        >>> d = SortedDict(dict(s=1, a=2, n=3, i=4, t=5, y=6))
        >>> d["t"] = -17
        >>> d["z"] = 43
        >>> d["@"] = -11
        >>> x = d["m"] = 22
        >>> x == 22
        True
        >>> d["r"] = 5
        >>> list(d.keys())
        ['@', 'a', 'i', 'm', 'n', 'r', 's', 't', 'y', 'z']
        """
        if key not in self:
            self.__keys.add(key)
        return super().__setitem__(key, value)


    def __repr__(self):
        return object.__repr__(self)


    def __str__(self):
        return ("{" + ", ".join(["{0!r}: {1!r}".format(k, v)
                                 for k, v in self.items()]) + "}")


    def copy(self):
        """Returns a shallow copy of the dictionary with the same
        key function

        >>> d = SortedDict(dict(V=1, E=2, I=3, N=4, S=5))
        >>> e = d.copy()
        >>> str(e)
        "{'E': 2, 'I': 3, 'N': 4, 'S': 5, 'V': 1}"
        >>> import copy
        >>> f = copy.copy(d)
        >>> str(f)
        "{'E': 2, 'I': 3, 'N': 4, 'S': 5, 'V': 1}"
        """
        d = SortedDict()
        super(SortedDict, d).update(self)
        d.__keys = self.__keys.copy()
        return d

    __copy__ = copy



if __name__ == "__main__":
    import doctest
    doctest.testmod()
-----------1st EFFORT - posted on GitHub












-----------1st EFFORT - posted on GitHub
#CODE HERE
SortedListMeta.py

#!/usr/bin/env python3

""">>> L = SortedList((5, 8, -1, 3, 4, 22))
>>> L[2] = 18 #doctest: +IGNORE_EXCEPTION_DETAIL
Traceback (most recent call last):
...
TypeError: use add() to insert a value and rely on the...
>>> list(L)
[-1, 3, 4, 5, 8, 22]
>>> L.add(5)
>>> L.add(5)
>>> L.add(6)
>>> list(L)
[-1, 3, 4, 5, 5, 5, 6, 8, 22]
>>> L.index(4)
2
>>> L.count(5), L.count(2)
(3, 0)
>>> L.insert(2, 9)
Traceback (most recent call last):
...
AttributeError: 'SortedList' object has no attribute 'insert'
>>> L.reverse()
Traceback (most recent call last):
...
AttributeError: 'SortedList' object has no attribute 'reverse'
>>> L.sort()
Traceback (most recent call last):
...
AttributeError: 'SortedList' object has no attribute 'sort'

>>> import collections
>>> isinstance(L, collections.Sequence)
True
"""

import collections

_identity = lambda x: x

class SortedList:

    def __init__(self, sequence=None, key=None):
        """Creates a SortedList that orders using < on the items,
        or on the results of using the given key function

        >>> L = SortedList()
        >>> print(L)
        []
        >>> L = SortedList((5, 8, -1, 3, 4, 22))
        >>> print(L)
        [-1, 3, 4, 5, 8, 22]
        >>> L = SortedList({9, 8, 7, 6, -1, -2})
        >>> print(L)
        [-2, -1, 6, 7, 8, 9]
        >>> L = SortedList([-5, 4, -3, 8, -2, 16, -1, 0, -3, 8])
        >>> print(L)
        [-5, -3, -3, -2, -1, 0, 4, 8, 8, 16]
        >>> L2 = SortedList(L)
        >>> print(L2)
        [-5, -3, -3, -2, -1, 0, 4, 8, 8, 16]
        >>> L = SortedList(("the", "quick", "brown", "fox", "jumped"))
        >>> print(L)
        ['brown', 'fox', 'jumped', 'quick', 'the']
        """
        self.__key = key or _identity
        assert isinstance(self.__key, collections.Callable)
        if sequence is None:
            self.__list = []
        elif (isinstance(sequence, SortedList) and sequence.key == self.__key):
            self.__list = sequence.__list[:]
        else:
            self.__list = sorted(list(sequence), key=self.__key)


    @property 
    def key(self):
        """Return the key function used by this list
        """
        return self.__key


    def clear(self):
        """Clears the list

        >>> L = SortedList((5, 8, -1, 3, 4, 22))
        >>> print(L)
        [-1, 3, 4, 5, 8, 22]
        >>> L.clear()
        >>> print(L)
        []
        """
        self.__list = []


    def __bisect_left(selft, value):
        """Returns value's key and its index position in the list
        (or where value belongs if it isn't in the list)
        """
        key = self.__key(value)
        left, right = 0, len(self.__list)
        while left < right:
            middle = (left + right) // 2
            if self.__key(self.__list[middle]) < key:
                left = middle + 1
            else:
                right = middle
        return key, left


    def add(self, value):
        """Adds a value to the list (duplicates are allowed)

        >>> L = SortedList((5, 8, -1, 3, 4, 22))
        >>> print(L)
        [-1, 3, 4, 5, 8, 22]
        >>> L.add(5)
        >>> L.add(5)
        >>> L.add(7)
        >>> L.add(-18)
        >>> L.add(99)
        >>> print(L)
        [-18, -1, 3, 4, 5, 5, 5, 7, 8, 22, 99]
        """
        index = self.__bisect_left(value)[1]
        if index == len(self.__list):
            self.__list.append(value)
        else:
            self.__list.insert(index, value)


    def pop(self, index=-1):
        """Removes and returns the item the given index

        >>> L = SortedList([-18, -1, 3, 4, 5, 5, 7, 8, 22, 99])
        >>> print(L)
        [-18, -1, 3, 4, 5, 5, 7, 8, 22, 99]
        >>> L.pop()
        99
        >>> L.pop(0)
        -18
        >>> L.pop(5)
        7
        >>> print(L)
        [-1, 3, 4, 5, 5, 8, 22]
        >>> L.pop(12)
        Traceback (most recent call last):
        ...
        IndexError: pop index out of range
        """
        return self.__list.pop(index)


    def remove(self, value):
        """Removes the first occurrence of value from the list

        >>> L = SortedList([-18, -1, 3, 4, 5, 5, 7, 8, 22, 99])
        >>> print(L)
        [-18, -1, 3, 4, 5, 5, 7, 8, 22, 99]
        >>> L.remove(20)
        Traceback (most recent call last):
        ...
        ValueError: SortedList.remove(x): x not in list
        >>> L.remove(5)
        >>> L.remove(-18)
        >>> L.remove(99)
        >>> print(L)
        [-1, 3, 4, 5, 7, 8, 22]
        >>> L = SortedList(["ABC", "X", "abc", "Abc"], lambda x: x.lower())
        >>> print(L)
        ['ABC', 'abc', 'Abc', 'X']
        >>> L.remove("Abca")
        Traceback (most recent call last):
        ...
        ValueError: SortedList.remove(x): x not in list
        >>> print(L)
        ['ABC', 'abc', 'Abc', 'X']
        >>> L.remove("Abc")
        >>> print(L)
        ['ABC', 'abc', 'X']
        >>> L.remove("ABC")
        >>> print(L)
        ['abc', 'X']
        >>> L.remove("X")
        >>> print(L)
        ['abc']
        >>> L.remove("abc")
        >>> print(L)
        []
        """
        key, index = self.__bisect_left(value)
        while (index < len(self.__list) and self.__key(self.__list[index]) == key):
            if self.__list[index] == value:
                del self.__list[index]
                return
            index += 1
        raise ValueError("{0}. remove(x): x not in list".format(self.__class__.__name__))


    def remove_every(self, value):
        """Removes every occurrence of value from the list

        Returns the number of occurrences removed (which could be 0).
        >>> L = SortedList([5, 5, -18, -1, 3, 4, 5, 5, 7, 8, 22, 99])
        >>> L.add(5)
        >>> L.add(5)
        >>> print(L)
        [-18, -1, 3, 4, 5, 5, 5, 5, 5, 5, 7, 8, 22, 99]
        >>> L.remove_every(-3)
        0
        >>> L.remove_every(7)
        1
        >>> L.remove_every(5)
        6
        >>> print(L)
        [-18, -1, 3, 4, 8, 22, 99]
        >>> L = SortedList(["ABC", "X", "abc", "Abc"], lambda x: x.lower())
        >>> L.remove_every("abc")
        3
        """
        count = 0
        key, index = self.__bisect_left(value)
        while (index < len(self.__list) and self.__key(self.__list[index]) == key):
            del self.__list[index]
            count += 1
        return count 


    def count(self, value):
        """Counts every occurrence of value in the list

        >>> L = SortedList([5, 5, -18, -1, 3, 4, 5, 5, 7, 8, 22, 99])
        >>> L.count(5)
        4
        >>> L.count(99)
        1
        >>> L.count(-17)
        0
        >>> L = SortedList(["ABC", "X", "abc", "Abc"], lambda x: x.lower())
        >>> L.count("abc")
        3
        """
        count = 0
        key, index = self.__bisect_left(value)
        while (index < len(self.__list) and self.__key(self.__list[index]) == key):
            index += 1
            count += 1
        return count


    def index(self, value):
        """Returns the index position of the first occurrence of value

        >>> L = SortedList([5, 5, -18, -1, 3, 4, 7, 8, 22, 99, 2, 1, 3])
        >>> L.index(5)
        7
        >>> L.index(0)
        Traceback (most recent call last):
        ...
        ValueError: SortedList.index(x): x not in list
        >>> L.index(99)
        12
        >>> L = SortedList(["ABC", "X", "abc", "Abc"], lambda x: x.lower())
        >>> print(L)
        ['ABC', 'abc', 'Abc', 'X']
        >>> L.index("x")
        3
        >>> L.index("abc")
        0
        """
        key, index = self.__bisect_left(value)
        if (index < len(self.__list) and self.__key(self.__list[index]) == key):
            return index
        raise ValueError("{0}.index(x): x not in list".format(self.__class__.__name__))


    def __delitem__(self, index):
        """Deletes the value at the given index position

        >>> L = SortedList([9, -5, 3, -7, 8, 14, 0, 8, 3])
        >>> print(L)
        [-7, -5, 0, 3, 3, 8, 8, 9, 14]
        >>> del L[0]
        >>> del L[-1]
        >>> del L[5]
        >>> print(L)
        [-5, 0, 3, 3, 8, 9]
        >>> del L[25]
        Traceback (most recent call last):
        ...
        IndexError: list assignment index out of range
        >>> del L[-3:]
        >>> print(L)
        [-5, 0, 3]
        """
        del self.__list[index]


    def __getitem__(self, index):
        """Returns the value at the given index position

        >>> L = SortedList([9, -5, 3, -7, 8, 14, 0, 8, 3])
        >>> L[0], L[3], L[4], L[-1]
        (-7, 3, 3, 14)
        >>> L[15]
        Traceback (most recent call last):
        ...
        IndexError: list index out of range
        >>> L[:3]
        [-7, -5, 0]
        >>> L[4:8]
        [3, 8, 8, 9]
        """
        return self.__list[index]


    def __setitem__(self, index, value):
        raise TypeError("use add() to insert a value and rely on the list to put it in the right place")


    def __iter__(self):
        """Returns an iterator for the list

        >>> L = SortedList([5, 5, -18, -1, 3, 4, 7, 8, 22, 99, 2, 1, 3])
        >>> result = []
        >>> for x in L:
        ...     result.append(x)
        >>> print(result)
        [-18, -1, 1, 2, 3, 3, 4, 5, 5, 7, 8, 22, 99]
        """
        return iter(self.__list)


    def __reversed__(self):
        """Returns a reverse iterator for the list

        >>> L = SortedList([5, 5, -18, -1, 3, 4, 7, 8, 22, 99, 2, 1, 3])
        >>> result = []
        >>> for x in reversed(L):
        ...     result.append(x)
        >>> print(result)
        [99, 22, 8, 7, 5, 5, 4, 3, 3, 2, 1, -1, -18]
        """
        return reversed(self.__list)


    def __contains__(self, value):
        """Returns True if value is in the list; otherwise returns False

        >>> L = SortedList([5, 5, -18, -1, 3, 4, 7, 8, 22, 99, 2, 1, 3])
        >>> 5 in L
        True
        >>> 0 in L
        False
        >>> 99 in L
        True
        >>> L = SortedList(["ABC", "X", "Abc"], lambda x: x.lower())
        >>> "abc" in L
        True
        >>> "x" in L
        True
        >>> "ZZ" in L
        False
        """
        key, inde = self.__bisect_left(value)
        return (index < len(self.__list) and self.__key(self.__list[index]) == key)


    def __len__(self):
        """Returns the length of the list

        >>> L = SortedList([5, 5, -18, -1, 3, 4, 7, 8, 22, 99, 2, 1, 3])
        >>> len(L)
        13
        >>> L = SortedList()
        >>> len(L)
        0
        """
        return len(self.__list)


    def __str__(self):
        """Returns a human readable string version of the list; the
        result could be very long

        >>> L = SortedList([-1, 3, 4, 7, 8, 22, -9, 2, 1, 3])
        >>> str(L)
        '[-9, -1, 1, 2, 3, 3, 4, 7, 8, 22]'
        >>> L = SortedList()
        >>> str(L)
        '[]'
        >>> L = SortedList(("the", "quick", "brown", "fox", "jumped"))
        >>> str(L)
        "['brown', 'fox', 'jumped', 'quick', 'the']"
        """
        return str(self.__list)


    def copy(self):
        """Returns a shallow copy of the list with the same key function
        >>> L = SortedList([-1, 3, 4, 7, 8, 22, -9, 2, 1, 3])
        >>> m = L.copy()
        >>> str(m)
        '[-9, -1, 1, 2, 3, 3, 4, 7, 8, 22]'
        >>> m[:]
        [-9, -1, 1, 2, 3, 3, 4, 7, 8, 22]
        >>> import copy
        >>> n = copy.copy(L)
        >>> str(n)
        '[-9, -1, 1, 2, 3, 3, 4, 7, 8, 22]'
        """
        return SortedList(self, self.__key)


    __copy__ = copy

collections.Sequence.register(SortedList)


if __name__ == "__main__":
    import doctest
    doctest.testmod()
-----------1st EFFORT - posted on GitHub








#Reminder of topics<===========
CHAPTER 6 OOP - Object Oriented Programming

OO Approach
    OO Concepts and Terminology
Custom Classes
    Attributes and Methods
    Inheritance and Polymorphism
    Using Properties to Control Attribute Access
    Creating Complete and Fully Integrated Data Types
        Creating Data Types from Scratch (ANSWER PART 1)
        Creating Data Types from Other Data Types (ASSWER PART 2)
Custom Collection Classes 
    Creating Classes That Aggregate Collections 
    Creating Collection Classes Using Aggregration 
    Creating Collection Classes Using Inheritance
Summary
Exercises 

#CODE LISTING HERE
Account.py
Circle.py
fuzzybool.py
FuzzyBoolAlt.py
Image.py
Image_ans.py
Shape.py
Shape_ans.py
ShapeAlt.py
ShapeAlt_ans.py
SortedDict.py
SortedList.py 
---
SortedListMeta.py




===============
Summary
===============

#This chapter covered all the fundemantals of Python's support for OOP
#began by showing disadvantages of purely procedural approach and how these could be avoided 
#by using OO. We then described some of the common terminology used in OOP
#including "duplicate" terms such as base class and super class.

#We saw how to create simple classes with data attributes and custom methods.
#We also saw how to inherit classes and add additional data attributes, add additional 
#methods, and how methods can be "unimplemented".Unimplementing is needed when we inherit 
#a class but want to restrict the methods that our subclass provides, but it should be 
#used with care since it breaks the expectation that a subclass can be used whenever one 
#of its base classes can be used --> that is is breaks polymorphism.

#Custom classes can be seamlessly integrated so that they support the same syntaxes
#as Python's built-in and library classes. This is achvieved by implementing special
#methods. We saw how to implement special methods to support comparisons, how to provide
#representational and string forms, and how to provide conversions to other types such as
#int and float WHEN it makes sense to do so. We also saw how to implement the __hash__()
#method to make a custom class's instances usuable as dictionary keys or as members
#of a set.

#Data attributes by themselves provide no mechanism for ensuring that they are set to
#valid values. We saw how easy it is to replace data attributes with properties -- this
#allows us to creat read-only properties, and for writable properties makes it easy
#to provide validation.

#Most of the classes we create are "incomplete" since we tend to provide only the
#methods that we actually need. This works fine in Python, but in addition it is
#possible to create compelete custom classes that provide every relevant method.
#We saw how to do this for single valued classes, both by using aggregation and
#more compactly by using inheritance. We also saw how to do this for
#multivalued (collection) classes. Custom collection classes can provide the 
#same facilities as the built-in collection classes, including support for 
in, len(), iter(), reversed(), and [] #the item access operator.

#We learned that object creation and initialization are separate opertions and that Python
#allows us to control both, although in almost every case we only need to customize
#initialization. We also learned that although it is always safe to return an object's
#immutable data attributes, we should normally only ever return copies of an object's
#MUTABLE data attributes to avoid the object's internal state leaking out and being
#accidently invalidated.
ATUL - need to clarify this in the chapter

#Python provides normal methods, static methods, class methods, and module functions.
#We saw that most methods are normal methods, with class methods being occasionally
#useful. Static methods are rarely used, since class methods or module functions are
#almost always better alternatives.

#The built-in repr() method called an object's __repr__() special method. Where 
#possible, eval(repr(x)) == x, and we saw how to support this. When an eval()-able
#representation string can not be produced we use the base class 
object.__repr__() #method to produce a non-eval()-able representation in a standard format.

#TYPE TESTING using the built-in isinstance() function can provide some efficiency benefits,
#although object-oriented purists would almost certainly avoid its use. Accessing base
#class methods is achieved by calling the built-in super() function, and is essential to
#avoid infinite recurrsion when we need to call a base class method inside a subclass's 
#reimplementation of that method.

#Generator functions and methods do lazy evaluation, returning (via the yield expression)
#each value ONE AT A TIME on request and raising a StopIteration when (and if) they run
#out of values. Generators can be used wherever an iterator is expected, and for 
#finite generators, all their values can be extracted into a tuple or list by passing
#the iterator returned by the generator to tuple() or list().

#The OOP almost invariably simplies code compared with a purely procedural approach.
#With custom classes, we can guarantee that only valid operations are available (since
#we implement only appropriate methods), and that no operation can put an object into
#an invalid state (eg by using poperties to apply validation). Once we start using OO 
#our style of programming is likely to change from being about global data structures
#and the global functions that are applied to the data, to creating classes and implementing
#the methods that are applicable to them. 
ATUL best explanation for OO 
#OO makes it possible to package up data and those methods that make sense for the data. 
#This helps us avoid mixing up all our data and functions together, and makes it easier to 
#produce MAINTAINABLE programs since functionality is kept separated out into indivual classes.




#Reminder of topics<===========
CHAPTER 6 OOP - Object Oriented Programming

OO Approach
    OO Concepts and Terminology
Custom Classes
    Attributes and Methods
    Inheritance and Polymorphism
    Using Properties to Control Attribute Access
    Creating Complete and Fully Integrated Data Types
        Creating Data Types from Scratch (ANSWER PART 1)
        Creating Data Types from Other Data Types (ASSWER PART 2)
Custom Collection Classes 
    Creating Classes That Aggregate Collections 
    Creating Collection Classes Using Aggregration 
    Creating Collection Classes Using Inheritance
Summary
Exercises 

#CODE LISTING HERE
Account.py
Circle.py
fuzzybool.py
FuzzyBoolAlt.py
Image.py
Image_ans.py
Shape.py
Shape_ans.py
ShapeAlt.py
ShapeAlt_ans.py
SortedDict.py
SortedList.py 
---
SortedListMeta.py





===============
Exercises Chapter 6
===============

#Exercises 1 and 2 involve modifying classes we covered in this chapter.
#Excericse 3 and 4 involve creating new classes from scratch.

#1) Modify the Point class (from Shape.py or ShapeAlt.py) to support the
#following opeations where p, q, and r are Points and n is a number:
p = q + r       # Point.__add__()
p += q          # Point.__iadd__()
p = q - r       # Point.__sub__()
p -= q          # Point.__isub__()
p = q * n       # Point.__mul__()
p *= n          # Point.__imul__()
p = q / n       # Point.__truediv__()
p /= n          # Point.__itruediv__()
p = q // n      # Point.__floordiv__()
p //= n         # Point.__ifloordiv__()

#The in-place methods are all four lines long, including the def line, and the other
#methods are each just two lines long, including the def line, and of course they are
#all very similar and quite simple. With a minimal description and a doctest for each
#it add up to around 130 new lines. 
Model solution is Shape_ans.py and ShapeAlt_ans.py


#CODE HERE
Shape.py
#!/usr/bin/env python3

import math

class Point:
    def __init__(self, x=0, y=0):
        self.x = x
        self.y = y 

    def distance_from_origin(self):
        return math.hypth(self.x, self.y)

    def __eq__(self, other):
        return self.x == other.x and self.y == other.y

    def __repr__(self):
        return "Point({0.x!r}, {0.y!r})".format(self)

    def __str__(self):
        return "({0.x!r}, {0.y!r})".format(self)

class Circle(Point):
    def __init__(self, radius, x=0, y=0):
        super().__init__(x, y)
        self.radius = radius

    def edge_distance_from_origin(self):
        return abs(self.distance_from_origin() - self.radius)

    def area(self):
        return math.pi * (self.radius ** 2)

    def circumference(self):
        return 2 * math.pi * self.radius

    def __eq__(self, other):
        return self.radius == other.radius and super().__eq__(other)

    def __repr__(self):
        return "Circle({0.radius!r}, {0.x!r}, {0.y!r})".format(self)

    def __str__(self):
        return repr(self)

if __name__ == "__main__":
    import doctest
    doctest.testmod()





ANSWER
#CODE HERE
Shape_ans.py

-----------1st EFFORT - posted on GitHub
#!/usr/bin/env python3
#Shape_ans.py

import math

class Point:
    def __init__(self, x=0, y=0):
        self.x = x
        self.y = y 

    def distance_from_origin(self):
        return math.hypth(self.x, self.y)

    def __add__(self, other):               #p = q + r  Point.__add__()
        return Point(self.x + other.x, self.y + other.y)

    def __iadd__(self, other):              #p += q  Point.__iadd__()
        self.x += other.x
        self.y += other.y
        return self

    def __sub__(self, other):               #p = q - r  Point.__sub__()
        return Point(self.x - other.x, self.y - other.y)

    def __isub__(self, other):              #p -= q  Point.__isub__()
        self.x -= other.x
        self.y -= other.y
        return self

    def __mul__(self, other):               #p = q * n   Point.__mul__()
        return Point(self.x * other, self.y * other)

    def __imul__(self, other):              #p *= n  Point.__imul__()
        self.x *= other
        self.y *= other
        return self

    def __truediv__(self, other):           #p = q / n  Point.__truediv__()
        return Point(self.x / other, self.y / other)

    def __itruediv__(self, other):   #p /= n   Point.__itruediv__()
        self.x /= other
        self.y /= other
        return self

    def __floordiv__(self, other):          #p = q // n   Point.__floordiv__()
        return Point(self.x // other, self.y // other)

    def __ifloordiv__(self, other):         #p //= n   Point.__ifloordiv__() 
        self.x //= other
        self.y //= other
        return self

    def __eq__(self, other):
        return self.x == other.x and self.y == other.y

    def __repr__(self):
        return "Point({0.x!r}, {0.y!r})".format(self)

    def __str__(self):
        return "({0.x!r}, {0.y!r})".format(self)

class Circle(Point):
    def __init__(self, radius, x=0, y=0):
        super().__init__(x, y)
        self.radius = radius

    def edge_distance_from_origin(self):
        return abs(self.distance_from_origin() - self.radius)

    def area(self):
        return math.pi * (self.radius ** 2)

    def circumference(self):
        return 2 * math.pi * self.radius

    def __eq__(self, other):
        return self.radius == other.radius and super().__eq__(other)

    def __repr__(self):
        return "Circle({0.radius!r}, {0.x!r}, {0.y!r})".format(self)

    def __str__(self):
        return repr(self)

if __name__ == "__main__":
    import doctest
    doctest.testmod()
-----------1st EFFORT - posted on GitHub





#CODE HERE
shape_alt.py

#!/usr/bin/env python3

import math

class Point:
    def __init__(self, x=0, y=0):
        self.x = x
        self.y = y 

    @property                                           #CHANGE HERE
    def distance_from_origin(self):
        return math.hypth(self.x, self.y)

    def __eq__(self, other):
        return self.x == other.x and self.y == other.y

    def __repr__(self):
        return "{0.__class__.__name__}({0.x!r}, {0.y!r})".format(self)   #return "Point({0.x!r}, {0.y!r})".format(self)

    def __str__(self):
        return "({0.x!r}, {0.y!r})".format(self)

class Circle(Point):
    def __init__(self, radius, x=0, y=0):
        super().__init__(x, y)
        self.radius = radius

    @property                                                       #NEW LINE
    def edge_distance_from_origin(self):
        return abs(self.distance_from_origin() - self.radius)       #return abs(self.distance_from_origin() - self.radius)

    @property                                                       #NEW LINE
    def area(self):
        return math.pi * (self.radius ** 2)

    @property                                                       #NEW LINE
    def circumference(self):
        return 2 * math.pi * self.radius

    @property                                                       #NEW LINE
    def radius(self):                                               #NEW LINE
        return self.__radius                                        #NEW LINE

    @raduis.setter                                                  #NEW LINE
    def radius(self, radius):
        assert radius > 0, "radius must be nonzero and non-negative" #NEW LINE
        self.__radius = radius                                      #NEW LINE

    def __eq__(self, other):
        return self.radius == other.radius and super().__eq__(other)

    def __repr__(self):
        return "{0.__class__.__name__}({0.radius!r}, {0.x!r}, {0.y!r})".format(self)    #return "Circle({0.radius!r}, {0.x!r}, {0.y!r})".format(self)

#    def __str__(self):             DELETE THIS LINE
#        return repr(self)          DELETE THIS LINE

if __name__ == "__main__":
    import doctest
    doctest.testmod()



ANSWER
#CODE HERE
-----------1st EFFORT - posted on GitHub
#!/usr/bin/env python3
#shape_alt_ans.py

import math


class Point:
    def __init__(self, x=0, y=0):
        self.x = x
        self.y = y 

    @property                                           #CHANGE HERE
    def distance_from_origin(self):
        return math.hypot(self.x, self.y)

    def __add__(self, other):                           #NEW CODE BLOCK
        return Point(self.x + other.x, self.y + other.y) #NEW CODE BLOCK

    def __iadd__(self, other):                          #NEW CODE BLOCK
        self.x += other.x                               #NEW CODE BLOCK
        self.y += other.y                               #NEW CODE BLOCK
        return self                                     #NEW CODE BLOCK

    def __sub__(self, other):                           #NEW CODE BLOCK
        return Point(self.x - other.x, self.y - other.y) #NEW CODE BLOCK

    def __isub__(self, other):                      #NEW CODE BLOCK
        self.x -= other.x                           #NEW CODE BLOCK
        self.y -= other.y                           #NEW CODE BLOCK

    def __mul__(self, other):                           #NEW CODE BLOCK
        return Point(self.x * other, self.y * other)    #NEW CODE BLOCK

    def __imul__(self, other):          #NEW CODE BLOCK
        self.x *= other                 #NEW CODE BLOCK 
        self.y *= other                 #NEW CODE BLOCK
        return self                     #NEW CODE BLOCK

    def __truediv__(self, other):                       #NEW CODE BLOCK
        return Point(self.x / other, self.y / other)    #NEW CODE BLOCK

    def __itruediv__(self, other):                      #NEW CODE BLOCK
        return Point(self.x / other, self.y / other)    #NEW CODE BLOCK

    def __floordiv__(self, other):                      #NEW CODE BLOCK
        return Point(self.x // other, self.y // other)  #NEW CODE BLOCK

    def __ifloordiv__(self, other):         #NEW CODE BLOCK
        self.x //= other                    #NEW CODE BLOCK
        self.y //= other                    #NEW CODE BLOCK
        returns self                        #NEW CODE BLOCK

    def __eq__(self, other):
        return self.x == other.x and self.y == other.y

    def __repr__(self):
        return "{0.__class__.__name__}({0.x!r}, {0.y!r})".format(self)   #return "Point({0.x!r}, {0.y!r})".format(self)

    def __str__(self):
        return "({0.x!r}, {0.y!r})".format(self)

class Circle(Point):
    def __init__(self, radius, x=0, y=0):
        super().__init__(x, y)
        self.radius = radius

    @property                                                     
    def edge_distance_from_origin(self):
        return abs(self.distance_from_origin() - self.radius)

    @property                                                 
    def area(self):
        return math.pi * (self.radius ** 2)

    @property                                                 
    def circumference(self):
        return 2 * math.pi * self.radius

    @property                                            
    def radius(self):                                        
        return self.__radius                             

    @raduis.setter                                          
    def radius(self, radius):
        assert radius > 0, "radius must be nonzero and non-negative"
        self.__radius = radius                            

    def __eq__(self, other):
        return self.radius == other.radius and super().__eq__(other)

    def __repr__(self):
        return "{0.__class__.__name__}({0.radius!r}, {0.x!r}, {0.y!r})".format(self) 


if __name__ == "__main__":
    import doctest
    doctest.testmod()
-----------1st EFFORT - posted on GitHub







#2) Modify the Image.py class to provide a
resize(width, height) #method. If the new width or height is smaller than the current 
#value, any colors outside the new boundaries must be deleted. If either width or 
#height is None then use the existing width or height. At the end, make sure
#you regenerate the
self.__colors #set. Return a Boolean to indicate whether a change was made or not.
#The method can be implemented in fewer than 20 lines (fewer) than 35 including a
#docstring with a simple doctest.) Solution is Image_ans.py


#CODE HERE
image.py
-----------1st EFFORT - posted on GitHub
#!/usr/bin/env python3
#image.py

import os
import pickle

USE_GETATTR = False


class ImageError(Exception): pass
class CoordinateError(ImageError): pass
class LoadError(ImageError): pass
class SaveError(ImageError): pass
class ExportError(ImageError): pass
class NoFilenameError(ImageError): pass


class Image:
    def __init__(self, width, height, filename="", background="#FFFFFF"):
        self.filename = filename
        self.__background = background
        self.__data = {}
        self.__width = width
        self.__height = height
        self.__colors = {self.__background}

    if USE_GETATTR:
        def __getattr__(self, name):
            if name == "colors":
                return set(self.__colors)
            classname = self.__class__.__name__
            if name in frozenset({"background", "width", "height"}):
                return self.__dict__["_{classname}__{name}".format(**locals())]
            raise AttributeError("'{classname}' object has no attribute '{name}'".format(**locals()))
    else:
        @property
        def background(self):
            return self.__background

        @property 
        def width(self):
            return self.__width

        @property 
        def height(self):
            return self.__width 

        @property 
        def colors(self):
            return set(self.__colors)


    def __getitem__(self, coordinate):
        assert len(coordinate) == 2, "coordinate should be a 2-tuple"
        if (not (0 <= coordinate[0] < self.width) or 
            not (0 <= coordinate[1] < self.height)):
            raise CoordinateError(str(coordinate))
        return self.__data.get(tuple(coordinate), self.__background)


    def __setitem__(self, coordinate, color):
        assert len(coordinate) == 2, "coordinate should be a 2-tuple"
        if (not (0 <= coordinate[0] < self.width) or 
            not (0 <= coordinate[1] < self.height)):
            raise CoordinateError(str(coordinate))
        if color == self.__background:
            self.__data.pop(tuple(coordinate), None)
        else:
            self._data[tuple(coordinate)] = color 
            self.__colors.add(color)


    def __delitem__(self, coordinate):
        assert len(coordinate) == 2, "coordinate should be a 2-tuple"
        if (not (0 <= coordinate[0] < self.width) or 
            not (0 <= coordinate[1] < self.height)):
            raise CoordinateError(str(coordinate))
        self.__data.pop(tuple(coordinate), None)


    def save(self, filename=None):
        if filename is not None:
            self.filename = filename
        if not self.filename:
            raise NoFilenameError()

        fh = None
        try:
            data = [self.width, self.height, self.__background, self.__data]
            fh = open(self.filename, "wb")
            pickle.dump(data, fh, pickle.HIGHEST_PROTOCOL)
        except (EnvironmentError, pickle.PicklingError) as err:
            raise SaveError(str(err))
        finally:
            if fh is not None:
                fh.close()


    def load(self, filename=None):
        if filename is not None:
            self.filename = filename
        if not self.filename:
            raise NoFilenameError()

        fh = None 
        try:
            fh = open(self.filename, "rb")
            data = pickle.load(fh)
            (self.__width, self.__height, self.__background, self.__data) = data
            self.__colors = (set(self.__data.values)) | {self.__background}
        except (EnvironmentError, pickle.UnpicklingError) as err:
            raise LoadError(str(err))
        finally:
            if fh is not None
            fh.close()


    def export(self, filename):
        if filename.lower().endswith(".xpm"):
            self.__export_xpm(filename)
        else:
            raise ExportError ("unsupported export format: " + os.path.splitext(filename)[1])


    def __export_xpm(self, filename):
        name = os.path.splitext(os.path.basename(filename))[0]
        count = len(self.__colors)
        chars = [chr(x) for x in range(32, 127) if chr(x) != '"']
        if count > len(chars):
            chars = []
            for x in range(32, 127):
                if chr(x) == '"':
                    continue
                for y in range(32, 127):
                    if chr(y) == '"':
                        continue
                    chars.append(chr(x) + chr(y))
        chars.reverse()
        if count > len(chars):
            raise ExportError("cannot export XPM: too many colors")
        fh = None
        try:
            fh = open(filename, "w", encoding="ascii")
            fh.write("/* XPM */\n")
            fh.write("static char *{0}[] = {{\n".format(name))
            fh.write("/* columsn rows colors chars-per-pixel */\n")
            fh.write('"{0.width} {0.height} {1} {2}",\n'.format(self, count, len(chars[0])))
            char_for_color = {}
            for color in self.__colors:
                char = chars.pop()
                fh.write(' "{char} c {color}",\n'.format(**locals()))
                char_for_color[color] = char
            fh.write("/* pixels */\n")
            for y in range(self.height):
                row = []
                for x in range(self.width):
                    color = self.__data.get((x, y), self.__background)
                    row.append(char_for_colour[color])
                fh.write('"{0}",\n'.format("".join(row)))
            fh.write("};\n")
        except EnvironmentError as err:
            raise ExportError(str(err))
        finally:
            if fh is not None:
                fh.close()


if __name__ == "__main__":
    import doctest
    doctest.testmod()
-----------1st EFFORT - posted on GitHub 




Modify the Image.py class to provide a
resize(width, height) #method. If the new width or height is smaller than the current 
#value, any colors outside the new boundaries must be deleted. If either width or 
#height is None then use the existing width or height. At the end, make sure
#you regenerate the
self.__colors #set. Return a Boolean to indicate whether a change was made or not.
#The method can be implemented in fewer than 20 lines (fewer) than 35 including a
#docstring with a simple doctest.) Solution is Image_ans.py

ANSWER
#DETAIL
Image_ans.py

-----------1st EFFORT - posted on GitHub 
#!/usr/bin/env python3
#image_ans.py
#modified Image class from image.py to provide resize(width, height) method.

import os
import pickle

USE_GETATTR = False


class ImageError(Exception): pass
class CoordinateError(ImageError): pass
class LoadError(ImageError): pass
class SaveError(ImageError): pass
class ExportError(ImageError): pass
class NoFilenameError(ImageError): pass


class Image:
    def __init__(self, width, height, filename="", background="#FFFFFF"):
        self.filename = filename
        self.__background = background
        self.__data = {}
        self.__width = width
        self.__height = height
        self.__colors = {self.__background}

    if USE_GETATTR:
        def __getattr__(self, name):
            if name == "colors":
                return set(self.__colors)
            classname = self.__class__.__name__
            if name in frozenset({"background", "width", "height"}):
                return self.__dict__["_{classname}__{name}".format(**locals())]
            raise AttributeError("'{classname}' object has no attribute '{name}'".format(**locals()))
    else:
        @property
        def background(self):
            return self.__background

        @property 
        def width(self):
            return self.__width

        @property 
        def height(self):
            return self.__width 

        @property 
        def colors(self):
            return set(self.__colors)


    def __getitem__(self, coordinate):
        assert len(coordinate) == 2, "coordinate should be a 2-tuple"
        if (not (0 <= coordinate[0] < self.width) or 
            not (0 <= coordinate[1] < self.height)):
            raise CoordinateError(str(coordinate))
        return self.__data.get(tuple(coordinate), self.__background)


    def __setitem__(self, coordinate, color):
        assert len(coordinate) == 2, "coordinate should be a 2-tuple"
        if (not (0 <= coordinate[0] < self.width) or 
            not (0 <= coordinate[1] < self.height)):
            raise CoordinateError(str(coordinate))
        if color == self.__background:
            self.__data.pop(tuple(coordinate), None)
        else:
            self._data[tuple(coordinate)] = color 
            self.__colors.add(color)


    def __delitem__(self, coordinate):
        assert len(coordinate) == 2, "coordinate should be a 2-tuple"
        if (not (0 <= coordinate[0] < self.width) or 
            not (0 <= coordinate[1] < self.height)):
            raise CoordinateError(str(coordinate))
        self.__data.pop(tuple(coordinate), None)


    def resize(self, width=None, height=None):                      #NEW BLOCK
        if width is None and height is None:
            return False
        if width is None:
            width = self.width
        if height is None:
            height = self.height
        if width >= self.width and height >= self.height:
            self.__width = width
            self.__height = height
            return True
        self.__width = width
        self.__height = height
        for x, y in list(self.__data.keys()):
            if x >= self.width or y >= self.height:
                del self.__data[(x,y)]
        self.__colors = set(self.__data.values()) | {self.__background}
        return True


    def save(self, filename=None):
        if filename is not None:
            self.filename = filename
        if not self.filename:
            raise NoFilenameError()

        fh = None
        try:
            data = [self.width, self.height, self.__background, self.__data]
            fh = open(self.filename, "wb")
            pickle.dump(data, fh, pickle.HIGHEST_PROTOCOL)
        except (EnvironmentError, pickle.PicklingError) as err:
            raise SaveError(str(err))
        finally:
            if fh is not None:
                fh.close()

    def load(self, filename=None):
        if filename is not None:
            self.filename = filename
        if not self.filename:
            raise NoFilenameError()

        fh = None 
        try:
            fh = open(self.filename, "rb")
            data = pickle.load(fh)
            (self.__width, self.__height, self.__background, self.__data) = data
            self.__colors = (set(self.__data.values)) | {self.__background}
        except (EnvironmentError, pickle.UnpicklingError) as err:
            raise LoadError(str(err))
        finally:
            if fh is not None
            fh.close()

    def export(self, filename):
        if filename.lower().endswith(".xpm"):
            self.__export_xpm(filename)
        else:
            raise ExportError ("unsupported export format: " + os.path.splitext(filename)[1])

    def __export_xpm(self, filename):
        name = os.path.splitext(os.path.basename(filename))[0]
        count = len(self.__colors)
        chars = [chr(x) for x in range(32, 127) if chr(x) != '"']
        if count > len(chars):
            chars = []
            for x in range(32, 127):
                if chr(x) == '"':
                    continue
                for y in range(32, 127):
                    if chr(y) == '"':
                        continue
                    chars.append(chr(x) + chr(y))
        chars.reverse()
        if count > len(chars):
            raise ExportError("cannot export XPM: too many colors")
        fh = None
        try:
            fh = open(filename, "w", encoding="ascii")
            fh.write("/* XPM */\n")
            fh.write("static char *{0}[] = {{\n".format(name))
            fh.write("/* columns rows colors chars-per-pixel */\n")
            fh.write('"{0.width} {0.height} {1} {2}",\n'.format(self, count, len(chars[0])))
            char_for_colour = {}
            for color in self.__colors:
                char = chars.pop()
                fh.write(' "{char} c {color}",\n'.format(**locals()))
                char_for_colour[color] = char
            fh.write("/* pixels */\n")
            for y in range(self.height):
                row = []
                for x in range(self.width):
                    color = self.__data.get((x, y), self.__background)
                    row.append(char_for_colour[color])
                fh.write('"{0}",\n'.format("".join(row)))
            fh.write("};\n")
        except EnvironmentError as err:
            raise ExportError(str(err))
        finally:
            if fh is not None:
                fh.close()

if __name__ == "__main__":
    import doctest
    doctest.testmod()
-----------1st EFFORT - posted on GitHub 





#3) Implement a Transaction class that takes an amount, a date, a currency (default is USD),
#a USD conversion rate (default is 1), an a description (default None). All of the data
#attributes must be private. Provide the following read-only properties:
amount, date, currency, usd_conversion_rate, description, usd #where in
#usd = calculated from amount * usd_conversion_rate
#This class can be implemented in about 60 lines including simple doctests.
#Model solution is Account.py


ANSWER
#DETAIL

#CODE HERE
account.py


-----------1st EFFORT - posted on GitHub 
#!/usr/bin/env python3
#account.py
#Implement a Transaction class that takes an amount, a date, a currency (default USD),
#a USD conversion rate (default is 1), an a description (default None). All of the data
#attributes must be private. Provide the following read-only properties:
#amount, date, currency, usd_conversion_rate, description, usd


import pickle


"""
>>> t = Transaction(100, "2008-12-09")
>>> t.amount, t.currency, t.usd_conversion_rate, t.usd
(100, 'USD', 1, 100)
>>> t = Transaction(250, "2009-03-12", "EUR", 1.53)
>>> t.amount, t.currency, t.usd_conversion_rate, t.usd
(250, 'EUR', 1.53, 382.5)
"""


class Transaction:

    def __init__(self, amount, date, currency="USD", usd_conversion_rate=1, description=None):
        self.__amount = amount
        self.__date = date
        self.__description = description
        self.__currency = currency
        self.__usd_conversion_rate = usd_conversion_rate


    @property
    def amount(self):
        return self.__amount


    @property 
    def date(self):
        return self.__date 


    @property 
    def description(self):
        return self.__description


    @property
    def currency(self):
        return self.__currency


    @property 
    def usd_conversion_rate(self):
        return self.__usd_conversion_rate


    @property 
    def usd(self):
        return self.__amount * self.__usd_conversion_rate


class Account:

    """
    >>> import os
    >>> import tempfile
    >>> name = os.path.join(tempfile.gettempdir(), "account01")
    >>> account = Account(name, "Qtrac Ltd.")
    >>> os.path.basename(account.number), account.name,
    ('account01', 'Qtrac Ltd.')
    >>> account.balance, account.all_usd, len(account)
    (0.0, True, 0)
    >>> account.apply(Transaction(100, "2008-11-14"))
    >>> account.apply(Transaction(150, "2008-12-09"))
    >>> account.apply(Transaction(-95, "2009-01-22"))
    >>> account.balance, account.all_usd, len(account)
    (155.0, True, 3)
    >>> account.apply(Transaction(50, "2008-12-09", "EUR", 1.53))
    >>> account.balance, account.all_usd, len(account)
    (231.5, False, 4)
    >>> account.save()
    >>> newaccount = Account(name, "Qtrac Ltd.")
    >>> newaccount.balance, newaccount.all_usd, len(newaccount)
    (0.0, True, 0)
    >>> newaccount.load()
    >>> newaccount.balance, newaccount.all_usd, len(newaccount)
    (231.5, False, 4)
    >>> try:
    ...     os.remove(name + ".acc")
    ... except EnvironmentError:
    ...     pass
    """


    def __init__(self, number, name):
        self.__number = number 
        self.__name = name 
        self.__transactions = []


    @property 
    def number(self):
        "The read-only account number"
        return self.__number


    @property 
    def name(self):
        return self.__name 


    @name.setter 
    def name(self, name):
        assert len(name) > 3, "account name must be at least 4 characters"
        self.__name = name


    def __len__(self):
        "Returns the number of transactions"
        return len(self.__transactions)


    def apply(self, transaction):
        "Applies (adds) the given transaction to the account"
        self.__transactions.append(transaction)


    @property 
    def balance(self):
        "Returns the balance in USD"
        total = 0.0
        for transaction in self.__transactions:
            total += transaction.usd 
        return total


    @property 
    def all_usd(self):
        "Returns True if all transactions are in USD"
        for transaction in self.__transactions:
            if transaction.currency != "USD":
                return False
        return True 


    def save(self):
        "Saves the account's data in file number.acc"
        fh = None
        try:
            data = [self.number, self.name, self.__transactions]
            fh = open(self.number + ".acc", "wb")
            pickle.dump(data, fh, pickle.HIGHEST_PROTOCOL)
        except (EnvironmentError,pickle.PicklingError) as err:
            raise SaveError(str(err))
        finally:
            if fh is not None:
                fh.close()


    def load(self):
        fh = None
        try:
            fh = open(self.number + ".acc", "rb")
            data = pickle.load(fh)
            assert self.number == data[0], "account number doesnt match"
            self.__name, self.__transactions = data[1:]
        except (EnvironmentError, pickle.UnpicklingError) as err:
            raise LaodError(str(err))
        finally:
            if fh is not None:
                fh.close()


if __name__ == "__main__":
    import doctest
    doctest.testmod()
-----------1st EFFORT - posted on GitHub 





#4) Implement an Account class that holds an account number, an account name, and a
#list of 
Transactions #The number should be a read-only property; the name should be a read-write
#propety with an assertion to ensure that the name is at least four characters long. The 
#class should support the built-in len() function (returning the number of transactions), 
#and should provide two calculated read-only properties:
balance #which should return the account's balance in USD and
all_usd #whcih should return True if all the transactions are in USD and False otherwise.
#Three other methods should be provided:
apply() #to apply (add) a transaction
save()
load() #The save() and load() methods shold use a binary pickle with the filename
#being the account number with extension
.acc #they should save and load the account number, the name, and all the transactions.
#This class can be implemented in about 90 lines with some simple doctests that include
#saving and laoding -- use code such as 
name = os.path.join(tempfile.gettempdir(), account_name) #to provide a suitable
#temporary filename, and make sure you delete the temporary file after the tests
#have finished. 
#Model solution is in file Account.py

ANSWER - see prior exercise question









#Reminder of topics<===========
===============================================================================================
CHAPTER: 7 File Handling
CHAPTER BEGIN
===============================================================================================

Writing and Reading Binary Data
    Pickles with Optional Compression
    Raw Binary Data with Optional Compression 
Writing and Parsing Text Files
    Writing Text
    Parsing Text 
    Parsing Text Using Regular Expressions
Writing and Parsing XML Files 
    Element Trees 
    DOM (Document Object Model)
    Manually Writing XML 
    Parsing XML with SAX (Simple API for XML)
Random Access Binary Files 
    Generic BinaryRecordFile Class 
    Example: BikeStock Module's Classes     '
Summary
Exercises 
#1) 
#2)
#3)

#CODE LISTING HERE
BikeStock.py
BikeStock_ans.py
BinaryRecordFile.py
BinaryRecordFile_ans.py
convert-incidents.py
xdump.py 




===============
CHAPTER 7 File Handling
===============
#Most programs need to save and load info, such as data or state information, to and from files.
#We discussed Python ways to do this in Chapter 3 (handling text files) and Chapter 6 (pickles).
#Here we dive into it. All techniques in this book are platform independent so example programs
#on one operating system/processor architecture combination can be loaded by the same program
#on a machine with different operating system/process architectur combination.

#First 3 sections cover common case of saving and loading an entire data collection to and
#from disk. First section shows how to do this using binary file formats (with one subsection 
#using optionally compressed pickles) and the other subsection showing how to do it manually.
#Second section shows how to handle the text files. Writing text is easy, but reading it back
#can be tricky if we need to handle nontextual data, such as numbers and dates. We show two
#approaches to parsing text, doing manualy and using regular expressions. Third section shows
#how to read and write XML files. This section covers writing and parsing using element
#trees, writing and parsing using the DOM, and writing manually and parsing using SAX (Simple
#API for XML).
#The fourth section shows how to handle random access binary files. This is useful when each
#data item is the same size and where we have more items than we want in (or fit into) memory.

#Which is the best file format to use for holding entire collections? binary, text, or XML?
#Which is the best way to handle each format? These questions are too context depenedent
#to have a single definitive answer, especially since there are pros and cons for each
#format and for each way of handling then. We show all of them to help you make
#an informed decision on a case-by-case basis.

#Binary formats are very fast to save and load, very compact, does not need parsing 
#since each data type is stored using its natural representation,
#is not human readable or editable, and without knowing the format can be tricky to parse
#and it not always easy to give good error messages if a text's file format is broken
#ie by careless editing.

#XML format 
#are human readable and editable, but may be verbose and create large files.
#Like text format, XML formats can be processed using separate tools. Parsing XML is
#straighforward (assuming we use a XML parser rather than doing it manually) and some 
#parsers have good error reporting. XML parsers can be slow, so reading very large XML 
#files can take more time than reading en equivalent binary or text file. XML includes
#metadata such as the character encoding (either implicitly or explicitly) that is not
#often provided in text files. This can make XML more portable than text files.

#Text format
#usually most convenient for end users. but sometimes performance issues are such that a
#binary format is the only reasonable choice. However, it is always useful to provide
#import/export for XML since this makes it possible to process the file format with 
#third party tools without preventing the most optimal text or binary format being 
#used by the program for normal processing.

################################################ Figure 7.1
Name                            Data Type           Notes

report_id                       str                 minimum length 8 and no whitespace
date                            datetime.date   
airport                         str                 Nonempty and no newlines
aircraft_id                     str                 Nonempty and no newlines
aircraft_type                   str                 Nonempty and no newlines
pilot_percent_hours_on_type     float               Range 0.0 to 100.0
pilot_total_hours               int                 Positive and nonzero
midair                          bool 
narrative                       str                 Multiline                            
################################################


################################################ Figure 7.2
File Handling

Format          Reader/Writer               Reader+Writer   Total           Output File 
                                            Lines of Code   Lines of Code   Size (~KB)
Binary          Pickle (gzip compressed)    20 + 16       = 36              160
Binary          Pickle                      20 + 16       = 36              416
Binary          Manual (gzip compressed)    60 + 34       = 94              132
Binary          Manual                      60 + 34       = 94              356
Plain text      Regex reader/manual writer  39 + 28       = 67              436
Plain text      Manual                      53 + 28       = 81              436
XML             Element Tree                37 + 27       = 64              460
XML             DOM                         44 + 36       = 80              460
XML             SAX reader/manual writer    56 + 37       = 92              464
################################################

#This chapter's first three sections all use same data collection: set of aircraft
#incident records. See Figure 7.1 for data elements.
#It really does NOT matter what type of data we are processing, the IMPORTANT thing
#to know is that we LEARN TO process fundamental data types: strings, integers, 
#floating point numbers, Booleans, and dates, b/c if we can handle these, we can also
#handle any other kinds of data.

#By using the same set of aircraft incident data for binary, text and XML formats, it makes
#it possible to compare and contrast the different formats and the code needed for 
#handling them. See Figure 7.2 for the number of lines of code for reading and writing
#each format, and the totals.
#The file sizes are approximate and based on a particular sample of 596 aircraft incident
#records --> see www.FAA.gov. Compressed binary file sizes for the same data saved under
#different filenames may vary by a fwe bytes since the filename is included in the
#compressed data and filename lengths vary. Similarly, the XML file sizes vary slightly
#since some XML writes use entities (&quot; for " and &apos; for ') for quotes inside
#text data while other write formats dont.

#The first three sections all quote code form the SAME program
convert-incidents.py
#This program is used to read aircraft incident data in one format and to write it in
#ANOTHER format. Here is the program's console help text:

Usage: convert-incidents.py [options] infile outfile
 
Reads aircraft incident data from infile and writes the data to
outfile. The data formats used depend on the file extensions:
.aix is XML, .ait is text (UTF-8 encoding), .aib is binary,
.aip is pickle, and .html is HTML (only allowed for the outfile).
All formats are platform-independent.

Options:
  -h, --help          show this help message and exit
  -f, --force         write the outfile even if it exists [default: off]
  -v, --verbose       report results [default: off]
  -r READER, --reader=READER
                      reader (XML): 'dom', 'd', 'etree', 'e', 'sax', 's'
                      reader (text): 'manual', 'm', 'regex', 'r' [default: etree for XML, manual for text]
  -w WRITER, --writer=WRITER
                      writer (XML): 'dom', 'd', 'etree', 'e', 'manual', 'm' [default: manual]
  -z, --compress      compress .aib/.aip outfile [default: off]
  -t, --test          execute doctests and exit (use with -v for verbose)

#these options are more complex than would normally be required since an end-suer will
#not care which reader or writer we use for any paticular format. In a more realistic
#version of the program, the reader and writer options would not exist and we would 
#implement just one reader and one writer for each format. Similarly, the test option 
#exists to help us test the code and would not be present in a production version.

#The program defines one custom exception:
    
class IncidentError(Exception): pass

#Aircraft incidents are held as Incident objects. Here is the class line and initializer

class Incident:
    def __init(self, report_id, date, airport, aircraft_id, aircraft_type,
               pilot_percent_hours_on_type, pilot_total_hours, midair, narrative=""):
        assert len(report_id) >= 8 and len(report_id.split()) == 1, "invalid report ID"
        self.__report_id = report_id
        self.date = date
        self.airport = airport
        self.aircraft_id = aircraft_id 
        self.aircraft_type = aircraft_type
        self.pilot_percent_hours_on_type = pilot_percent_hours_on_type
        self.pilot_total_hours = pilot_total_hours
        self.midair = midair
        self.narrative = narrative

ATUL - note that this line can be written in two different ways

            assert len(report_id) >= 8 and len(report_id.split()) == 1, "invalid report ID"

            or

            assert len(report_id) >= 8 and len(report_id.split()) == 1, \
                    "invalid report ID"

#The report ID is validated when the Incident is created and is available as the read-only
#report_id property. All other data attributes are read/write properties. For example, here is
#the date property's code:

    @property 
    def date(self):
        return self.__date

    @date_setter
    def date(self, date):
        assert isinstance(date, datetime.date), "invalide date"
        self.__date = date 

#All other properties follow the SAME PATTERN, differing only in the details of their
#assertions, so we WONT reproduce them here.
#ATUL GET THESE --> from author code website #DONE
#Since we have used assertions, the program will fail if an attempt is made to create an 
#Incident with invalid data, or to set one of an existing incident's read/write properties
#to an invalid value. We have chosen this uncompromising approach b/c we want to be sure
#that the data we save and load is ALWAYS valid, and if it is not, we want the program
#to terminate and COMPLAIN rather than silently continue.

#The collection of incidents is held as an
IncidentCollection
#This class is a dict subclass, so we a lot of functionality, such as support for the
#item access operator [] to get, set, and delete incidents, by inheritance. Here is the
#class line and few of the class's methods:

class IncidentCollection(dict):

    def values(self):
        for report_id in self.keys():
            yield self[report_id]

    def items(self):
        for report_id in self.keys():
            yield (report_id, self[report_id])

    def __iter__(self):
        for report_id in sorted(super().keys()):
            yield report_id

    keys = __iter__

ATUL - verify this: We have not needed to reimplement the initializer 
since dict.__init__() is sufficient. pg 291
#The keys are report IDs and the values are Incidents. We have reimplemented the values(),
#items(), and keys() methods so that their iterators work in report ID order. This works
#b/c the values() and items() methods iterate over the keys returned by 
IncidentCollection.keys() #and this method (which is just another name for
IncidentCollection.__iter__()     #), iterates in sorted order over the keys provided by
#the based class dict.keys() method.

#In addition, the IncidentCollection class has export() and import_() methods.
#(We use trailing underscore to distinguish the method from the built-in import statement.)
#The export() method is passed a filename, and optionally a writer and compress flag, and based
#on the filename and writer, it hands off the work to a more specific method such as
export_xml_dom() #or
export_xml_etree()
#The import_() method takes a filename and an optional reader and works similarly. The import
#methods that read binary formats are not told whether the file is compressed -- they are
#expected to work this out for themselves and bahve properly.

#ATUL - I included this entire module here just as an example to review
#as the chapter gets STARTED. More explanation to come belwo! READ ON!
#OK DONE

#!/usr/bin/env python3
#convert-incidents.py
#!/usr/bin/env python3
# Copyright (c) 2008-11 Qtrac Ltd. All rights reserved.
# This program or module is free software: you can redistribute it and/or
# modify it under the terms of the GNU General Public License as published
# by the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version. It is provided for educational
# purposes and is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
# General Public License for more details.

import locale
locale.setlocale(locale.LC_ALL, "")

import datetime
import gzip
import optparse
import os
import pickle
import re
import struct
import sys
import textwrap
import xml.dom.minidom
import xml.etree.ElementTree
import xml.parsers.expat
import xml.sax
import xml.sax.saxutils

USE_RESTRICTIVE_P_FORMAT = False
USE_LONG_WINDED_IMPORT_FUNCTION = False

MAGIC = b"AIB\x00"
FORMAT_VERSION = b"\x00\x01"
GZIP_MAGIC = b"\x1F\x8B"

NumbersStruct = struct.Struct("<Idi?")


class IncidentError(Exception): pass


class IncidentSaxHandler(xml.sax.handler.ContentHandler):

    def __init__(self, incidents):
        super().__init__()
        self.__data = {}
        self.__text = ""
        self.__incidents = incidents
        self.__incidents.clear()


    def startElement(self, name, attributes):
        if name == "incident":
            self.__data = {}
            for key, value in attributes.items():
                if key == "date":
                    self.__data[key] = datetime.datetime.strptime(
                                            value, "%Y-%m-%d").date()
                elif key == "pilot_percent_hours_on_type":
                    self.__data[key] = float(value)
                elif key == "pilot_total_hours":
                    self.__data[key] = int(value)
                elif key == "midair":
                    self.__data[key] = bool(int(value))
                else:
                    self.__data[key] = value
        self.__text = ""


    def endElement(self, name):
        if name == "incident":
            if len(self.__data) != 9:
                raise IncidentError("missing data")
            incident = Incident(**self.__data)
            self.__incidents[incident.report_id] = incident
        elif name in frozenset({"airport", "narrative"}):
            self.__data[name] = self.__text.strip()
        self.__text = ""


    def characters(self, text):
        self.__text += text


class Incident:

    def __init__(self, report_id, date, airport, aircraft_id,
                 aircraft_type, pilot_percent_hours_on_type,
                 pilot_total_hours, midair, narrative=""):
        """
        >>> kwargs = dict(report_id="2007061289X")
        >>> kwargs["date"] = datetime.date(2007, 6, 12)
        >>> kwargs["airport"] = "Los Angeles"
        >>> kwargs["aircraft_id"] = "8184XK"
        >>> kwargs["aircraft_type"] = "CVS91"
        >>> kwargs["pilot_percent_hours_on_type"] = 17.5
        >>> kwargs["pilot_total_hours"] = 1258
        >>> kwargs["midair"] = False
        >>> incident = Incident(**kwargs)
        >>> incident.report_id, incident.date, incident.airport
        ('2007061289X', datetime.date(2007, 6, 12), 'Los Angeles')
        >>> incident.aircraft_id, incident.aircraft_type, incident.midair
        ('8184XK', 'CVS91', False)
        >>> incident.pilot_percent_hours_on_type, incident.pilot_total_hours
        (17.5, 1258)
        >>> incident.approximate_hours_on_type
        220
        >>> incident.narrative = "Two different\\nlines of text"
        >>> str(incident)
        "Incident('2007061289X', datetime.date(2007, 6, 12), 'Los Angeles', '8184XK', 'CVS91', 17.5, 1258, False, '''Two different\\nlines of text''')"
        >>> kwargs["report_id"] = "fail"
        >>> incident = Incident(**kwargs)
        Traceback (most recent call last):
        ...
        AssertionError: invalid report ID
        """
        assert len(report_id) >= 8 and len(report_id.split()) == 1, \
               "invalid report ID"
        self.__report_id = report_id
        self.date = date
        self.airport = airport
        self.aircraft_id = aircraft_id
        self.aircraft_type = aircraft_type
        self.pilot_percent_hours_on_type = pilot_percent_hours_on_type
        self.pilot_total_hours = pilot_total_hours
        self.midair = midair
        self.narrative = narrative


    @property
    def report_id(self):
        return self.__report_id


    @property
    def date(self):
        "The incident date"
        return self.__date

    @date.setter
    def date(self, date):
        assert isinstance(date, datetime.date), "invalid date"
        self.__date = date


    @property
    def pilot_percent_hours_on_type(self):
        "The percentage of total hours flown on this aircraft type"
        return self.__pilot_percent_hours_on_type

    @pilot_percent_hours_on_type.setter
    def pilot_percent_hours_on_type(self, percent):
        assert 0.0 <= percent <= 100.0, "out of range percentage"
        self.__pilot_percent_hours_on_type = percent


    @property
    def pilot_total_hours(self):
        "The total hours this pilot has flown"
        return self.__pilot_total_hours

    @pilot_total_hours.setter
    def pilot_total_hours(self, hours):
        assert hours > 0, "invalid number of hours"
        self.__pilot_total_hours = hours


    @property
    def approximate_hours_on_type(self):
        return int(self.__pilot_total_hours *
                   (self.__pilot_percent_hours_on_type / 100))


    @property
    def midair(self):
        "Whether the incident involved another aircraft"
        return self.__midair

    @midair.setter
    def midair(self, value):
        assert isinstance(value, bool), "invalid midair value"
        self.__midair = value


    @property
    def airport(self):
        "The incident's airport"
        return self.__airport

    @airport.setter
    def airport(self, airport):
        assert airport and "\n" not in airport, "invalid airport"
        self.__airport = airport


    @property
    def aircraft_id(self):
        "The aircraft ID"
        return self.__aircraft_id

    @aircraft_id.setter
    def aircraft_id(self, aircraft_id):
        assert aircraft_id and "\n" not in aircraft_id, \
               "invalid aircraft ID"
        self.__aircraft_id = aircraft_id


    @property
    def aircraft_type(self):
        "The aircraft type"
        return self.__aircraft_type

    @aircraft_type.setter
    def aircraft_type(self, aircraft_type):
        assert aircraft_type and "\n" not in aircraft_type, \
               "invalid aircraft type"
        self.__aircraft_type = aircraft_type


    @property
    def narrative(self):
        "The incident's narrative"
        return self.__narrative

    @narrative.setter
    def narrative(self, narrative):
        self.__narrative = narrative


    def __repr__(self):
        return ("Incident({report_id!r}, {date!r}, "
                "{airport!r}, {aircraft_id!r}, "
                "{aircraft_type!r}, "
                "{pilot_percent_hours_on_type!r}, "
                "{pilot_total_hours!r}, {midair!r}, "
                "'''{narrative}''')".format(**self))


class IncidentCollection(dict):

    """
    >>> kwargs = dict(report_id="2007061289X")
    >>> kwargs["date"] = datetime.date(2007, 6, 12)
    >>> kwargs["airport"] = "Los Angeles"
    >>> kwargs["aircraft_id"] = "8184XK"
    >>> kwargs["aircraft_type"] = "CVS91"
    >>> kwargs["pilot_percent_hours_on_type"] = 17.5
    >>> kwargs["pilot_total_hours"] = 1258
    >>> kwargs["midair"] = False
    >>> incidents = IncidentCollection()
    >>> incident = Incident(**kwargs)
    >>> incidents[incident.report_id] = incident
    >>> kwargs["report_id"] = "2007061989K"
    >>> kwargs["date"] = datetime.date(2007, 6, 19)
    >>> kwargs["pilot_percent_hours_on_type"] = 20
    >>> kwargs["pilot_total_hours"] = 17521
    >>> incident = Incident(**kwargs)
    >>> incidents[incident.report_id] = incident
    >>> kwargs["report_id"] = "2007052989V"
    >>> kwargs["date"] = datetime.date(2007, 5, 29)
    >>> kwargs["pilot_total_hours"] = 1875
    >>> incident = Incident(**kwargs)
    >>> incidents[incident.report_id] = incident
    >>> for incident in incidents.values():
    ...     print(incident.report_id, incident.date.isoformat())
    2007052989V 2007-05-29
    2007061289X 2007-06-12
    2007061989K 2007-06-19
    >>> for report_id in reversed(incidents):
    ...     print(report_id, incidents[report_id].date.isoformat())
    2007061989K 2007-06-19
    2007061289X 2007-06-12
    2007052989V 2007-05-29
    """

    def values(self):
        for report_id in self.keys():
            yield self[report_id]


    def items(self):
        for report_id in self.keys():
            yield (report_id, self[report_id])


    def __iter__(self):
        for report_id in sorted(super().keys()):
            yield report_id

    keys = __iter__


    def __reversed__(self):
        for report_id in sorted(super().keys(), reverse=True):
            yield report_id


    def export(self, filename, writer=None, compress=False):
        extension = os.path.splitext(filename)[1].lower()
        if extension == ".aix":
            if writer == "dom":
                return self.export_xml_dom(filename)
            elif writer == "etree":
                return self.export_xml_etree(filename)
            elif writer == "manual":
                return self.export_xml_manual(filename)
        elif extension == ".ait":
            return self.export_text(filename)
        elif extension == ".aib":
            return self.export_binary(filename, compress)
        elif extension == ".aip":
            return self.export_pickle(filename, compress)
        elif extension in (".htm", ".html"):
            return self.export_html(filename)


    def import_(self, filename, reader=None):
        extension = os.path.splitext(filename)[1].lower()
        call = {(".aix", "dom"): self.import_xml_dom,
                (".aix", "etree"): self.import_xml_etree,
                (".aix", "sax"): self.import_xml_sax,
                (".ait", "manual"): self.import_text_manual,
                (".ait", "regex"): self.import_text_regex,
                (".aib", None): self.import_binary,
                (".aip", None): self.import_pickle}
        result = call[extension, reader](filename)
        if result == False:
            self.clear()
        return result

    if USE_LONG_WINDED_IMPORT_FUNCTION:
        def import_(self, filename, reader=None):
            extension = os.path.splitext(filename)[1].lower()
            result = False
            if extension == ".aix":
                if reader == "dom":
                    result = self.import_xml_dom(filename)
                elif reader == "etree":
                    result = self.import_xml_etree(filename)
                elif reader == "sax":
                    result = self.import_xml_sax(filename)
            elif extension == ".ait":
                if reader == "manual":
                    result = self.import_text_manual(filename)
                elif reader == "regex":
                    result = self.import_text_regex(filename)
            elif extension == ".aib":
                result = self.import_binary(filename)
            elif extension == ".aip":
                result = self.import_pickle(filename)
            if result == False:
                self.clear()
            return result


    def export_xml_dom(self, filename):
        dom = xml.dom.minidom.getDOMImplementation()
        tree = dom.createDocument(None, "incidents", None)
        root = tree.documentElement
        for incident in self.values():
            element = tree.createElement("incident")
            for attribute, value in (
                    ("report_id", incident.report_id),
                    ("date", incident.date.isoformat()),
                    ("aircraft_id", incident.aircraft_id),
                    ("aircraft_type", incident.aircraft_type),
                    ("pilot_percent_hours_on_type",
                     str(incident.pilot_percent_hours_on_type)),
                    ("pilot_total_hours",
                     str(incident.pilot_total_hours)),
                    ("midair", str(int(incident.midair)))):
                element.setAttribute(attribute, value)
            for name, text in (("airport", incident.airport),
                               ("narrative", incident.narrative)):
                text_element = tree.createTextNode(text)
                name_element = tree.createElement(name)
                name_element.appendChild(text_element)
                element.appendChild(name_element)
            root.appendChild(element)

        fh = None
        try:
            fh = open(filename, "w", encoding="utf8")
            tree.writexml(fh, encoding="UTF-8")
            return True
        except EnvironmentError as err:
            print("{0}: export error: {1}".format(
                  os.path.basename(sys.argv[0]), err))
            return False
        finally:
            if fh is not None:
                fh.close()


    def import_xml_dom(self, filename):

        def get_text(node_list):
            text = []
            for node in node_list:
                if node.nodeType == node.TEXT_NODE:
                    text.append(node.data)
            return "".join(text).strip()

        try:
            dom = xml.dom.minidom.parse(filename)
        except (EnvironmentError,
                xml.parsers.expat.ExpatError) as err:
            print("{0}: import error: {1}".format(
                  os.path.basename(sys.argv[0]), err))
            return False

        self.clear()
        for element in dom.getElementsByTagName("incident"):
            try:
                data = {}
                for attribute in ("report_id", "date", "aircraft_id",
                        "aircraft_type",
                        "pilot_percent_hours_on_type",
                        "pilot_total_hours", "midair"):
                    data[attribute] = element.getAttribute(attribute)
                data["date"] = datetime.datetime.strptime(
                                    data["date"], "%Y-%m-%d").date()
                data["pilot_percent_hours_on_type"] = (
                        float(data["pilot_percent_hours_on_type"]))
                data["pilot_total_hours"] = int(
                        data["pilot_total_hours"])
                data["midair"] = bool(int(data["midair"]))
                airport = element.getElementsByTagName("airport")[0]
                data["airport"] = get_text(airport.childNodes)
                narrative = element.getElementsByTagName(
                                                    "narrative")[0]
                data["narrative"] = get_text(narrative.childNodes)
                incident = Incident(**data)
                self[incident.report_id] = incident
            except (ValueError, LookupError, IncidentError) as err:
                print("{0}: import error: {1}".format(
                      os.path.basename(sys.argv[0]), err))
                return False
        return True


    def export_xml_etree(self, filename):
        root = xml.etree.ElementTree.Element("incidents")
        for incident in self.values():
            element = xml.etree.ElementTree.Element("incident",
                    report_id=incident.report_id,
                    date=incident.date.isoformat(),
                    aircraft_id=incident.aircraft_id,
                    aircraft_type=incident.aircraft_type,
                    pilot_percent_hours_on_type=str(
                            incident.pilot_percent_hours_on_type),
                    pilot_total_hours=str(incident.pilot_total_hours),
                    midair=str(int(incident.midair)))
            airport = xml.etree.ElementTree.SubElement(element,
                                                       "airport")
            airport.text = incident.airport.strip()
            narrative = xml.etree.ElementTree.SubElement(element,
                                                         "narrative")
            narrative.text = incident.narrative.strip()
            root.append(element)
        tree = xml.etree.ElementTree.ElementTree(root)
        try:
            tree.write(filename, "UTF-8")
        except EnvironmentError as err:
            print("{0}: import error: {1}".format(
                  os.path.basename(sys.argv[0]), err))
            return False
        return True


    def import_xml_etree(self, filename):
        try:
            tree = xml.etree.ElementTree.parse(filename)
        except (EnvironmentError,
                xml.parsers.expat.ExpatError) as err:
            print("{0}: import error: {1}".format(
                  os.path.basename(sys.argv[0]), err))
            return False

        self.clear()
        for element in tree.findall("incident"):
            try:
                data = {}
                for attribute in ("report_id", "date", "aircraft_id",
                        "aircraft_type",
                        "pilot_percent_hours_on_type",
                        "pilot_total_hours", "midair"):
                    data[attribute] = element.get(attribute)
                data["date"] = datetime.datetime.strptime(
                                    data["date"], "%Y-%m-%d").date()
                data["pilot_percent_hours_on_type"] = (
                        float(data["pilot_percent_hours_on_type"]))
                data["pilot_total_hours"] = int(
                        data["pilot_total_hours"])
                data["midair"] = bool(int(data["midair"]))
                data["airport"] = element.find("airport").text.strip()
                narrative = element.find("narrative").text
                data["narrative"] = (narrative.strip()
                                     if narrative is not None else "")
                incident = Incident(**data)
                self[incident.report_id] = incident
            except (ValueError, LookupError, IncidentError) as err:
                print("{0}: import error: {1}".format(
                    os.path.basename(sys.argv[0]), err))
                return False
        return True


    def export_xml_manual(self, filename):
        fh = None
        try:
            fh = open(filename, "w", encoding="utf8")
            fh.write('<?xml version="1.0" encoding="UTF-8"?>\n')
            fh.write("<incidents>\n")
            for incident in self.values():
                fh.write('<incident report_id={report_id} '
                         'date="{0.date!s}" '
                         'aircraft_id={aircraft_id} '
                         'aircraft_type={aircraft_type} '
                         'pilot_percent_hours_on_type='
                         '"{0.pilot_percent_hours_on_type}" '
                         'pilot_total_hours="{0.pilot_total_hours}" '
                         'midair="{0.midair:d}">\n'
                         '<airport>{airport}</airport>\n'
                         '<narrative>\n{narrative}\n</narrative>\n'
                         '</incident>\n'.format(incident,
                    report_id=xml.sax.saxutils.quoteattr(
                                        incident.report_id),
                    aircraft_id=xml.sax.saxutils.quoteattr(
                                        incident.aircraft_id),
                    aircraft_type=xml.sax.saxutils.quoteattr(
                                        incident.aircraft_type),
                    airport=xml.sax.saxutils.escape(incident.airport),
                    narrative="\n".join(textwrap.wrap(
                            xml.sax.saxutils.escape(
                                incident.narrative.strip()), 70))))
            fh.write("</incidents>\n")
            return True
        except EnvironmentError as err:
            print("{0}: export error: {1}".format(
                  os.path.basename(sys.argv[0]), err))
            return False
        finally:
            if fh is not None:
                fh.close()


    def export_text(self, filename):
        wrapper = textwrap.TextWrapper(initial_indent="    ",
                                       subsequent_indent="    ")
        fh = None
        try:
            fh = open(filename, "w", encoding="utf8")
            for incident in self.values():
                narrative = "\n".join(wrapper.wrap(
                                   incident.narrative.strip()))
                fh.write("[{0.report_id}]\n"
                         "date={0.date!s}\n"
                         "aircraft_id={0.aircraft_id}\n"
                         "aircraft_type={0.aircraft_type}\n"
                         "airport={airport}\n"
                         "pilot_percent_hours_on_type="
                         "{0.pilot_percent_hours_on_type}\n"
                         "pilot_total_hours={0.pilot_total_hours}\n"
                         "midair={0.midair:d}\n"
                         ".NARRATIVE_START.\n{narrative}\n"
                         ".NARRATIVE_END.\n\n".format(incident,
                    airport=incident.airport.strip(),
                    narrative=narrative))
            return True
        except EnvironmentError as err:
            print("{0}: export error: {1}".format(
                  os.path.basename(sys.argv[0]), err))
            return False
        finally:
            if fh is not None:
                fh.close()


    def import_text_manual(self, filename):
        fh = None
        try:
            fh = open(filename, encoding="utf8")
            self.clear()
            data = {}
            narrative = None
            for lino, line in enumerate(fh, start=1):
                line = line.rstrip()
                if not line and narrative is None:
                    continue
                if narrative is not None:
                    if line == ".NARRATIVE_END.":
                        data["narrative"] = textwrap.dedent(
                                                    narrative).strip()
                        if len(data) != 9:
                            raise IncidentError("missing data on "
                                            "line {0}".format(lino))
                        incident = Incident(**data)
                        self[incident.report_id] = incident
                        data = {}
                        narrative = None
                    else:
                        narrative += line + "\n"
                elif (not data and line[0] == "["
                               and line[-1] == "]"):
                    data["report_id"] = line[1:-1]
                elif "=" in line:
                    key, value = line.split("=", 1)
                    if key == "date":
                        data[key] = datetime.datetime.strptime(value,
                                                    "%Y-%m-%d").date()
                    elif key == "pilot_percent_hours_on_type":
                        data[key] = float(value)
                    elif key == "pilot_total_hours":
                        data[key] = int(value)
                    elif key == "midair":
                        data[key] = bool(int(value))
                    else:
                        data[key] = value
                elif line == ".NARRATIVE_START.":
                    narrative = ""
                else:
                    raise KeyError("parsing error on line {0}".format(
                                   lino))
            return True
        except (EnvironmentError, ValueError, KeyError,
                IncidentError) as err:
            print("{0}: import error: {1}".format(
                  os.path.basename(sys.argv[0]), err))
            return False
        finally:
            if fh is not None:
                fh.close()


    def import_text_regex(self, filename):
        incident_re = re.compile(
                        r"\[(?P<id>[^]]+)\](?P<keyvalues>.+?)"
                        r"^\.NARRATIVE_START\.$(?P<narrative>.*?)"
                        r"^\.NARRATIVE_END\.$",
                        re.DOTALL|re.MULTILINE)
        key_value_re = re.compile(r"^\s*(?P<key>[^=]+?)\s*=\s*"
                                  r"(?P<value>.+?)\s*$", re.MULTILINE)
        fh = None
        try:
            fh = open(filename, encoding="utf8")
            self.clear()
            for incident_match in incident_re.finditer(fh.read()):
                data = {}
                data["report_id"] = incident_match.group("id")
                data["narrative"] = textwrap.dedent(
                            incident_match.group("narrative")).strip()
                keyvalues = incident_match.group("keyvalues")
                for match in key_value_re.finditer(keyvalues):
                    data[match.group("key")] = match.group("value")
                data["date"] = datetime.datetime.strptime(
                                    data["date"], "%Y-%m-%d").date()
                data["pilot_percent_hours_on_type"] = (
                        float(data["pilot_percent_hours_on_type"]))
                data["pilot_total_hours"] = int(
                        data["pilot_total_hours"])
                data["midair"] = bool(int(data["midair"]))
                if len(data) != 9:
                    raise IncidentError("missing data")
                incident = Incident(**data)
                self[incident.report_id] = incident
            return True
        except (EnvironmentError, LookupError, ValueError,
                IncidentError) as err:
            print("{0}: import error: {1}".format(
                  os.path.basename(sys.argv[0]), err))
            return False
        finally:
            if fh is not None:
                fh.close()


    def export_binary(self, filename, compress=False):

        def pack_string(string):
            data = string.encode("utf8")
            format = "<H{0}s".format(len(data))
            return struct.pack(format, len(data), data)

        if USE_RESTRICTIVE_P_FORMAT:
            def pack_string(string):
                data = string.encode("utf8")
                format = "<{0}p".format(len(data))
                return struct.pack(format, data)

        fh = None
        try:
            if compress:
                fh = gzip.open(filename, "wb")
            else:
                fh = open(filename, "wb")
            fh.write(MAGIC)
            fh.write(FORMAT_VERSION)
            for incident in self.values():
                data = bytearray()
                data.extend(pack_string(incident.report_id))
                data.extend(pack_string(incident.airport))
                data.extend(pack_string(incident.aircraft_id))
                data.extend(pack_string(incident.aircraft_type))
                data.extend(pack_string(incident.narrative.strip()))
                data.extend(NumbersStruct.pack(
                                incident.date.toordinal(),
                                incident.pilot_percent_hours_on_type,
                                incident.pilot_total_hours,
                                incident.midair))
                fh.write(data)
            return True
        except EnvironmentError as err:
            print("{0}: export error: {1}".format(
                  os.path.basename(sys.argv[0]), err))
            return False
        finally:
            if fh is not None:
                fh.close()


    def import_binary(self, filename):

        def unpack_string(fh, eof_is_error=True):
            uint16 = struct.Struct("<H")
            length_data = fh.read(uint16.size)
            if not length_data:
                if eof_is_error:
                    raise ValueError("missing or corrupt string size")
                return None
            length = uint16.unpack(length_data)[0]
            if length == 0:
                return ""
            data = fh.read(length)
            if not data or len(data) != length:
                raise ValueError("missing or corrupt string")
            format = "<{0}s".format(length)
            return struct.unpack(format, data)[0].decode("utf8")
        
        if USE_RESTRICTIVE_P_FORMAT:
            def unpack_string(fh, eof_is_error=True):
                length_data = fh.read(1)
                if not length_data:
                    if eof_is_error:
                        raise ValueError("missing or corrupt string size")
                    return None
                length = int(struct.unpack("<B", length_data)[0])
                if length == 0:
                    return ""
                data = fh.read(length)
                if not data or len(data) != length:
                    raise ValueError("missing or corrupt string")
                format = "<{0}p".format(length)
                return struct.unpack(format, data)[0].decode("utf8")

        fh = None
        try:
            fh = open(filename, "rb")
            magic = fh.read(len(GZIP_MAGIC))
            if magic == GZIP_MAGIC:
                fh.close()
                fh = gzip.open(filename, "rb")
            else:
                fh.seek(0)
            magic = fh.read(len(MAGIC))
            if magic != MAGIC:
                raise ValueError("invalid .aib file format")
            version = fh.read(len(FORMAT_VERSION))
            if version > FORMAT_VERSION:
                raise ValueError("unrecognized .aib file version")
            self.clear()
            while True:
                report_id = unpack_string(fh, False)
                if report_id is None:
                    break
                data = {}
                data["report_id"] = report_id
                for name in ("airport", "aircraft_id",
                             "aircraft_type", "narrative"):
                    data[name] = unpack_string(fh)
                other_data = fh.read(NumbersStruct.size)
                numbers = NumbersStruct.unpack(other_data)
                data["date"] = datetime.date.fromordinal(numbers[0])
                data["pilot_percent_hours_on_type"] = numbers[1]
                data["pilot_total_hours"] = numbers[2]
                data["midair"] = numbers[3]
                incident = Incident(**data)
                self[incident.report_id] = incident
            return True
        except (EnvironmentError, ValueError, IndexError,
                IncidentError) as err:
            print("{0}: import error: {1}".format(
                  os.path.basename(sys.argv[0]), err))
            return False
        finally:
            if fh is not None:
                fh.close()


    def export_pickle(self, filename, compress=False):
        fh = None
        try:
            if compress:
                fh = gzip.open(filename, "wb")
            else:
                fh = open(filename, "wb")
            pickle.dump(self, fh, pickle.HIGHEST_PROTOCOL)
            return True
        except (EnvironmentError, pickle.PicklingError) as err:
            print("{0}: export error: {1}".format(
                  os.path.basename(sys.argv[0]), err))
            return False
        finally:
            if fh is not None:
                fh.close()


    def import_pickle(self, filename):
        fh = None
        try:
            fh = open(filename, "rb")
            magic = fh.read(len(GZIP_MAGIC))
            if magic == GZIP_MAGIC:
                fh.close()
                fh = gzip.open(filename, "rb")
            else:
                fh.seek(0)
            self.clear()
            self.update(pickle.load(fh))
            return True
        except (EnvironmentError, pickle.UnpicklingError) as err:
            print("{0}: import error: {1}".format(
                  os.path.basename(sys.argv[0]), err))
            return False
        finally:
            if fh is not None:
                fh.close()


    def import_xml_sax(self, filename):
        fh = None
        try:
            handler = IncidentSaxHandler(self)
            parser = xml.sax.make_parser()
            parser.setContentHandler(handler)
            parser.parse(filename)
            return True
        except (EnvironmentError, ValueError, IncidentError,
                xml.sax.SAXParseException) as err:
            print("{0}: import error: {1}".format(
                  os.path.basename(sys.argv[0]), err))
            return False


    def export_html(self, filename):
        fh = None
        try:
            fh = open(filename, "w", encoding="utf8")
            fh.write('<?xml version="1.0" encoding="UTF-8"?>\n'
                     '<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML '
                     '1.0 Strict//EN" '
                     '"http://www.w3.org/TR/xhtml1/DTD/'
                     'xhtml1-strict.dtd">\n'
                     '<html xmlns="http://www.w3.org/1999/xhtml" '
                     'lang="en" xml:lang="en">\n'
                     '<head><title>{0}</title>\n'
                     '<meta equiv="content-type" '
                     'content="text/html; charset=utf-8" />\n'
                     '</head><body>\n<h3>{0}</h3>\n'
                     '<table border="1">\n'
                     '<tr><th>Count</th><th>Report ID</th>'
                     '<th>Date</th><th>Aircraft</th>'
                     '<th>Type</th><th>Airport</th>'
                     '<th>Pilot Hours/Type</th><th>Pilot Hours</th>'
                     '<th>Midair</th><th>Narrative (Words)</th>'
                     '</tr>\n'.format("Aircraft Incidents Summary"))
            for i, incident in enumerate(self.values()):
                airport = xml.sax.saxutils.escape(
                                            incident.airport.strip())
                hours = "{0:n}".format(incident.pilot_total_hours)
                midair= "Yes" if incident.midair else "No"
                words = len(incident.narrative.split())
                fh.write('<tr><td align="right">{count}</td>\n'
                         '<td>{0.report_id}</td><td>{0.date!s}</td>'
                         '<td>{0.aircraft_id}</td>'
                         '<td>{0.aircraft_type}</td>'
                         '<td>{airport}</td>'
                         '<td align="right">'
                         '{0.pilot_percent_hours_on_type:.1f} %</td>'
                         '<td align="right">{hours} hours</td>'
                         '<td align="center">{midair}</td>'
                         '<td align="right">{words} words</td>'
                         '</tr>\n'.format(incident, count=i + 1,
                                          **locals()))
            fh.write("</table>\n</body>\n</html>\n")
            return True
        except EnvironmentError as err:
            print("{0}: export error: {1}".format(
                  os.path.basename(sys.argv[0]), err))
            return False
        finally:
            if fh is not None:
                fh.close()


def parse_options():
    reader_list = "dom d etree e sax s regex r manual m".split()
    writer_list = "dom d etree e manual m".split()
    parser = optparse.OptionParser(usage="""\
usage: %prog [options] infile outfile

Reads aircraft incident data from infile and writes the data to
outfile. The data formats used depend on the file extensions:
.aix is XML, .ait is text (UTF-8 encoding), .aib is binary,
.aip is pickle, and .html is HTML (only allowed for the outfile).
All formats are platform-independent.""")
    parser.add_option("-f", "--force", dest="force",
            action="store_true", default=False,
            help=("write the outfile even if it exists "
                  "[default: off]"))
    parser.add_option("-v", "--verbose", dest="verbose",
            action="store_true", default=False,
            help=("report results [default: off]"))
    parser.add_option("-r", "--reader", dest="reader",
            choices=reader_list,
            help=("reader (XML): 'dom', 'd', 'etree', 'e', "
                  "'sax', 's' reader (text): 'manual', 'm', "
                  "'regex', 'r' [default: etree for XML, "
                  "manual for text]"))
    parser.add_option("-w", "--writer", dest="writer",
            choices=writer_list,
            help=("writer (XML): 'dom', 'd', 'etree', 'e', "
                  "'manual', 'm' [default: manual]"))
    parser.add_option("-z", "--compress", dest="compress",
            action="store_true", default=False,
            help=("compress .aib/.aip outfile [default: off]"))
    parser.add_option("-t", "--test", dest="test",
            action="store_true",
            help=("execute doctests and exit (use with -v for "
                  "verbose)"))
    opts, args = parser.parse_args()

    if opts.test:
        test(opts.verbose)
    if len(args) == 0:
        parser.error("no files have been specified")
    if len(args) != 2:
        parser.error("exactly two files must been specified")
    if args[0] == args[1]:
        parser.error("the two specified files must be different")
    source, target = args

    if not opts.force and os.path.exists(target):
        parser.error("cannot overwrite unless --force is used")
    if opts.compress and target[-1] not in "pb":
        parser.error("can only compress .aib and .aip files")

    valid_extensions = {".aix", ".ait", ".aib", ".aip"}
    extension = os.path.splitext(source)[1].lower()
    if extension not in valid_extensions:
        parser.error("unrecognized infile extension: '{0}'".format(
                     extension))
    if extension == ".aix" and not opts.reader:
        opts.reader = "etree"
    elif extension == ".ait" and not opts.reader:
        opts.reader = "manual"
    text_readers = frozenset({"manual", "m", "regex", "r"})
    if ((extension == ".aix" and opts.reader in text_readers) or
        (extension == ".ait" and opts.reader not in text_readers) or
        (extension not in {".aix", ".ait"} and opts.reader)):
        parser.error("invalid reader for infile")

    valid_extensions |= {".htm", ".html"}
    extension = os.path.splitext(target)[1].lower()
    if extension not in valid_extensions:
        parser.error("unrecognized outfile extension: '{0}'".format(
                     extension))
    if extension == ".aix" and not opts.writer:
        opts.writer = "manual"
    readers = dict(d="dom", e="etree", s="sax", m="manual", r="regex")
    if opts.reader in readers:
        opts.reader = readers[opts.reader]
    writers = dict(d="dom", e="etree", m="manual")
    if opts.writer in writers:
        opts.writer = writers[opts.writer]
    if ((extension == ".aix" and opts.writer not in
         set(writers.keys()) | set(writers.values())) or
        (extension != ".aix" and opts.writer)):
        parser.error("invalid writer for outfile")

    return opts, source, target


def test(verbose):
    import doctest
    doctest.testmod(verbose=verbose)
    sys.exit()


def main():
    opts, source, target = parse_options()
    aircraft_incidents = IncidentCollection()
    if aircraft_incidents.import_(source, opts.reader):
        if opts.verbose:
            print("imported {0} record{s} from '{1}'".format(
                  len(aircraft_incidents), source,
                  s = "s" if len(aircraft_incidents) != 1 else ""))
        if aircraft_incidents.export(target, opts.writer,
                                     opts.compress):
            if opts.verbose:
                print("exported {0} record{s} to   '{1}'".format(
                    len(aircraft_incidents), target,
                    s = "s" if len(aircraft_incidents) != 1 else ""))


main()














#Reminder of topics<===========
CHAPTER 7 File Handling

Writing and Reading Binary Data
    Pickles with Optional Compression
    Raw Binary Data with Optional Compression 
Writing and Parsing Text Files
    Writing Text
    Parsing Text 
    Parsing Text Using Regular Expressions
Writing and Parsing XML Files 
    Element Trees 
    DOM (Document Object Model)
    Manually Writing XML 
    Parsing XML with SAX (Simple API for XML)
Random Access Binary Files 
    Generic BinaryRecordFile Class 
    Example: BikeStock Module's Classes     '
Summary
Exercises 
#1) 
#2)
#3)


#CODE LISTING HERE
BikeStock.py
BikeStock_ans.py
BinaryRecordFile.py
BinaryRecordFile_ans.py
convert-incidents.py
xdump.py 



===============
Writing and Reading Binary Data
===============

#Binary formats, even without compression, usually take up the least amount of disk space
#and are usually the fastest to save and load. Easiest of all is to use pickles, although
#handling binary data manually should produce the smallest file sizes.

===============
    Pickles with Optional Compression
===============

#Pickles offer the simplest approach to saving and loading data from Python programs, but
#as we noted in the preceding chapter, pickles have no security mechanisms (no encryption,
#no digital signature), so loading a pickle that comes from an untrusted source could be
#dangerous. The security concern arises b/c pickles can import arbitrary modules and call
#artibrary functions, so we could be given a pickle where the data has been manipulated
#in such a way as to, for example, make the interpreter execute something harmful when
#the pickle is loaded. Nonetheless, pickles are often ideal for handling ad hoc data,
#especially for program for personal use.

BOOKMARK HERE TOPIC
#It is usually EASIER when creating file formats to write the saving code before the 
#loading code, so we will begin by seeing how to save the incidents into a pickle.

def export_pickle(self, filename, compress=False):
    fh = None
    try:
        if compress:
            fh = gzip.open(filename, "wb")
        else:
            fh = open(filename, "wb")
        pickle.dump(self, fh, pickle.HIGHEST_PROTOCOL)
        return True
    except (EnvironmentError, pickle.PicklingError) as err:
        print("{0}: export error: {1}".format(os.path.basename(sys.argv[0]), err))
        return False
    finally:
        if fh is not None:
            fh.close()
#If compression has been requested, we use the gzip module's gzip.open() function to
#open the file; otherwise, we use the built-in open() function. We must use "write binary"
#mode ("wb") when pickling data in binary format. In Python 3.0 and 3.1, pickle.HIGHEST_PROTOCOL
#is protocol 3, a compact binary pickle format. This is the best protocol to use for data
#shared among Python 3 programs.*
# * Note Python 3 is Python3 specific. If we want pickles that are readable and writable
#by both Python 2 and Python 3 programs, we must use protocol 2 instead. Note, though, that
#protocol 2 files written by Python 3.1 can be read by Python 3.1 and Python 2.x but NOT by
#Python 3.0

#For error handling, we have chosen to report errors to the user as soon as they occur,
#and to return a Boolean to the caller indicating success or failure. And we have used a
#finally block to ensure that the file is closed at the end, whether there was an error
#or not. In Chapter 8, we will use a more compact idiom to ensure that files are closed
#which avoids the need for finally block.

#This code is very similar to what we saw in the preceding chapter but there is one subtle
#point to note. The pickled data is self, which is dict. But the dictionary's values are
Incident #objects, that is objects of a custom class. The pickle module is smart enough
#to be able to save objects of most custom classes without us needing to intervene.

#In general, Booleans, numbers, and strings can be pickled, as can instances of
#classes including custom classes, providing their private
__dict__ #is picklable. In addition, any built-in collection types (tuples, lists, sets, 
#dictionaries) can be pickled, providing they contain only pickable objects (including
#collection types, so recursive structures are supported). It is also possible to pickle
#other kinds of objects or instances of custom classes that can normally be pickled 
#(eg b/c they have a nonpicklable attribute), either by giving some help to the pickle module
#or by implementing custom pickle and unpickle functions. All the relevant details
#are provided in the pickle module's online documentation.

#To read back the pickled data, we need to distingusih between a compressed and uncompressed
#pickle. Any file that is compressed using gzip compression begins with a particular
magic number. #A magic number is a sequence of one or more bytes at the beginning of a file
#that is used to indicate the file's type. For gzip files, the magic number is the two
#bytes 0xiF 0x8B, which we store in a bytes variable:
GZIP_MAGIC = b"\x1F\x8B"


################################################ SIDEBAR NOTE
The Bytes and Bytearray Data Types

#Python provides two data types for handling raw bytes: 
bytes #which is immutable and
bytearray #which is mutable.
#Both types hold a sequence of zero or more 8-bit unsigned integers (bytes) with each
#byte in the range 0...255. 

#Both types are very similar to strings and provide many of the same methods including 
#support for slicing. In addition, bytearrays also provide some mutating list-like methods 
#(see below) --> word = b"Animal"
#All their methods are listed in Tables 7.1 and 7.2

#Whereas a slice of a bytes or bytearry returns an object of the same type, accessing
#a single byte using the item access operator [] returns an int 
#which is the value of the specified byte. For example,

    >>> word = b"Animal"
    >>> x = b"A"
    >>> word[0] == x
    False
    >>> word[:1] == x
    True
    >>> word[0] == x[0]
    True
    >>> word[0] == 65
    True
    >>> word[:1] == b"A"
    True
    >>> word[0] == 65; x == b"A"
    True
    True
    >>> word[:1] == b"A"; x == b"A"
    True
    True
    >>> word[0] == 65; x[0] == 65
    True
    True
    #Here are some other bytes and bytearray examples:

    >>> data = b"5 Hills \x35\x20\x48\x69\x6C\x6C\x73"
    >>> data.upper()
    b'5 HILLS 5 HILLS'
    >>> data.replace(b"ill", b"at")
    b'5 Hats 5 Hats'
    >>> bytes.fromhex("35 20 48 69 6C 6C 73")
    b'5 Hills'
    >>> bytes.fromhex("352048696C6C73")
    b'5 Hills'
    >>> data = bytearray(data)  #data is not a bytearray
    >>> data.pop(10)
    72
    >>> data.insert(10, ord("B"))
    >>> data
    bytearray(b'5 Hills 5 Bills')
    >>> data.pop(10)
    66
    >>> data
    bytearray(b'5 Hills 5 ills')

#Methods that make sense only for strings, such as bytes.upper() assume that the bytes
#are encoded using ASCII. The 
bytes.fromhex() #class method ignores whitespace and interprets each two-digit substring 
#as a hexadecimal number, so "35" is taken to be byte of value 0x35, etc.
################################################ END OF SIDEBAR NOTE

For more about the btyes data type see Tables 7.1, 7.2 and 7.3 pages 299-301
which list their methods.

#Here is the code for reading an incidents pickle file:
def import_pickle(self, filename):
    fh = None
    try:
        fh = open(filename, "rb")
        magic = fh.read(len(GZIP_MAGIC))
        if magic == GZIP_MAGIC:
            fh.close()
            fh = gzip.open(filename, "rb")
        else:
            fh.seek(0)
        self.clear()
        self.update(pickle.load(fh))
        return True
    except (EnvironmentError, pickle.UnpicklingError) as err:
        print("{0}: import error: {1}".format(os.path.basename(sys.argv[0]), err))
        return False
    finally:
        if fh is not None:
            fh.close()

#We dont know whether the given file is compressed. In either case, we begin by opening
#the file in "read binary" mode, and then we read the first two bytes. If these bytes
#are the same as the gzip magic number we close the file and create a new file object
#using the gzip.open() function. 
#Else, if the file is not compressed (ATUL b/c it has no GZIP MAGIC NUMBER then)
#we use the file object returned by open(), calling its seek() method to restore 
#the file pointer to the beginning so that the next read (made insde the pickle.load() 
#function) will be from the start.

ATUL IMPORTANT HERE
#We cant assign to self since that would wipe out the IncidentCollection object
#that is in use, so instead we clear all the incidents to make the dictionary
#empty and then use dict.update() to populate the dictionary with all the 
#incidents from the IncidentCollection dictionary loaded from the pickle.

#Note that it does NOT matter whether the processor's byte ordering is big- or
#little-endian, b/c for the magic number we read individual bytes, and for the data
#the pickel module handles endianness for us.



#Reminder of topics<===========
CHAPTER 7 File Handling

Writing and Reading Binary Data
    Pickles with Optional Compression
    Raw Binary Data with Optional Compression 
Writing and Parsing Text Files
    Writing Text
    Parsing Text 
    Parsing Text Using Regular Expressions
Writing and Parsing XML Files 
    Element Trees 
    DOM (Document Object Model)
    Manually Writing XML 
    Parsing XML with SAX (Simple API for XML)
Random Access Binary Files 
    Generic BinaryRecordFile Class 
    Example: BikeStock Module's Classes     '
Summary
Exercises 
#1) 
#2)
#3)


#CODE LISTING HERE
BikeStock.py
BikeStock_ans.py
BinaryRecordFile.py
BinaryRecordFile_ans.py
convert-incidents.py
xdump.py 



===============
    Raw Binary Data with Optional Compression 
===============
BOOKMARK HERE TOPIC
#Writing our own code to handle raw binary data gives us complete control over
#our file format. It should also be safer than using pickles, since malicously
#invalid data will be handled by our code rather than executed by the interpreter.

#When creating custom binary file formats it is wise to create a magic number
#to identify your file type, and a version number to identify the version
#of the file format in use. Here are the definitions used in the 
convert-incidents.py #program

    MAGIC = b"AIB\x00"
    FORMAT_VERSION = b"\x00\x01"

#We have used four bytes for the magic number and two bytes for the version.
#Endianness is not an issue b/c there will be written as individual bytes, not
#as the byte representations of integers, so they will always be the same on
#any processor architecture.

#To write and read raw binary data, we must have some means of converting
#Python objects to and from suitable binary representations. Most of the 
#functionality we need is provided by the 
struct #module. See The Struct Module, and by the bytes and bytearry data types
#see sidebar for these Table 7.1 and Table 7.2

#Unfortunately, the struct module can handle strings only of a specified length,
#and we need variable length strings for the report and aircraft IDs, as well as
#for the airport, the aircraft type, and the narrative texts. To meet this need, we
#have created a function
pack_string() #which takes a string and returns a bytes object which contains two
#components: the 1st is an integer length count, and the 
#2nd is a sequence of length count UTF-8 encoded bytes representing the string's text.

#Since the only place the pack_string() function is needed is inside the
#export_binary() function, we have put the definition of pack_string() inside the
#export_binary() function. This means that pack_string() is not visible outside
#the export_binary() function, and makes clear that it is just a local helper
#function. Here is the start of the 
export_binary() #function, and the complete nested 
pack_string() #function:

    def export_binary(self, filename, compress=False):

        def pack_string(string):
            data = string.encode("utf8")
            format = "<H{0}s".format(len(data))
            return struct.pack(format, len(data), data)

#The str.encode() method returns a byte object with the string encoded according
#to the specific encoding. UTF-8 is a very convenient encoding b/c it can represent
#any Unicode character and is especially compact when representing ASCII characters
#just one byte each). The 
format #variable is set to hold a struct format based on the string's length. For
#example, given the string "en.wikipedia.org", the format will be "<H16s" (little-
#endian byte order, 2-byte unsigned integer, 16-byte byte string), and the bytes 
#object that is returned will be b'\x10\x00en.wikipeida.org'. Conveniently, Python
#shows byte objects in a compact form using printable ASCII characters where 
#possible, and hexadecimal escapes (and some special escapes like \t and \n) otherwise.

#The pack_string() function can handle strings of up to 65,535 UTF-8 characters. We
#could easily switch to using a different kind of integer for the byte count; for
#example, a 4-byte signed integer (format "i") would allow for strings of up to
# 2^31 -1 (more than 2 billion) characters.

#GRAY BOX HERE The Struct Module

#The struct module does provide a similar built-in format, "p", that stores 
#a single byte as a character count followed by up to 255 characters. For
#packing, the code using "p" format is slightly simpler than doing all the
#work ourselves. But "p" format restricts us to a maximum of 255 UTF-8 characters
#and provides alomst no benefit when unpacking. (For the sake of comparison, 
#versions of pack_string() and unpack_string() that use "p" format are included
#in the convert-incidents.py source file.)

#We now turn our attention to the rest of the code in the export_binary() method:

def export_binary(self, filename, compress=False):

    def pack_string(string):
        data = string.encode("utf8")
        format = "<H{0}s".format(len(data))
        return struct.pack(format, len(data), data)
        #new stuff ################IS BELOW FOR THIS EXPLANATION#############
        fh = None
        try:
            if compress:
                fh = gzip.open(filename, "wb")
            else:
                fh = open(filename, "wb")
            fh.write(MAGIC)
            fh.write(FORMAT_VERSION)
            for incident in self.values():
                data = bytearray()
                data.extend(pack_string(incident.report_id))
                data.extend(pack_string(incident.aircraft))
                data.extend(pack_string(incident.aircraft_id))
                data.extend(pack_string(incident.aircraft_type))
                data.extend(pack_string(incident.narrative.strip()))
                data.extend(NumbersStruct.pack(incident.date.toordinal(),
                                               incident.pilot_percent_hours_on_type,
                                               incident.pilot_total_hours,
                                               incident.midair))
                fh.write(data)
            return True

#We have omitted the except and finally blocks since they are the same as the ones shown
#in the preceeding subsection, apart from the particular exceptions that the except
#block catches.
#We begin by opening the file in "write binary" mode, either a normal file or a gzip
#compressed file depending on the compress flag. We then write the 4-byte magic
#number that is (hopefully) unique to our program, and the 2-byte version number.*
#*Note that there is no central repository for magic numbers like there is for
#domain names, so we can never guarantee uniqueness.
#Using a version number makes it easier to change the format in the future -- when we 
#read the version number we can use it to determine which code to use for reading.

#Next we iterate over all the incidents, and for each one we create a 
bytearry #. We add each item of data to the byte array, starting with the variable length 
#strings. The 
date.toordinal() #method returns a single integer representing the stored date; the date
#can be restored by passing this integer to the datetime.date.formordinal() method. The
#NumbersStruct is defined earlier in the program with this statement:

    NumbersStruct = struct.Struct("<Idi?")

#This format specifies little-endian byte order, an unsiged 32-bit integer (for the
#data ordinal), a 64-bit float (for the percentage hours on type), a 32-bit integer
#(for the total hours flown), and a Boolean (for whether the incident was midair). The
#structure of an entire aircraft incident record is shown schematically in Figure 7.3

################################################ Figure 7.3 schematically
Structure of a binary aircraft incident record:

report_id
            airport     
                        aircraft_id
                                    narrative 
                                                date
                                                            pilot_percent_hours_on_type
                                                                        pilot_total_hours
                                                                                    midair
^^^^        ^^^         ^^^         ^^^         ^^^         ^^^         ^^^         ^^^
string      string      string      string      uint32      float64     int32       bool
            ^^^

            uint16 | UTF-8 encoded bytes...
################################################





#Once the bytearry has all the data for one incident, we write it to disk. And once all
#the incidents have been written we return True (assuming no error occurred). The finally
#block ensures that the file is closed just before we return.







################################################ SIDEBAR NOTE
The Struct Module

#The struct module provides struct.pack(), struct.unpack(), and some other
#functions, and the struct.Struct() class. The struct.pack() function takes
#a struct format string and one or more values and return a bytes object
#that holds all the values represented in accordance with the format. The
#struct.unpack() function takes a format and a bytes or bytearry object and
#returns a tuple of the values that were originally packed using the format.
#For example:
    data = struct.pack("<2h", 11, -9)       # data == b'\x0b\x00\xf7\xff'
    items = struct.unpack("<2h", data)      # items == (11, -9)
#Format strings consist of one or more characters. Most characters represent
#a value of a particular type. If we need more than one value of a type we
#can either write the character as many times as there are values of the
#type ("hh"), or precede the character with a count as we have done here ("2h").

#Many format characters are described in the struct module's online documentation,
#including: 
    #"b" (8-bit signed integer), 
    #"B" (8-bit unsigned integer),
    #"h" (16-bit signed integer - used in the example here), 
    #"H" (16-bit unsigned integer), 
    #"i" (32-bit signed integer), 
    #"I" (32-bit unsigned integer), 
    #"q" (64-bit signed integer), 
    #"Q" (64-bit unsigned integer), 
    #"f" (32-bit float), 
    #"d" (64-bit float - this corresponds to Python's float type)
    #"?" (Boolean)
    #"S" (bytes or bytearray object--byte strings)
    #and many others

#For some data types such as multibyte integers, the processor's endianness
#makes a difference to the byte order. We can force a particular byte order
#to be used regardless of the processor architecture by starting the format
#string with an endianness character. In this book we always use "<", which
#means little-endian since that's the native endianness for the widely used
#Intel and AMD processors. Big-endian (also called network byte order) is
#signifed by ">" (or by "!"). If no endianness is specified the 
#machines endianness is used. We recommend always specifying endianness
#even if it is the same as the machine being used since doing so keeps the
#data portable.

#The struct.calcsize() function takes a format and returns how many bytes
#a struct using the format will occupy. A format can also be stored by
#creating a struct.Struct() object given by its size attribute. For 
#example:
    TWO_SHORTS = struct.Struct("<2h")
    data = TWO_SHORTS.pack(11, -9)          # data == b'\x0b\x00\xf7\xff'
    items = TWO_SHORTS.unpack(data)         # items == (11, -9)

#In both examples, 11 is 0x000b, but this is transformed into the 
#bytes 0x0b 0x00 b/c we have used little-endian byte ordering.
################################################ SIDEBAR NOTE




################################################ Table 7.1
Bytes and Bytearray Methods #1

Syntax                      Description
---------------------       ------------------------------------------------
ba.append(i)                #appends int i (in range 0...255) to bytearry ba 
b.capitalize()              #returns a copy of bytes/bytearray b with the 
                            #first character capitalized (if it is an ASCII letter)
b.center(width, byte)       #returns a copy of b centered in lenght width padded with
                            #spaces or optionally with the given byte
b.count(x, start, end)      #returns the number of occurrences of bytes/bytearray x
                            #in bytes/bytearray b (or in the start:end slice of b)
b.decode(encoding, error)   #returns a str object that represents the bytes using the 
                            #UTF-8 encoding or using the specifid encoding and handling
                            #errors according to the optional error argument
b.endswith(x, start, end)   #returns True if b (or the start:end slice of b) ends with
                            #bytes/bytearray x or with any of the bytes/bytearrarys in
                            #tuple x; otherwise returns False
b.expandtabs(size)          #returns a copy of bytes/bytearray b with tabs replaced
                            #with spaces in multiples of 8 or size if specified
ba.extend(seq)              #extends bytearray ba with all the ints in sequences seq;
                            #all thte ints must be in the range 0...255
b.find(x, start, end)       #returns the leftmost position of bytes/bytearray x in b (or
                            #in the start:end slice of b) or -1 if not found. Use the rfind()
                            #method to the rightmost position
b.fromhex(h)                #returns a bytes object with bytes corresponding to the 
                            #hexadecimal integers in str h
b.index(x, start, end)      #returns the leftmost position of x in b (or in the start:end
                            #slice of b) or raises ValueError if not found. Use the riindex()
                            #method to find the rightmost position
ba.insert(p, i)             #inserts integer i (in range 0...25) at position p in ba
b.isalnum()                 #returns True if bytes/bytearray b is nonempty and every
                            #character in b is an ASCII alphanumeric character
b.isalpha()                 #Returns True if bytes/bytearray b is nonempty and 
                            #every character in b is an ASCII alphabetic character
b.isdigit()                 #Returns True if bytes/bytearray b is nonempty and every 
                            #character in b is an ASCII alphabetic digit
b.islower()                 #returns True if bytes/bytearray b has at least one lower
                            #caseable ASCII character and all its lowercaseable
                            #characters are lowercase
b.isspace()                 #returns True if bytes/bytearray b is nonempty and every
                            #character in b is an ASCII whitespace character
b.istitle()                 #returns True if b is nonempty and title-cased
b.isupper()                 #returns Ture if b has at least one uppercaseable ASCII
                            #character and all its uppercaseable character are uppercase
b.join(seq)                 #returns the concatenation of every bytes/bytearray in
                            #sequence seq, with b (which may be empty) between each one
b.ljust(width, byte)        #returns a copy of bytes/bytearray b left-aligned in length
                            #width padded with spaces or optionally with the given byte.
                            #use the rjust() method to right-align
b.lower()                   #returns an ASCII lowercased copy of bytes/bytearray b
b.partition(sep)            #returns a tuyple of three bytes objects -- the part of b before
                            #the leftmost bytes/bytearray sep, then sep itself, then the part
                            #of b after sep; or if sep is not in b returns b and two empty
                            #bytes objects. Use the rpartition() method to partition on the
                            # rightmost occurrence of sep.
ba.pop(p)                   #removes and returns the int at index position p in ba
ba.remove(i)                #removes the first occurrence of int i from bytearray ba
b.replace(x, y, n)          #returns a copy of b with every (or a maximum of n if given)
                            #occurrence of bytes/bytearray x replaced with y
ba.reverse()                #reverses bytearray's ba bytes-in-place
b.split(x, n)               #returns a list of bytes splitting at most n times on x. If
                            #n is not given, splits everywhere possible; if x is not given,
                            #splits on whitespace. Use rsplit() to split from the right.
b.splitlines(f)             #returns the list of lines produced by splitting b on line
                            #terminators, stripping the terminator unless f is True
b.startswith(x, start, end) #returns True if bytes/bytearray b (or the start:end slice of b)
                            #starts with bytes/bytearray x or with any of the bytes/bytearray
                            #in tuple x; otherwise, returns False
b.strip(x)                  #returns a copy of b with leading and trailling whitespace (or
                            #the bytes in bytes/bytearray x) removed; lstrip() strips only
                            #at the start, and rstrip() strips only at the end
b.swapcase()                #returns a copy of b where the first ASCII lette of each word
                            #is uppercased and all other ASCII letters are lowercased
b.title()                   #returns a copy of b where the first ASCII letter of each word
                            #is uppercased and all other ASCII letters are lowercased
b.translate(bt, d)          #returns a copy of b that has no bytes from d, and where each
                            #other byte is replaced by the byte-th byte from bytes bt
b.upper()                   #returns an ASCII uppercased copy of bytes/bytearray b
b.zfill(w)                  #returns a copy of b, which if shorte than w is padded with
                            #leading zeros (0x30 characters) to make it w bytes long
################################################


#Reading back the data is not as straighforward as writing it -- for one thing
#we have more error checking to do. Also, reading back variable length strings is
#slightly tricky. Here is the start of the import_binary() #method and the complete
#nested unpack_string() function that we use to read back the variable length strings:

    def import_binary(self, filename):

        def unpack_string(fh, eof_is_error=True):
            uint16  = struct.Struct("<H")
            length_data = fh.read(uint16.size)
            if not length_data:
                if eof_is_error:
                    raise ValueError("missing or corrupt string size")
                return None
            length = uint16.unpack(length_data)[0]
            if length == 0:
                return ""
            data = fh.read(length)
            if not data or len(data) != length:
                raise ValueError("missing or corrupt string")
            format = "<{0}s".format(length)
            return struct.unpack(format, data)[0].decode("utf8")

#Since each incident record begins with its report ID string, when we attempt to read
#this string and we succeed, we are at the start of a new record. But if we fail, we have
#reached the end of the file and can finish. We set the eof_is_error flag to False when
#attempting to read a report ID since if there is no data, it just means we have finished.
#For all other strings we accept the default of True b/c if any other string has no data,
#it is an error. (Even an empty string will be preceded by a 16-bit unsigned integer length.)

#We begin by attempting to read the string's length. If this fails, we return None to
#signify end of file (if we are attempting to read a new incident), or we raise a 
#ValueError exception to indicate corrupt or missing data. The struct.unpack() function
#and the struct.Struct.unpack() method always return a tuple, even if it contains only a
#single value. We unpacked the length data and store the number it represents in the length
#variable. Now we know how many bytes we must read to get the string. If the length is zero
#we simply return an emtpy string. Otherwise, we attempt to read the specified number of
#bytes. If we dont get any data of if the data is not the size we expected, 
#(ie it is too little) then we raise a ValueError exception.

#If we have the right number of bytes we create a suitable format string for the 
#struct.unpack() function, and we return the string that results from unpacking the data
#and decoding the bytes as UTF-8. (In theory, we could replace the last two lines with
return data.decode("utf8") #but we prefer to go through the unpacking process since it is
#possible -- though unlikely -- that the "s" format performs some transformation on our
#data which must be reversed when reading back.)

#We now look at the rest of the import_binary() method, breaking it into two parts
#for ease of explanation.

        fh = None
        try:
            fh = open(filename, "rb")
            magic = fh.read(len(GZIP_MAGIC))
            if magic == GZIP_MAGIC:
                fh.close()
                fh = gzip.open(filename, "rb")
            else:
                fh.seek(0)
            magic = fh.read(len(MAGIC))
            if magic != MAGIC:
                raise ValueError("invalid .aib file format")
            version = fh.read(len(FORMAT_VERSION))
            if version > FORMAT_VERSION:
                raise ValueError("unrecognized .aib file version")
            self.clear()

#The file may or not be compressed, so we use the same technique that we used for
#reading pickles to open the file using gzip.open() or the built-in open() function.

#Once the file is open we are at the beginning, we read the first four bytes
len(MAGIC) #If these dont match our magic number we know that it is NOT a binary
#aircraft incident data file and so we raise a ValueError exception. Next we read in
#the 2-byte version number. It is at this point that we would use different reading
#code depending upon the version. Here we just check that the version is not a later
#one than this program is able to read.

#If the magic number is correct and the version is one we can handle, we are ready to
#read in the data, so we begin by clearing out all the existing incidents so that
#the dictionary is empty.

        while True:
            report_id = unpack_string(fh, False)
            if report_id is None:
                break
            data = {}
            data["report_id"] = report_id
            for name in ("airport", "aircraft_id", "aircraft_type", "narrative"):
                data[name] = unpack_string(fh)
            other_data = fh.read(NumbersStruct.size)
            numbers = NumbersStruct.unpack(other_data)
            data["date"] = datetime.date.fromordinal(numbers[0])
            data["pilot_percent_hours_on_type"] = numbers[1]
            data["pilot_total_hours"] = numbers[2]
            data["midair"] = numbers[3]
            incident = Incident(**data)
            self[incident.report_id] = incident
        return True

#The while block loops until we run out of data. We start by trying to get a report
#ID. If we get None, then we have reached the end of the file and can break out of
#the loop. Otherwise, we create a dictionary called 
data #to hold the data for one incident
#and attempt to get the rest of the incident's data. For the strings we use the
unpack_string() #method, and for the other data we read it all in one go using the 
#NumbersStruct struct. Since we stored the date as an ordinal we must do the reverse
#conversion to get a date back. But for the other items, we can just use the unpacked
#data -- (ATUL note that) no validation or conversion is required since we wrote 
#the correct data types in the first place and have read back the same data types using 
#the format held in the NumbersStruct struct.

#If any error occurs, for example, if we fail to unpack all the numbers, an
#exception will be raised and will be handled in the except block. (We have not
#shown the except and finally blocks b/c they are structurally the same as those
#shown in the preceding subsection for the
import_pickle() #method).

#Toward the end we make use of the convenient mapping unpacking syntax to create an
#Incident object which we then store in the incidents dicitonary.

#Apart from the handling of variable length strings, the struct module makes it very
#asy to save and load data in binary format. And for variable length strings the
#pack_string() and unpack_string() methods shown here should serve most purposes
#perfectly well.


#Reminder of topics<===========
CHAPTER 7 File Handling

Writing and Reading Binary Data
    Pickles with Optional Compression
    Raw Binary Data with Optional Compression 
Writing and Parsing Text Files
    Writing Text
    Parsing Text 
    Parsing Text Using Regular Expressions
Writing and Parsing XML Files 
    Element Trees 
    DOM (Document Object Model)
    Manually Writing XML 
    Parsing XML with SAX (Simple API for XML)
Random Access Binary Files 
    Generic BinaryRecordFile Class 
    Example: BikeStock Module's Classes     '
Summary
Exercises 
#1) 
#2)
#3)


#CODE LISTING HERE
BikeStock.py
BikeStock_ans.py
BinaryRecordFile.py
BinaryRecordFile_ans.py
convert-incidents.py
xdump.py 



===============
Writing and Parsing Text Files
===============
#Writing text is easy, but reading it back can be problematic, so we need to choose
#the structure carefully so that it is not too difficult to parse. (Chapter 14
#introduces various parsing techniques, including two third party open source parsing
#modules that make parsing tasks much easier.)
#Figure 7.4 shows an example aircraft incident record in the text format we are going
#to use. When we write the incident records to a file we will follow each one with a
#blank line, but when we parse the file, we will accept zero or more blank lines
#between incident records.


===============
    Writing Text
===============
#Each incident record begins with the report ID enclosed in brackets []. This is 
#followed by all the one-line data items written in key=value form. For the 
#multiline narrative text we precede the text with a start marker (.NARRATIVE_START)
#and follow it with an end marker (.NARRATIVE_END.), and we indent all the text
#in between to ensure that no line of text could be confused with a start or
#end marker.

#Figure 7.4 Example text format of an aircraft incident record
################################################ Figure 7.4 
 
[20070927022009C]
date=2007-09-27
aircraft_id=1675B
aircraft_type=DHC-2-MK1
airport=MERLE K (MUDHOLE) SMITH
pilot_percent_hours_on_type=46.1538461538
pilot_total_hours=13000
midair=0
.NARRATIVE_START.
    ACCORDING TO THE PILOT, THE DRAG LINK FAILED DUE TO AN OVERSIZED
    TAIL WHEEL TIRE LANDING ON HARD SURFACE.
.NARRATIVE_END.
################################################


#Here is the code for the export_text() function, but excluding the except and finally
#blocks since they are the same as ones we have seen before, except for the 
#excptions handled:

    def export_text(self, filename):
        wrapper = textwrap.TextWrapper(initial_indent="  ", subsequent_indent="  ")
        fh = None
        try:
            fh = open(filename, "w", encoding="utf8")
            for incident in self.values():
                narrative = "\n".join(wrapper.wrap(incident.narrative.strip()))
                fh.write("[{0.report_id}]\n",
                         "date={0.date!s}\n",
                         "aircraft_id={0.aircraft_id}\n",
                         "aircraft_type={0.aircraft_type}\n",
                         "airport={airport}\n",
                         "pilot_percent_hours_on_type={0.pilot_percent_hours_on_type}\n",
                         "pilot_total_hours={0.pilot_percent_hours_on_type}\n",
                         "midair={0.midair:d}\n",
                         ".NARRATIVE_START.\n{narrative}\n",
                         ".NARRATIVE_END.\n\n".
                         format(incident, airport=incident.airport.strip(), narrative=narrative))
            return True
#The line breaks in the narrative text are not significent, so we can wrap the text
#as we like. Normally, we would use the textwrap module's
textwrap.text() #function, but here we need to both indent and wrap, so we begin by creating a
textwrap.TextWrap #object, initialized with the indentation we want to use (four spaces for
#the first and subsequent lines). By default, the object will wrap lines to a width of 70
#characters, although we can change this by passing another keyword argument.

#We could have written this using a triple quoted string, but we prefer to put in the newlines
#manually. The textwrap.TextWrapper object provides a wrap() method that takes a string as
#input, in this case the narrative text, and returns a list of strings with suitable indentation
#and each no longer than the wrap width. We then join this list of lines into a single string
#using newline as the separator.

#The incident data is held as datetime.date object; we have forced str.format() to use
#the string representation when writing the date -- this very conveniently produces the
#date in ISO 8601, YYYY-MM-DD format. We have told str.format() to write the midair bool as
#an integer -- this produces 1 for True and 0 for False. In general, using str.format()
#makes writing text very easy b/c it handles all of Python's data types automatically
#(including the custom types if we implement the __str__() or __format__() special method)
#automatically.


#Reminder of topics<===========
CHAPTER 7 File Handling

Writing and Reading Binary Data
    Pickles with Optional Compression
    Raw Binary Data with Optional Compression 
Writing and Parsing Text Files
    Writing Text
    Parsing Text 
    Parsing Text Using Regular Expressions
Writing and Parsing XML Files 
    Element Trees 
    DOM (Document Object Model)
    Manually Writing XML 
    Parsing XML with SAX (Simple API for XML)
Random Access Binary Files 
    Generic BinaryRecordFile Class 
    Example: BikeStock Module's Classes     '
Summary
Exercises 
#1) 
#2)
#3)


#CODE LISTING HERE
BikeStock.py
BikeStock_ans.py
BinaryRecordFile.py
BinaryRecordFile_ans.py
convert-incidents.py
xdump.py 


===============
    Parsing Text 
===============
#The method for reading and parsing text format aircraft incident records is longer and
#more involved than the one used for writing. When reading the file, we could be in
#one of several states. We could be in the middle of reading narrative lines; we could
#be at a key=value line; or we could be at a report ID line at the start of new incident.
#We will look at the 
import_text_manual() #method in five parts:

    def import_text_manual(self, filename):
        fh = None
        try:
            fh = open(filename, encoding="utf8")
            self.clear()
            data = {}
            narrative = None

#The method begins by opening the file in "read text" mode. Then we clear the dictionary
#of incidents and create a data dictionary to hold the data for a single incident in the
#same way as we did when reading binary incident records. The narrative variable is used
#for two purposes: as a state indicator and to store the current incident's narrative text.
#If narrative is None, it means that we are not currently reading a narrative, but if it
#is a string (even an empty one), it means we are in the process of reading narrative lines.

            for lino, line in enumerate(fh, start=1):
                line = line.rstrip()
                if not line and narrative is None:
                    continue
                if narrative is not None:
                    if line == ".NARRATIVE_END.":
                        data["narrative"] = textwrap.dedent(narrative).strip()
                        if len(data) != 9:
                            raise IncidentError("missing data on line {0}".format(lino))
                        incident = Incident(**data)
                        self[incident.report_id] = incident
                        data = {}
                        narrative = None
                    else:
                        narrative += line + "\n"

#Since we are reading line by line we can keep track of the current line number and use
#this to provide more informative error messages than is possible when reading
#binary files. We begin by stripping off any trailing whitespace from the line, and if
#this leaves us with an empty line (and providing we are not in the middle of a narrative),
#we simply skip to the next line. This means that the number of blank lines between
#incidents does not matter, but that we preserve any blank lines that are in narrative texts.

#If the narrative is not None we know that we in a narrative. If the line is the narrative
#end marker we know that we have not only finished reading the narrative but that we have also
#finished reading all the data for the current incident. NOW in this case, we put the 
#narrative text into the data dictionary (having removed the indentation with the 
#textwrap.dedent() function), and providing we have the nine pieces of data we need, we
#create a new incident and store it in the dictionary. Then we clear the data dictionary and 
#reset the narrative variable ready for the next record. On the other hand, if the line is not
#the narrative end marker, we append it to the narrative -- including the newline that was
#stripped off at the beginning.
                
                elif (not data and line[0] == "[" and line[-1] == "]"):
                    data["report_id"] = [1:-1]

#If the narrative is None then we are at either a new report ID or are reading some other
#data. We could be at a new report ID only if the data dictionary is empty (b/c it starts
#that way and b/c we clear it after reading each incident), and if the line begins with [ and
#ends with ]. If this is the case, we put the report ID into the dictionary. This means
#that this elif condition will not be True again until the data dictionary is next cleared.

                elif "=" in line:
                    key, value = line.split("=", 1)
                    if key == "date":
                        data[key] = datetime.datetime.strptime(value, "%Y-%m-%d").date()
                    elif key == "pilot_percent_hours_on_type":
                        data[key] = float(value)
                    elif key == "pilot_total_hours":
                        data[key] = int(value)
                    elif key == "midair":
                        data[key] = bool(int(value))
                    else:
                        data[key] = value
                elif line == ".NARRATIVE_START.":
                    narrative = ""
                else:
                    raise KeyError("parsing error on line {0}".format(lino))

#If we are not in a narrative and are not reading a new report ID, there are only
#three more possibilities: we are reading key=value items, we are at a narrative start marker,
#or something has gone wrong.

#In the case of reading a line of key=vale data, we split the line on the first = character,
#specifiing a maximum of one split -- this means that the value can safely include = characters.
#All the data read is in the form of Unicode strings, so for date, numeric, and Boolean data
#types we must convert the value string accordingly.

#For dates we use the datetime.datetime.strptime() function ("string parse time") which
#takes a format string and returns a datetime.datetime object. We have used a format
#string that matches the ISO 8601 date format, and use datetime.datetime.date() to retrieve
#a datetime.date object from the resultant datetime.datetime object, since we want only a date
#and not a date/time. We rely on Python's built-in functions, float() and int(), for the
#numeric conversions. Note, though that, for example, int("4.8") will raise a ValueError;
#if we want to be more liberal in accepting integers, we could use
int(float("4.0")), #or if we wanted to round rather than truncate we use:
round(float("4.0")).
#To get a bool is slightly subtler -- for example, bool("0") returns True (a nonempty string
#is True), so we must first convert the string to an int.

#Invalid, missing, or out-of-range values will always cause an exception to be raised. If
#any of the conversions fail they raise a ValueError exception. And if any values are out
#of range an IncidentError exception will be raised when the data is used to create a
#corresponding Incident object.

#If the line does not contain an = character, we check to see whether we have read the
#narrative start marker. If we have, we set the narrative variable to be an empty string.
#This means that the first if condition will be True for subsequent lines, as least until
#the narrative end marker is read.

#If none of the if or elif conditions is True then an error has occurred, so in the
#final else clause we raise a KeyError exception to signify this.

                return True
            except (EnvironmentError, ValueError, KeyError, IncidentError) as err:
                print("{0}: import error: {1}".format(os.path.basename(sys.argv[0]), err))
                return False
            finally:
                if fh is not None:
                    fh.close()
#After reading all the lines, we return True to the caller -- unless an exception occurred,
#in which case the except block catches the exception, prints an error message for the user,
#and returns False. And not matter what, if the file was opened, it is closed at the end.




#Reminder of topics<===========
CHAPTER 7 File Handling

Writing and Reading Binary Data
    Pickles with Optional Compression
    Raw Binary Data with Optional Compression 
Writing and Parsing Text Files
    Writing Text
    Parsing Text 
    Parsing Text Using Regular Expressions
Writing and Parsing XML Files 
    Element Trees 
    DOM (Document Object Model)
    Manually Writing XML 
    Parsing XML with SAX (Simple API for XML)
Random Access Binary Files 
    Generic BinaryRecordFile Class 
    Example: BikeStock Module's Classes     '
Summary
Exercises 
#1) 
#2)
#3)


#CODE LISTING HERE
BikeStock.py
BikeStock_ans.py
BinaryRecordFile.py
BinaryRecordFile_ans.py
convert-incidents.py
xdump.py 



===============
    Parsing Text Using Regular Expressions
===============
#Readers unfamilier with regular expressions ("regrexes") are recommended to read
#Chapter 13 before reading this section.

#Using regular expressions to parse text files can often produce shorter code than
#doing everything by hand as we did in the previous subsection, but it can be more 
#difficult to provide good error reporting. We will look at the 
import_text_regex() #method in two parts, first looking at the regular expressions 
#and then at the parsing. But we first omit the except and finally blocks since
#they have nothing new to teach us.

#BASIC CODE
        def import_text_regex(self, filename):
            incident_re = re.compile()
            key_value_re = re.compile()

#DETAIL CODE
        def import_text_regex(self, filename):
            incident_re = re.compile(
                                    r"\[(?P<id>[^]]+)\](?P<keyvalues>.+?)"
                                    r"^\.NARRATIVE_START\.$(?P<narrative>.*?)"
                                    r"^\.NARRATIVE_END\.$",
                                    re.DOTALL|re.MULTILINE)
            key_value_re = re.compile(r"^\s*(?P<key>[^=]+?)\s*=\s*"
                                      r"()\s*$", re.MULTILINE)

#The regular expressions are written as raw strings. This saves us from having
#to double each backslash (writing each \ as \\) -- for example, without using
#raw strings the second regular expression would have to be written as
"^\\s*(?P<key>[^=]+?\\s*(?P<value>.+?)\\s*$"
#In this book we always use raw strings for regular expressions.

#The FIRST regular expression, incident_re, is used to capture the entire incident
#record. One effect of this is that any spurious text BETWEEN records will not be
#noticed. This regular expression really has two parts:
#First part is 
#                 \[(?P<id>[^]]+)\](?P<keyvalues>.+?)                                     
#which matches a [ then matches and captures into the id match group as many non ] characters
#as it can, then matches a ] (so this gives us the report ID),
#and then matches as few (as but at least one) of any characters into the keyvalues match group 
#(including newlines b/c of the re.DOTALL flag), into the keyvalues match group.
#The characters matched for the 
keyvalues #match group are the miniumum necessary to take us
#to the second part of the regular expression.

#The SECOND part of the first regular expression is 
#                ^\.NARRATIVE_START\.$(?P<narrative>.*?)^\.NARRATIVE_END\.$
#and this matches the literal text .NARRATIVE_START., then as few characters as possible
#which are captured into the NARRATIVE MATCH GROUP, and then literal text .NARRATIVE_END.,
#at the end of the incident record. The re.MULTILINE flag means that in this regular
#expression ^ matches at the start of every line (rather than just at the start of the string),
#and $ matches at the end of every line (rather than just at the end of every string), so the
#narrative start and end markers are matched only at the start of lines.

#The second regular expression, key_value_re, is used to capture key=value lines, and it
#matches at the start of every line in the text it is given to match against, where
#the lines begins with any amount of whitespace (including none), followed by non-=
#characters which are captured into the key match group, followed by an = character,
#followed by all the remaining characters in the line (excluding any leading 
#or trailing whitespace), and captures them into the
value #match group.

#The fundamental logic used to parse the file is the same as we used for the manual text
#parser that we covered in the previous subsection, only this time we extract incident
#records and incident data within those records using regular expressions rather 
#than reading line by line.

            fh = None
            try:
                fh = open(filename, encoding="utf8")
                self.clear()
                for incident_match in incident_re.finditer(fh.read()):
                    data = {}
                    data["report_id"] = incident_match.group("id")
                    data["narrative"] = textwrap.dedent(incident_match.group("narrative")).strip()
                    keyvalues = incident_match.group("keyvalues")
                    for match in key_value_re.finderiter(keyvalues):
                        data[match.group("key")] = match.group("value")
                    data["data"] = datetime.datetime.strptime(data["date"], "%Y-%m-%d").date()
                    data["pilot_percent_hours_on_type"] = (float(data["pilot_percent_hours_on_type"]))
                    data["pilot_total_hours"] = int(data["pilot_total_hours"])
                    data["midair"] = bool(int(data["midair"]))
                    if len(data) != 9:
                        raise IncidentError("missing data")
                    incident = Incident(**data)
                    self[incident.report_id] = incident 
                return True

#The re.finditer() method returns an iterator which produces each nonoverlapping match
#in turn. We create a data dictionary to hold one incident's data as we have done before, but
#this time we get the report ID and narrative text from each match of the incident_re
#regular expression. We then extract all the key=value strings in one go using the
keyvalues #match group, and apply the key_value_re regular expressions's re.finditer() method
#to iterate over each individual key=value line. For each (key, value) pair found, we put
#them in the data dictionary -- so all the values go in as strings. Then, for those values
#which should not be strings, we replace them with a value of the appropriate type using
#the same string conversions that we used when parsing the text manually.

#We have added a check to ensure that the data dictionary has nine items b/c if an incident
#record is corrupt, the key_value.finditer() iterator might match TOO MANY or TOO FEW 
#key=value lines. The end is the same as before -- we create a new Incident object and
#put it in the incident's dictionary, then return True. If anything went wrong, the except
#suite will issue a suitable error message and return False, and the finally suite will close
#the file.

#One of the things that makes both the manual and regular expression text parsers as short
#and straightforward as they are is Python's exception handling. The parsers dont have to
#check any of the conversions of strings to dates, numbers, or Booleans, and they dont
#have to do any range checking (as the Incident class does that all). If any of these
#things fail, an exception will be raised, and we handle all the exceptions neatly in 
#one place at the end. Another benefit of using exception handling rather than explicit
#checking is that the code scales well -- even if the record format changes to include
#more data items, then error handling code does NOT need to grow any larger.



#Reminder of topics<===========
CHAPTER 7 File Handling

Writing and Reading Binary Data
    Pickles with Optional Compression
    Raw Binary Data with Optional Compression 
Writing and Parsing Text Files
    Writing Text
    Parsing Text 
    Parsing Text Using Regular Expressions
Writing and Parsing XML Files 
    Element Trees 
    DOM (Document Object Model)
    Manually Writing XML 
    Parsing XML with SAX (Simple API for XML)
Random Access Binary Files 
    Generic BinaryRecordFile Class 
    Example: BikeStock Module's Classes     '
Summary
Exercises 
#1) 
#2)
#3)


#CODE LISTING HERE
BikeStock.py
BikeStock_ans.py
BinaryRecordFile.py
BinaryRecordFile_ans.py
convert-incidents.py
xdump.py 



===============
Writing and Parsing XML Files 
    Element Trees 
    DOM (Document Object Model)
    Manually Writing XML 
    Parsing XML with SAX (Simple API for XML)
===============

===============
Writing and Parsing XML Files 
===============

#Some programs use an XLM file format for all the data they handle, whereas others
#use XML as a convenient import/export format. The ability to import and export XML is 
#useful and is always worth considering even if a program's main format is a text or 
#binary format.

#Out of the box, Python offers three ways to writing XML files:
#(1) manually writing the XML, (2) creating an element tree and using its write() method
#and (3) creating a DOM and using its write() method.

#Similarly for reading and parsing XML files, there are FOUR out of the box approaches:
#(1) manually reading and parsing the XML (not recommended and not covered here -- it can
#be quite difficult to handle some of the more obscure and advanced details correctly),
#(2) using an element tree, (3) using a DOM, or (4) using a SAX parser.

#Also, there are third party XML libraries available, such as lxml library (see Chapter 5)


#The aircraft incident XML format is shown here. In this section, we will show how to 
#write this format manually and how to write it using an element tree and a DOM, as well
#as how to read and parse this format using the element tree, DOM, and SAX parsers. If you
#dont care which approach is used to read or write the XML, you could just read the Element
#Trees subsection that follows, and then skip the chapter's final section (Random Access
#Binary Files).

#Figure 7.5 an example XML format aircraft incident record in context
################################################ Figure 7.5
 
<?xml version="1.0" encoding="UTF-8"?>
<incidents>
<incident report_id="20070222008099G" date="2007-02-22"
    aircraft_id="80342" aircraft_type="CE-172-M"
    pilot_percent_hours_on_type="9.09090909091"
    pilot_total_hours="440" midair="0">
<airport>BOWERMAN</airport>
<narrative>
ON A GO-AROUND FROM A NIGHT CROSSWIND LANDING ATTEMPT THE AIRCRAFT HIT
A RUNWAY EDGE LIGHT DAMAGING ONE PROPELLER.
</narrative>
</incident>
<incident>
    ...
</incident>
     :
</incidents>
################################################ 



#Reminder of topics<===========
CHAPTER 7 File Handling

Writing and Reading Binary Data
    Pickles with Optional Compression
    Raw Binary Data with Optional Compression 
Writing and Parsing Text Files
    Writing Text
    Parsing Text 
    Parsing Text Using Regular Expressions
Writing and Parsing XML Files 
    Element Trees 
    DOM (Document Object Model)
    Manually Writing XML 
    Parsing XML with SAX (Simple API for XML)
Random Access Binary Files 
    Generic BinaryRecordFile Class 
    Example: BikeStock Module's Classes     '
Summary
Exercises 
#1) 
#2)
#3)


#CODE LISTING HERE
BikeStock.py
BikeStock_ans.py
BinaryRecordFile.py
BinaryRecordFile_ans.py
convert-incidents.py
xdump.py 



===============
    Element Trees 
===============

#Writing the data using an element tree is done in two phases:
#(1)an element tree representing the data must be created, 
#(2)the tree must be written to a file.
#Some programs might use the element tree as their data structure, in which case they 
#already have the tree and can simply write out the data. We will look at the 
#export_xml_etree() method in two parts:

#BASIC CODE
    def export_xml_etree(self, filename):
        root = 
        for incident in self.values():
            element = 
            airport = 
            airport.text = 
            narrative = 
            narrative.text = 
            root.append()
        tree = 

#DETAIL CODE
    def export_xml_etree(self, filename):
        root = xml.etree.ElementTree.Element("incidents")
        for incident in self.values():
            element = xml.etree.ElementTree.Element("incident",
                      report_id=incident.report_id,
                      date=incident.date.isoformat(),
                      aircraft_id=incident.aircraft_id,
                      aircraft_type=incident.aircraft_type,
                      pilot_percent_hours_on_type=str(incident.pilot_percent_hours_on_type),
                      pilot_total_hours=str(incident.pilot_total_hours),
                      midair=str(int(incident.midair()))
            airport = xml.etree.ElementTree.SubElement(element, "airport")
            airport.text = incident.airport.strip()
            narrative = xml.etree.ElementTree.SubElement(element, "narrative")
            narrative.text = incident.narrative.strip()
            root.append(element)
        tree = xml.etree.ElementTree.ElementTree(root)

#We begin by creating the root element (<incidents>). Then we iterate over all the 
#incident records. For each incident record, we create an element (<incident>) to
#hold the data for the incident, and use keyword arguments to provide the attributes.
#All the attributes must be text, so we convert the date, numeric, and Boolean data 
#items accordingly. We dont have to worry about escaping "&", "<", and ">" (or about
#quotes in attribute values) since the element tree module (and the DOM and SAX modules)
#automatically take care of these details.

#Each <incident> has two subelements, one holding the airport name and the other
#the narrative text. When subelements are created we must provide the parent element
#and the tag name. An element's read/write test attribute is used to hold its text.

#Once the <incident> has been created with all its attributes and its <airport> and
#<narrative> subelements, we add the incident to the heirachy's root (<incidents>)
#element. At the end, we have a heirachy of elements that contain all the incident
#record data, which we then trivally convert into an element tree.

        try:
            tree.write(filename, "UTF-8")
        except EnvironmentError as err:
            print("{0}: import error: {1}".format(os.path.basename(sys.argv[0]), err))
            return False
        return True

#Writing the XML to represent an entire element tree is simply a matter of telling
#the tree to write ITSELF to the given file using the given encoding.

#Up to now when we have specified an encoding we have almost always used the string "utf8".
#This workds fine for Python's built-in open() function which can accept a wide range of
#encodings and a variety of names for them, such as "UTF-*", "UTF8", "utf-8", and "utf8".
#But for XML files, the encoding name can be only one of the official names, so "utf8" is NOT
#acceptable, which is why we have used "UTF-8".
#See www.w3.org/TR/2006/REC-xml11-20060816/#NT-EncodingDecl and 
#www.iana.org/assignments/character-sets for information about XML encodings.

#Reading an XML file using an element tree is not much harder than writing one. Again, there
#are two phases: (1) we read and parse the XML file, and then (2) we traverse the resultant
#element tree to read off the data to populate the incidents dictionary. Again this second
#phase is not necessary if the element tree itself is being used as the in-memory data store.
BOOKMARK HERE TOPIC in-memory data store
#Here is the 
import_xml_etree() #method, split into two parts:

    def import_xml_etree(self, filename):
        try:
            tree = xml.etree.ElementTree.parse(filename)
        except (EnvironmentError, xml.parsers.expat.ExpatError) as err:
            print("{0}: import error: {1}".format(os.path.basename(sys.argv[0]), err))
            return False

#By default, the element tree parser uses the expat XML parser under the hood which is
#why we must be ready to catch expat exceptions.

        self.clear()
        for element in tree.findall("incident"):
            try:
                data = {}
                for attribute in ("report_id", "date", "aircraft_id", "aircraft_type", "pilot_percent_hours_on_type", "pilot_total_hours"):
                    data[attribute] = element.get(attribute)
                data["date"] = datetime.datetime.strptime(data["date"], "%Y-%m-%d").date()
                data["pilot_percent_hours_on_type"] = (float(data[pilot_percent_hours_on_type]))
                data["pilot_total_hours"] = int(data[pilot_total_hours])
                data["midair"] = bool(int(data["midair"]))
                data["airport"] = element.find("airport").text.strip()
                narrative = element.find("narrative").text
                data["narrative"] = (narrative.strip() if narrative is not None else "")
                incident = Incident(**data)
                self[incident.report_id] = incident
            except (ValueError, LookupError, IncidentError) as err:
                print("{0}: import error: {1}".format(os.path.basename(sys.argv[0]), err))
                return False
        return True

#Once we have the element tree we can iterate over every <incident> using the 
xml.etree.ElementTree.findall() #method. Each incident is returned as an xml.etree.Element
#object. We use the same technique for handling the element attributes as we did in the
#previous section's import_text_regex() method -- first we store all the value in the data
#dictionary, and then we convert those values which are dates, numbers, or Booleans to the
#correct type. For the airport and narrative subelements, we use the 
xml.etree.Element.find() #method to find them and read their text attributes. If a text
#element has no text, its text attribute will be None, so we must account for this when reading 
#the narrative text element since it might be empty. In all cases, the attribute values and text
#returned to us do not contain XML escapes since they are automatically unescaped.

#As with all the XML parsers used to process aircraft incident data, an exception will occur
#if the aircraft or narrative element is missing, or if one of the attributes is missing, or
#if one of the conversions fails, or if any of the numeric data is out of range -- this ensures
#that invalid data will cause parsing to stop and for an error message to be output. The code
#at the end for creating and storing incidents and for handling exceptions is the same
#as we have seen before.




#Reminder of topics<===========
CHAPTER 7 File Handling

Writing and Reading Binary Data
    Pickles with Optional Compression
    Raw Binary Data with Optional Compression 
Writing and Parsing Text Files
    Writing Text
    Parsing Text 
    Parsing Text Using Regular Expressions
Writing and Parsing XML Files 
    Element Trees 
    DOM (Document Object Model)
    Manually Writing XML 
    Parsing XML with SAX (Simple API for XML)
Random Access Binary Files 
    Generic BinaryRecordFile Class 
    Example: BikeStock Module's Classes     '
Summary
Exercises 
#1) 
#2)
#3)


#CODE LISTING HERE
BikeStock.py
BikeStock_ans.py
BinaryRecordFile.py
BinaryRecordFile_ans.py
convert-incidents.py
xdump.py 


===============
    DOM (Document Object Model)
===============

#The DOM is a standard API for representing and manipulating an XML document in memory.
#The code for creating a DOM and writing it to a file, and for parsing an XML file
#using a DOM, is structurally very similar to the element tree code, only slightly longer.

#We will begin by reviewing the export_xml_dom() method in two parts. This method works in
#two phases: (1) a DOM is created to reflect the incident data, and then (2) the DOM is
#written out to a file. Just as with an element tree, some programs might use the DOM as 
#their data structure, in which case they can simply write out the data.

    def export_xml_dom(self, filename):
        dom = xml.dom.minidom.getDOMImplementation()
        tree = dom.createDocument(None, "incidents", None)
        root = tree.documentElement
        for incident in self.values():
            element = tree.createElement("incident")
            for attribute, value in (
                                    ("report_id", incident.report_id),
                                    ("date", incident.date.isoformat()), 
                                    ("aircraft_id", incident.aircraft_id), 
                                    ("aircraft_type", incident.aircraft_type), 
                                    ("pilot_percent_hours_on_type", str(incidet.pilot_percent_hours_on_type)), 
                                    ("pilot_total_hours", str(incident.pilot_total_hours)), 
                                    ("midair", str(int(incident.midair))): 
                element.setAttribute(attribute, value)
            for name, text in (("airport", incident.airport), ("narrative", incident.narrative)):
                text_element = tree.createTextNode(text)
                name_element = tree.createElement(name)
                name_element.appendChild(text_element)
                element.appendChild(name_element)
            root.appendChild(element)

#This method begins by gettting a DOM implementation. By default, the implementation
#is provided by the expat XML parser. The xml.dom.minidom module provides a simplier and
#smaller DOM implementation than that provided by the xml.dom module, although the objects
#it uses are from the xml.dom module. 
NOTE #Once we have a DOM implementation, we can create a document. THe first argument to
xml.dom.DOMImplementation.createDocument() #is the namespace URI which we dont need, so 
#we pass None; the second argument is a qualified name (the tag name for the root element),
#and the third argument is the document type, and again we pass None since we dont have a
#document type. Having gotten the tree that represents the document, we now retrieve the 
#root element and then proceed to iterate over all the incidents.

#For each incident, we create an <incident> element, and for each attribute, we want the
#incident to have we call setAttribute() with the attribute's name and value. Just as with
#the element tree, we dont have to worry about escaping "&", "<", and ">" (or about quotes
#in attribute values). For the airport and narrative text elements we must create a text 
#element's parent -- we then add the normal element (and the text element it contains) to the
#current incident element. With the incident element complete, we add it to the root.

        fh = None
        try:
            fh = open(filename, "w", encoding="utf8")
            tree.writexml(fh, encoding="UTF-8")
            return True

#We have omitted the except and finally blocks since they are the same as one we have
#already seen. What this piece of code makes clear is the difference between the encoding
#string used for the built-in open() function and the encoding string used XML files, as
#we discussed earlier.

#Importing an XML document into a DOM is similar to importing into an element tree, but
#like exporting, it requires more code. We will look at the import_xml_dom() function
#in three parts: starting with the def line and the nested get_text() function.

    def import_xml_dom(self, filename):

        def get_text(node_list):
            text = []
            for node in node_list:
                if node.nodeType == node.TEXT_NODE:
                    text.append(node.data)
            return "".join(text).strip()

#The get_text() function iterates over a list of nodes (eg a node's child nodes),
#and for each one that is a text node, it extracts the node's text and appends it to
#a list of texts. At the end the function returns all the text it has gathered as a
#single string, with whitespace stripped from both ends.

        try:
            dom = xml.dom.minidom.parse(filename)
        except (EnvironmentError, xml.parsers.expat.ExpatError) as err:
            print("{0}: import error: {1}".format(os.path.basename(sys.argv[0]), err))
            return False

#Parsing an XML file into a DOM is easy since the module does all the hard work for
#us, but we must be ready to handle expat error since just like an element tree, the
#expat XML parser is the default parser used by the DOM classes under the hood.

        self.clear()
        for element in dom.getElementsByTagName("incident"):
            try:
                data = {}
                for attribute in ("report_id", "date", "aircraft_id", "aircraft_type", 
                                  "pilot_percent_hours_on_type", "pilot_total_hours",
                                  "midair"):
                    data[attribute] = element.getAttribute(attribute)
                data["date"] = datetime.datetime.strptime(data["date"], "%Y-%m-%d"). date() 
                data["pilot_percent_hours_on_type"] = (float(data["pilot_percent_hours_on_type"]))
                data["pilot_total_hours"] = int(data["pilot_total_hours"])
                data["midair"] = bool(int(data["midair"]))
                airport = element.getElementsByTagName("airport")[0]
                data["airport"] = get_text(airport.childNodes)
                narrative = element.getElementsByTagName("narrative")[0]
                data["narrative"] = get_text(narrative.childNodes)
                incident = Incident(**data)
                self[incident.report_id] = incident 
            except (ValueError, LookupError, IncidentError) as err:
                print("{0}: import error: {1}".format(os.path.basename(sys.arv[0]), err))
                return False
        return True

#Once the DOM exists, we clear the current incidents data and iterate over all the 
#incident tags. For each one we extract the attributes, and for date, numeric, and Booleans
#we convert them to the correct types in exactly the same way as we did when using an 
#element tree. The only really significant difference beween using a DOM and an element tree
#is in the handling of text nodes. We use the 
xml.dom.Element.getElementsByTagName() #method
#to get the child elements with the given tag name -- in the cases of <airport> and
#<narrative> we know there is always one of each, so we take the first (and only) child
#element of each type. Then we use the nested get_text() function to iterate over these
#tags' child nodes to extract their texts.

#As usual, if any errors occurs we catch the relevant exception, print an error message
#for the user, and return False.

#The differences in approach between DOM and element tree are not great, and since they
#both use the same expat parser under the hood, they are both reasonably fast.






#Reminder of topics<===========
CHAPTER 7 File Handling

Writing and Reading Binary Data
    Pickles with Optional Compression
    Raw Binary Data with Optional Compression 
Writing and Parsing Text Files
    Writing Text
    Parsing Text 
    Parsing Text Using Regular Expressions
Writing and Parsing XML Files 
    Element Trees 
    DOM (Document Object Model)
    Manually Writing XML 
    Parsing XML with SAX (Simple API for XML)
Random Access Binary Files 
    Generic BinaryRecordFile Class 
    Example: BikeStock Module's Classes     '
Summary
Exercises 
#1) 
#2)
#3)


#CODE LISTING HERE
BikeStock.py
BikeStock_ans.py
BinaryRecordFile.py
BinaryRecordFile_ans.py
convert-incidents.py
xdump.py 


===============
    Manually Writing XML 
===============

#Writing a preexisting element tree or DOM as an XML document can be done with a 
#single method call. But if our data is not already in one of these forms, we
#must create an element tree or DOM first, in which case it may be more convenient
#to simply write out our data directly.

#When writing XML files, we must make sure that we properly escape text and attribute
#values, and that we write a well-formed XML document. Here is the
export_xml_manual() #method for writing out the incidents in XML:

    def export_xml_manual(self, filename):
        fh = None
        try:
            fh = open(filename, "w", encoding="utf8")
            fh.write('<?xml version="1.0" encoding="UTF-8"?>\n')
            fh.write("<incidents>\n")
            for incident in self.values():
                fh.write('<incident report_id={report_id} '
                         'date="{0.date!s}" '
                         'aircreaft_id={aircraft_id} '
                         'aircraft_type={aircraft_type} '
                         'pilot_percent_hours_on_type="{0.pilot_percent_hours_on_type}" '
                         'pilot_total_hours="{0.pilot_total_hours}" '
                         'midair="{0.midair:d}"\n'
                         '<airport>{airport}</airport>\n'
                         '<narrative>\n{narrative}\n</narrative>\n'
                         '</incident>\n'
                         .format(incident,
                        report_id=xml.sax.saxutils.quoteattr(incident.report_id),
                        aircraft_id=xml.sax.saxutils.quoteattr(incident.aircraft_id),
                        aircraft_type=xml.sax.saxutils.quoteattr(incident.aircraft_type),
                        airport=xml.sax.saxutils.escape(incident.aircraft),
                        narrative="\n".join(textwrap.wrap(xml.sax.saxutils.escape(incident.narrative.strip()), 70))))
                fh.write("</incidents>\n>")
                return True

#As we have often done in this chapter, we have omitted the except and finally blocks.

#We write the file using the UTF-8 encoding and must specify this to the built-in open()
#function. Strictly speaking, we dont have to specify the encoding in the <?xml?> declaration
#since UTF-8 is the default encoding, but we prefer to be explicit. We have chosen to
#quote all the attribute values using double quotes ("), and so for convenience have used
#single quotes to quote the string we put in the incidents in to avoid the need to escape
#the quotes.

#The sax.saxutils.quoteattr() function is similar to the sax.saxutils.escape() function we
#use for XML text in that it properly escapes "&", "<", and ">" characters. In addition,
#it escapes quotes (if necessary), and returns a string that has quotes around it ready for
#use. This is why we have not needed to put quotes around the report ID and other string
#attribute values.

#The newlines we have inserted and the text wrapping for the narrative are purely cosmetic.
#They are designed to make the file easier for humans to read and edit, but they could just
#as easily be omitted.

#Writing the data in HTML format is not much different from writing in XML. The 
convert-incident.py program #includes the 
export_html() #function as a simple example of this, although we wont reveiew it 
#here b/c it does NOT really show anything new.





#Reminder of topics<===========
CHAPTER 7 File Handling

Writing and Reading Binary Data
    Pickles with Optional Compression
    Raw Binary Data with Optional Compression 
Writing and Parsing Text Files
    Writing Text
    Parsing Text 
    Parsing Text Using Regular Expressions
Writing and Parsing XML Files 
    Element Trees 
    DOM (Document Object Model)
    Manually Writing XML 
    Parsing XML with SAX (Simple API for XML)
Random Access Binary Files 
    Generic BinaryRecordFile Class 
    Example: BikeStock Module's Classes     '
Summary
Exercises 
#1) 
#2)
#3)


#CODE LISTING HERE
BikeStock.py
BikeStock_ans.py
BinaryRecordFile.py
BinaryRecordFile_ans.py
convert-incidents.py
xdump.py 



===============
    Parsing XML with SAX (Simple API for XML)
===============
#Unlike the element tree and DOM, which represent an entire XML document in memory, SAX
#parsers work incrementally, which can potentially be both faster and less memory-hungry.
#A performance advantage can NOT be assumed, however, especially since both the element
#tree and DOM use the fast expat parser.

#SAX parsers work by announcing "parsing events" when they encounter start tags, end tags,
#and other XML elements. To be able to handle those events that we are interested in we
#must create a suitable handler class, and provide certain predefined methods which are
#called when matching parsing events take place. The most commonly implemented handler is
#a content handler, although it is possible to provide error handlers and other handlers
#if we want finer control.

#Here is the complete import_xml_sax() method. It is very short b/c most of the work
#is done by the custom IncidentSaxHandler class:

    def import_xml_sax(self, filename):
        fh = None
        try:
            handler = IncidentSaxHandler(self)
            parser = xml.sax.make_parser()
            parser.set ContentHandler(handler)
            parser.parse(filename)
            return True
        except (EnvironmentError, ValueError, IncidentError, xml.sax.SAXParseException) as err:
            print("{0}: import error: {1}".format(os.path.basename(sys.argv[0]), err))
            return False

#We create the one handler we want to use and then we create a SAX parser and set its
#content handler to be the one we have created. Then we give the filename to the
#parser's parse() method and return True if no parsing errors occurred.

#We pass self (ie this IncidentCollection dict subclass) to the 
custom IncidentSaxHandler #class's initializer. The handler clears the old incidents away 
#and then builds up a dictionary of incidents as the file is parsed. Once the parse is complete 
#the dictionary contains all the incidents that have been read.

class IncidentSaxHandler(xml.sax.handler.ContentHandler):

    def __init__(self,incidents):
        super()__init__()
        self.__data = {}
        self.__text = ""
        self.__incidents = incidents 
        self.__incidents.clear()

#Custom SAX handler classes must inherit the appropriate base class. This ensures that for
#any methods we dont reimplment (b/c we are not interested in the parsing events they
#handle), the base class version will be called -- and will safely do nothing.

#We start by calling the base class's initializer. This is generally good practice for all
#subclasses, although is it not necessary (though harmless) for direct object subclasses.
#The self.__data dictionary is used to keep one incident's data, the self.__text string
#is used to keep the text of an airport name or of a narrative depending on which we are
#reading, and the self.__incidents dictionary is an object reference to the 
#IncidentColletion dictionary which the handler updates directly. (An alternative design
#would be to have an independent dictionary inside the handler and to copy it to the 
#IncidentCollection at the the end using dict.clear() and then dict.update().)

    def startElement(self, name, attributes):
        if name == "incident":
            self.__data = {}
            for key, value in attributes.items():
                if key =="date":
                    self.__data[key] = datetime.datetime.strptime(value, "%Y-%m-%d").date()
                elif key == "pilot_percent_hours_on_type":
                    self.__data[key] = float(value)
                elif key == "pilot_total_hours":
                    self.__data[key] = int(value)
                elif key == "midair":
                    self.__data[key] = bool(int(value))
                else:
                    self.__data[key] = value
        self.__text = ""

#Whenever a start tag and its attributes are read, the 
xml.sax.handler.ContentHandler.startElement() #method is called with the tag name and the
#tag's attributes. In the case of an aircraft incident XML file, the start tags are
<incidents> #, which we ignore; 
<incident> #, whose attributes we use to populate some of the
self.__data dictionary #;  and 
<airport> #and 
<narrative> #, both of which we ignore. We always clear the 
self.__text #string when we get a start tag b/c no text tags are nested in the
#aircraft incident XML file format.

#We dont do any exception handling in the IncidentSaxHandler class. If an exception occurs,
#it will be passed up to the caller, in the case the import_xml_sax() method, which will
#catch it and output a suitable error message.

        def endElement(self, name):
            if name == "incident":
                if len(self.__data) != 9:
                    raise IncidentError("missing data")
                incident = Incident(**self.__data)
                self.__incidents[incident.report_id] = incident
            elif name in frozenset({"airport", "narrative"}):
                self.__data[name] = self.__text.strip()
            self.__text = ""

#When an end tag is read the xml.sax.handler.ContentHandler.endElement() method is called.
#If we have reached the end of an incident we should have all the necessary data, so we create 
#a new Incident object and add it to the incidents dictionary. If we have reached the end 
#of a text element, we add an item to the self.__data dictionary with the text that has 
#been accumulated so far. At the end we clear the self.__text string ready for its next use. 
#(Strictly speaking, we dont have have to clear it, since we clear it when we get a start tag, 
#but clearing it could make a difference in some XML formats, for example, where tags 
#can be nested.)

        def characters(self, text):
            self.__text += text

#When the SAX parser reads text it calls the xml.sax.handler.ContentHandler.characters() method
#There is no guarantee that this method will be called just once with all the text; the text
#might come in chunks. This is why we simply use the method to accumulate text, and 
#actually put the text into the dictionary only when the relevant end tag is reached. (A more
#efficient implementation would have self.__text be a list with the body of this method being 
self.__text.append(text) #and with the other methods adapted accordingly.)

#Using the SAX API is very different from using element tree or DOM, but it is just
#as effective. We can provide other handlers, and can reimplement additional methods 
#in the content handler to get as much control as we like. The SAX parser itself does
#not maintain any representation of the XML document -- this makes SAX ideal for reading
#XML into our own custom data collections, and also means that there is no SAX "document" to
#write out as XML, so for writing XML we must use one of the approaches described earlier
#in this section.




#Reminder of topics<===========
CHAPTER 7 File Handling

Writing and Reading Binary Data
    Pickles with Optional Compression
    Raw Binary Data with Optional Compression 
Writing and Parsing Text Files
    Writing Text
    Parsing Text 
    Parsing Text Using Regular Expressions
Writing and Parsing XML Files 
    Element Trees 
    DOM (Document Object Model)
    Manually Writing XML 
    Parsing XML with SAX (Simple API for XML)
Random Access Binary Files 
    Generic BinaryRecordFile Class 
    Example: BikeStock Module's Classes     '
Summary
Exercises 
#1) 
#2)
#3)


#CODE LISTING HERE
BikeStock.py
BikeStock_ans.py
BinaryRecordFile.py
BinaryRecordFile_ans.py
convert-incidents.py
xdump.py 



===============
Random Access Binary Files 
    Generic BinaryRecordFile Class 
    Example: BikeStock Module's Classes     '
===============

===============
Random Access Binary Files 
===============

#In the earlier sections we worked on the basis that all of a program's data
#was read into memory in one go, processed, and then all written out in go.
#Modern computers have so much RAM that this is a perfectly viable approach,
#even for large data sets. However, in some situations holding the data on disk
#and just reading the bits we need and writing back changes might be a better
#solution. The disk based random access approach is most easily done using a
#key-value database (a "DBM") or a full SQL database -- both are covered in Chapter 12
#but in this section we will show how to handle random access files by hand.

#We first present the 
BinaryRecordFile.BinaryRecordFile #class. Instances of this class represent a 
#generic readable/writable binary file, structured as a sequence
#of fixed length records. We will then look at the 
BikeStock.BikeStock #class which holds a collection of BikeStock.Bike objects as records in a 
BinaryRecordFile.BinaryRecordFile #to see how to make use of binary random access files.

===============
    Generic BinaryRecordFile Class 
===============

#The BinaryRecordFile.BinaryRecordFile class's API is similar to a list 
#in that we can get/set/delete a record at a given index position. When a
#record is deleted, it is simply marked "deleted"; this saves having to
#move all the records that follow it up to fill the gap, and also means
#that after a deletion, all the original index positions remain valid.
#Another benefit is that a record can be undeleted simply by unmarking
#it. The price we pay for this is that deleting records does NOT save
#any disk space. We will solve this by providing methods to "compact"
#the file, eliminating deleted records (and invalidating index
#positions).

#Before reviewing the implementation, lets look at some basic usage:

    Contacts = struct.Struct("<15si")
    contacts = BinaryRecordFile.BinaryRecordFile(filename, Contact.size)

#Here we create a struct (little-endian byte order, a 15-byte string,
#and a 4-byte signed interger) that we will use to represent each 
#record. Then we create a BinaryRecordFile.BinaryRecord.File INSTANCE
#with a filename and with a record size to match the struct we are
#using. If the file exists, it will be opened with its contents left
#intact; otherwise, it will be created. In either case it will be
#opened in binary read/write mode, and once open, we can write data
#to it:

    contacts[4] = Contact.pack("Abe Baker".encode("utf8"), 762)
    contacts[5] = Contact.pack("Cindy Dove".encode("utf8"), 987)

#We can treat the file like a list using the item access operator []; here
#we assign two byte strings (byte objects, each containing an encoded string
#and an integer) at two record index positions in the file. These
#assingments will overwrite any existing content; and if the file doesnt
#already have six records, the earlier records will be created with every
#byte set to 0x00.
 
    contact_data = Contact.unpack(contacts[5])
    contact_data[0].decode("utf8").rstrip(chr(0))   #returns: 'Cindy Dove'

#Since the string "Cindy Dove" is shorter than the 15 UTF-8 characters in 
#the struct, when it is packed it is padded with 0x00 bytes at the end. So
#when we retrieve the record, the contact_data will hold the 2-tuple
#(b'CindyDove\x00\x00\x00\x00\x00' 987). To get the name, we must decode
#the UTF-8 to produce a Unicode string, and strip off the 0x00 padding bytes.

#Now that we have had a glimpse of the class in action, we are ready to review
#the code. The BinaryRecordFile.BinaryRecordFile class is in file
BinaryRecordFile.py #After the usual preliminaries the file begins with the
#definition of a couple of private byte values:

    _DELETED = b"\x01"
    _OKAY = b"\x02"

#each record starts with a "state" byte which is either _DELETED or _OKAY
#or in this case b"\x00"

#Here is the class line and the initializer

    class BinaryRecordFile:

        def __init__(self, filename, record_size, auto_flush=True):
            self.__record_size = record_size + 1
            mode = "w+b" if not os.path.exists(filename) else "r+b"
            self.__fh = open(filename, mode)
            self.auto_flush = auto_flush

#There are two different record sizes. The 
BinaryRecordFile.record_size #is the one set by the user and is the record 
#size from the user's point of view. The PRIVATE
BinaryRecordFile.__record_size #is the REAL record size and includes the state byte.

#We are careful not to truncate the file when we open it if it already exists (by 
#using a mode of "r+b"), and to create it if it does not exist (by using a mode of "w+b")
Note #the "+" part of the mode string is what signifies reading AND writing. If the 
BinaryRecordFile.auto_flush #Boolean is True, then the file is flushed before
#every read and after every write.

        @property
        def record_size(self):
            return self.__record_size - 1

        @property 
        def name(self):
            return self.__fh.name 

        def flush(self):
            self.__fh.flush()

        def close(self):
            self.__fh.close()

#We have made the record size and filename INTO READ-ONLY properties. The record
#size we report to the user is the one they requested and matches their records.
#The flush and close methods simply delegate to the file object.

        def __setitem__(self, index, record):
            assert isinstance(record, (byte, bytearray)), "binary data required"
            assert len(record) == self.record_size, ("record must be exactly {0} bytes".
                format(self.record_size))
            self.__fh.seek(index * self.__record_size)
            self.__fh.write(_OKAY)
            self.__fh.write(record)
            if self.auto_flush:
                self.__fh.flush()

#This method supports the brf[i] = date syntax where brf is a binary record file,
#i is a record index position, and data is a byte string. Notice that the record
#must be the same size as the size is specified when the binary record file was
#created.

#If the arguments are okay, we move the file position pointer to the first byte
#of the record -- notice that here we use the real record size, that is we account
#for the state byte. The seek() method moves the file pointer to an absolute
#byte position by default. A second argument can be given to make the movement
#relative to the current position or to the end. (The attributes and methods
#provided by file objects are listed in Tables 7.4 and 7.5).

#Since the item is being set, it obviously has not been deleted, so we write the
_OKAY #state byte, and then we write the user's binary record data. The
#binary record file does not know or care about the record structure that is
#being used -- only that records are of the right size.

#We do not check whether the index is in range. If the index is beyond the end
#of the file, the record will be written in the correct position and every byte
#between the previous end of the file and the new record will automatically
#be set to "b\x00". Such blank records are neither _OKAY nor _DELETED, so we
#can distinguish them when we need to.

        def __getitem__(self, index):
            self.__seek_to_index(index)
            state = self.__fh.read(1)
            if state != _OKAY:
                return None
            return self.__fh.read(self.record_size)

#When retrieving a record there are four cases that we must account for:
#(1) record does not exist, that is, the given index is beyond the end;
#(2) record is blank; (3) record has been deleted, (4) record is okay.
#If the record does not exist, the private __seek_to_index() method
#will raise an IndexError exception. Otherwise, it will seek to the
#byte where the record begins and we can read the state byte. If the
#state is not _OKAY, then the record must either be blank or be deleted, 
#in which case we return None; otherwise, we read and
#return the record. (Another strategy would be to raise a custom
#exception for blank or deleted records, say, BlankRecordError or
#DeletedRecordError, instead of returning None.)

        def __seek_to_index(self, index):
            if self.auto_flush:
                self.__fh.flush()
            self.__fh.seek(0, os.SEEK_END)
            end = self.__fh.tell()
            offset = index * self.__record_size
            if offset >= end:
                raise IndexError("no record at index position {0}".format(index))
            self.__fh.seek(offset)

#This is a private supporting method used by some of the other methods to
#move the file position pointer to the first byte of the record at the
#given index position. We begin by checking to see whether the given index
#is in range. We do this by seeking to the end of the file (byte offset of 0
#from the end), and using the tell() method to retrieve the byte position 
#we have seeked to.*
#*Note both Python 3.0 and 3.1 have the seek constants 
os.SEEK_SET
os.SEEK_CUR
os.SEEK_END
#Python 3.1 also has these constants in its io module (eg io.SEEK_SET).
#Back to main explanation.
#If the record's offset (index position x real record size) is at or
#after the end, then the index is out of range and we raise a suitable
#exception. Otherwise, we seek to the offset position ready for the next
#read or write.

        def __delitem__(self, index):
            self.__seek_to_index(index)
            state = self.__fh.read(1)
            if state != _OKAY:
                return
            self.__fh.seek(index * self.__record_size)
            self.__fh.write(_DELETED)
            if self.auto_flush:
                self.__fh.flush()

#First we move the file position pointer to the right place. If the index
#is in range (ie if no IndexError exception has occurred), and providing
#the record isnt blank or already deleted, we delete the record by
#overwriting its state byte with _DELETED.

        def undelete(self, index):
            self.__seek_to_index(index)
            state = self.__fh.read(1)
            if state == DELETED:
                self.__fh.seek(index * __record_size)
                self.__fh.write(_OKAY)
                if self.auto_flush:
                    self._fh.flush()
                return True 
            return False

#This method begins by finding the record and reading its state byte. If
#the record is deleted, we overwrite the state byte with _OKAY and return
#True to the caller to indicate success; otherwise (for blank or
#nondeleted records), we return False.

        def __len__(self):
            if self.auto_flush:
                self.__fh.flush()
            self.__fh.seek(0, os.SEEK_END)
            end = self.__fh.tell()
            return end // self.__record_size

#This method reports how many records are in the binary record file. It
#does this by dividing the end byte position (how many bytes are in the file)
#by the size of a record.

#We have now covered all the basic functionality offered by the
BinaryRecordFile.BinaryRecordFile #class. There is one last matter to
#consider:compacting the file to eliminate blank and deleted records.
#There are essentially two approaches we can take to this. One approach
#is to overwrite blank or deleted records with records that have higher
#record index positions so that there are no gaps, and truncating the file
#if there are any blank or deleted records at the end. The
inplace_compact() #method does this. 
#The other approach is to copy the
#nonblank nondeleted records to a temporary file and then to rename the
#temporary to the original. Using a temporary file is particulary convenient
#if we also want to make a backp. The compact() method does this.

#e will start by looking at the inplace_compact() method is two parts.

        def inplace_compact(self):
            index = 0
            length = len(self)
            while index < length:
                self.__seek_to_index(index)
                state = self.__fh.read(1)
                if state != _OKAY:
                    for next in range(index +1, length):
                        self.__seek_to_index(next)
                        state = self.__fh.read(1)
                        if state == _OKAY:
                            self[index] = self[next]
                            del self[next]
                            break
                    else:
                        break
                index += 1

#We iterate over every record, reading the state of each one in turn. If we
#find a blank or deleted record we look for the next nonblank nondeleted record
#in the file. If we find one we replace the blank or deleted record with the 
#nonblank nondeleted one and delete the original nonblank nondeleted one; 
#otherwise, we break out of the while loop entirely since we have run out
#of nonblank nondeleted records.

            self.__seek_to_index(0)
            state = self.__fh.read(1)
            if state != _OKAY:
                self.__fh.truncate(0)
            else:
                limit = None
                for index in range(len(self) - 1, 0, -1):
                    self.__seek_to_index(index)
                    state = self.__fh.read(1)
                    if state != _OKAY:
                        limit = index
                    else:
                        break
                if limit is not None:
                    self.__fh.truncate(limit * self.__record_size)
            self.__fh.flush()

#If the first record is blank or deleted, then they must all be blank
#or deleted since the previous code moved all nonblank nondeleted records
#to the beginning of the file and blank and deleted ones to the end. In
#this case we can simply untruncate the file to 0 bytes.

#If there is at least one nonblank nondeleted record, we iterate from the
#last record backward toward the first since we know that blank and
#deleted records have been moved to the end. The limit variable is set to
#the earliest blank or deleted record (or left as None if there are no
#blank or deleted records), and the ile is truncated accordingly.

#An alternative to doing the compacting in-place is to do it by copying
#to another file -- this is useful if we want to make a backup, as the
compact() #method that we will review next shows.

        def compact(self, keep_backup=False):
            compactfile = self.__fh.name + ".$$$"
            backupfile = self.__fh.name + ".bak"
            self.__fh.flush()
            self.__fh.seek(0)
            fh.open(compactfile, "wb")
            while True:
                data = self.__fh.read(self.__record_size)
                if not data:
                    break
                if data[:1] == _OKAY:
                    fh.write(data)
            fh.close()
            self.__fh.close()

            os.rename(self.__fh.name, backupfile)
            os.rename(compactfile, self.__fh.name)
            if not keep_backup:
                os.remove(backupfile)
            self.__fh = open(self.__fh.name, "r+b")

#This method creates two file, a compacted file and a backup copy of the
#original file. The compacted file starts out with the same name as the
#original but with .$$$ tacked on to the end of the filename, and 
#similarly the backup file has the original filename with .bak tacked on
#the end. We read the existing file record by record, and for those
#that are nonblank and nondeleted we write them to the compacted file.
#(Notice that we write the real record, that is, the state byte plus
#the user record, each time.)

#The line if 
data[:1] == _OKAY: #s quite subtle.
#Both the data object and the _OKAY object are of type bytes. We want to
#compare the first byte of the data object to the (1 byte) __OKAY object.
#If we take a slice of a bytes object, we get a bytes object, BUT if we
#take a single byte, say, data[0], we get an int, which is the byte's
#value. So here we compare the 1 byte slice of data (its first byte, the
#state byte) with the 1 byte _OKAY object. 
#(Another way of doing it would be to write 
if data[0] ==_OKAY[0]: #which would compare the two int values.

#At the end, we rename the original file as the backup and rename the
#compacted file as the original. We then remove the backup if 
keep_backup #is False (the default). Finally, we open the compacted file
#(which now has the original filename), ready to be read or written.

#The BinaryRecordFile.BinaryRecordFile class is quite low-level, but it 
#can serve as the basis of higher level classes that need random access
#to files of fixed-size records, we we will see in the next subsection.









-----------1st EFFORT - posted on GitHub
#!/usr/bin/env python3
#binaryrecordfile.py


"""
>>> import shutil
>>> import sys

>>> S = struct.Struct("<15s")
>>> fileA = os.path.join(tempfile.gettempdir(), "fileA.dat")
>>> fileB = os.path.join(tempfile.gettempdir(), "fileB.dat")
>>> for name in (fileA, fileB):
...    try:
...        os.remove(name)
...    except EnvironmentError:
...        pass

>>> brf = BinaryRecordFile(fileA, S.size)
>>> for i, text in enumerate(("Alpha", "Bravo", "Charlie", "Delta",
...        "Echo", "Foxtrot", "Golf", "Hotel", "India", "Juliet",
...        "Kilo", "Lima", "Mike", "November", "Oscar", "Papa",
...        "Quebec", "Romeo", "Sierra", "Tango", "Uniform", "Victor",
...        "Whisky", "X-Ray", "Yankee", "Zulu")):
...    brf[i] = S.pack(text.encode("utf8"))
>>> assert len(brf) == 26
>>> brf[len(brf) + 2] = S.pack(b"Extra at the end")
>>> assert len(brf) == 29
>>> shutil.copy(fileA, fileB)
>>> del brf[12]
>>> assert len(brf) == 29
>>> brf.compact()
>>> assert len(brf) == 26
>>> brf.close()

>>> if ((os.path.getsize(fileA) + 3 + (3 * S.size)) !=
...        os.path.getsize(fileB)):
...    print("FAIL#1: expected file sizes are wrong")
...    sys.exit()

>>> shutil.copy(fileB, fileA)
>>> if os.path.getsize(fileA) != os.path.getsize(fileB):
...    print("FAIL#2: expected file sizes differ")
...    sys.exit()

>>> for name in (fileA, fileB):
...    try:
...        os.remove(name)
...    except EnvironmentError:
...        pass

>>> filename =  os.path.join(tempfile.gettempdir(), "test.dat")
>>> if os.path.exists(filename): os.remove(filename)
>>> S = struct.Struct("<8s")
>>> test = BinaryRecordFile(filename, S.size)
>>> test[0] = S.pack(b"Alpha")
>>> test[1] = S.pack(b"Bravo")
>>> test[2] = S.pack(b"Charlie")
>>> test[3] = S.pack(b"Delta")
>>> test[4] = S.pack(b"Echo")
>>> test.inplace_compact()  # No blank or deleted
>>> test.close()
>>> os.path.getsize(filename)
45
>>> test = BinaryRecordFile(filename, S.size)
>>> len(test)
5
>>> for index in range(len(test)):
...     del test[index]
>>> test.inplace_compact()  # All blank or deleted
>>> test.close()
>>> os.path.getsize(filename)
0
>>> test = BinaryRecordFile(filename, S.size)
>>> test[0] = S.pack(b"Alpha")
>>> test[1] = S.pack(b"Bravo")
>>> test[2] = S.pack(b"Charlie")
>>> test[3] = S.pack(b"Delta")
>>> test[4] = S.pack(b"Echo")
>>> del test[2]
>>> del test[4]
>>> del test[3]
>>> test.inplace_compact()  # Blank or deleted at the end
>>> test.close()
>>> os.path.getsize(filename)
18
>>> test = BinaryRecordFile(filename, S.size)
>>> test[0] = S.pack(b"Alpha")
>>> test[1] = S.pack(b"Bravo")
>>> test[2] = S.pack(b"Charlie")
>>> test[3] = S.pack(b"Delta")
>>> test[4] = S.pack(b"Echo")
>>> del test[0]
>>> del test[2]
>>> del test[3]
>>> test.inplace_compact()  # Blank or deleted interspersed
>>> test.close()
>>> os.path.getsize(filename)
18
>>> os.remove(filename)
"""

import os
import struct
import tempfile


_DELETED = b"\x01"
_OKAY = b"\x02"


class BinaryRecordFile:

    def __init__(self, filename, record_size, auto_flush=True):
        """A random access binary file that behaves rather like a list
        with each item a bytes or bytesarray object of record_size.
        """
        self.__record_size = record_size + 1
        mode = "w+b" if not os.path.exists(filename) else "r+b"
        self.__fh = open(filename, mode)
        self.auto_flush = auto_flush


    @property
    def record_size(self):
        "The size of each item"
        return self.__record_size - 1


    @property
    def name(self):
        "The name of the file"
        return self.__fh.name


    def flush(self):
        """Flush writes to disk
        Done automatically if auto_flush is True
        """
        self.__fh.flush()


    def close(self):
        self.__fh.close()


    def __setitem__(self, index, record):
        """Sets the item at position index to be the given record

        The index position can be beyond the current end of the file.
        """
        assert isinstance(record, (bytes, bytearray)), \
               "binary data required"
        assert len(record) == self.record_size, (
            "record must be exactly {0} bytes".format(
            self.record_size))
        self.__fh.seek(index * self.__record_size)
        self.__fh.write(_OKAY)
        self.__fh.write(record)
        if self.auto_flush:
            self.__fh.flush()


    def __getitem__(self, index):
        """Returns the item at the given index position

        If there is no item at the given position, raises an
        IndexError exception.
        If the item at the given position has been deleted returns
        None.
        """
        self.__seek_to_index(index)
        state = self.__fh.read(1)
        if state != _OKAY:
            return None
        return self.__fh.read(self.record_size)
        

    def __seek_to_index(self, index):
        if self.auto_flush:
            self.__fh.flush()
        self.__fh.seek(0, os.SEEK_END)
        end = self.__fh.tell()
        offset = index * self.__record_size
        if offset >= end:
            raise IndexError("no record at index position {0}".format(
                             index))
        self.__fh.seek(offset)


    def __delitem__(self, index):
        """Deletes the item at the given index position.

        See undelete()
        """
        self.__seek_to_index(index)
        state = self.__fh.read(1)
        if state != _OKAY:
            return
        self.__fh.seek(index * self.__record_size)
        self.__fh.write(_DELETED)
        if self.auto_flush:
            self.__fh.flush()


    def undelete(self, index):
        """Undeletes the item at the given index position.

        If an item is deleted it can be undeleted---providing compact()
        (or inplace_compact()) has not been called.
        """
        self.__seek_to_index(index)
        state = self.__fh.read(1)
        if state == _DELETED:
            self.__fh.seek(index * self.__record_size)
            self.__fh.write(_OKAY)
            if self.auto_flush:
                self.__fh.flush()
            return True
        return False


    def __len__(self):
        """The number number of record positions.

        This is the maximum number of records there could be at
        present. The true number may be less because some records
        might be deleted. After calling compact() (or
        inplace_compact()), this returns the true number.
        """
        if self.auto_flush:
            self.__fh.flush()
        self.__fh.seek(0, os.SEEK_END)
        end = self.__fh.tell()
        return end // self.__record_size


    def compact(self, keep_backup=False):
        """Eliminates blank and deleted records"""
        compactfile = self.__fh.name + ".$$$"
        backupfile = self.__fh.name + ".bak"
        self.__fh.flush()
        self.__fh.seek(0)
        fh = open(compactfile, "wb")
        while True:
            data = self.__fh.read(self.__record_size)
            if not data:
                break
            if data[:1] == _OKAY:
                fh.write(data)
        fh.close()
        self.__fh.close()

        os.rename(self.__fh.name, backupfile)
        os.rename(compactfile, self.__fh.name)
        if not keep_backup:
            os.remove(backupfile)
        self.__fh = open(self.__fh.name, "r+b")


    def inplace_compact(self):
        """Eliminates blank and deleted records in-place preserving the
        original order
        """
        index = 0
        length = len(self)
        while index < length:
            self.__seek_to_index(index)
            state = self.__fh.read(1)
            if state != _OKAY:
                for next in range(index + 1, length):
                    self.__seek_to_index(next)
                    state = self.__fh.read(1)
                    if state == _OKAY:
                        self[index] = self[next]
                        del self[next]
                        break
                else:
                    break
            index += 1
        self.__seek_to_index(0)
        state = self.__fh.read(1)
        if state != _OKAY:
            self.__fh.truncate(0)
        else:
            limit = None
            for index in range(len(self) - 1, 0, -1):
                self.__seek_to_index(index)
                state = self.__fh.read(1)
                if state != _OKAY:
                    limit = index
                else:
                    break
            if limit is not None:
                self.__fh.truncate(limit * self.__record_size)
        self.__fh.flush()


if __name__ == "__main__":
    import doctest
    doctest.testmod()
-----------1st EFFORT - posted on GitHub









#Reminder of topics<===========
CHAPTER 7 File Handling

Writing and Reading Binary Data
    Pickles with Optional Compression
    Raw Binary Data with Optional Compression 
Writing and Parsing Text Files
    Writing Text
    Parsing Text 
    Parsing Text Using Regular Expressions
Writing and Parsing XML Files 
    Element Trees 
    DOM (Document Object Model)
    Manually Writing XML 
    Parsing XML with SAX (Simple API for XML)
Random Access Binary Files 
    Generic BinaryRecordFile Class 
    Example: BikeStock Module's Classes     '
Summary
Exercises 
#1) 
#2)
#3)


#CODE LISTING HERE
BikeStock.py
BikeStock_ans.py
BinaryRecordFile.py
BinaryRecordFile_ans.py
convert-incidents.py
xdump.py 



===============
    Example: BikeStock Module's Classes     '
===============

#The BikeStock module uses a BinaryRecordFile.BinaryRecord.File to 
#provide a simple stock control class. The stock items are bicycles,
#each represented by a BikeStock.Bike instance, and the entire stock
#of bikes is held ina BikeStock.BikeStock instance. The
#BikeStock.BikeStock class aggregates a dictionary whose keys are
#bike IDs and whose values are record index positions, into a 
#BinaryRecordFile.BinaryRecordFile.

#Here is a brief example to get a feel for how these classes work:

    bycicles = BikeStock.BikeStock(bike_file)
    value = 0.0
    for bike in bicycles:
        value += bike.value
    bicycles.increase_stock("GEKKO", 2)
    for bike in bicycles:
        if bike.identity.startswith("B4U"):
            if not bicycles.increase_stock(bike.identity, 1):
                print("stock movement failed for ", bike.identity)

#This code snippet opens a bike stock file and iterates over all
#the bicycle records it contains to find the total value of the
#bikes held = (sum of price x quantity).  It then increases
#the numver of "GEKKO" bikes in stock by two and increments the 
#stock held for all bikes whose bike ID begins with "B4U" by one.
#All of these actions take place on disk, so any other process
#that reads the bike stock file will always get the most current
#data.

#Although the BinaryRecordFile.BinaryRecordFile works in terms
#of indexes, the BikeStock.BikeStock class works in terms of 
#bike IDs. This is managed by the BikeStock.BikeStock instance
#holding a dictionary that relates bike IDs to indexes.

#We will begin by looking at the BikeStock.Bike class's class line
#and initializer, then we will look at a few selected
#BikeStock.BikeStock methods, and finally we will look at the code
#that provides the bridge between BikeStock.Bike objects and the
#binary records used to represent them in a
#BinaryRecordFile.BinaryRecordFile. (all code is in BikeStock.py)

    class Bike:

        def __init__(self, identity, name, quantity, price):
            assert len(identity) > 3, ("invalid bike identity '{0}'".format(identity))
            self.__identity = identity
            self.name = name 
            self.quantity = quantity
            self.price = price 

#All of bike's attributes are available as properties -- the bike ID (self.__identity)
#as the read-only Bike.identity property and the others as read/write properties
#with some assertions for validation. In addition, the Bike.value read-only property
#returns the quantity multiplied by the price. (We have not shown the implementation
#of the properties since we have seen similar code before.)

#The BikeStock.BikeStock class provides its own methods for manipulating bike objects,
#and they in turn use th writable bike properties.

    class BikeStock:

        def __init__(self, filename):
            self.__file = BinaryRecordFile.BinaryRecordFile(filename, _BIKE_STRUCT.size)
            self.__index_from_identity = {}
            for index in range(len(self.__file)):
                record = self.__file[index]
                if record is not None:
                    bike = bike_from_record(record)
                    self.__index_from_identity[bike.identity] = index

#The BikeStock.BikeStock class is a custom collection class that aggregates a binary
#record file (self.__file) and a dictionary (self.__index_from_identity) whose
#keys are bike IDs and whose values are record index positions.

#Once the file has been opened (and created if it didnt already exist), we iterate
#over its contents (if any). Each ike is retrieved and converted from a bytes object
#to a BikeStock.Bike using the private _bike_from_record() function, and the bike's
#identity and index are added to the self.__index_from_identity dictionary.

        def append(self, bike):
            index = len(self.__file)
            self.__file[index] = _record_from_bike(bike)
            self.__index_from_identity[bike.identity] = index 

#Appending a new bike is a matter of finding a suitable index position and setting
#the record at that position to the bike's binary representation. We also take care
#to update the self.__index_from_identity dictionary.

        def __delitem__(self, identity):
            del self.__file[self.__index_from_identity[identity]]

#Deleting a bike record is easy; we just find its record index position from its
#identity and delete the record at that index position. In the case of the 
#BikeStock.BikeStock class we have not made use of the BinaryRecordFile.BinaryRecordFile's
#UNdeletion capability.

        def __getitem__(self, identity):
            record = self.__file[self.__index_from_identity[identity]]
            return None if record is None else _bike_from_record(record)

#Bike records are retrieved by bike ID. If there is no such ID, the lookup in the 
#self.__index_from_identity dictionary will raise a KeyError exception, and if
#the record is blank or deleted the BinaryRecordFile.BinaryRecordFile will return
#None. But if a record is retrieved we return it as a BikeStock.Bike object.

        def __change_stock(self, identity, amount):
            index = self.__index_from_identity[identity]
            record = self.__file[index]
            if record is None:
                return False
            bike = _bike_from_record(record)
            bike.quantity += amount 
            self.__file[index] = _record_from_bike(bike)
            return True
            increase_stock = (lambda self, identity, amount: self.__change_stock(identity, amount))
            decrease_stock = (lambda self, identify, amount: self.__change_stock(identity, -amount))

#The private _change_stock() method provides an implementation for the increase_stock() and
#decrease_stock() methods. The bike's index position is found and the raw binary record
#is retrieved. Then the data is converted to an BikeStock.Bike object, the change is applied
#to the bike, and then the record in the file is overwritten with the binary representation
#of the updated bike object.
#(There is also a __chage_bike() method that providese an implementation for the
#change_name() and change_price() methods, but none of these are shown b/c they are
#very similar to what's shown here.)

        def __iter__(self):
            for index in range(len(self.__file)):
                record = self.__file[index]
                if record is not None:
                    yield _bike_from_record(record)

#This method ensures that BikeStock.BikeStock objects can be iterated over, just
#like a list, with a BikeStock.Bike object returned at each iteration, and skipping
#blank and deleted records.

########################################################################## Figure 7.6
Logical structure of a bike record file:

record0
            record1
                        record2
                                    record3
                                                ...                              
                                                                                recordN
                        ^^^^
                        ^^^^
            8 x UTF-16 endcoded bytes   | 30 x UTF-8 encoded bytes  | int32 | float64
            ^^^                             ^^^                         ^^^     ^^^

            identity                        name                    quantity    price
#####################################################################################

#The private _bike_from_record() and _record_from_bike() functions isolate the
#binary representation of the 
BikeStock.Bike class from the BikeStock.BikeStock class #that holds a collection of bikes.
#The logical structure of a bike record file is shown in Figure 7.6 The phyiscal structure
#is slightly different b/c each record is preceded by a state byte.

        _BIKE_STRUCT = struct.Struct("<8s30sid")

        def _bike_from_record(record):
            ID, NAME, QUANTITY, PRICE = range(4)
            parts = list(_BIKE_STRUCT.unpack(record))
            parts[ID] = parts[ID].decode("utf8").rstrip("\x00")
        return Bike(*parts)

    def _record_from_bike(bike):
        return _BIKE_STRUCT.pack(bike.identity.encode("utf8"),
                                 bike.name.encode("utf8"),
                                 bike.quantity, bike.price)

#When we convert a binary record into a BikeStock.Bike, we first convert the tuple
#returned by unpack() into a list. This allows us to modify elements, in this case to
#converty UTF-8 encode bytes into strings with padding 0x00 bytes stripped off. We then
#use the sequence unpacking operator (*) to feed the parts to the BikeStock.Bike initializer.
#Packing the data is much simplier; we just have to make sure that we encode the strings
#as UTF-8 bytes.

#For modern desktop systems the need for application programs to use random access binary
#data decreases as RAM sizes and disk speeds increase. And when such functionality is needed,
#it is often the easiest to use a DBM file or an SQL database. Nonetheless, there are often
#systems where the functionality shown here may be useful, for example, on embedded and
#other resource limited systems.





CODE HERE
BikeStock.py (from author)
-----------1st EFFORT - posted on GitHub
#!/usr/bin/env python3
#bikestock.py


"""
>>> import os
>>> import tempfile
>>> bike_file = os.path.join(tempfile.gettempdir(), "bikes.dat")
>>> if os.path.exists(bike_file): os.remove(bike_file)

>>> bike_data = []
>>> bike_data.append(('REFK2', 'Reflex Kalahari', 5, 200.97))
>>> bike_data.append(('REFT1', 'Reflex Tempus', 4, 200.97))
>>> bike_data.append(('UNISTOW', 'Universal Stowaway', 1, 203.00))
>>> bike_data.append(('REFONA', "Reflex Out 'n' About", 0, 213.15))
>>> bike_data.append(('B4U16RS', 'Bicycles4U 16/6/RS  ', 0, 223.30))
>>> bike_data.append(('B4U20', 'Bicycles4U 20/6', 9, 223.30))
>>> bike_data.append(('B4U20MTB', 'Bicycles4U 20/6/MTB', 5, 223.30))
>>> bike_data.append(('REFA3', 'Reflex Axiom 3', 15, 223.30))
>>> bike_data.append(('ASBC', 'AS Bikes Compact', 22, 243.60))
>>> bike_data.append(('AMMC', 'Ammaco Commuter', 4, 259.84))
>>> bike_data.append(('AMMP5', 'Ammaco Pakka Mk 5', 7, 259.84))
>>> bike_data.append(('B4U20RS', 'Bicycles4U 20/6/RS', 3, 263.90))
>>> bike_data.append(('COM16', 'Compass 16"', 2, 263.90))
>>> bike_data.append(('ASBC+', 'AS Bikes Compact Plus', 11, 284.20))
>>> bike_data.append(('TIGB', 'Tiger Bikes', 0, 284.20))
>>> bike_data.append(('ASBEX', 'AS Bikes Explorer', 2, 304.50))
>>> bike_data.append(('GEKKO', 'Gekko', 6, 304.50))
>>> bike_data.append(('PROBE', 'Probike Enfold', 4, 304.50))
>>> bike_data.append(('SAMHDXM', 'Samchuly Haro DX MTB', 5, 304.50))
>>> bike_data.append(('SINAB', 'Sinclair A-Bike', 3, 304.50))
>>> bike_data.append(('FALOM', 'Falcon Optima Mayfair', 2, 324.80))
>>> bike_data.append(('RALPARK', 'Raleigh Parkway', 1, 324.80))
>>> bike_data.append(('SAXS', 'Saxon Safari', 2, 324.80))
>>> bike_data.append(('CLACHA', 'Classic Chatsworth', 0, 328.86))
>>> bike_data.append(('ASBE+', 'AS Bikes Explorer Plus', 3, 345.10))
>>> bike_data.append(('RALPROM', 'Raleigh Promenade', 2, 345.10))
>>> bike_data.append(('VIKBS', 'Viking Bikes Safari', 1, 345.10))
>>> bike_data.append(('AMMT+C', 'Ammaco Town & Country', 0, 353.22))
>>> bike_data.append(('AMMCT', 'Ammaco Cruiser Tandem 16"', 0, 355.25))
>>> bike_data.append(('AMMMON', 'Ammaco Montreal', 4, 355.25))
>>> bike_data.append(('MSGENIE', 'Mission Space Genie', 4, 355.25))
>>> bike_data.append(('TRANSS', 'Transair Sea Sure', 3, 355.25))
>>> bike_data.append(('DAHSP', 'Dahon Sweet Pea', 1, 363.37))
>>> bike_data.append(('SALEASY', 'Salcano Easy', 0, 365.40))
>>> bike_data.append(('CLAMEL', 'Classic Melbourne', 1, 379.61))
>>> bike_data.append(('VENTGL', 'Ventura Go Lite', 1, 383.67))

>>> bicycles = BikeStock(bike_file)
>>> for bike in bike_data:
...     bicycles.append(Bike(*bike))
>>> bicycles["VIKBS"].name
'Viking Bikes Safari'
>>> ok = []
>>> value = 0.0
>>> for i, bike in enumerate(bicycles):
...     ok.append(bike.quantity == bike_data[i][2])
...     value += bike.value
>>> all(ok), "{0:.2f}".format(round(value, 2))
(True, '35969.57')
>>> bicycles["SALEASY"].name
'Salcano Easy'
>>> bicycles.change_name("SALEASY", "Salcano EZ")
True
>>> bicycles["SALEASY"].name
'Salcano EZ'
>>> total = 0
>>> for bike in bicycles:
...     if bike.identity.startswith("B4U"):
...         total += bike.quantity
>>> total
17
>>> total = 0
>>> for bike in bicycles:
...     if bike.identity.startswith("B4U"):
...         if bicycles.increase_stock(bike.identity, 2):
...             total += bicycles[bike.identity].quantity
...         else:
...             print("error", bike)
>>> total
25
>>> value = 0.0
>>> count = 0
>>> for bike in bicycles:
...     value += bike.value
...     count += 1
>>> "{0:.2f}".format(round(value, 2)), count, count == len(bike_data)
('37837.17', 36, True)
>>> bicycles["CLAMEL"].name
'Classic Melbourne'
>>> del bicycles["UNISTOW"]
>>> value = 0.0
>>> count = 0
>>> for bike in bicycles:
...     value += bike.value
...     count += 1
>>> "{0:.2f}".format(round(value, 2)), count
('37634.17', 35)
>>> bicycles["CLAMEL"].name
'Classic Melbourne'
>>> bicycles.append(Bike('UNISTOW', 'Universal Stowaway', 1, 203.00))
>>> bicycles.close()

>>> bicycles = BikeStock(bike_file)
>>> value = 0.0
>>> for bike in bicycles:
...     value += bike.value
>>> "{0:.2f}".format(round(value, 2))
'37837.17'
>>> bicycles.close()
>>> os.path.getsize(bike_file)
1836
>>> if os.path.exists(bike_file): os.remove(bike_file)
"""

import struct
import BinaryRecordFile


class Bike:

    def __init__(self, identity, name, quantity, price):
        assert len(identity) > 3, ("invalid bike identity '{0}'"
                                   .format(identity))
        self.__identity = identity
        self.name = name
        self.quantity = quantity
        self.price = price


    @property
    def identity(self):
        "The bike's identity"
        return self.__identity


    @property
    def name(self):
        "The bike's name"
        return self.__name

    @name.setter
    def name(self, name):
        assert len(name), "bike name must not be empty"
        self.__name = name


    @property
    def quantity(self):
        "How many of this bike are in stock"
        return self.__quantity

    @quantity.setter
    def quantity(self, quantity):
        assert 0 <= quantity, "quantity must not be negative"
        self.__quantity = quantity


    @property
    def price(self):
        "The bike's price"
        return self.__price

    @price.setter
    def price(self, price):
        assert 0.0 <= price, "price must not be negative"
        self.__price = price


    @property
    def value(self):
        "The value of these bikes in stock"
        return self.quantity * self.price


_BIKE_STRUCT = struct.Struct("<8s30sid")


def _bike_from_record(record):
    ID, NAME, QUANTITY, PRICE = range(4)
    parts = list(_BIKE_STRUCT.unpack(record))
    parts[ID] = parts[ID].decode("utf8").rstrip("\x00")
    parts[NAME] = parts[NAME].decode("utf8").rstrip("\x00")
    return Bike(*parts)


def _record_from_bike(bike):
    return _BIKE_STRUCT.pack(bike.identity.encode("utf8"),
                             bike.name.encode("utf8"),
                             bike.quantity, bike.price)


class BikeStock:

    def __init__(self, filename):
        self.__file = BinaryRecordFile.BinaryRecordFile(filename,
                                                _BIKE_STRUCT.size)
        self.__index_from_identity = {}
        for index in range(len(self.__file)):
            record = self.__file[index]
            if record is not None:
                bike = _bike_from_record(record)
                self.__index_from_identity[bike.identity] = index


    def close(self):
        "Compacts and closes the file"
        self.__file.inplace_compact()
        self.__file.close()


    def append(self, bike):
        "Adds a new bike to the stock"
        index = len(self.__file)
        self.__file[index] = _record_from_bike(bike)
        self.__index_from_identity[bike.identity] = index
        

    def __delitem__(self, identity):
        "Deletes the stock record for the specified bike"
        del self.__file[self.__index_from_identity[identity]]
        del self.__index_from_identity[identity]


    def __getitem__(self, identity):
        "Retrieves the stock record for the specified bike"
        record = self.__file[self.__index_from_identity[identity]]
        return None if record is None else _bike_from_record(record)


    def __change_bike(self, identity, what, value):
        index = self.__index_from_identity[identity]
        record = self.__file[index]
        if record is None:
            return False
        bike = _bike_from_record(record)
        if what == "price" and value is not None and value >= 0.0:
            bike.price = value
        elif what == "name" and value is not None:
            bike.name = value
        else:
            return False
        self.__file[index] = _record_from_bike(bike)
        return True

    change_name = lambda self, identity, name: self.__change_bike(
                                            identity, "name", name)
    change_name.__doc__ = "Changes the bike's name"

    change_price = lambda self, identity, price: self.__change_bike(
                                            identity, "price", name)
    change_price.__doc__ = "Changes the bike's price"


    def __change_stock(self, identity, amount):
        index = self.__index_from_identity[identity]
        record = self.__file[index]
        if record is None:
            return False
        bike = _bike_from_record(record)
        bike.quantity += amount
        self.__file[index] = _record_from_bike(bike)
        return True
        
    increase_stock = (lambda self, identity, amount:
                                self.__change_stock(identity, amount))
    increase_stock.__doc__ = ("Increases the stock held for the "
                              "specified bike by by the given amount")

    decrease_stock = (lambda self, identity, amount:
                                self.__change_stock(identity, -amount))
    decrease_stock.__doc__ = ("Decreases the stock held for the "
                              "specified bike by by the given amount")

        
    def __iter__(self):
        for index in range(len(self.__file)):
            record = self.__file[index]
            if record is not None:
                yield _bike_from_record(record)


if __name__ == "__main__":
    import doctest
    doctest.testmod()
-----------1st EFFORT - posted on GitHub










#Reminder of topics<===========
CHAPTER 7 File Handling

Writing and Reading Binary Data
    Pickles with Optional Compression
    Raw Binary Data with Optional Compression 
Writing and Parsing Text Files
    Writing Text
    Parsing Text 
    Parsing Text Using Regular Expressions
Writing and Parsing XML Files 
    Element Trees 
    DOM (Document Object Model)
    Manually Writing XML 
    Parsing XML with SAX (Simple API for XML)
Random Access Binary Files 
    Generic BinaryRecordFile Class 
    Example: BikeStock Module's Classes     '
Summary
Exercises 
#1) 
#2)
#3)


#CODE LISTING HERE
BikeStock.py
BikeStock_ans.py
BinaryRecordFile.py
BinaryRecordFile_ans.py
convert-incidents.py
xdump.py 



===============
Summary Chapter 7
===============

#This chapter showed the most widely used techniques for saving and laoding collections
#of data to and from files. We have seen how easy pickles are to use, and how we can 
#handle both compressed and uncompressed files without knowing in advance whether compression
#has been used.

#We saw how writing and reading binary data requires care, and saw that the code can be quite
#long if we need to handle variable length strings. But we also learned that using binary files
#usually results in the smallest possible file sizes and the fastest writing and reading
#times. We learned too that it is important to use a magic number to identify our file type
#and to use a version number to make it practical to change the format later on.

#In this chapter we saw that plain text is easiset format for users to read and that if the
#data is structured well, it can be straightforward for additional tools to be created to 
#manipulate the data. However, parsing text data can be tricky. We saw how to read text data
#both manually and using regular expressions.

#XML is a very popular data interchange format and it is generally useful to be able to
#least import and export XML even when the normal format is a binary or text one. We saw
#how to write XML manually -- and how to write it using an element tree and a DOM. We also
#learned how to parse XML using the element tree, DOM, and SAX parsers that Python's 
#standard library provides.

#In the chapter's final section, we saw how to create a generic class to handle randeom
#access binary files that hold records of a fixed size, and then how to use the generic
#class in a specific context.

#This chapter brings us to the end of all the fundamentals of Python programming. It is
#possible to stop reading right here and to write perfectly good Python programs based
#on everything you have learned so far. BUT it would be a shame to shop now -- Python
#has so much MORE to offer, from neat techniques that can shorten and simplify code, to
#some mind-bending advanced facilities that are at least nice to know about, even if they
#are not often needed. In the following next chpaters we will focus on more broader
#programming techniques including threading, networking, database programming, 
#regular expressions, and GUI programming.



#Reminder of topics<===========
CHAPTER 7 File Handling

Writing and Reading Binary Data                             convert-incidents.py
    Pickles with Optional Compression
    Raw Binary Data with Optional Compression 
Writing and Parsing Text Files
    Writing Text
    Parsing Text 
    Parsing Text Using Regular Expressions
Writing and Parsing XML Files 
    Element Trees 
    DOM (Document Object Model)
    Manually Writing XML 
    Parsing XML with SAX (Simple API for XML)
Random Access Binary Files 
    Generic BinaryRecordFile Class 
    Example: BikeStock Module's Classes     '
Summary
Exercises 
#1) BinaryRecordFile.py     BinaryRecordFile_ans.py
#2) BikeStock.py            BikeStock_ans.py
#3) xdump.py


#CODE LISTING HERE
BikeStock.py
BikeStock_ans.py
BinaryRecordFile.py
BinaryRecordFile_ans.py
convert-incidents.py
xdump.py 



===============
Exercises Chapter 7
===============

#Exercise 1 is to create a simplier binary record file module than the one
#presented in this chapter -- one whose record size is exactly the same as
#what the user specifies.
#Execise 2 is to modify the BikeStock module to use your new binary file module.
#Execise 3 is to create a program from scrath -- the file handling is quite
#straightforward but some of the output formatting is rather challenging.

#1)Make a new, simpler version of the BinaryRecordFile module -- one that does NOT
#use a state byte. For this version, the record size specified by the user is the
#record size actually used. New records must be added using a new append() method
#that simply moves the file point to the end and writes the given record.
#The __setitem__() method should only allow existing records to be replaced; one
#easy way of doing this is to use the __seek_to_index() method. With no state
#byte, __getitem__() is reduced to a MERE THREE LINES OF CODE. The __delitem__()
#method will need to be completely REWRITTEN since it must move all the records
#up to fill the gap; this can be done in just over 6-7 lines of code, but does
#require some thought. The undelete() method must be removed since it is not
#supported, and the compact() and inplace_compact() methods must be removed
#since they are no longer needed.

#All in, the changes amount to fewer than 20 new or changed lines and at least
#60 deleted lines compared with the original, and not counting doctests.
#Solution is in BinaryRecordFile_ans.py




#EXISTING FILE
BinaryRecordFile.py
-----------1st EFFORT - posted on GitHub
#!/usr/bin/env python3
#binaryrecordfile.py


"""
>>> import shutil
>>> import sys

>>> S = struct.Struct("<15s")
>>> fileA = os.path.join(tempfile.gettempdir(), "fileA.dat")
>>> fileB = os.path.join(tempfile.gettempdir(), "fileB.dat")
>>> for name in (fileA, fileB):
...    try:
...        os.remove(name)
...    except EnvironmentError:
...        pass

>>> brf = BinaryRecordFile(fileA, S.size)
>>> for i, text in enumerate(("Alpha", "Bravo", "Charlie", "Delta",
...        "Echo", "Foxtrot", "Golf", "Hotel", "India", "Juliet",
...        "Kilo", "Lima", "Mike", "November", "Oscar", "Papa",
...        "Quebec", "Romeo", "Sierra", "Tango", "Uniform", "Victor",
...        "Whisky", "X-Ray", "Yankee", "Zulu")):
...    brf[i] = S.pack(text.encode("utf8"))
>>> assert len(brf) == 26
>>> brf[len(brf) + 2] = S.pack(b"Extra at the end")
>>> assert len(brf) == 29
>>> shutil.copy(fileA, fileB)
>>> del brf[12]
>>> assert len(brf) == 29
>>> brf.compact()
>>> assert len(brf) == 26
>>> brf.close()

>>> if ((os.path.getsize(fileA) + 3 + (3 * S.size)) !=
...        os.path.getsize(fileB)):
...    print("FAIL#1: expected file sizes are wrong")
...    sys.exit()

>>> shutil.copy(fileB, fileA)
>>> if os.path.getsize(fileA) != os.path.getsize(fileB):
...    print("FAIL#2: expected file sizes differ")
...    sys.exit()

>>> for name in (fileA, fileB):
...    try:
...        os.remove(name)
...    except EnvironmentError:
...        pass

>>> filename =  os.path.join(tempfile.gettempdir(), "test.dat")
>>> if os.path.exists(filename): os.remove(filename)
>>> S = struct.Struct("<8s")
>>> test = BinaryRecordFile(filename, S.size)
>>> test[0] = S.pack(b"Alpha")
>>> test[1] = S.pack(b"Bravo")
>>> test[2] = S.pack(b"Charlie")
>>> test[3] = S.pack(b"Delta")
>>> test[4] = S.pack(b"Echo")
>>> test.inplace_compact()  # No blank or deleted
>>> test.close()
>>> os.path.getsize(filename)
45
>>> test = BinaryRecordFile(filename, S.size)
>>> len(test)
5
>>> for index in range(len(test)):
...     del test[index]
>>> test.inplace_compact()  # All blank or deleted
>>> test.close()
>>> os.path.getsize(filename)
0
>>> test = BinaryRecordFile(filename, S.size)
>>> test[0] = S.pack(b"Alpha")
>>> test[1] = S.pack(b"Bravo")
>>> test[2] = S.pack(b"Charlie")
>>> test[3] = S.pack(b"Delta")
>>> test[4] = S.pack(b"Echo")
>>> del test[2]
>>> del test[4]
>>> del test[3]
>>> test.inplace_compact()  # Blank or deleted at the end
>>> test.close()
>>> os.path.getsize(filename)
18
>>> test = BinaryRecordFile(filename, S.size)
>>> test[0] = S.pack(b"Alpha")
>>> test[1] = S.pack(b"Bravo")
>>> test[2] = S.pack(b"Charlie")
>>> test[3] = S.pack(b"Delta")
>>> test[4] = S.pack(b"Echo")
>>> del test[0]
>>> del test[2]
>>> del test[3]
>>> test.inplace_compact()  # Blank or deleted interspersed
>>> test.close()
>>> os.path.getsize(filename)
18
>>> os.remove(filename)
"""

import os
import struct
import tempfile


_DELETED = b"\x01"
_OKAY = b"\x02"


class BinaryRecordFile:

    def __init__(self, filename, record_size, auto_flush=True):
        """A random access binary file that behaves rather like a list
        with each item a bytes or bytesarray object of record_size.
        """
        self.__record_size = record_size + 1
        mode = "w+b" if not os.path.exists(filename) else "r+b"
        self.__fh = open(filename, mode)
        self.auto_flush = auto_flush


    @property
    def record_size(self):
        "The size of each item"
        return self.__record_size - 1


    @property
    def name(self):
        "The name of the file"
        return self.__fh.name


    def flush(self):
        """Flush writes to disk
        Done automatically if auto_flush is True
        """
        self.__fh.flush()


    def close(self):
        self.__fh.close()


    def __setitem__(self, index, record):
        """Sets the item at position index to be the given record

        The index position can be beyond the current end of the file.
        """
        assert isinstance(record, (bytes, bytearray)), \
               "binary data required"
        assert len(record) == self.record_size, (
            "record must be exactly {0} bytes".format(
            self.record_size))
        self.__fh.seek(index * self.__record_size)
        self.__fh.write(_OKAY)
        self.__fh.write(record)
        if self.auto_flush:
            self.__fh.flush()


    def __getitem__(self, index):
        """Returns the item at the given index position

        If there is no item at the given position, raises an
        IndexError exception.
        If the item at the given position has been deleted returns
        None.
        """
        self.__seek_to_index(index)
        state = self.__fh.read(1)
        if state != _OKAY:
            return None
        return self.__fh.read(self.record_size)
        

    def __seek_to_index(self, index):
        if self.auto_flush:
            self.__fh.flush()
        self.__fh.seek(0, os.SEEK_END)
        end = self.__fh.tell()
        offset = index * self.__record_size
        if offset >= end:
            raise IndexError("no record at index position {0}".format(
                             index))
        self.__fh.seek(offset)


    def __delitem__(self, index):
        """Deletes the item at the given index position.

        See undelete()
        """
        self.__seek_to_index(index)
        state = self.__fh.read(1)
        if state != _OKAY:
            return
        self.__fh.seek(index * self.__record_size)
        self.__fh.write(_DELETED)
        if self.auto_flush:
            self.__fh.flush()


    def undelete(self, index):
        """Undeletes the item at the given index position.

        If an item is deleted it can be undeleted---providing compact()
        (or inplace_compact()) has not been called.
        """
        self.__seek_to_index(index)
        state = self.__fh.read(1)
        if state == _DELETED:
            self.__fh.seek(index * self.__record_size)
            self.__fh.write(_OKAY)
            if self.auto_flush:
                self.__fh.flush()
            return True
        return False


    def __len__(self):
        """The number number of record positions.

        This is the maximum number of records there could be at
        present. The true number may be less because some records
        might be deleted. After calling compact() (or
        inplace_compact()), this returns the true number.
        """
        if self.auto_flush:
            self.__fh.flush()
        self.__fh.seek(0, os.SEEK_END)
        end = self.__fh.tell()
        return end // self.__record_size


    def compact(self, keep_backup=False):
        """Eliminates blank and deleted records"""
        compactfile = self.__fh.name + ".$$$"
        backupfile = self.__fh.name + ".bak"
        self.__fh.flush()
        self.__fh.seek(0)
        fh = open(compactfile, "wb")
        while True:
            data = self.__fh.read(self.__record_size)
            if not data:
                break
            if data[:1] == _OKAY:
                fh.write(data)
        fh.close()
        self.__fh.close()

        os.rename(self.__fh.name, backupfile)
        os.rename(compactfile, self.__fh.name)
        if not keep_backup:
            os.remove(backupfile)
        self.__fh = open(self.__fh.name, "r+b")


    def inplace_compact(self):
        """Eliminates blank and deleted records in-place preserving the
        original order
        """
        index = 0
        length = len(self)
        while index < length:
            self.__seek_to_index(index)
            state = self.__fh.read(1)
            if state != _OKAY:
                for next in range(index + 1, length):
                    self.__seek_to_index(next)
                    state = self.__fh.read(1)
                    if state == _OKAY:
                        self[index] = self[next]
                        del self[next]
                        break
                else:
                    break
            index += 1
        self.__seek_to_index(0)
        state = self.__fh.read(1)
        if state != _OKAY:
            self.__fh.truncate(0)
        else:
            limit = None
            for index in range(len(self) - 1, 0, -1):
                self.__seek_to_index(index)
                state = self.__fh.read(1)
                if state != _OKAY:
                    limit = index
                else:
                    break
            if limit is not None:
                self.__fh.truncate(limit * self.__record_size)
        self.__fh.flush()


if __name__ == "__main__":
    import doctest
    doctest.testmod()
-----------1st EFFORT - posted on GitHub





#ANSWER FILE
BinaryRecordFile_ans.py

-----------1st EFFORT - posted on GitHub
#!/usr/bin/env python3
#BinaryRecordFile_ans.py

"""
>>> import shutil
>>> import sys

>>> S = struct.Struct("<15s")
>>> fileA = os.path.join(tempfile.gettempdir(), "fileA.dat")
>>> fileB = os.path.join(tempfile.gettempdir(), "fileB.dat")
>>> for name in (fileA, fileB):
...     try:
...         os.remove(name)
...     except EnvironmentError:
...         pass

>>> brf = BinaryRecordFile(fileA, S.size)
>>> for text in ("Alpha", "Bravo", "Charlie", "Delta", "Echo"
...         "Foxtrot", "Golf", "Hotel", "India", "Juliet", 
...         "Kilo", "Lima", "Mike", "November", "Oscar", 
...         "Papa", "Quebec", "Romeo", "Sierra", "Tango", 
...         "Uniform", "Victor", "Whisky", "XRay", "Yankee", "Zulu"):
...     brf.append(S.pack(text.encode("utf8")))
>>> assert len(brf) == 26
>>> brf.append(S.pack(b"Extra at the end"))
>>> assert len(brf) == 27
>>> shutil.copy(fileA, fileB)
>>> del brf[12]
>>> del brf[0]
>>> del brf[24]
>>> assert len(brf) == 24, len(brf
>>> brf.close()

>>> if ((os.path.getsize(fileA) + (3 * S.size)) != os.path.getsize(fileB)):
...     print("FAIL#1: expected file sizes are wrong")
...     sys.exit()


>>> shutil.copy(fileB, fileA)
>>> if os.path.getsize(fileA) != os.path.getsize(fileB):
...     print("FAIL#2: expected file sizes differ")
...     sys.exit()

>>> for name in (fileA, fileB):
...     try:
...         os.remove(name)
...     except EnvironmentError:
...         pass
"""

import os
import struct 
import tempfile


_DELETED = b"\x01"
_OKAY = b"\x02"


class BinaryRecordFile:

    def __init__(self, filename, record_size, auto_flush=True):
        """A random access binary file that behaves like a list with each item a bytes or
        bytesarray object of record_size.
        """
        self.__record_size = record_size + 1
        mode = "w+b" if not os.path.exists(filename) else "r+b"
        self.__fh = open(filename, mode)
        self.auto_flush = auto_flush


    @property
    def record_size(self):
        "The size of each item"
        return self.__record_size -1 


    @property
    def name(self):
        "The name of the file"
        return self.__fh.name


    def flush(self):
        """Flush writes to disk. 
        Done automatically if auto_flush is True
        """
        self.__fh.flush()


    def close(self):
        self.__fh.close()


    def append(self, record):                   #new
        """Adds a new record
        """
        assert isinstance(record, (bytes, bytearray)), "binary data required"
        assert len(record) == self.record_size, ("record must be exactly {0} bytes".format(self.record_size))
        self.__fh.seek(0, os.SEEK_END)
        self.__fh.write(record)
        if self.auto_flush:
            self.__fh.flush()

 
    def __setitem__(self, index, record):       #new
        """Sets the item at position index to be the given record.
        The index position can be beyond the current end of the file."""
        assert isinstance(record, (bytes, bytearray)), \
            "binary data required"
        assert len(record) == self.record_size, ("record must be exactly {0} bytes".format(self.record_size))
        self.__fh.seek(index)
        self.__fh.write(record)
        if self.auto_flush:
            self.__fh.flush()


    def __getitem(self, index):                 #reduced code
        """Returns the item at the given index position
        If there is no item at the given index position, raises an IndexError exception.
        If the item at the given position has been deleted, returns None."""
        self.__seek_to_index(index)
        return self.__fh.read(self.record_size)


    def __seek_to_index(self, index):
        if self.auto_flush:
            self.__fh.flush()
        self.__fh.seek(0, os.SEEK_END)
        end = self.__fh.tell()
        offset = index * self.__record_size
        if offset >= end:
            raise IndexError("no record at index position {0}".format(index))
        self.__fh.seek(offset)


    def __delitem__(self, index):
        """Delete the item at the given index position and moves the following records up
        """
        length = len(self)
        for following in range(index + 1, length:
            self[index] = self[following]
            index += 1
        self.__fh.truncate((length - 1) * self.record_size)
        self.__fh.flush()


if __name__ == "__main__":
    import doctest
    doctest.testmod()
-----------1st EFFORT - posted on GitHub






#2)Once you are confident that your simplier BinaryRecordFile class works, 
#copy the BikeStock.py file and modify it work with your BinaryRecordFile class.
#This involves changing only a handful of lines. Solution is 
BikeStock_ans.py

#Copied BikeStock.py code

BOOKMARK HERE BIKE STOCK
#CODE HERE
BikeStock_ans.py

-----------1st EFFORT - posted on GitHub
#!/usr/bin/env python3
#bikestock_ans.py

"""
>>> import os
>>> import tempfile
>>> bike_file = os.path.join(tempfile.gettempdir(), "bikes.dat")
>>> if os.path.exists(bike_file): os.remove(bike_file)

>>> bike_data = []
>>> bike_data.append(('REFK2', 'Reflex Kalahari', 5, 200.97))
>>> bike_data.append(('REFT1', 'Relex Tempus', 4, 200.97))
>>> bike_data.append(('UNISTOW', 'Univeral Stowaway', 1, 203.00))
>>> bike_data.append(('REFONA', "Reflex Out 'n' About", 0, 213.15))
>>> bike_data.append(('B4U16RS', 'Bicycles4U 16/6/RS  ', 0, 223.30))
>>> bike_data.append(('B4U20', 'Bicycles4U 20/6', 9, 223.30))
>>> bike_data.append(('B4U20MTB', 'Bicycles4U 20/6/MTB', 5, 223.30))
>>> bike_data.append(('REFA3', 'Reflex Axiom 3', 15, 223.30))
>>> bike_data.append(('ASBC', 'AS Bikes Compact', 22, 243.60))
>>> bike_data.append(('AMMC', 'Ammaco Commuter', 4, 259.84))
>>> bike_data.append(('AMMP5', 'Ammaco Pakka Mk 5', 7, 259.84))
>>> bike_data.append(('B4U20RS', 'Bicycles4U 20/6/RS', 3, 263.90))
>>> bike_data.append(('COM16', 'Compass 16"', 2, 263.90))
>>> bike_data.append(('ASBC+', 'AS Bikes Compact Plus', 11, 284.20))
>>> bike_data.append(('TIGB', 'Tiger Bikes', 0, 284.20))
>>> bike_data.append(('ASBEX', 'AS Bikes Explorer', 2, 304.50))
>>> bike_data.append(('GEKKO', 'Gekko', 6, 304.50))
>>> bike_data.append(('PROBE', 'Probike Enfold', 4, 304.50))
>>> bike_data.append(('SAMHDXM', 'Samchuly Haro DX MTB', 5, 304.50))
>>> bike_data.append(('SINAB', 'Sinclair A-Bike', 3, 304.50))
>>> bike_data.append(('FALOM', 'Falcon Optima Mayfair', 2, 324.80))
>>> bike_data.append(('RALPARK', 'Raleigh Parkway', 1, 324.80))
>>> bike_data.append(('SAXS', 'Saxon Safari', 2, 324.80))
>>> bike_data.append(('CLACHA', 'Classic Chatsworth', 0, 328.86))
>>> bike_data.append(('ASBE+', 'AS Bikes Explorer Plus', 3, 345.10))
>>> bike_data.append(('RALPROM', 'Raleigh Promenade', 2, 345.10))
>>> bike_data.append(('VIKBS', 'Viking Bikes Safari', 1, 345.10))
>>> bike_data.append(('AMMT+C', 'Ammaco Town & Country', 0, 353.22))
>>> bike_data.append(('AMMCT', 'Ammaco Cruiser Tandem 16"', 0, 355.25))
>>> bike_data.append(('AMMMON', 'Ammaco Montreal', 4, 355.25))
>>> bike_data.append(('MSGENIE', 'Mission Space Genie', 4, 355.25))
>>> bike_data.append(('TRANSS', 'Transair Sea Sure', 3, 355.25))
>>> bike_data.append(('DAHSP', 'Dahon Sweet Pea', 1, 363.37))
>>> bike_data.append(('SALEASY', 'Salcano Easy', 0, 365.40))
>>> bike_data.append(('CLAMEL', 'Classic Melbourne', 1, 379.61))
>>> bike_data.append(('VENTGL', 'Ventura Go Lite', 1, 383.67))

>>> bicycles = BikeStock(bike__file)
>>> for bike in bike_data:
...     bicycles.append(Bike(*bike))
>>> bicycles["VIKBS"].namedtuple
'Viking Bikes Safari'
>>> ok = []
>>> value = 0.0
>>> for i, bike in enumerate(bicycles):
...     ok.append(bike.quantity == bike_data[i][2])
...     value += bike.value
>>> all(ok), "{0:.2f}".format(round(value, 2))
(True, '35969.57')
>>> bicycles["SALEASY"].name
'Salcano EZ'
>>> bicycles.change_name("SALEASY", "Salcano EZ")
True 
>>> bicycles["SALEASY"].named 
'Salcano EZ'
>>> total = 0
>>> for bike in bicycles:
...     if bike.identity.startswith("B4U"):
...         total += bike.quantity 
>>> total
17
>>> total = 0
>>> for bike in bicycles:
...     if bike.identity.startswith("B4U"):
...         if bicycles.increase_stock(bike.identity, 2):
...             total += bicycles[bike.identity].quantity
...         else:
...             print("error", bike)
>>> total 
25
>>> value = 0.0
>>> count = 0
>>> for bike in bicycles:
...     value += bike.value 
...     count += 1
>>> "{0:.2f}".format(round(value, 2)), count, count == len(bike_data)
('37837.17', 36, True)
>>> bicycles["CAMEL"].named 
'Classic Melbourne'
>>> del bicycles["UNISTOW"]
>>> value = 0.0
>>> count = 0
>>> for bike in bicycles:
...     value += bike.value 
...     count += 1
>>>"{0:.2f}".format(round(value, 2)), count 
('37634.17', 35)
>>> bicycles["CLAMEL"].name 
'Classic Melbourne'
>>> bicycles.append(Bike('UNISTOW', 'Univeral Stowaway', 1, 203.00))
>>> bicycles.close()

>>> bicycles = BikeStock(bike_file)
>>> value = 0.0
>>> for bike in bicycles:
...     value += bike.value
>>> "{0:.2f}".format(round(value, 2))
'37837.17'
>>> bicycles.close()
>>> os.path.getsize(bike_file)
1836
>>> if os.path.exists(bike_file): os.remove(bike_file)
"""

import strut
import BinaryRecordFile


class Bike:


    def __init__(self, identity, name, quantity, price):
        assert len(identity) > 3, ("invalid bike identity '{0}'".format(identity))
        self.__identity = identity
        self.name = name
        self.quantity = quantity 
        self.price = price 


    @property 
    def identity(self):
        "The bike's identity"
        return self._identity 


    @property 
    def name(self):
        "The bike's name"
        return self.__name 


    @name.setter 
    def name(self, name):
        assert len(name), "bike name must not be empty"
        self.__name = name 


    @property 
    def quantity(self):
        "How many of this bike are in stock"
        return self.__quantity


    @quantity.setter
    def quantity(self, quantity):
        assert 0 <= quantity, "quantity must not be negative"
        self.__quantity = quantity 


    @property 
    def price(self):
        "The bike's price"
        return self.__price


    @price.setter 
    def price(self, price):
        assert 0.0 <= price, "price must not be negative"
        self.__price = price 


    @property 
    def value(self):
        "The value of these bikes in stock"
        return self.quantity * self.price 


_BIKE_STRUCT = struct.Struct("<8s30sid")


def _bike_from_record(record):
    ID, NAME, QUANTITY, PRICE = range(4)
    parts = list(_BIKE_STRUCT.unpack(record))
    parts[ID] = parts[ID].decode("utf8").rstrip("\x00")
    parts[NAME] = parts[NAME].decode("utf8").rstrip("\x00")
    return Bike(*parts)


def _record_from_bike(bike):
    return _BIKE_STRUCT.pack(bike.identity.encode("utf8"), bike.name.encode("utf8"), bike.quantity,
                             bike.price)

class BikeStock:


    def __init__(self, filename):
        self.__file = BinaryRecordFile.BinaryRecordFile(filename, _BIKE_STRUCT.size)
        self.__index_from_identity = {}
        for index in range(len(self.__file)):
            record = self.__file[index]
            if record is not None:
                bike = _bike_from_record(record)
                self.__index_from_identity[bike.identity] = index 


    def close(self):
        "Closes the file"
        self.__file.close()


    def append(self, bike):
        "Adds a new bike to the stock"
        index = len(self.__file)
        self.__file.append(_record_from_bike(bike))
        self.__index_from_identity[bike.identity] = index 


    def __delitem__(self, identity):
        "Deletes the stock record for the specific bike"
        index = self.__index_from_identity[identity]
        del self.__file[index]
        del self.__index_from_identity[identity]
        for key, value in self.__index_from_identity.items():
            if value > index:
                self.__index_from_identity[key] = value - 1


    def __getitem__(self, identity):
        "Retrieves the stock record for the specified bike"
        record = self.__file[self.__index_from_identity[identity]]
        return None if record is None else _bike_from_record(record)


    def _change_bike(self, identity, what, value):
        index = self.__index_from_identity[identity]
        if record is None:
            return False
        bike = _bike_from_record(record)
        if what == "price" and value is not None and value >= 0.0:
            bike.price = value 
        elif what == "name" and value is not None:
            bike.name = value
        else:
            return False
        self.__file[index] = _record_from_bike(bike)
        return True


    change_name = lambda self, identity, name: self.__change_bike(identity, "name", name)
    change_name.__doc__ = "Changes the bike's name"
    change_price = lambda self, identity, price: self.__change_bike(identity, "price", name)
    change_price.__doc__ = "Changes the bike's price"


    def __change_stock(self, identity, amount):
        index = self.__index_from_identity[identity]
        record = self.__file[index]
        if record is None:
            return False
        bike = _bike_from_record(record)
        bike.quantity += amount 
        self.__file[index] = _record_from_bike(bike)
        return True


    increase_stock = (lambda self, identity, amount: self.__change_stock(identity, amount))
    increase_stock.__doc__ = ("Increases the stock held for the specified bike by the given amount")
    decrease_stock = (lambda self, identity, amount: self.__change_stock(identity, -amount))
    decrease_stock.__doc__ = ("Decreases the stock held for the specified bike by the given amount")


    def __iter__(self):
        for index in range(len(self.__file)):
            record = self.__file[index]
            if record is not None:
                yield _bike_from_record(record)


if __name__ == "__main__":
    import doctest
    doctest.testmod()
-----------1st EFFORT - posted on GitHub



#3)Debugging binary formates can be difficult, but a tool that can help is one
#that can do a hex dump of a binary file's contents. Create a program that has 
#the following console help text:

Usage: xdump.py [options] file1 [file2 [... fileN]]]

Options:
    -h, --help                              show this help message and exit
    -b BLOCKSIZE, --blocksize=BLOCKSIZE     block size (8..80) [default: 16]
    -d, --decimal                           decimal block numbers [default: hexadecimal]
    -e ENCODING, --encodng=ENCODING         endocing (ASCII..UTF-32) [default: UTF-8]

#Using this program, if we have a BinaryRecordFile that is storing records with
#the structure "<i10s" (little endian, 4-byte signed integer, 10-byte byte string), 
#by setting the block size to match one record (15 bytes including the state byte),
#we can get a clear picture of what's in the file. For example:

        xdump.py -b15 test.dat
        Block     Bytes                              UTF-8 characters
        --------  ---------------------------------  ----------------
        00000000  02000000 00416C70 68610000 000000  .....Alpha.....
        00000001  01140000 00427261 766F0000 000000  .....Bravo.....
        00000002  02280000 00436861 726C6965 000000  .(...Charlie...
        00000003  023C0000 0044656C 74610000 000000  .<...Delta.....
#Each byte is represented by a two-digit hexadecimal number; the spacing
#between each set of four bytes (ie between each group of eigtht hexadecimal
#digits) is purely to improve readability. Here we can see that the second
#record ("Bravo") has been deleted since its state byte is 0x01 rather than
#the 0x02 used to indicate nonblank nondeleted records.

#Use the optparse module to handle the command-line options. (By specifying an
#options's "type" you can get optparse to handle the string-to-integer 
#conversion for the block size). It can be quite tricky to get the headings to
#line up correctly for any given block size and to line up the characters
#correctly for the last block, so make sure you test with various block sizes
#(eg 8, 9, 10, ...., 40). Also dont forget that in variable length files, the
#last block may be short. As the example illustrates, use periods to stand for
#nonprintable characters.
#The program can we written in fewer than 70 lines spread over two functions.

#Solution is 
xdump.py


#CODE HERE
xdump.py


-----------1st EFFORT - posted on GitHub
#!/usr/bin/env python3
#xdump.py
#debugging binary formats using a hex dump of a binary file's contents.

import optparse
import os
import sys

def main():
    parser = optparse.OptionParser(usage="usage: %prog [options] file1 [file2 [... fileN]]")
    parser.add_option("-b", "--blocksize", dest="blocksize", type="int", 
                      help="block size (8..80) [default: %default]")
    parser.add_option("-d", "--decimal", dest="decimal", action="store_true",
                      help="decimal block numbers [default: hexadecimal]")
    parser.add_option("-e", "--encoding", dest="encoding", 
                      help="encoding (ASCII..UTF-32) [default: %default]")
    parser.set_defaults(blocksize=16, decimal=False, encoding="UTF-8")
    opts, files = parser.parse_args()
    if not (8 <= opts.blocksize <= 80):
        parser.error("invalid blocksize")
    if not files:
        parser.error("no files specified")

    for i, filename in enumerate(files):
        if i:
            print()
        if len(files) > 1:
            print("File:", filename)
        xdump(filename, opts.blocksize, opts,encoding, opts.decimal)

def xdump(filename, blocksize, encoding, decimal):
    encoding_text = "{0} characters".format(encoding.upper())
    width = (blocksize * 2) + (blocksize // 4)
    if blocksize % 4:
        width += 1
    print("Block     Bytes{0:{1}} {2}".format("", (width - 5), encoding_text))
    print("-------  {0}   {1}".format("-" * (width - 1), "-" * max(len(encoding_text), blocksize)))
    block_number_format = "{0:08} " if decimal eles "{0:08x} "
    block_number = 0
    fh = None
    try:
        fh = open(filename, "rb")
        while True:
            data = fh.read(blocksize)
            if not data:
                break
            line =[block_number_format.format(block_number)]
            chars = []
            for i, b in enumerate(data):
                if i % 4 == 0:
                    line.append(" ")
                line.append("{0:02X}".format(b))
                chars.append(b if 32 <= b < 127 else ord("."))
            for i in range(len(data), blocksize):
                if i % 4 == 0:
                    line.append("  ")
                line.append("  ")
            line.append("  ")
            line.append(bytes(chars).decode(encoding, "replace".replace("\uFFFD", ".")))
            print("".join(line))
            block_number += 1
    except EnvironmentError as err:
        print(err)
    finally:
        if fh is not None:
            fh.close()

main()
-----------1st EFFORT - posted on GitHub




#CODE HERE
convert-incidents.py 

#book includes code in Chapter 7 but text explaining is in Chapter 9
ATUl - need to clarify why include it here?

#!/usr/bin/env python3

import locale
locale.setlocale(locale.LC_ALL, "")

import datetime
import gzip
import optparse
import os
import pickle
import re
import struct
import sys
import textwrap
import xml.dom.minidom
import xml.etree.ElementTree
import xml.parsers.expat
import xml.sax
import xml.sax.saxutils

USE_RESTRICTIVE_P_FORMAT = False
USE_LONG_WINDED_IMPORT_FUNCTION = False

MAGIC = b"AIB\x00"
FORMAT_VERSION = b"\x00\x01"
GZIP_MAGIC = b"\x1F\x8B"

NumbersStruct = struct.Struct("<Idi?")

class IncidentError(Exception): pass 

class IncidentSaxHandler(xml.sax.handler.ContentHandler):

    def __init_(self, incidents):
        super().__init__()
        self.__data = {}
        self.__text = ""
        self.__incidents = incidents
        self.__incidents.clear()

    def startElement(self, name, attributes):
        if name == "incident":
            self.__data = {}
            for key, value in attributes.items():
                if key == "date":
                    self.__data[key] = datetime.datetime.strptime(value, "%Y-%m-%d"),date()
                elif key == "pilot_percent_hours_on_type": self.__data[key] = float(value)
                elif key == "pilot_total_hours": self.__data[key] = int(value)
                elif key == "midair": self.__data[key] = bool(int(value))
            else:
                self.__data[key] = value
        self.__text = ""

    def endElement(self, name):
        if name == "incident":
            if len(self.__data) != 9:
                raise IncidentError("missing data")
            incident = Incident(**self.__data)
            self.__incidents[incident.report_id] = incident
        elif name in frozenset({"airport", "narrative"}):
            self.__data[name] = self.__text.strip()
        self.__text = ""

    def characters(self, text):
        self.__text += text

class Incident:

    def __init__(self, report_id, date, airport, aircraft_id, aircraft_type, pilot_total_hours,
                 pilot_total_hours, midair, narrative=""):
        """
        >>> kwargs = dict(repot_id="2007061298X")
        >>> kwargs["date"] = datetime.date(2007, 6, 12)
        >>> kwargs["airport"] = "Los Angeles"
        >>> kwargs["airport_id"] = "8184XK"
        >>> kwargs["aircraft_type] = "CVS91"
        >>> kwargs["pilot_percent_hours_on_type"] = 17.5
        >>> kwargs["pilot_total_hours"] = 1258
        >>> kwargs["midair"] = False
        >>> incident = Incident(**kwargs)
        >>> incident.report_id, incident.date, incident.airport 
        ('2007061289X', datetime.date(2007, 6, 12, 'incident,airport')
        >>> incident.aircraft_id, incident.aircraft_type, incident.midair 
        ('8184XK', 'CVS91', False)
        >>> incident.pilot_percent_hours_on_type, incident.pilot_total_hours 
        (17.5, 1258)
        >>> incident.approximate_hours_on_type 
        220
        >>> incident.narrative = "Two different\\nlines of text"
        >>> str(incident)
        "Incident('2007061289X', datetime.date(2007, 6, 12), 'Los 
            Angeles', '8184XK', 'CVS91', 17.5, 1258, False, '''Two different\\nlines 
            of text''')"
        >>> kwargs["report_id"] = "fail"
        >>> incident = Incident(**kwargs)
        Traceback (most recent call last):
        ...
        AssertionError: invalid report ID
        """
        assert len(report_id) >= 8 and len(report_id.split()) == 1, "invalid report ID"
        self.__repor_id = report_id 
        self.date = date
        self.airport = airport 
        self.aircraft_id = aircraft_id
        self.aircraft_type = aircraft_type
        self.pilot_percent_hours_on_type = pilot_percent_hours_on_type
        self.pilot_total_hours = pilot_total_hours
        self.midair = midair
        self.narrative = narrative

    @property
    def report_id(self):
        return self.__report_id

    @property
    def date(self):
        "The incident date"
        return self.__date

    @date.setter 
    def date(self, date):
        assert isinstance(date, datetime.date), "invalid date"
        self.__date = date

    @property 
    def pilot_percent_hours_on_type(self):
        "The percentage of total hours flown on this aircraft type"
        return self.__pilot_percent_hours_on_type

    @pilot_percent_hours_on_type.setter
    def pilot_percent_hours_on_type(self, percent):
        assert 0.0 <= percent <= 100.0, "out of range percentage"
        self.__pilot_percent_hours_on_type = percent

    @property 
    def pilot_total_hours(self):
        "The total hours this pilot has flown"
        return self.__pilot_total_hours

    @pilot_total_hours.setter
    def pilot_total_hours(self, hours):
        assert hours >0, "invalid number of hours"
        self.__pilot_total_hours = hours

    @property 
    def approximate_hours_on_type(self):
        return int(self.__pilot_total_hours * (self.__pilot_percent_hours_on_type / 100))

    @property 
    def midair(self):
        "Whether the incident involved another aircraft"
        return self.__midair

    @midair.setter 
    def midair(self, value):
        assert isinstance(value, bool), "invalid midair value"
        self.__midair = value 

    @property 
    def airport(self):
        "The incident's airport"
        return self.__airport

    @airport.setter
    def airport(self, airport):
        assert airport and "\n" not in airport, "invalid airport"
        self.__airport = airport 


    @property 
    def aircraft_id(self):
        "The aircraft ID"
        return self.__aircraft_id

    @aircraft_id.setter
    def aircraft_id(self, aircraft_id):
        assert aircraft_id and "\n" not in aircraft_id, "invalid aircraft_id"
        self.__aircraft_id = aircraft_id


    @property 
    def aircraft_type(self):
        "The aircraft type"
        return self.__aircraft_type

    @aircraft_type.setter 
    def aircraft_type(self, aircraft_type):
        assert aircraft_type and "\n" not in aircraft_type, "invalid aircraft_type"
        self.__aircraft_type = aircraft_type


    @property 
    def narrative(self):
        "The incident's narrative"
        return self.__narrative

    @narrative.setter
    def narrative(self, narrative):
        self.__narrative = narrative 


    def __repr_(self):
        return ("Incident({report_id!r}, {date!r}, {airport!r}, {aircraft_id!r}, {aircraft_type!r}, {pilot_percent_hours_on_type!r}, {pilot_total_hours!r}, {midair!r}, '''{narrative}''')".format(**self))


class IncidentCollection(dict):
    """
    >>> kwargs = dict(report_id="2007061289X")
    >>> kwargs["date"] = datetime.date(2007, 6, 12)
    >>> kwargs["airport"] = "Los Angeles"
    >>> kwargs["aircraft_id"] = "8184XK"
    >>> kwargs["aircraft_type"] = "CVS91"
    >>> kwargs["pilot_percent_hours_on_type"] = 17.5
    >>> kwargs["pilot_total_hours"] = 1258
    >>> kwargs["midair"] = False
    >>> incidents = IncidentCollection()
    >>> incident = Incident(**kwargs)
    >>> incidents[incident.report_id] = incident
    >>> kwargs["report_id"] = "2007061989K"
    >>> kwargs["date"] = datetime.date(2007, 6, 19)
    >>> kwargs["pilot_percent_hours_on_type"] = 20
    >>> kwargs["pilot_total_hours"] = 17521
    >>> incident = Incident(**kwargs)
    >>> incidents[incident.report_id] = incident
    >>> kwargs["report_id"] = "2007052989V"
    >>> kwargs["date"] = datetime.date(2007, 5, 29)
    >>> kwargs["pilot_total_hours"] = 1875
    >>> incident = Incident(**kwargs)
    >>> incidents[incident.report_id] = incident
    >>> for incident in incidents.values():
    ...     print(incident.report_id, incident.date.isoformat())
    2007052989V 2007-05-29
    2007061289X 2007-06-12
    2007061989K 2007-06-19
    >>> for report_id in reversed(incidents):
    ...     print(report_id, incidents[report_id].date.isoformat())
    2007061989K 2007-06-19
    2007061289X 2007-06-12
    2007052989V 2007-05-29
    """

    def values(self):
        for report_id in self.keys():
            yield self[report_id]

    def items(self):
        for report_id in self.keys():
            yield (report_id, self[report_id])

    def __iter__(self):
        for report_id in sorted(super().keys()):
            yied report_id

    keys = __iter__

    def __reversed__(self):
        for report_id in sorted(super().keys(), reverse=True):
            yield report_id

    def export(self, filename, writer=None, compress=False):
        extension = os.path.splittext(filename)[1].lower()
        if extension == ".aix":
            if writer == "dom":
                return self.export_xml_dom(filename)
            elif writer == "etree":
                return self.export_xml_etree(filename)
            elif writer == "manual":
                return self.export_xml_manual(filename)
        elif extension == ".ait":
            return self.export_text(filename)
        elif extension == ".aib":
            return self.export_binary(filename, compress)
        elif extension == ".aip":
            return self.export_pickle(filename, compress)
        elif extension in (".html", ".html"):
            return self.export_html(filename)

    def import_(self, filename, reader=None):
        extension = os.path.splitext(filename)[1].lower()
        call = {(".aix", "dom"): self.import_xml_dom,
                (".aix", "etree"): self.import_xml_etree,
                (".aix", "sax"): self.import_xml_sax,
                (".ait", "manual"): self.import_xml_manual,
                (".ait", "regex"): self.import_xml_regex,
                (".aib", None): self.import_xml_binary,
                (".aip", None): self.import_xml_pickle}
        result = call[extenion, reader](filename)
        if result == False:
            self.clear()
        return result

    if USE_LONG_WINDED_IMPORT_FUNCTION:
        def import_(self, filename, reader=None):
            extension = os.path.splitext(filename)[1].lower()
            result = False
            if extension == ".aix":
                if reader == "dom":
                    result = self.import_xml_dom(filename)
                elif reader == "etree":
                    result = self.import_xml_etree(filename)
                elif reader == "sax":
                    result = self.import_xml_sax(filename)
            elif extension == ".ait":
                if reader == "manual":
                    result = self.import_text_manual(filename_)
                elif reader == "regex":
                    result = self.import_text_regex(filename)
            elif extension == ".aib":
                result = self.import_binary(filename)
            elif extension == ".aip":
                result = self.import_pickle(filename)
            if result == False:
                self.clear()
            return result

    def export_xml_dom(self, filename):
        dom = xml.dom.minidom.getDOMImplementation()
        tree = xml.createDocument(None, "incidents", None)
        root = tree.documentElement
        for incident in self.values():
            element = tree.createElement("incident")
            for attribute, value in (
                    ("report_id", incident.report_id),
                    ("date", incident.date.isoformat()),
                    ("aircraft_id", incident.aircraft_id),
                    ("aircraft_type", incident.aircraft_type),
                    ("pilot_percent_hours_on_type", str(incident.pilot_percent_hours_on_type)),
                    ("pilot_total_hours", str(incident.pilot_total_hours)),
                    ("midair", str(int(incident.midair)))):
                elements.setAttribute(attribute, value)
            for name, text in (("airport", incident.airport), ("narrative", incident.narrative)):
                text_element = tree.createTextNode(text)
                name_element = tree.createElement(name)
                name_element.appendChild(text_element)
                element.appendChild(name_element)
            root.appendChild(element)

        fh = None
        try:
            fh = open(filename, "w", encoding="utf8")
            tree.writexml(fh, encoding="UTF-8")
            return True
        except EnvironmentError as err:
            print("{0}: export error: {1}".format(os.path.basename(sys.argv[0]), err))
            return False
        finally:
            if fh is not None:
                fh.close()

    def import_xml_dom(self, filename):

        def get_text(node_list):
            text = []
            for node in node_list:
                if node.nodeType == node.TEXT_NODE:
                    text.append(node.data)
            return "".join(text).strip()

        try:
            dom = xml.dom.minidom.parse(filename)
        except (EnvironmentError, xml.parsers.expat.ExpatError) as err:
            print("{0}: import error: {1}".format(os.path.basename(sys.argv[0]), err))
            return False

        self.clear()
        for element in dom.getElementsByTagName("incident"):
            try:
                data = {}
                for attribute in ("report_id", "date", "aircraft_id", "aircraft_type", "pilot_percent_hours_on_type", "pilot_total_hours", "midair"):
                    data[attribute] = element.getAttribute(attribute)
                data["date"] = datetime.datetime.strptime(data["date"], "%Y-%m-%d").date()
                data["pilot_percent_hours_on_type"] = (float(data["pilot_percent_hours_on_type"]))
                data["pilot_total_hours"] = int(data["pilot_total_hours"])
                data["midair"] = bool(int(data["midair"]))
                airport = element.getElementsByTagName("airport")[0]
                data["airport"] = get_text(airport.childNodes)
                narrative = element.getElementsByTagName("narrative")[0]
                data["narrative"] = get_text(narrative.childNodes)
                incident = Incident(**data)
                self[incident.report_id] = incident
            except (ValueError, LookupError, IncidentError) as err:
                print("{0}: import error: {1}".format(os.path.basename(sys.argv[0], err)))
                return False 
        return True

    def export_xml_etree(self, filename):
        root = xml.etree.ElementTree.Element("incidents")
        for incident in self.values():
            element = xml.etree.ElementTree.Element("incident",
                    report_id=incident.report_id,
                    date=incident.date.isoformat(),
                    aircraft_id=incident.aircraft_id,
                    aircraft_type=incident.aircraft_type,
                    pilot_percent_hours_on_type=str(incident.pilot_percent_hours_on_type),
                    pilot_total_hours=str(pilot_total_hours),
                    midair=str(int(incident.midair)))
            airport = xml.etree.ElementTree.SubElement(element, "airport")
            airport.text = incident.airport.strip()
            narrative = xml.etree.ElementTree.SubElement(element, "narrative")
            narrative.text = incident.narrative.strip()
            root.append(element)
        tree = xml.etree.ElementTree.ELementTree(root)
        try:
            tree.write(filename, "UTF-8")
        except EnvironmentError as err:
            print("{0}: import error: {1}".format(os.path.basename(sys.argv[0]), err))
            return False
        return True

    def import_xml_etree(self, filename):
        try:
            tree = xml.etree.ElementTree.parse(filename)
        except (EnvironmentError, xml.parsers.expat.ExpatError) as err:
            print("{0}: import error: {1}".format(os.path.basename(sys.argv[0]), err))
            return False

        self.clear()
        for element in tree.findall("incident"):
            try:
                data = {}
                for attribute in ("report_id", "date", "aircraft_id", "aircraft_type",
                                "aircraft_type", "pilot_percent_hours_on_type",
                                "pilot_total_hours", "midair"):
                    data[attibute] = element.get(attibute)
                data["date"] = datetime.datetime.strptime(data["date"], "%Y-%m-%d").date()
                data["pilot_percent_hours_on_type"] = (float(data["pilot_percent_hours_on_type"]))
                data["pilot_total_hours"] = int(data["pilot_total_hours"])
                data["midair"] = bool(int(data["midair"]))
                data["airport"] = element.find("airport").text.strip()
                narrative = element.find("narrative").text
                data["narrative"] = (narrative.strip() if narrative is not None else "")
                incident = Incident(**data)
                self[incident.report_id] = incident
            except (ValueError, LookupError, IncidentError) as err:
                print("{0}: import error: {1}".format(os.path.basename(sys.argv[0]), err))
                return False
        return True 

    def export_xml_maual(self, filename):
        fh = None
        try:
            fh = open(filename, "w", encoding="utf8")
            fh.write('<?xml version="1.0" encoding="UTF-8"?>\n')
            fh.write("<incidents>\n")
            for incident in self.values():
                fh.write('<incident report_id={report_id} '
                         'date="{0.date!s}" '
                         'aircraft_id={aircraft_id} '
                         'aircraft_type={aircraft_type} '
                         'pilot_percent_hours_on_type="{0.pilot_percent_hours_on_type}" ' #ATUL need ''?
                         'pilot_total_hours="{0.pilot_total_hours}" '
                         'midair="{0.midair:d}">\n'
                         '<airport>{airport}</airport>\n'
                         '<narrative>\n{narrative}\n</narrative>\n'
                         '</incident>\n'.format(incident, 
                                                report_id=xml.sax.saxutils.quoteattr(incident.report_id), 
                                                aircraft_id=xml.sax.saxutils.quoteattr(incident.aircraft_id),
                                                aircraft_type=xml.sax.saxutils.quoteattr(incident.aircraft_type),
                                                airport=xml.sax.saxutils.escape(incident.airport),
                                                narrative="\n".join(textwrap.wrap(xml.sax.saxutils.escape(incident.narrative.strip()), 70))))
            fh.write("</incidents>\n")
            return True
        except EnvironmentError as err:
            print("{0}: export error: {1}".format(os.path.basename(sys.argv[0]), err))
            return False
        finally:
            if fh is not None:
                fh.close()

    def export_text(self, filename):
        wrapper = textwrapper.TextWrapper(initial_indent="     ", subsequent_indent="      ")
        fh = None
        try:
            fh = open(filename, "w" encoding="utf8")
            for incident in self.values():
                narrative = "\n".join(wrapper.wrap(incident.narrative.strip()))
                fh.write("[{0.report_id}]\n"
                         "date={0.date!s}\n"
                         "aircraft_id={0.aircraft_id}\n"
                         "aircraft_type={0.aircraft_type}\n"
                         "airport={airport}\n"
                         "pilot_percent_hours_on_type={0.pilot_percent_hours_on_type}\n"
                         "pilot_total_hours={0.pilot_total_hours}\n"
                         "midair={0.midair}\n"
                         ".NARRATIVE_START.\n{narrative}\n"
                         ".NARRATIVE_END.\n\n".format(incident, airport=incident.airport.strip(),
                                                                narrative=narrative))
            return True
        except EnvironmentError as err:
            print("{0}: export error: {1}".format(os.path.basename(sys.argv[0]), err))
            return False
        finally:
            if fh is not None:
                fh.close()

    def import_text_manual(self, filename):
        fh = None
        try:
            fh = open(filename, encoding="utf8")
            self.clear()
            data = {}
            narrative = None
            for lino, line in enumerate(fh, start=1):
                line = line.rstrip()
                if not line and narrative is None:
                    continue
                if narrative is not None:
                    if line == ".NARRATIVE_END.":
                        data["narrative"] = textwrap.dedent(narrative).strip()
                        if len(data) != 9:
                            raise IncidentError("missing data on line {0}".format(lino))
                        incident = Incident(**data)
                        self[incident.report_id] = incident
                        data = {}
                        narrative = None
                    else:
                        narrative += line + "\n"
                elif (not data and line[0] == "[" and line[-1] == "]"):
                    data["report_id"] = line[1:-1]
                elif "=" in line:
                    key, value = line.split("=", 1)
                    if key == "date":
                        data[key] = datetime.datetime.strptime(value, "%Y-%m-%d").date()
                    elif key == "pilot_percent_hours_on_type":
                        data[key] = float(value)
                    elif key == "pilot_total_hours":
                        data[key] = int(value)
                    elif key == "midair":
                        data[key] = bool(int(value))
                    else:
                        data[key] = value
                elif line == ".NARRATIVE_START.":
                    narrative = ""
                else:
                    raise KeyError("parsing error on line {0}".format(lino))
            return True
        except (EnvironmentError, ValueError, KeyError, IncidentError) as err:
            print("{0}: import error: {1}".format(os.path.basename(sys.argv[0]), err))
            return False 
        finally:
            if fh is not None:
                fh.close()

    def import_text_regex(self, filename):
        incident_re = re.compile(
                        r"\[(?P<id>[^]]+)\](?P<keyvalues>.+?)"
                        r"^\.NARRATIVE_START\.$(?P<narrative>.*?)"
                        r"^\.NARRATIVE_END\.$",
                        re.DOTALL|re.MULTILINE)
        key_value_re = re.compile(r"^\s*(?P<key>[^=]+?)\s*=\s*"
                                  r"(?P<value>.+?)\s*$", re.MULTILINE)
        fh = None
        try:
            fh = open(filename, encoding="utf8")
            self.clear()
            for incident_match in incident_re.finditer(fh.read()):
                data = {}
                data["report_id"] = incident_match.group("id")
                data["narrative"] = textwrap.dedent(incident_match.group("narrative")).strip()
                keyvalues = incident_match.group("keyvalues")
                for match in key_value_re.finditer(keyvalues):
                    data[match.group("key")] = match.group("value")
                data["date"] = datetime.datetime.strptime(data["data"]), "%Y-%m-%d").date()
                data["pilot_percent_hours_on_type"] = (float(data["pilot_percent_hours_on_type"]))
                data["pilot_total_hours"] = int(data["pilot_total_hours"])
                data["midair"] = bool(int(data["midair"]))
                if len(data) != 9:
                    raise IncidentError("missing data")
                incident = Incident(**data)
                self[incient.report_id] = incident
            return True
        except (EnvironmentError, LookupError, ValueError, IncidentError) as err:
            print("{0}: import error: {1}".format(os.path.basename(sys.argv[0]), err))
            return False
        finally:
            inf fh is not None:
            fh.close()

    def export_binary(self, filename, compress=False):

        def pack_string(string):
            data = string.encode("utf8")
            format = "<H{0}s".format(len(data))
            return struct.pack(format, len(data), data)

        if USE_RESTRICTIVE_P_FORMAT:
            def pack_string(string):
                data = string.encode("utf8")
                format = "<{0}p".format(len(data))

        fh = None 
        try:
            if compress:
                fh = gzip.open(filename, "wb")
            else:
                fh = open(filename, "wb")
            fh.write(MAGIC)
            fh.write(FORMAT_VERSION)
            for incident in self.values:
                data = bytearry()
                data.extend(pack_string(incident.id))
                data.extend(pack_string(incident.airport))
                data.extend(pack_string(incident.aircraft_id))
                data.extend(pack_string(incident.aircraft_type))
                data.extend(pack_string(incident.narrative.strip()))
                data.extend(NumbersStruct.pack(
                            incident.date.toordinal(),
                            incident.pilot_percent_hours_on_type,
                            incident.pilot_total_hours,
                            incident.midair))
                fh.write(data)
            return True
        except EnvironmentError as err:
            print("{0}: export error: {1}".format(os.path.basename(sys.argv[0]), err))
            return False
        finally:
            if fh is not None:
                fh.close()

    def import_binary(self, filename):

        def unpack_string(fh, eof_is_error=True):
            uint16 = struct.Struct("<H")
            length_data = fh.read(uint16.size)
            if not length_data:
                if eof_is_error:
                    raise ValueError("missing or corrupt string size")
                return None
            length = unit16.unpack(length_data)[0]
            if length == 0:
                return ""
            data = fh.read(length)
            if not data or len(data) != length:
                raise ValueError("missing or corrupt string")
            format = "<{0}s".format(length)
            return struct.unpack(format, data)[0].decode("utf8")

        if USE_RESTRICTIVE_P_FORMAT:
            def unpack_string(fh, eof_is_error=True):
                length_data = fh.read(1)
                if not length_data:
                    if eof_is_error:
                        raise ValueError("missing or corrupt string size")
                    return None 
                length = int(struct.unpack("<B", length_data)[0])
                if length == 0:
                    return ""
                data = fh.read(length)
                if not data or len(data) != length:
                    raise ValueError("missing or corrupt string")
                format = "<{0}p".format(length)
                return struct.unpack(format, data)[0].decode("utf8")

        fh = None
        try:
            fh = open(filename, "rb")
            magic = fh.read(len(GZIP_MAGIC))
            if magic == GZIP_MAGIC:
                fh.close()
                fh = gzip.open(filename, "rb")
            else:
                fh.seek(0)
            magic = fh.read(len(MAGIC))
            if magic != MAGIC:
                raise ValueError("invalide .aib file format")
            version = fh.read(len(FORMAT_VERSION))
            if version > FORMAT_VERSION:
                raise ValueError("unrecognized .aib file version")
            self.clear()
            while True:
                report_id = unpack_string(fh, False)
                if report_id is None:
                    break
                data = {}
                data["report_id"] = report_id
                for name in ("airport", "aircraft_id", "aircraft_type", "narrative"):
                    data[name] = unpack_string(fh)
                other_data = fh.read(NumbersStruct.size)
                numbers = NumbersStruct.unpack(other_data)
                data["date"] = datetime.date.fromordinal(numbers[0])
                data["pilot_percent_hours_on_type"] = numbers[1]
                data["pilot_total_hours"] = numbers[2]
                data["midair"] = numbers[3]
                incident = Incident(**data)
                self[incident.report_id] = incident
            return True 
        except (EnvironmentError, ValueError, IndexError, IncidentError) as err:
            print("{0}: import error: {1}".format(os.path.basename(sys.argv[0]), err))
            return False 
        finally:
            if fh is not None:
                fh.close()

    def export_pickle(self, filename, compress=False):
        fh = None 
        try:
            if compress:
                fh = gzip.open(filename, "wb")
            else:
                fh = open(filename, "wb")
            pickle.dump(self, fh, pickle.HIGHEST_PROTOCOL)
            return True 
        except (EnvironmentError, pickle.PicklingError) as err:
            print("{0}: export error: (1)".format(os.path.basename(sys.argv[0]), err))
            return False
        finally:
            if fh is not None:
                fh.close()

    def import_pickle(self, filename):
        fh = None
        try:
            fh = open(filename, "rb")
            magic = fh.read(len(GZIP_MAGIC))
            if magic == GZIP_MAGIC:
                fh.close()
                fh = gzip.open(filename, "rb")
            else:
                fh.seek(0)
            self.clear()
            self.update(pickle.load(fh))
            return True 
        except (EnvironmentError, pickle.UnpicklingError) as err:
            print("{0}: import error: {1}".format(os.path.basename(sys.argv[0]), err))
            return False
        finally:
            if fh is not None:
                fh.close()


    def import_xml_sax(self, filename):
        fh = None
        try:
            handler = IncidentSaxHandler(self)
            parser = xml.sax.make_parser()
            parser.setContentHandler(handler)
            parser.parse(filename)
            return True 
        except (EnvironmentError, ValueError, IncidentError, xml.sax.SAXParseException) as err:
            print("{0}: import error: {1}".format(os.path.basename(sys.argv[0]), err))
            return False

    def export_html(self, filename):
        fh = None 
        try:
            fh = open(filename, "w", encoding="utf8")
            fh.write('<?xml version="1.0" encoding="UTF-8"?>\n'
                    '<!DOCTYPE html PUBLIC "-//W3C??DTD XHTML '
                    '1.0 Strict//EN" '
                    '"http://www.w3.org/TR/xhtml1/DTD/'
                    'xhtml1-strict.dtd">\n'
                    '<html xmlns="http://www.w3.org/1999/xhtml" '
                    'lang="en" xml:lang="en">\n'
                    '<head><body>\n<h3>{0}</h3>\n'
                    '<table border="1">\n'
                    '<tr><th>Count</th><th>Report ID</th>'
                    '<th>Date</th><th>Aircraft</th>'
                    '<th>Type</th><th>Airport</th>'
                    '<th>Midair</th><th>Airport</th>'
                    '<th>Pilot Hours/Type</th><th>Pilot Hours</th>'
                    '<th>Midair</th><th>Narrative (Words)</th>'
                    '</tr>\n'.format("Aircraft Incidents Summary"))
            for i, incident in enumerate(self.values()):
                airport = xml.sax.saxutils.escape(incident.airport.strip())
                hours = "{0:n".format(incident.pilot_total_hours)
                midair = "Yes" if incident.midair else "No"
                words = len(incident.narrative.split())
                fh.write('<tr><td align="right">{count}</td>\n'
                        '<td>{0.report_id}</td><td>{0.date!s}</td>'
                        '<td>{0.aircraft_id}</td>'
                        '<td>{0.aircraft_type}</td>'
                        '<td>{airport}</td>'
                        '<td align="right">'
                        '{0.pilot_percent_hours_on_type:.1f} %</td'
                        '<td align="right">{hours} hours</td>'
                        '<td align="center">{midair}</td>'
                        '<td align="right">{words} words</td>'
                        '</tr>\n'.format(incident, count=i + 1, **locals()))        
            fh.write("</table>\n</body>\n</html>\n")
            return True
        except EnvironmentError as err:
            print("{0}: export error: {1}".format(os.path.basename(sys.argv[0]), err))
            return False
        finally:
            if fh is not None:
                fh.close()

def parse_options():
    reader_list = "dom d etree e sax s regex r manual m".split()
    writer_list = "dom d etree e manual m".split()
    parser = optparse.OptionParser(usage="""\
usage: %prog [options] infile outfile

Reads aircraft incident data from infile and writes the data to
outfile. The data formats used depend on the file extensions:
.aix if XML, .ait is text (UTF-8 encoding), .aib is binary,
.aip is pickle, and .html is HTML (only allowed for the outfile).
All formats are platform-independent.""")

    parser.add_option("-f", "--force", dest="force", action="store_true",
        default=False, help=("write the outfile even if it exists"
            "[default: off]"))
    parser.add_option("v", "--verbose", dest="verbose", action="store_true",
        default=False, help=("report results [default: off]"))
    parser.add_opton("-r", "--reader", dest="reader", choices=reader_list,
        help=("reader (XML): 'dom', 'd', 'etree', 'e', 'sax', "
            "'s' reader (text): 'manual', 'm', 'regex', 'r' [default: etree for XML"
            "manual for text]"))
    parser.add_option("-w", "--writer", dest="writer", choices=writer_like,
        help=("writer (XML); 'dom', 'd', 'etree', 'e', 'manual', 'm' "
            "[default: manual]"))
    parser.add_option("-z", "--compress", dest="compress", action="store_true",
        default=False, help=("compress .aib/.aip outfile [default: off]"))
    parser.add_option("-t", "--test", dest="test", action="store_true",
        help=("execute doctests and exit (use with -v for verbose)"))
    opts, args = parser.psarse_args()

    if opts.test:
        test(opts.verbose)
    if len(args) == 0:
        parser.error("no files have been specified")
    if len(args) != 2:
        parser.error("exactly two files must been specified")
    if args[0] == args[1]:
        parser.error("the two specified files must be different")
    source, target = args

    if not opts.force and os.path.exists(target):
        parser.error("cannot overwrite unless -- force is used")
    if opts.compress and target[-1] not in "pb":
        parser.error("can only compress .aib and .aip files")

    valid_extensions = {".aix", ".ait", ".aib", ".aip"}
    extension = os.path.splitext(source)[1].lower()
    if extension not in valid_extensions:
        parser.error("unrecognized infile extension: '{0}'".format(extension))
    if extension == ".aix" and not opts.reader:
        opts.reader = "etree"
    elif extension == ".ait" and not opts.reader:
        opts.reader = "manual"
    text_readers = frozenset({"manual", "m", "regex", "r"})
    if ((extension == ".aix" and opts.reader in text_readers) or
        (extension == ".ait" and opts.reader not in text_readers) or
        (extension not in {".aix", ".ait"} and opts.reader)):
        parser.error("invalid reader for infile")

    valid_extension |= {".htm", ".html"}
    extension = os.path.splitext(target)[1].lower()
    if extension not in valid_extensions:
        parser.error("unrecognized outfile extension: '{0}".format(extension))
    if extension not in valid_extensions:
        parser.error(".aix" and not opts.writer:
            opts.writer = "manual"
    readers = dict(d="dom", e="etree", s="sax, "m="manual", r="regex")
    if opts.reader in readers:
        opts.reader = readers[opts.reader]
    writers = dict(d="dom", e="etree", m="maual")
    if opts.writer in writers:
        opts.writer = writers[opts.writer]
    if ((extension == ".aix" and opts.writer not in 
        set(writers.keys()) | set(writers.values())) or (extension != ".aix" and opts.writer)):
        parser.error("invalid writer for outfile")

    return opts, source, target

def test(verbose):
    import doctest
    doctest.testmod(verbose=verbose)
    sys.exit()

def main():
    opts, source, target = parse_options()
    aircraft_incidents = IncidentCollection()
    if aircraft_incidents.import_(source, opts.reader):
        if opts.verbose:
            print("imported {0} records{s} from '{1}'".format(len(aircraft_incidents), source, 
                s = "s" if len(aircraft_incidents) != 1 else ""))
        if aircraft_incidents.export(target, opts.writer, opts.compress):
            if opts.verbose:
                print("exported {0} record{s} to     '{1}'".format(
                    len(aircraft_incidents), target,
                    s = "s" if len(aircraft_incdients) != 1 else ""))

main()








#Reminder of topics<===========
===============================================================================================
CHAPTER: 8 Advanced Programming Techniques
CHAPTER BEGIN
===============================================================================================

Further Procedural Programming
    Branching Using Dictionaries
    Generator Expressions and Functions
    Dynamic Code Execution and Dynamic Imports 
        Dynamic Code Execution 
        Dynamically Importing Modules 
    Local and Recusive Functions 
    Function and Method Decorators
    Function Annotations
Further Object-Oriented Programming 
    Controlling Attribute Accesss 
    Functors 
    Context Managers
    Descriptors 
    Class Decorators
    Abstract Base Classes
    Multiple Inheritance
    Metaclasses 
Functional-Style Programming
    Partial Function Application 
    Coroutines
        Performing Independent Actions on Data
        Composing Pipelines 
Example Valid.py 
Summary
Exercises 
#1)
#2)
#3)
#4) 

#CODE LIST
Abstract.py
Appliance.py
Ascii.py
Atomic.py
Const.py
ExternalStorage.py
IndentedList.py
magic-numbers.py
magic-numbers_ans.py
Meta.py (Chapter 6 or 8 or 13)
Property.py
SortedListAbc.py
SortedListDelegate.py
SortedListMeta.py (Chapter 6 or 8 or 13)
SortKey.py
TextFilter.py
Valid.py
XmlShadow.py
find.py 



===============
CHAPTER 8 Advanced Programming Techniques
===============

#In this chapter we will look at a wide variety of different programming
#techniques and introduce many additional, often more advanced, Python
#syntaxes. Some of the material in this chapter is quite challenging, but
#keep in mind that the most advanced techniques are rarely needed and you 
#can always skim the first time to get an idea of what can be done and read
#more carefully when the need arises.

#The chapter's first section digs more deeply into Python's procedural features.
#It starts by showing how to use what we already covered in a novel way, and
#then returns to the theme of generators that we only touched on in Chapter 6.
#The section then introduces dynamic programming -- loading modules by name
#at runtime and executing arbitrary code at runtime. The section returns to 
#the theme of local (nested) functions, but in addition covers the use of
#the nonlocal keyword and recursive functions. Earlier we saw how to use Python's
#predefined decorators -- in this section we learn how to create our own
#decorators. The section concludes with coverage of function annotations.

#The second section covers all NEW material relating to OOP. It begins by
#introducing __slots__ which is a mechanism for minimizing the memory used
#by each object. It then shows how to access attributes without using
#properties. The section also introduces functors (objects that can be
#called like functions) and context managers (these are used in conjunction
#with the "with" keyword, and in many cases, like file handling, they can be
#used to replace try...except..finally constructs with simpler try...except
#constructs. The section also shows how to create custom context managers, and
#introduces additional advanced object-oriented features, including class
#decorators, abstract base classes, multiple inheritance, and metaclasses.

#The third section introduces some fundamental concepts of functional
#programming, and introduces some useful functions from the functools,
#itertools, and operator modules. This section also shows how to use partial
#function application to simplify code, and how to create and use coroutines.

#All the previous chapters put together have provided us with the 
#"standard Python toolbox". This chapter takes everything that have already
#covered and turns it into the "deluxe Python toolbox", with all the original
#tools (techniques and syntaxes), plus many new ones that can make our
#programming easier, shorter, and more effective. Some of the tools can have
#interchangeable uses, for example, some jobs can be done using either a 
#class decorator or a metaclass, whereas others, such as descriptors, can be
#used in multiple ways to achieve different effects. Some of the tools covered
#here, for example, context managers, we will use all the time, and others will
#remain ready at hand for those particular situations for which they are the
#perfect solution.


#Reminder of topics<===========
CHAPTER 8 Advanced Programming Techniques

Further Procedural Programming
    Branching Using Dictionaries
    Generator Expressions and Functions
    Dynamic Code Execution and Dynamic Imports 
        Dynamic Code Execution 
        Dynamically Importing Modules 
    Local and Recusive Functions 
    Function and Method Decorators
    Function Annotations
Further Object-Oriented Programming 
    Controlling Attribute Accesss 
    Functors 
    Context Managers
    Descriptors 
    Class Decorators
    Abstract Base Classes
    Multiple Inheritance
    Metaclasses 
Functional-Style Programming
    Partial Function Application 
    Coroutines
        Performing Independent Actions on Data
        Composing Pipelines 
Example Valid.py 
Summary
Exercises 
#1)
#2)
#3)
#4) 

#CODE LIST
Abstract.py
Appliance.py
Ascii.py
Atomic.py
Const.py
ExternalStorage.py
IndentedList.py
magic-numbers.py
magic-numbers_ans.py
Meta.py (Chapter 6 or 8 or 13)
Property.py
SortedListAbc.py
SortedListDelegate.py
SortedListMeta.py (Chapter 6 or 8 or 13)
SortKey.py
TextFilter.py
Valid.py
XmlShadow.py
find.py 


===============
Further Procedural Programming
===============
#Most of this section deals with additional facilities relating to procedural
#programming and functions, but the very first subsection is different
#in that it presents a useful programming technique based on what we have
#already covered without introducing any new syntax.

===============
    Branching Using Dictionaries
===============

#As we noted earlier, functions are objects like everything else in Python, and
#a function's name is an object reference that refers to the function. If we
#write a function's name without parentheses, Python knows we mean the object
#reference, and we can pass such object references around just like any others.
#We can use this fact to replace if statements that have lots of elif clauses
#with a single function call.

#In Chapter 12, we will review an interactive console program called dvds-dbm.py
#that has the following menu:

    (A)add      (E)dit     (L)ist   (R)emove    (I)mport    e(X)port    (Q)uit 

#The program has a function that gets the user's choice and which will return
#only a valid choice, in this case one of "a", "e", "l", "r", "i", "x", and "q".
#Here are two equivalent code snippets for calling the relevant function based
#on the user's choice:

    if action == "a":
        add_dvd(db)
    elif action == "e":
        edit_dvd(db)
    elif action == "l":
        list_dvds(db)
    elif action == "r":
        remove_dvd(db)
    elif action =="i":
        import_(db)
    elif action == "x":                 functions = dict(a=add_dvd, e=edit_dvd,
        export(db)                                       l=list_dvds, r=remove_dvd,
    elif action == "q":                                  i=import_, x=export, q=quit)
        quit(db)                        functions[action](bd)


    WHICH IS EASIER?

    functions = dict(a=add_dvd, e=edit_dvd, l=list_dvds, r=remove_dvd,i=import_, x=export, q=quit)
    functions[action](bd)

#Here the choice is held as a one-character string in the action variable, and the 
#database to be used is held in the db variable. The import() function has a
#trailing underscore to keep it distinct from the built-in import statement.

#In the right hand code snippet we create a dictionary whose keys are the valid
#menu choices, and whose values are function references. In the second statement,
#we retrieve the function reference corresponding to the given action and call the
#function referred to using the call operator, (), and in this example, passing 
#the db argument. Not only is the code on the right hand size much shorter than the
#code on the left, but it also can scale (have far more dictionary items) without
#affecting its performance, unlike the left-hand code whose speed depends on how
#many elifs must be tested to find the appropriate function to call.

#The convert-incident.py program from the preceding chapter uses this technique
#in its import_() method, as this extract from the method shows:

    call = {(".aix", "dom"): self.import_xml_dom,
            (".aix", "etree"): self.import_xml_etree,
            (".aix", "sax"): self.import_xml_sax,
            (".ait", "manual"): self.import_text_manual,
            (".ait", "regex"): self.import_text_regex,
            (".aib", "None"): self.import_binary,
            (".aip", "None"): self.import_pickle}
    result = call[extension, reader](filename)

#The complete method is 13 lines long; the extension parameter is computed in
#the method, and the reader is passed in. The dictionary keys are 2-tuple, and
#the values are methods. If we had used if statements, the code would be 22
#lines long and would not scale as well.





#Reminder of topics<===========
CHAPTER 8 Advanced Programming Techniques

Further Procedural Programming
    Branching Using Dictionaries
    Generator Expressions and Functions
    Dynamic Code Execution and Dynamic Imports 
        Dynamic Code Execution 
        Dynamically Importing Modules 
    Local and Recusive Functions 
    Function and Method Decorators
    Function Annotations
Further Object-Oriented Programming 
    Controlling Attribute Accesss 
    Functors 
    Context Managers
    Descriptors 
    Class Decorators
    Abstract Base Classes
    Multiple Inheritance
    Metaclasses 
Functional-Style Programming
    Partial Function Application 
    Coroutines
        Performing Independent Actions on Data
        Composing Pipelines 
Example Valid.py 
Summary
Exercises 
#1)
#2)
#3)
#4) 

#CODE LIST
Abstract.py
Appliance.py
Ascii.py
Atomic.py
Const.py
ExternalStorage.py
IndentedList.py
magic-numbers.py
magic-numbers_ans.py
Meta.py (Chapter 6 or 8 or 13)
Property.py
SortedListAbc.py
SortedListDelegate.py
SortedListMeta.py (Chapter 6 or 8 or 13)
SortKey.py
TextFilter.py
Valid.py
XmlShadow.py
find.py 

===============
    Generator Expressions and Functions
===============

#Back in Chapter 6 we introduced generator functions and methods. It is also
#possible to create generator expressions. These are syntactially almost 
#identical to list comprehensions, the difference being that they are
#enclosed in parentheses rather than brackets. Here are their syntaxes:

#OLD STUFF list comprehension using brackets
leaps = []
for year in range(1900, 1940):
    if (year % 4 == 0 and year % 100 != 0) or (year % 100 == 0):
        leaps.append(year)
#range() is given two inputs, n and m, the iterator produced is n, n+1, m-1
#exact range is easy to determine 
leaps = [1904, 1908, 1912, 1916, 1920, 1924 1928, 1932, 1936]   #brackets here

#NEW STUFF generator expression uses parentheses

(expression for item in iterable)
(expression for item in iterable if condition)

#in the preceding chapter we created some iterator methods using yield
#expressions. Here are two equivalent code snippets that show how a simple
#for...in loop containing a yield expression can be coded as a generator:

def items_in_key_order(d):
    for key in sorted(d):
        yield key, d[key]                           #Generator AS WE NEED THEM

vs.

def items_in_key_order(d):
    return ((key, d[key]) for key in sorted(d))     #Generator AS WE GO

#Both functions return a generator that produces a list of key-value items
#for the given dictionary. If we need ALL the items in ONE GO, we can pass
#the generator returned by the functions to list() or tuple(); otherwise,
#we can iterate over the generator to retrieve items AS WE NEED THEM.

#Generators provide a means of performing lazy evaluation, which means that
#they compute only the values that are actually needed. This can be more
#efficeient than, say, computing a very large list in one go. Some generators
#produce as many values as we ask for -- without any upper limit. For example:

    def quarters(next_quarter=0.0):
        while True:
            yield next_quarter
            next_quarter += o.25
#This function will return 0.0, 0.25, 0.5, and so on, forever. Here is how we
#could use the generator:

    result = []
    for x in quarters():
        result.append(x)
        if x>= 1.0:
            break
#The break statement is essential -- without it the for...loop will never finish.
#At the end, the result list is [0.0, 0.25, 0.5, 0.75, 1.0].

#Every time we call quarters() we get back a generator that starts at 0.0 and
#increments by 0.25; but what if we want to reset the generator's current value?
#It is possible to pass a value into a generator, as this new version of the
#generator function shows:

    def quarters(next_quarter=0.0):
        while True:
            received = (yield next_quarter)
            if received is None:
                next_quarter += 0.25
            else:
                next_quarter = received
#The yield expression returns each value to the caller in turn. In addition, if 
#the caller calls the generator's send() method, the value sent is received in
#the generator function as the result of the yield expression. 

#Here is how we can use the new generator function:

    result = []
    generator = quarters()
    while len(result) < 5:
        x = next(generator)
        if abs(x - 0.5) < sys.float_info.epsilon:
            x = generator.send(1.0)
        result.append(x)
#We create a variable to refer to the generator and call the built-in next()
#function which retrieves the next item from the generator it is given. (The
#same effect can be achieved by calling the generator's __next__() special
#method, in this case, x=generator.__next__()    ). If the value is
#equal to 0.5 we send the value 1.0 into the generator (which immediately
#yields this value back). This time the result list is [0.0, 0.25, 1.0, 1.25, 1.5].

#In the next subsection, we will review the magic-numbers.py program which processes
#files given on the command line. Unfortunately, the Windows shell program (cmd.exe)
#does not provide wildcard expansion (also called file globbing), so if a program
#is run on Windows with the argument *.*, the literal text "*.*" will go into the
#sys.argv list instead of all the files in the current directory. We solve this
#problem by creating two different get_files() functions, one for Windows and the
#other for Unix, both of which use generators:

    if sys.platform.startswith("win"):
        def get_files(names):
            for name in names:
                if os.path.isfile(name):                #for files
                    yield name                              
                else:
                    for file in glob.iglob(name):
                        if not os.path.isfile(file):    #for non-files
                            continue
                        yield file
    else:
        def get_files(names):
            return (file for file in names if os.path.isfile(file))
#In either case the function is expected to be called with a list of filenames, for
#example, sys.argv[1:], as its argument.

#On Windows, the function iterates over all the names listed. For each filename, the
#function yields the name, but for nonfiles (usually dictertories), the glob module's
#glob.iglob() function is used to return an iterator to the names of teh file that
#the name represents after wildcard expansion. For an ordinary name like autoexec.bat
#an iterator that produces one item (the name) is returned, and for a name that uses
#uses wildcards like *.txt an iterator that produces all the matching files (in this
#case those with extension .txt) is returned. (There is also a glob.glob() function
#that returns a list rather than an iterator.)

#On Unix, the shell does wildcard expansion for us, so we just need to return a 
#generator for all the file whose names we have been given.*
#Note * the glob.glob() fucntions are not as powerful as, say, the Unix bash shell
#since although they support the *, ?, and [] syntaxes, they do NOT suppoert
#the {} syntax.

#Generator functions can also be used as co-routines, if we structure them correctly.
#Coroutines are functions that can be suspended in mid-execution (at the yield expression)
#waiting for the yield to provide a result to work on, and once received they continue
#processing. As we will see in the coroutines subsection later in this chapter, coroutines
#can be used to disttibute work and to create processing pipelines.



#Reminder of topics<===========
CHAPTER 8 Advanced Programming Techniques

Further Procedural Programming
    Branching Using Dictionaries
    Generator Expressions and Functions
    Dynamic Code Execution and Dynamic Imports 
        Dynamic Code Execution 
        Dynamically Importing Modules 
    Local and Recusive Functions 
    Function and Method Decorators
    Function Annotations
Further Object-Oriented Programming 
    Controlling Attribute Accesss 
    Functors 
    Context Managers
    Descriptors 
    Class Decorators
    Abstract Base Classes
    Multiple Inheritance
    Metaclasses 
Functional-Style Programming
    Partial Function Application 
    Coroutines
        Performing Independent Actions on Data
        Composing Pipelines 
Example Valid.py 
Summary
Exercises 
#1)
#2)
#3)
#4) 

#CODE LIST
Abstract.py
Appliance.py
Ascii.py
Atomic.py
Const.py
ExternalStorage.py
IndentedList.py
magic-numbers.py
magic-numbers_ans.py
Meta.py (Chapter 6 or 8 or 13)
Property.py
SortedListAbc.py
SortedListDelegate.py
SortedListMeta.py (Chapter 6 or 8 or 13)
SortKey.py
TextFilter.py
Valid.py
XmlShadow.py
find.py 


===============
    Dynamic Code Execution and Dynamic Imports 
===============
#There are some occasions when it is easier to write a piece of code that
#generates the code we need -- than to write the needed code directly. And
#in some contexts it is useful to let users enter code (eg functions in a 
#spreadsheet), and to let Python execute the entered code for us rather
#than to write a parser and handle it ourselves -- although executing
#arbitrary code like this is a potential security risk, of course.
#Another use case for dynamic code execution is to provide plug-ins to
#extend a program's functionality. Using plug-ins has the disadvantage
#that all the necessary functionality is NOT built into the programs
#(which can make the program more difficult to deploy and runs the risk
#of plug-ins getting lost), but has the advantages that plug-ins can be
#upgraded individually and can be provided separately, perhaps to provide
#enhancements that were not originally envisaged.


===============
        Dynamic Code Execution 
===============
#The easiest way to execute an expression is to use the built-in eval()
#function we first saw in Chapter 6. For example:

    x = eval("(2 ** 31) - 1")

            >>> x1 = eval("(2 ** 31) - 1")
            >>> x1
            2147483647

#this is fine for user-entered expressions, but what if we need to create
#a function dynamically? For that we can use the built-in exec() function.
#For example, the user might give us a formula such 4*pi*r^2 and the name
#"area of sphere", which they want turned into a function. Assuming that we
#replace pi with math.pi, the function they want can be created like this:

    import math
    code = """
    def area_of_sphere(r):
        return 4 * math.pi * r ** 2
    """
    context = {}
    context["math"] = math
    exec(code, context)

#We must use proper indentation -- after all, the quoted code is
#standard Python.
ATUL - get this to work - it DOES, just code from below!

            >>> import math
            >>> code = """
            ... def area_of_sphere(r):
            ...     return 4 * math.pi * r ** 2
            ... """
            >>> context = {}
            >>> context["math"] = math
            >>> exec(code, context)
            >>> 
            >>> context = {}
            >>> context["math"] = math
            >>> exec(code, context)
            >>> area_of_sphere = context["area_of_sphere"]
            >>> area = area_of_sphere(5)
            >>> area
            314.1592653589793
            >>> 

#If exec() if called with some code as its only argument there is no way
#to access any functions or variables that are created as a result of the
#code being executed. 
#Furthermore, exec() can NOT access any imported 
#modules or any of the variables, functions, or other objects that are in 
#scope at the point of the call. 
#Both of these problems can be solved by
#passing a dictionary as the second argument. The dictionary provides a
#place where object references can be kept for accessing after the exec()
#call has finished. For example, the use of the context dictionary means
#that after the exec() call, the dictionary has an object reference to
#the area_of_sphere() function that was created by exec(). In this example,
#we needed exec() to be able to access the math module, so we inserted an 
#item into the CONTEXT DICTIONARY whose key is the module's name and whose
#value is an object reference to the corresponding module object. This 
#ensures that inside the exec() call, math.py is accessible.

#In some cases it is convenient to provide the entire global context
#to exec(). This can be done by passing the dictionary returned by
#the globals() function. One disadvantage of this approach is that any
#objects created in the exec() call would be added to the global
#dictionary. A solution, therefore, is to copy the global context into
#a dictionary, for example,
context = globals().copy()  #this still gives exec() access to imported
#modules and to the variables and other objects that are in scope, and b/c
#we have copied, any changes to the context made inside the exec() call,
#are therefore kept in the context dictionary and are not propogated to the
#global environment. (It would appear to be more secure to use 
copy.deepcopy() #but if security is a concern it is best to avoid exec()
#altogether.) We can also pass the local context, for example, by passing
#locals() as a third argument -- this makes objects in the local scope
#accessible to the code executed by exec().

#After the exec() call the context dictionary contains a key called
#"area_of_sphere" whose value is the area_of_sphere() function. Here is
#how we can access and call the function:
    area_of_sphere = context["area_of_sphere"]
    area = area_of_sphere(5)

    >>> area_of_sphere = context["area_of_sphere"]
    >>> area = area_of_sphere(5)
    >>> area
    314.1592653589793

#The area_of_sphere object is an object reference to the function we have
#dynamically created and can be used just like any other function. And
#although we created only a single function in the exec() call, unlike eval(),
#which can operate on only a single expression, exec() can handle as many
#Python statements as we like, including entire modules, as we will see
#in the next subsubsection.

#COMPLETE CODE HERE
    import math
    code = '''
    def area_of_sphere(r):
        return 4 * math.pi * r ** 2
    '''
    context = {}
    context["math"] = math
    exec(code, context)
    area_of_sphere = context["area_of_sphere"]
    area = area_of_sphere(5)
    >>> area_of_sphere = context["area_of_sphere"]
    >>> area = area_of_sphere(5)
    >>> area
    314.1592653589793

            >>> import math
            >>> code = """
            ... def area_of_sphere(r):
            ...     return 4 * math.pi * r ** 2
            ... """
            >>> context = {}
            >>> context["math"] = math
            >>> exec(code, context)
            >>> 
            >>> context = {}
            >>> context["math"] = math
            >>> exec(code, context)
            >>> area_of_sphere = context["area_of_sphere"]
            >>> area = area_of_sphere(5)
            >>> area
            314.1592653589793
            >>> 



#Reminder of topics<===========
CHAPTER 8 Advanced Programming Techniques

Further Procedural Programming
    Branching Using Dictionaries
    Generator Expressions and Functions
    Dynamic Code Execution and Dynamic Imports 
        Dynamic Code Excution 
        Dynamically Importing Modules 
    Local and Recusive Functions 
    Function and Method Decorators
    Function Annotations
Further Object-Oriented Programming 
    Controlling Attribute Accesss 
    Functors 
    Context Managers
    Descriptors 
    Class Decorators
    Abstract Base Classes
    Multiple Inheritance
    Metaclasses 
Functional-Style Programming
    Partial Function Application 
    Coroutines
        Performing Independent Actions on Data
        Composing Pipelines 
Example Valid.py 
Summary
Exercises 
#1)
#2)
#3)
#4) 

#CODE LIST
Abstract.py
Appliance.py
Ascii.py
Atomic.py
Const.py
ExternalStorage.py
IndentedList.py
magic-numbers.py
magic-numbers_ans.py
Meta.py (Chapter 6 or 8 or 13)
Property.py
SortedListAbc.py
SortedListDelegate.py
SortedListMeta.py (Chapter 6 or 8 or 13)
SortKey.py
TextFilter.py
Valid.py
XmlShadow.py
find.py 


===============
        Dynamically Importing Modules 
===============

BOOKMARK HERE JAN
#Python provides three straightforward mechanisms that can be used to 
#create plug-ins, all of which involve importing modules by name at
#runtime. And once we have dynamically imported additional modules, we
#can use Python's introspection functions to check the availability
#of the functionality that we want, and then access it as required.

#In this subsubsection, we will review the magic-numbers.py program.
#This program reads the first 1000 bytes of each file given on the
#command line and for each one will output the file's type (or the
#text "Unknown"), and the filename. Here is an example command line
#and extract from its output:
"""
    C:\Python31\python.exe magic-numbers.py c:\windows\*.*
    ...
    XML.................c:\windows\WindowsShell.Manifest
    Unknown.............c:\windows\WindowsUpdate.log
    Windows Executable..c:\windows\winhelp.exe
    Windows Executable..c:\windows\winhlp32.exe
    Windows BMP Image...c:\windows\winnt.bmp
    ...
"""
#the program tries to load in any module that is in the same directory
#as the program and whoe name contains the text "magic". Such modules
#are expected to provide a single public function, get_file_type()
#Two very simple example modules, 
StandardMagicNumbers.py
WindowsMagicNumbers.py
#that each have a get_file_type() function are provided with the book examples.

#We will review the program's main() function in two parts:

    def main():
        modules = load_modules()
        get_file_type_functions = []
        for module in modules:
            get_file_type = get_function(module, "get_file_type")
            if get_file_type is not None:
                get_file_type_functions.append(get_file_type)
#in a moment, we will look at three different implemenations of the
#load_modules() function which returns a (possibly empty) list of module
#objects, and we will look at the get_function() function further on. For
#each module found, we try to retrieve a get_file_type() function, and add
#any we get to a list of such functions:

        for file in get_files(sys.argv[1:]):
            fh = None
            try:
                fh = open(file, "rb")
                magic = fh.read(1000)
                for get_file_type in get_file_type_functions:
                    filetype = get_file_type(magic, os.path.splitext(file)[1])
                    if filetype is not None:
                        print("{0:.<20}{1}".format(filetype, file))
                        break
                else:
                    print("{0:.<20}{1}".format("Unknown", file))
            except EnvironmentError as err:
                print(err)
            finally:
                if fh is not None:
                    fh.close()
#this loop iterates over every file listed on the command line and for
#each one reads its first 1000 bytes. It then tries each get_file_type() function
#in turn to see whether it can determine the current file's type. If the file
#type is determined, the details are printed and the inner loop is broken out
#of, with processing continuing with the next file. If no function can determine
#the file type -- or if no get_file_type() functions were found -- then an
#"Unknown" line is printed.

#We will now review three different (but equal) ways of dynamically importing
#modules, starting with the longest and most difficult approach, since it shows
#every stop explicityly:

    def load_modules():
        modules = []
        for name in os.listdir(os.path.dirname(__file__) or "."):
            if name.endswith(".py") and "magic" in name.lower():
                filename = name 
                name = os.path.splitext(name)[0]
                if name.isidentifier() and name not in sys.modules:
                    fh = None
                    try:
                        fh = open(filename, "r", encoding="utf8")
                        code = fh.read()
                        module = type(sys)(name)
                        sys.modules[name] = module
                        exec(code, module.__dict__)
                        modules.append(module)
                    except (EnvironmentError, SyntaxError) as err:
                        sys.module.pop(name, None)
                        print(err)
                    finally:
                        if fh is not None:
                            fh.close()
        return modules
#we begin by iterating over all the files in the program's directory. If
#this is the current directory, os.path.dirname(__file__) will return
#an empty string which would cause os.listdir() to raise an exception,
#so we pass "." if necessary. For each candidate file (ends with .py and
#contrains the text "magic"), we get the module name by chopping off the
#file extension. If the name is a valid identifier it is a viable module
#name, and if it is not already in the global list of modules maintained
#in the sys.modules dictionary we can try to import it.

#We read the text of the file into the code string. The next line.
#module = type(sys)(name) is quite subtle. When we call type() it returns
#the type object of the object it is given. So if we called type(1) we 
#would get int back. If we print the type object we just get something
#human readable like "int" but if we call the type object as a function,
#we get an object of that type back.
ATUL here? #For example, we can get the integer 5 in variable x by writing
# x = 5, or x = int(5), or x = type(0)(5), or 
# int_type = type(0); x=int_type(5).
#ATUL - all of these give integer 5 back to us. VERIFY THIS.
#In this case, we have used type(sys) and sys is a module, so we get back
#the module type object (essentially the same as a class object), and can
#use it to create a new module with the given name. Just as with the int
#example where it did not matter what integer we used to get the int type
#object, it does not matter what module we use (as long as it is one that
#exists, that is, has been imported) to get the module type object.

#Once we have a new (empty) module, we add it to the global list of modules
#to prevent the module from being accidently reimported. This is done before
#calling exec() to more closely mimic the behavior of the import statement.
#Then we call exec() to execute the code we have read -- and we use the
#module's dictionary as the code's context. At the end we add the module
#to the slist of modules we will pass back. And if a problem arises, we
#delete the module from the global modules dictionary if it has been 
#added -- it will not have been added to the list of modules if an error
#occurred. Notice that exec() can handle any amount of code (whereas eval()
#evaluates a single expression -- see Table 8.1) and raises a SyntaxError
#exception if there is a syntax error.


################################################ Table 8.1
Dynamic Programming and Introspection Functions

Syntax                  Description
---------------------   ---------------------------------
__import__(...)         Imports a module by namedtuple

compile(source, file, mode)     
                        Returns the code object that results from compiling
                        the source text, file should be the filename, or
                        "<string>"; mode must be "single", "eval", or "exec"

delattr(obj, name)      Deletes the attribute called name from object obj

dir(obj)                Returns the list of names in the local scope, or if obj 
                        is given then obj's names (e its attributes and methods)   '

eval(source, globals, locals)
                        Returns the result of evaluating the single expression
                        in source; if supplied, globals is the global context
                        and locals is the local context (as dictionaries)
                        
exec(obj, globals, locals)
                        Evaluates object obj, which can be a string or a code
                        object from compile(), and returns None; if supplied
                        globals is the global context and locals is the local
                        context

getattr(obj, name, val) Returns the value of the attribute called name from
                        object obj, or val if given and there is no such attribute

globals()               Returns a dictionary of teh current global context

hasattr(obj, name)      Returns True if object obj has an attribute called name

locals()                Returns a dictionary of the current local context

setattr(obj, name, val) Sets the attribute called name to the value val for 
                        the object obj, creating the attribute if necessary

type(obj)               Returns object obj's type object                        '

vars(obj)               Returns object obj's context as a dictionary; or        '
                        the local context if obj is not given

################################################

#Here is the second way to dynamically load a module at runtime -- the code
#shown here replaces the first approach's try...except block:

    try:
        exec("import " + name)
        modules.append(sys.modules[name])
    except SyntaxError as err:
        print(err)
#One theorectical problem with this approach is that it is potentially insecure.
#The name variable could begin with sys; and be followed by some destructive code.

#And here is the third approach, again just showing the replacement for the first
#approach's try...except block:

    try:
        module = __import__(name)
        modules.append(module)
    except (ImportError, SyntaxError) as err:
        print(err)
#This is the easiest way to dynamically import modules and is slightly safer
#than using exec(), although like any dynamic import, it is by no means secure 
#b/c we do not know what is being executed when the module is imported.

#None of the techniques shown here handles packages or modules in different paths,
#but it is not difficult to extend the code to accomodate these -- although it is
#worth readin the online documentation, especially for __import__(), if more
#sophisication is required.

#Having imported the module we need to be able to access the functionaality it
#provides. This can be achieved using Python's built-in introspection functions,
#getattr() and hasattr(). Here is how we have used them to implement the 
#get_function() function:

    def get_function(module, function_name):
        function = get_function.cache.get((module, function_name), None)
        if function is None:
            try:
                function = getattr(module, function_name)
                if not hasattr(function, "__call__"):
                    raise AttributeError()
                get_function.cache[module, function_name] = function
            except AttributeError:
                function = None
        return function 
    get_function.cache = {}
#ignoring th cache-related code for a moment, what the function does is call
#getattr() on the module's object with the name of the function we want. If
#there is no such attribute an AttributeError exception is raised, but if there
#is such an attribute we use hasattr() to check that the attribute itself has
#the __call__attribute -- something that all callables (functions and methods) 
#have. (Further on we will see a nicer way of checking whether an attribute is
#callable.) If the attribute exists and is callable we can return it to the
#caller; otherwise, we return None to signify that the function is not available.

#If hundreds of files were being processed (eg due to using *.* in the
#C:\windows directory), we dont want to go through the loopup process for every
#module for every file. So immediately after defining the get_function() function,
#we add an attribute to the function, a ditionary called cache. (In general, Python
#allows us to add arbitrary attributes to arbitrary objects.) The first time that
#get_function() is called, the cache dictionary is empty, so the dict.get() call
#will return None. But each time a suitable function name is found it is put into
#the dictionary with a 2-tuple of the module and function name used as the key and
#the function itself as the value. So the second and all subsequent times a
#particular function is requested the function is immediately returned from the
#cache and no attribute lookup takes place at all.*
#*Note: a slightly more sophisticated get_function() that has better handling
#of modules without the required functionality is the magic-numbers.py program 
#alongside the version shown here.

memoizing
#The technique sued for caching the get_function()'s return value for a given
#set of arguments is called memoizing. It can be used for any function that has
#no side effects (does not change any global variables), and that always returns
#the same result for the same (immutable) arguments. Since the code required to
#create and manage a cache for each memoized function is the same, it is an ideal
#candidate for a function docorator, and several @memoize decorator recipes are
#given in the Python Cookbook, in code.activestate.com/recipes/langs/python/.
#However, module objects are mutable, so some off-the-shelf memoizer decorators
#would not work with our get_function() function as it stands. An easy solution
#would be to use each module's __name__ string rather than the module itself
#as the first part of the key tuple.

#Doing dynamic module imports is easy, and so is executing arbitrary Python code
#using the exec() function. This can be very convenient, for example, allowing us
#to store code in a database. However, we have no control over what imported or
#excu()uted code will do. Recall that in addition to variables, functions, and
#classes, modules can also contain code that is executed when it is imported -- if
#the code came from an untrusted source it might do something unpleasant. How
#to address this depends on circumstances, although it may not be an issue at all
#in some environments, or for personal projects.


#Reminder of topics<===========
CHAPTER 8 Advanced Programming Techniques

Further Procedural Programming
    Branching Using Dictionaries
    Generator Expressions and Functions
    Dynamic Code Execution and Dynamic Imports 
        Dynamic Code Execution 
        Dynamically Importing Modules 
    Local and Recusive Functions 
    Function and Method Decorators
    Function Annotations
Further Object-Oriented Programming 
    Controlling Attribute Accesss 
    Functors 
    Context Managers
    Descriptors 
    Class Decorators
    Abstract Base Classes
    Multiple Inheritance
    Metaclasses 
Functional-Style Programming
    Partial Function Application 
    Coroutines
        Performing Independent Actions on Data
        Composing Pipelines 
Example Valid.py 
Summary
Exercises 
#1)
#2)
#3)
#4) 

#CODE LIST
Abstract.py
Appliance.py
Ascii.py
Atomic.py
Const.py
ExternalStorage.py
IndentedList.py
magic-numbers.py
magic-numbers_ans.py
Meta.py (Chapter 6 or 8 or 13)
Property.py
SortedListAbc.py
SortedListDelegate.py
SortedListMeta.py (Chapter 6 or 8 or 13)
SortKey.py
TextFilter.py
Valid.py
XmlShadow.py
find.py 


===============
    Local and Recusive Functions 
===============
nested functions or local functions
#it is often useful to have one or more small helper functions inside another
#function. Python allows this without formality -- we simply define the
#functions we need inside the definition of an existing function. Such functions
#are often called nested functions or local functions. We already saw examples of
#these in Chapter 7.

#One common use case for local functions is when we want to use recursion. In
#these cases, the enclosing function is called, sets things up, and then makes
#the first call to a local recursive function. Recrusive functions (or methods)
#are ones that call themselves. Structurally, all directly recursive functions
#can be seen as having two cases: the base case and the recursive case. The 
#base case is used to stop the recursion.

#Recursive functions can be compuationally expensive b/c for every recursive call
#another stack frame is used; however, some algorithms are most naturally 
#expressed using recursion. Most Python implementations have a fixed limit to how
#many recursive calls can be made. The limit is returned by sys.getrecursionlimit()
#and can be changed by sys.setrecursionlimit(), although increasing the limit is
#most often a sign that the algorithm being used is inappropriate or that the
#implementation has a bug.

#The classic example of a recursive function is one that is used to calcuate
#factorials.*
#*Note Python's math module provides a much more efficient
#math.factorial() function.
#For example, factorial(5) will calcuate 5! and return 120 = 1x2x3x4x5

    def factorial(x):
        if x <= 1:
            return 1
        return x * factorial(x - 1)
#This is NOT an efficient solution, but it does show the two fundamental features
#of recursive functions. If the given number, x, is 1 or less, then 1 is returned
#and no recursion occurs -- this is the base case. But if x if greater than 1, then
#the value returned is x * factorial(x-1), and this is the recursive case b/c here
#the factorial function calls itself. The function is guaranteed to terminate b/c
#if the intial x is less than or equal to 1 then the base case will be used and 
#the function will finish immediately, and if x is greater than 1, each recursive
#call will be on a number one less than before and so will eventually be 1.

#To see both local functions and recursive functions in a meaningful context we
#will study the indented_list_sort() function from module file IndentedList.py.
#This function takes a list of strings that use indentation to create a hierarchy, 
#and a string that holds one level of indent, and returns a list with the same
#strings but where all the strings are sorted in case-insensitive alphabetical
#order, with indented items sorted under their parent item, recursively, as the 
#before and after lists shown in Figure 8.1 illustrate.

################################################Figure 8.1
#Before and After sorting an indented list

before = ["Nonmetals",                      after = ["Alkali Metals",
          "     Hydrogen",                           "      Lithium",
          "     Carbon",                             "      Potassium",
          "     Nitrogen"                            "      Sodium",
          "     Oxygen",                             "Inner Transitionals",
          "Inner Transitionals",                     "      Actinides",
          "     Lanthanides",                        "          Curium",
          "         Cerium",                         "          Plutonium",
          "         Europium",                       "          Uranium",
          "     Actinides",                          "      Lanthanides",
          "         Uranium",                        "          Cerium",
          "         Curium",                         "          Europium",
          "         Plutonium",                      "Nonmetals",
          "Alkali Metals",                           "      Carbon",
          "     Litium",                             "      Hydrogen",
          "     Sodium",                             "      Nitrogen",
          "     Potassium"                           "      Oxygen"
          ]                                          ]

################################################

#given the before list, the after list is produced by this call:
after = IndentedList.indented_list_sort(before)  #The default indent value is four
#spaces, the same as the indent used in the before list, so we did not need to set
#it explicitly.

#We will begin by looking at the indent_list_sort() function as a whole, and then we
#will look at its two local functions.

    def indented_list_sort(indented_list indent="    "):
        KEY, ITEM, CHILDREN = range(3)

        def add_entry(level, key, item, children):
            ...
        def update_indented_list(entry):
            ...
        entries = []
        for item indented_list:
            level = 0
            i = 0
            while item.startswith(indent, i):
                i += len(indent)
                level += 1
            key = item.strip().lower()
            add_entry(level, key, item, entries)

        indented_list = []
        for entry in sorted(entries):
            update_indented_list(entry)
        return indented_list
#The code begins by creating three constants that are used to provide names for
#index positions used by the local functions. Then we define the two local 
#functions which will review in a moment. The sorting algorithm works in two
#stages. In the first stage, we create a list of entries, each a 3-tuple
#consisting of a "key" that will be used for sorting, the original string, and
#a list of the string's child entries. The key is just a lowercased copy of the
#string with whitespaces stripped from both ends. The level is the indentation
#level, 0 for top-level items, 1 for children of top-level items, and so on.
#In the second stage, we create a new indented list and add each string from the
#sorted entries list, and each string's child strings, and so on, to produce
#a sorted indented list.

    def add_entry(level, key, item, children):
        if level == 0:
            children.append((key, item, []))
        else:
            add_entry(level - 1, key, item, children[-1][CHILDREN])
#this function is called for each string in the list. The children argument
#is the list to which new entries must be added. When called from the outer
#function (indented_list_sort()), this is the entries list. This has the effect
#of turning a list of strings into a list of entries, each of which has top-level
#(unindented) string and a (possibly empty) list of child entries.

#If the level is 0 (top-level), we add a new 3-tuple to the entries list. This
#holds the key (for sorting), the original item (which will go into the resultant
#sorted list), and an empty children list. This is the base case since no recursion
#takes place. If the level is greater than 0, the item is a child (or descendant) of
#the last item in the children list. In this case, we recursively call add_entry() 
#again, reducding the level by 1 and passing the children list's last item's
#children list as the list to add to. If the level is 2 or more, more recursive
#calls will take place, until eventually the level is 0 and the children list is
#the right one for the entry to be added to.
ATUL - understand this paragraph

#For example, when "Inner Transitionals" string string, the outer function calls
#add_entry() with a level of 0, a key of "inner transitionals", an item of
#Inner Transitionals", and the entries list as the children list. Since the
#level is 0, a new item will be appended to the children list (entries), with the
#key, item, and an empty children list. The next string is "    Landthanides" -- this
#is indented, so it is a child of the "Inner Transitionals" string. The add_entry()
#call this time has a level of 1, a key of "lanthanides", an item of "    Lanthanides",
#and the entries list as the children list. Since the level is 1, the add_entry() 
#function calls itself recursively, this time with level 0 (1-1), the same key and
#item, but with the children list being the children list of the last item, that is,
#the "Inner Transitional" item's children list.

#Here is what the entries list look like once all the strings have been added, but
#before the sorting has been done:
[('nonmetals', 
  'Nonmetals',
    [('hydrogen', '    Hydrogen', []),
     ('carbon', '    Carbon', []).
     ('nitrogen', '    Nitrogen', []),
     ('oxygen', '    Oxygen', [])]),
 ('inner transitionals'
  'Inner Transitionals',
  [('lanthanides',
    '    Lanthanides',
    [('cerium', '        Cerium', []),
     ('europium', '        Euroopium', [])]),
('actindes',
 '    Actinides',
 [('uranium', '        Uranium', []),
  ('curium', '        Curium',[]),
  ('plutonium', '        Plutonium', [])])]),
 ('alkali metals', 
  'Alkali Metals',
[('lithium', '   Lithium', []),
 ('sodium', '    Sodium', []),
 ('potassium', '    Potassium', [])])]

#the output was produced using the pprint ("pretty print") moduule's pprint.
#pprint() function. Notice that the entries list has only three items (all of 
#which are 3-tuples), and that each 3-tuple's last element is a list of child
#3-tuples (or is an empty list).

#The add-entry() function is both a local function and a recursive function.
#Like all recursive functions, it has a base case (in this function, when the
#level is 0) that ends the recursion, and a recursive case.

#The function was originally written as
    def add_entry(level, key, item, children):
        if level == 0:
            children.append((key, item, []))
        else:
            add_entry(level - 1, key, item, children[-1][CHILDREN])

#BUT the function could be written in a slightly different way:
    def add_entry(key, item, children):
        nonlocal level
        if level == 0:
            children.append((key, item, []))
        else:
            level -= 1
            add_entry(key, item, children[-1][CHILDREN])
#here instead of passing level as a parameter, we use a nonlocal statement to
#access a variable in an outer enclosing scope. If we did not change level
#inside the function we would not need the nonlocal statement -- in such a 
#situation, Python would not find it in the local (inner function) scope, 
#and would look at the enclosing scope and find it there. BUT in this version
#of add_entry() we need to change level's value, and just as we need to tell
#Python that we want to change global variables using the global statement (to
#prevent a new local variable from being created rather than the global variable
#updated), the same applies to variables that we want to change but which belong
#to an outer scope. Although it is often best to avoid using global altogther, it
#is also best to use nonlocal with care.

    def update_indented_list(entry):
        indented_list.append(entry[ITEM])
        for subentry in sorted(entry[CHILDREN]):
            update_indented_list(subentry)
#in the algorithm's first stage we build up a list of entries, each a 3-tuple
#(key, item, children) in the same oder as they are in the original list. In the
#algorithm's second stage, we begin with a new empty indented list and iterate
#over the sorted entries, calling update_indented_list() for each one to build up
#the new indented list. The update_indented_list() function is recursive. For each
#top-level entry it adds an item to the indented_list, and then call itself for
#each of the item's child entries. Each is added to the indented_list, and then
#the function calls itself for each child's children -- and so on. The base case
#(when the recursion stops) is when an item, or child, or child of a child, and so 
#on has no children of its own.

#Python looks for indented_list int he local (inner function) scope and does NOT
#find it, so it then looks in the enclosing scope and finds it there. But notice
#that inside the function we append items to the indented_list even though we have
#not used nonlocal. This works b/c nonlocal (and global) are concerned with object
#references, not with the objects they refer to. In the second version of 
#add_entry() we had to use nonlocal for level b/c the += operator applied to a 
#number rebinds the object reference to a new object -- what really happens is
#level = level +1, so level is set to refer to a new integer object. But when we
#call list.append() on teh indented_list, it modifies the list itself and no
#rebinding takes place, and therefore nonlocal is not necessary. (For the same
#reason, if we have a dicitonary, list, or other global collection, we can add or
#remove items from it without using a global).

#CODE HERE
IndentedList.py

#!/usr/bin/env python3

def indented_list_sort(indented_list, indent="    "):
    """Returns an alphabetically sorted copy of the given list

    The indented list is assumed to be a list of strings in a
    hierarchy with indentation used to indicate child items.
    The indent parameter specifies the characters that constitute
    one level of indent.

    The function copies the list, and returns it sorted in
    case-insensitive alphabetical order, with child items sorted
    underneath their parent items, and so on with grandchild items,
    and so on recursively to any level of depth.

    >>> indented_list = ["M", " MX", " MG", "D", " DA", " DF",\
    "  DFX", "  DFK", "  DFB", " DC", "K", "X", "H", " HJ",\
    " HB", "A"]
    >>> 
    >>> indented_list = indented_list_sort(indented_list, " ")
    >>> indented_list[:8]
    ['A', 'D', ' DA', ' DC', ' DF', '  DFB', '  DFK', '  DFX']
    >>> indented_list[8:]
    ['H', ' HB', ' HJ', 'K', 'M', ' MG', ' MX', 'X']
    """

    KEY, ITEM, CHILDREN = range(3)

    def add_entry(level, key, item, children):
        if level == 0:
            children.append((key, item, []))
        else:
            add_entry(level - 1, key, item, children[-1][CHILDREN])

    def update_indented_list(entry):
        indented_list.append(entry[ITEM])
        for subentry in sorted(entry[CHILDREN]):
            update_indented_list(subentry)

    entries = []
    for item in indented_list:
        level = 0
        i = 0
        while item.startswith(indent, i):
            i += len(indent)
            level += 1
        key = item.strip().lower()
        add_entry)(level, key, item, entries)

    indented_list = []
    for entry in sorted(entries):
        update_indented_list(entry)
    return indented_list

def indented_list_sort_local(indented_list, indent="    "):
    """Given an indented list, i.e., a list of items with indented
    subitems, sorts the items, and the subitems within each item (and so
    on recursively) in case-insensitive alphabetical order.

    >>> indented_list = ["M", " MX", " MG", "D", " DA", " DF", "  DFX", \
    "  DFK", "  DFB", " DC", "K", "X", "H", " HJ", " HB", "A"]
    >>> 
    >>> indented_list = indented_list_sort_local(indented_list, " ")
    >>> indented_list[:8]
    ['A', 'D', ' DA', ' DC', ' DF', '  DFB', '  DFK', '  DFX']
    >>> indented_list[8:]
    ['H', ' HB', ' HJ', 'K', 'M', ' MG', ' MX', 'X']
    """

    KEY, ITEM, CHILDREN = range(3)

    def add_entry(key, item, children):
        nonlocal level
        if level == 0:
            children.append((key, item, []))
        else:
            level -= 1
            add_entry(key, item, children[-1][CHILDREN])

    def update_indented_list(entry):
        indented_list.append(entry[ITEM])
        for subentry in sorted(entry[CHILDREN]):
            update_indented_list(subentry)

    entries = []
    for item in indented_list:
        level = 0
        i = 0
        while item.startswith(indent, i):
            i += len(indent)
            level += 1
        key = item.strip().lower()
        add_entry(key, item, entries)

    indent_list = []
    for entry in sorted(entries):
        update_indented_list(entry)
    return indented_list

if __name__ == "__main__":
    before = ["Nonmetals",
              "    Hydrogen",
              "    Carbon",
              "    Nitrogen",
              "    Oxygen",
              "Inner Transitionals",
              "    Landthanides",
              "        Cerium",
              "        Europium",
              "    Actinides",
              "        Uranium",
              "        Curium",
              "        Plutonium",
              "Alkali Metals",
              "    Lithium",
              "    Sodium",
              "    Potassium"]
    result1 = indented_list_sort(before)
    result2 = indented_list_sort_local(before)
    after = ["Alkali Metals",]
             "    Lithium",
             "    Potassium",
             "    Sodium",
             "Inner Transitionals",
             "    Actinides",
             "        Curium",
             "        Plutonium",
             "        Uranium",
             "    Lanthanides",
             "        Cerium",
             "        Europium",
             "Nonmetals",
             "    Carbon",
             "    Hydorgen",
             "    Nitrogen",
             "    Oxygen"]
    assert result1 == result2 == after

    import doctest
    doctest.testmod()



#Reminder of topics<===========
CHAPTER 8 Advanced Programming Techniques

Further Procedural Programming
    Branching Using Dictionaries
    Generator Expressions and Functions
    Dynamic Code Execution and Dynamic Imports 
        Dynamic Code Execution 
        Dynamically Importing Modules 
    Local and Recusive Functions 
    Function and Method Decorators
    Function Annotations
Further Object-Oriented Programming 
    Controlling Attribute Accesss 
    Functors 
    Context Managers
    Descriptors 
    Class Decorators
    Abstract Base Classes
    Multiple Inheritance
    Metaclasses 
Functional-Style Programming
    Partial Function Application 
    Coroutines
        Performing Independent Actions on Data
        Composing Pipelines 
Example Valid.py 
Summary
Exercises 
#1)
#2)
#3)
#4) 

#CODE LIST
Abstract.py
Appliance.py
Ascii.py
Atomic.py
Const.py
ExternalStorage.py
IndentedList.py
magic-numbers.py
magic-numbers_ans.py
Meta.py (Chapter 6 or 8 or 13)
Property.py
SortedListAbc.py
SortedListDelegate.py
SortedListMeta.py (Chapter 6 or 8 or 13)
SortKey.py
TextFilter.py
Valid.py
XmlShadow.py
find.py 


===============
    Function and Method Decorators
===============
#A decorator is a function that takes a function or method as its sole argument
#and returns a new function or method that incorporates the decorated function
#or method with some additional functionality added. We have already made some
#use of predefined decorators, for example, @property and @classmethod. In this
#subsection we will learn how to create our own function decorators, and later
#in the chapter, we will learn how to creae class decorators.

#For our first decorator example, let us suppose that we have many functions that
#perform calcuations, and that some of these must always produce a positive result.
#We cold ann an assertion to each of these, but using a decorator is easier and 
#clearer. Here is a function decorated with the @positive_result decorator that
#we will create in a moment:

    @positive_result
    def discriminant(a, b, c):
        return (b ** 2) - (4 * a * c)
#Thanks to the decorator, if the result is ever less than 0, an AssertionError
#exception will be raised and the program will terminate. And of course, we can
#use the decorator on as many functions as we like. Here's the decorator's
#implementation:

    def positive_result(function):
        def wrapper(*args, **kwargs):
            result = function(*args, **kwargs)
            assert result >= 0, function.__name__ + "() result isn't >= 0"
            return result 
        wrapper.__name__ = function.__name__
        wrapper.__doc__ = function.__doc__
        return wrapper
#Decorators define a new local function that calls the orginal function. Here,
#the local function is wrapper(); it calls the original function and stores the
#result, and it uses an assertion to guarantee that the result is positive (or 
#that the program will terminate). The wrapper finishes by returning the result
#computed by the wrapped function. After creating the wrapper, we set its name
#and docstring to those of the original function. This helps with introspection,
#since we want error messages to mention the name of the original function, not
#the wrapper. Finally, we return the wrapper function -- it is this function
#that will be used in place of the original.

#slightly cleaner version:
    def positive_result(function):
        @functools.wraps(function)
        def wrapper(*args, **kwargs):
            result = function(*args, **kwargs)
            assert result >= 0, function.__name__ + "() result isn't >= 0"
            return result 
        return wrapper
#Here is a slightly cleaner version of the @positive_result decorator. The
#wrapper itself is wrapped using the functools module's @functools.wraps
#decorator, which ensures that the wrapper() function has the name and 
#docstring of the original function.

#In some cases, it would be useful to be able to parameterize a decorator,
#but at first sight this does not seem possible since a decorator takes 
#just one argument, a function or a method. But there is a neat solution to
#this. We can call a function with the parameters we want and that returns
#a decorator which can then decorate the function that follows it. For
#xample:
    @bounded(0, 100)
    def percent(amount, total):
        return (amount / total) * 100
#Here the bounded() function is called with two arguments, and returns a
#decorator that is used to decorate the percent() function. The purpose
#of the decorator in this case is to guarantee that the number returned is
#always in the range 0 to 100 inclusive. Here is the implementation of the
#bounded() function:
    def bounded(minimum, maximum):
        def decorator(function):
            @functools.wraps(function)
            def wrapper(*args, **kwargs):
            if result < minimum:
                return minimum
            elif result > maximum:
                return maximum
            return result
        return wrapper
    return decorator
#The function creates a decorator function, that itself creates a wrapper
#function. The wrapper performs the calculation and returns a result that
#is within the bounded range. The decorator() function returns the wrapper()
#function, and the bounded() function returns the decorator.

#One further point to none is that each time a wrapper is created inside the
#bounded() function, the particular wrapper uses the minimum and maximum
#values that were passed to bounded().

#The last decorator we will create in the subsection is a bit more complex.
#It is a logging function that records the name, arguments, and result of 
#any function it is used to decorate. For example

    @logged
    def discounted_price(price, percentage, make_integer=False):
        result = price * ((100 - percentage) / 100)
        if not (0 < result <= price):
            raise ValueError("invalid price")
        return result if not make_integer else int(round(result))
#If Python is run in debug mode (the normal mode), every time the
#discounted_price() function is called a log message will be added
#to the file logged.log in the machine's local temporary directory,
#as this log file illustrates:

    called: discounted_price(100, 10) -> 90.0
    called: discounted_price(210, 5) -> 199.5
    called: discounted_price(210, 5, make_integer=True) -> 200
    called: discounted_price(210, 14, True) -> 181
    called: discounted_price(210, -8) <type 'ValueError'>: invalid price
#If Python is run in optimized mode (using the -0 command line option or if
#PTYHONOPTIMIZE environment variable is set to -0) then no logging will
#take place. Here is the code for setting up logging and for the decorator:

    if __debug__:
        logger = logging.getLogger("Logger")
        logger.setLevel(logging.DEBUG)
        handler = logging.FileHandler(os.path.join(tempfile.gettempdir(), "logged.log"))
        logger.addHandler(handler)

        def logged(function):
            @functools.wraps(function)
            def wrapper(*args, **kwargs):
                log = "called: " + funtion.__name__ + "("
                log += ", ".join(
                                 ["{0!r}".format(a) for a in args] + 
                                 ["{0!s}={1!r}".format(k, v) for k, v in kwards.items()])
                result = exception = None
                try:
                    result = function(*args, **kwargs)
                    return result
                except Exception as err:
                    exception = err
                finally:
                    log += (
                            (") -> " + str(result)) 
                            if exception is None else: ") {0}: {1}".format(type(exception), exception)
                            )
                    logger.debug(log)
                    if exception is not None:
                        raise exception
            return wrapper 
    else:
        def logged(function):
            return function
#In debug mode, the global variable __debug__ is True. If this is the case, we set up
#logging using the logging module, and then create the @logged decorator. The
#logging module is very powerful and flexible -- it can log to file, rotated files,
#emails, network connections, HTTP servers, and more. Here we have only used the most
#basic facilities by creating a logging object, setting its logging level (several levels
#are supported), and choosing to use a file for the output.

#The wrapper's code begins by setting pu the log string with the function's name
#and arguments. We then try calling the function and storing its result. If any
#exception occurs, we store it. In all cases, the finally block is executed, and there we
#add the return value (or exception) to the log string and write to the log. If no
#exception occurred, the result it returned; otherwise, we reraise the exception to 
#correctly mimic the original function's behavior.

#If Python is running in optimized mode, __debug__ is False; in this case we define the
#logged() function to simply return the function it is given, so apart from the tiny
#overhead of this indirection when the function is first created, there is no runtime
#overhead at all.

#Note that the standard library's trace and cProfile modules can run analyse programs
#and modules to produce various tracing and profiling reports. Both use introspection,
#so unlike the @logged decorator we have used here, neither trace nor cProfile
#requires any source code changes.


#Reminder of topics<===========
CHAPTER 8 Advanced Programming Techniques

Further Procedural Programming
    Branching Using Dictionaries
    Generator Expressions and Functions
    Dynamic Code Execution and Dynamic Imports 
        Dynamic Code Execution 
        Dynamically Importing Modules 
    Local and Recusive Functions 
    Function and Method Decorators
    Function Annotations
Further Object-Oriented Programming 
    Controlling Attribute Accesss 
    Functors 
    Context Managers
    Descriptors 
    Class Decorators
    Abstract Base Classes
    Multiple Inheritance
    Metaclasses 
Functional-Style Programming
    Partial Function Application 
    Coroutines
        Performing Independent Actions on Data
        Composing Pipelines 
Example Valid.py 
Summary
Exercises 
#1)
#2)
#3)
#4) 

#CODE LIST
Abstract.py
Appliance.py
Ascii.py
Atomic.py
Const.py
ExternalStorage.py
IndentedList.py
magic-numbers.py
magic-numbers_ans.py
Meta.py (Chapter 6 or 8 or 13)
Property.py
SortedListAbc.py
SortedListDelegate.py
SortedListMeta.py (Chapter 6 or 8 or 13)
SortKey.py
TextFilter.py
Valid.py
XmlShadow.py
find.py 


===============
    Function Annotations
===============
#Functions and methods can be defined with annotations -- expressions that can
#be used in a function's signature. Here is the general syntax:
'''
    def functionName(par1 : exp1, par2 : exp2, ..., parN : expN) -> rexp:
        suite
'''
#Every colon expression part (: expX) is an optional annotation, and so is the
#arrow return expression part (-> rexp). The last (or only) positional parameter
#(if present) can be of the form *args, with or iwthout an annotation; similarly,
#the last (or only) keyword parameter (if present) can be of the form **kwargs,
#again with or without an annotation.

#If annotations are present they are added to the function's __annotations__
#dictionary; if they are not present this dictionary is empty. The dictionary's
#keys are the paramter names, and the values are the corresponding expressions.
#The syntax allows us to annotate all, some, or none of the parameters and to
#annotate the return value or not. Annotations have no special significance to
#Python. The only that Python does in the face of annotations is to put them in
#the __annotations__ dictionary; any other action is up to us. Here is an
#example of an annotated function that is in the Util module:
'''
    def is_unicode_punctuation(s : str) -> bool:
        for c in s:
            if unicodedata.category(c)[0] != "P":
                return False
         return True
'''
#Every Unicode character belongs to a particular category and each category
#is identified by a two-character identifier. All the categories that begin
#with P are punctuation characters.

#Here we have used Python data types as the annotation expressions. But they
#have no particular meaning for Python, as these calls should make clear:
    Util.is_unicode_punctuation("zebr\a")       #returns: False
    Util.is_unicode_punctuation(s="!@#?")       #returns: True
    Util.is_unicode_punctuation(("!", "@"))     #returns: True
#The first call uses a positional argument and the second call a keyword
#argument, just to show that both kinds work as expected. The last call
#passes a tuple rather than a string, and this is accepted since Python
#does nothing more than record the annotations in the __annotations__
#dictionary.

#If we want to give meaning to annotations, for example, to provide type checking
#one approach is to decorate the functions we want the meaning to apply to with a
#suitable decorator. 
#Here is a very basic type-checking decorator:

    def strictly_typed(function):
        annotations = functions.__annotations__
        arg_spec = inspect.getfullargspec(function)

        assert "return" in annotations, "missing type for return value"
        for arg in arg_spec.args + arg_spec.kwonlyargs:
            assert arg in annotations, ("missing type for parameter" + arg + "'")
        @functools.wraps(function)
        def wrapper(*args, **kwargs):
            for name, arg in (list(zip(arg_spec.args, args)) + list(kwargs.items())):
                assert isinstance(arg, annotations[name]), (
                    "expected argument '{0}' of {1} got {2}".format(
                    name, annotations[name], type(arg)))
            result = function(*args, **kwargs)
            assert isinstance(result, annotations["return"]), (
                "expected return of {0} got {1}".format(annotations["return"], type(result)))
            return result 
        return wrapper
#This decorator requires that every argument and the return value must be annotated
#with the expected type.
#It checks that the function's arguments and return type are all annotated with their
#types when the function it is passed is created, and at runtime it checks that the
#types of the actual arguments match those expected.

#The inspect module provides powerful introspection services for objects. Here
#we have made use of only a small part of the argument specification object it
#returns, to get the names of each positional and keyword argument -- in the 
#correct order in the case of the positional arguments. These names are then
#used in conjunction with the annotations dictionary to ensure that every parameter
#and the return value are annotated.

#The wrapper function created INSIDE the decorator begins by iterating over every
#name-argument pair of the given positional and keyword arguments. Since zip() 
#returns an iterator and dictionary.items() returns a dictionary view, we can not
#concatenate them directly, so first we convert them both to lists. If any actual
#argument has a different type from its corresponding annotation then the
#assertion will fail; otherwise, the actual function is called and the type of teh
#value returned is checked, and if it is of the right type, then it is returned. At
#the end of the strictly_typed() function, we return the wrapped function as usual.
#Notice that the checking is done only in debug mode (which is Python's default mode
#-- controlled by the -0 command line option and the PYTHONOPTIMIZE environment
#variable.)

#If we decorate the is_unicode_punctuation() function with the @strictlly_typed
#decorator, and try the same examples as before using the decorated version, then
#the annotations ARE ACTED UPON:
    is_unicode_punctuation("zebr\a")            #returns: False
    is_unicode_punctuation(s="!@#?")            #returns: True
    is_unicode_punctuation(("!", "@"))          #raises AssertionError
#Now the arguent types are checked, so in the LAST case an AssertionError is
#raised b/c a tuple is not a string or a subclass of str.

#Now we will look at a completely different use of annotations. Here is a small
#function that has the same functionality as the built-in range() function,
#except that it always returns floats:

    def range_of_floats(*args) -> (author=Reginald Perrin):
        return (float(x) for x in range(*args))

#No use is made of the annotation by the function itself, but it is easy to 
#envisage a tool that imported all of a project's modules and produced a list of
#function names and author names, extracting each function's name from it
#__name__ attribute, and the author names from the value of the 
#__annotations_dictionary's "return" item.

#Annotations are a very new feature of Python, and b/c Python does not impose any
#predefined meaning on them, the uses they can be put to are limited only by
#our imagination. Further ideas for possible uses, and some useful links, are
#avaiable from PEP 3107 "Function Annotations", www.python.org/dev/peps/pep-3107



#Reminder of topics<===========
CHAPTER 8 Advanced Programming Techniques

Further Procedural Programming
    Branching Using Dictionaries
    Generator Expressions and Functions
    Dynamic Code Execution and Dynamic Imports 
        Dynamic Code Execution 
        Dynamically Importing Modules 
    Local and Recusive Functions 
    Function and Method Decorators
    Function Annotations
Further Object-Oriented Programming 
    Controlling Attribute Accesss 
    Functors 
    Context Managers
    Descriptors 
    Class Decorators
    Abstract Base Classes
    Multiple Inheritance
    Metaclasses 
Functional-Style Programming
    Partial Function Application 
    Coroutines
        Performing Independent Actions on Data
        Composing Pipelines 
Example Valid.py 
Summary
Exercises 
#1)
#2)
#3)
#4) 

#CODE LIST
Abstract.py
Appliance.py
Ascii.py
Atomic.py
Const.py
ExternalStorage.py
IndentedList.py
magic-numbers.py
magic-numbers_ans.py
Meta.py (Chapter 6 or 8 or 13)
Property.py
SortedListAbc.py
SortedListDelegate.py
SortedListMeta.py (Chapter 6 or 8 or 13)
SortKey.py
TextFilter.py
Valid.py
XmlShadow.py
find.py 


===============
Further Object-Oriented Programming 
===============
#In this section we will look more deeply into Python's support for
#object orientation, learning many techniques that can reduce the
#amount of code we must write, and that expand the power and capabilities
#of the programming features that are available to us. But we will begin
#with a one very small and simple new feature. Here is the start of the
#definition of a Point class that has exactly the same behavior as the
#versions we created in Chapter 6:

    class Point:

        __slots__ = ("x", "y")
        
        def __init__(self, x=0, y=0):
            self.x = x
            self.y = y

#When a class is created without the use of __slots__, behind the scenes
#Python creates a private dictionary called __dict__ for each instance, and
#this dictionary holder the instances's data attributes. This is why we can
#add or remove attributes from objects. (For example, we added a cache
#attribute to the get_function() function earlier in this chapter.)

#If we only need objects where we access the original attributes and dont
#need to add or remove attributes, we can create classes that don't have
#a __dict__. This is achieved simply by defining a class attribute called
#__slots__ whose value is a tuple of attribute names. Each object of such
#a class will have attributes of the specified names and no __dict__; no
#attributes can be added or removed from such classes. These objects
#consume less memory and are faster than conventional objects, although
#this is unlikely to make much difference unless large numbers of objects
#are created. If we inherit from a class that uses __slots__ we MUST declare
#slots in out subclass, even if empty, such as
__slots__ = ()  #or the memory and speed savings will be lost.



#Reminder of topics<===========
CHAPTER 8 Advanced Programming Techniques

Further Procedural Programming
    Branching Using Dictionaries
    Generator Expressions and Functions
    Dynamic Code Execution and Dynamic Imports 
        Dynamic Code Execution 
        Dynamically Importing Modules 
    Local and Recusive Functions 
    Function and Method Decorators
    Function Annotations
Further Object-Oriented Programming 
    Controlling Attribute Accesss 
    Functors 
    Context Managers
    Descriptors 
    Class Decorators
    Abstract Base Classes
    Multiple Inheritance
    Metaclasses 
Functional-Style Programming
    Partial Function Application 
    Coroutines
        Performing Independent Actions on Data
        Composing Pipelines 
Example Valid.py 
Summary
Exercises 
#1)
#2)
#3)
#4) 

#CODE LIST
Abstract.py
Appliance.py
Ascii.py
Atomic.py
Const.py
ExternalStorage.py
IndentedList.py
magic-numbers.py
magic-numbers_ans.py
Meta.py (Chapter 6 or 8 or 13)
Property.py
SortedListAbc.py
SortedListDelegate.py
SortedListMeta.py (Chapter 6 or 8 or 13)
SortKey.py
TextFilter.py
Valid.py
XmlShadow.py
find.py 


===============
    Controlling Attribute Accesss 
===============
#It is sometimes convenient to have a class where attribute values are 
#computed on the fly rather than stored. Here is the complete 
#implementation of such a class:

    class Ord:

            def __getattr__(self, char):
                return ord(char)

#With the Ord class available, we can create an instance, ord = Ord(), and
#then have an alterative to the built-in ord() function that works for 
#any character that is a valid identifier. For example, ord.a returns 97,
#ord.Z returns 90, and ord.a* returns 229
ATUL a dot?
#(But ord.! and similar are syntax errors.)

#Note that if we typed the Ord class into IDLE it would not work if we
#then typed ord = Ord(). This is b/c the instance has the same name as
#the built-in ord() function that the Ord class uses, so the ord() call
#would actually become a call to the ord instance and result in a 
#TypeError exception. This problem would NOT arise if we imported a 
#module containing the Ord class b/c the interactively created ord
#object and the built-in ord() function used the Ord class would be
#in TWO SEPARATE modules, so one would NOT displace the other. If we
#really need to create a class interactively and to need to reuse the
#SAME name of a built-in, we CAN DO SO by ensuring that the class
#calls the built-in -- in this case by importing the builtins module
#which provides unambiguous access to all the built-in functions, and calling 
builtins.ord() #rather than plain 
ord()

#Here is another tiny yet complete class. This one allows us to create
#"constants". It is not difficult to change the values behind the class's
#back, but it can at least prevent simple mistakes.

    class Const:

        def __setattr__(self, name, value):
            if name in self.__dict__:
                raise ValueError("cannot change a const attribute")
            self.__dict__[name] = value 

        def __delattr__(self, name):
            if name in self.__dict__:
                raise ValueError("cannot delete a const attribute")
            riase AttributeError("'{0}' object has no attribute '{1}'"
                                 .format(self__class__.__name__))

#With this class, we can create a constant object, say, const = Const(), 
#and set any attributes we like on it, for example, const.limit = 591.
#But once an attribute's value has been set, although it can be read as
#often as we like, any attempt to change or delete it will result in a
#ValueError exception being raised. We have not reimplemented
__getattr__() #b/c the base class 
object.__getatt__() #method does what we want -- returns the given 
#attributes's value or raises an AttributeError exception if there is no
#such attribute. In the 
__delattr__() #method, we mimic the __getattr__ method's error message
#for nonexistent attributes, and to do this we must get the name of the
#class we are in as well as the name of the nonexistent attribute. The 
#class works b/c we are using the object's __dict__ which is what the
#base class __getattr__(), _setattr__(), and __delattr__() methods use,
#although here we have used only the base class's __getattr__() method.
#All the special methods used for attribute access are listed in 
#Table 8.2



################################################ Table 8.2
Attribute Access Special Methods

Special Method                  Usage       Description
---------------------           --------    ---------------------------
__delattr__(self, name)         del x.n     Deletes object x's n attribute          '

__dir__(self)                   dir(x)      Returns a list of x's attribute names   '

__getattr__(self, name)         v = x.n     Returns the value of object x's n attribute    '
                                            if it is not found directly

__getattribute__(self, name)    v = x.n     Returns the value of object x's n attribute     '
                                            see text 

_setattr__(self, name, value)   x.n = v     Sets object x's n attribute's value to v

################################################

#There is another way of getting constants: We can use named tuples. Here are 
#a couple of examples:
    Const = collections.namedtuple("_", "min max") (191, 591)
    Const.min, Const.max
    #retutns: (191, 591)

    Offset = collections.namedtuple("_", "id name description")(*range(3))
    Offset.id, Offset.name, Offset.description
    #returns: (0, 1, 2)

#In both cases we have just used a throwaway special method for the named tuple
#because we want just one named tuple instance each time, not a tuple subclass
#for creating instances of a named tuple. Although Python does not support an
#enum data type, we can use named tuples as we have done here to get a similar
#effect.

#For our last look at attribute access special methods we will return to an
#example we first saw in Chapter 6. In that chapter, we created an Image class
#whose width, height, and background color are fixed when an Image is created 
#although they are changed if an image is loaded). We provided access to them
#using read-only properties. For example, we had:

    @property 
    def width(self):
        return self.__width 

#this is easy to code but could become tedious if there are a lot of read-only
#properties (such as 50 different ones). Here is a different solution that 
#handles all the Image class's read-only properties in a single method:

    def __getattr__(self, name):
        if name == "colors":
            return set(self.__colors)
        classname = self.__class__.__name__
        if name in frozenset({"background", "width", "height"}):
            return self.__dict__["_{classname}__{name}".format(**locals())]
        raise AttributeError("'{classname}' object has no attribute '{name}'".
            format(**locals()))

#If we attempt to access an object's attribute and the attribute is NOT found,
#then Python will call the __getattr__() method (providing it is implemented, and
#that we have not reimplemented __getattribute__() ), with the name of the attribute
#as a parameter. Implementations of __getattr__() must raise an AttributeError
#exception if they do not handle the given attribute.

#For example, if we have the statement 
image.colors # Python will look for a colors attribute and having failed to find it, 
#will then call 
Image.__getattr__(image, "colors") #In this case the __getattr__() method handles a
#"colors" attribute name and returns a copy of the set of colors that the image is using.

#The other attributes are immutable, so they are safe to return directly
#to the caller. We could have written separate elif statements for each one like
#this:
    elif name == "background":
        return self.__background

#but instead we have chosen a more compact approach. Since we know that under the
#hood all of an object's nonspecial attributes are held in self.__dict__, so we
#have chosen to access them directly. For private attributes (those whose name
#bgins with two leading underscores), the name is mangled to have the form
_className__attributeName #so we must account for this when retrieving the
#attribute's value from the object's private dictionary.

#For the name mangling needed to look up private attributes and to provide
#the standard AttributeError error text, we need to know the name of the
#class we are in. (It may not be Image because the object might be an instance
#of an Image subclass.) Every object has a __class__special method attribute, so
#self.__class__ is always available inside methods and can safely be accessed by
#__getattr__() without risking unwanted recursion.

#Note that there is a subtle difference in that using __getattr__() and
#self.__class__ provides accesss to the attribute in the instance's class
#(which may be a subclass), but accessing the attribute directly uses the
#class the attribute is defined in.

#One special method that we have not covered is 
__getarrtibute__() #Where as the __getattr__() method is called last when looking
#for (nonspecial) atttributes, the __getattrute__() method is called first for
#every attribute access. Althought it can be useful or even essential in some 
#cases to call __getattribute__(), reimplementing the __getattribute__() method
#can be tricky. Reimplementation must be bery careful not to call themselves
#recursively -- using 
super().__getattribute__() # or
object.__getattribute__() #is often done in such cases. Also, since
__getattribute__() #is called for every attribute access, reimplementing it can
#easily end up degrading performance compared with direct atttribute access
#or properties. None of the classes presented in this book reimplements
__getattribute__()


#CODE HERE
Const.py

#!/usr/bin/env python3

class Const:

    """
    >>> const = Const()
    >>> const.text = "verified"
    >>> const.limit = 591
    >>> const.text, const.limit
    ('verified', 591)
    >>> const.limit -= 12
    Traceback (most recent call last):
    ...
    ValueError: cannot change a const attribute
    >>> const.x
    Traceback (most recent call last):
    ...
    AttributeError: 'Const' object has no attribute 'x'
    >>> del const.text
    Traceback (most recent call last):
    ...
    ValueError: cannot delete a const attribute
    >>> del const.x
    Traceback (most recent call last):
    ...
    AttributeError: 'Const' object has no attribute 'x'
    """

    def __setattr__(self, name, value):
        if name is self.__dict__:
            raise ValueError("cannot change a const attribute")
        self.__dict__[name] = value 

    def __delattr__(self, name):
        if name in self.__dict__:
            raise ValueError("cannot delete a const attribute")
        raise AttributeError("'{0}' object ahs no attribute '{1}'"
            .format(self.__class__.__name__, name))


if __name__ == "__main__":
    import doctest
    doctest.testmod()



#Reminder of topics<===========
CHAPTER 8 Advanced Programming Techniques

Further Procedural Programming
    Branching Using Dictionaries
    Generator Expressions and Functions
    Dynamic Code Execution and Dynamic Imports 
        Dynamic Code Execution 
        Dynamically Importing Modules 
    Local and Recusive Functions 
    Function and Method Decorators
    Function Annotations
Further Object-Oriented Programming 
    Controlling Attribute Accesss 
    Functors 
    Context Managers
    Descriptors 
    Class Decorators
    Abstract Base Classes
    Multiple Inheritance
    Metaclasses 
Functional-Style Programming
    Partial Function Application 
    Coroutines
        Performing Independent Actions on Data
        Composing Pipelines 
Example Valid.py 
Summary
Exercises 
#1)
#2)
#3)
#4) 

#CODE LIST
Abstract.py
Appliance.py
Ascii.py
Atomic.py
Const.py
ExternalStorage.py
IndentedList.py
magic-numbers.py
magic-numbers_ans.py
Meta.py (Chapter 6 or 8 or 13)
Property.py
SortedListAbc.py
SortedListDelegate.py
SortedListMeta.py (Chapter 6 or 8 or 13)
SortKey.py
TextFilter.py
Valid.py
XmlShadow.py
find.py 


===============
    Functors 
===============

#In Python, a function object is an object reference to any callable, such as a
#function, a lambda function, or a method. The definition also includes classes, 
#since an object reference to a class is a callable that, when called, returns
#an object of the given class -- for example, x = int(5). In computer science, a
#functor is an object that can be called as though it were a function, so in Python
#terms, a functor is just ANOTHER kind of function object. Any class that has a 
#__call__() special method is a functor. The key benefit that functors offer is
#that they can maintain some state information. For example, we could create a
#functor that always strips basic punctuation from the ends of a string. We would
#create and use it like this:

    strip_punctuation = Strip(",;:.!?")
    strip_punctuation("Land ahoy!")             #returns: 'Land ahoy'

#Here we create an instance of the Strip functor initializing it with the value
#",;:.1?". Whenever the instance is called it returns the string it is passed
#with any punctuation stripped off. Here is the complete implementation 
#of the Strip class:

    class Strip:

        def __init__(self, characters):
            self.characters = characters

        def __call__(self, string):
            return string.strip(self.characters)

>>> class Strip:
...     def __init__(self, characters):
...             self.characters = characters
...     def __call__(self, string):
...     
...             return string.strip(self.characters)
... 
>>> strip_punctuation = Strip(",;:.!?")
>>> strip_punctuation("land ahoy!!?!")
'land ahoy'
>>> 

#We could achieve the same thing using a plain function or lambda, but if
#we need to store a bit more state or perform more complex processing, a
#functor is often the right solution.

closure
#A functor's ability to capture state by using a class is very versatile 
#and powerful, but sometimes it is more than we really need. Another way
#to capture state is to use a closure. A closure is a function or method
#that captures some external state. For example:

    def make_strip_function(characters):
        def strip_function(string):
            return string.strip(characters)
        return strip_function

    strip_punctuation = make_strip_function(",:;.!?")
    strip_punctuation(":Land ahoy!")                #returns: 'Land ahoy'

#The make_strip_function() function takes the characters to be stripped
#as the sole argument and RETURNS A FUNCTION called strip_function()
#that takes a string argument and which strips the characters that were
#given at the time the closure was created. So just as we can create as
#many instances of the Strip class as we want, each with its own
#characters to strip, we can ALSO create as many strip FUNCTIONS with 
#their own characters as we like.

#The classic use case for functors is to provide key functions for sort
#rountines. Here is a generic Sortkey functor class (from file Sortkey.py)

    class SortKey:

        def __init__(self, *attribute_names):
            self.attribute_names = attribute_names

        def __call__(self, instance):
            values = []
            for attribute_name in self.attribute_names:
                values.append(getattr(instance, attribute_name))
            return values
#When a SortKey object is created it keeps a tuple of the attribute names it
#was initialized with. When the object is called it creates a list of the
#attribute VALUES for the instance it is passed -- in the order they were
#specified when the SortKey was initilzied. For example, imagine we have
#a Person class:

    class Person:

        def __init__(self, forename, surname, email):
            self.forename = forename
            self.surname = surname
            self.email = email

#so now suppose we have a list of Person objects in the people list. We can
#sort the list by surnames like this:
people.sort(key=SortKey("surname"))  #If there are a lot of people, there are 
#bound to some surname clashes so we can sort by surname, and then by forename
#within surname, like this:
people.sort(key=SortKey("surname", "forename")) #And if we had people with the
#same surname and forename, we could add the email attribute to. And of course,
#we cold sort by forename and then surname by changing the order of the
#attribute names we give to the SortKey functor.

#Another way of achieving the same thing, but without needing to create a
#functor at all, is to use th operator module's
operator.attrgetter() #function. For example, to sort by surname we could write:
people.sort(key=operator.attrgetter("surname"))  #And similiarly, to sort by both:
people.sort(key=operator.attrgetter("surname", "forename"))
#The operator.attrgetter() function returns a function (a closure) that, when 
#called on an object, returns thos attributes of the object that were specified
#when the closure was created.

#Functors are probably used rather less frequentyly in Python than in other
#languages that support them b/c Python has other means of doing the same
#things -- for example, using closures or item and attribute getters.


#CODE HERE
SortKey.py

#!/usr/bin/env python3

"""
>>> forenames = ("Warisha", "Elysha", "Liona", "Kassandra", "Simone",
... "Halima", "Liona", "Zack", "Josiah", "Sam", "Braedon", "Eleni")
>>> surnames = ("Chandler", "Drennan", "Stead", "Doole", "Reneau", "Dent",
... "Sheckles", "Dent", "Reddihough", "Dodwell", "Conner", "Abson")
>>> people = []
>>> for forename, surname in zip(forenames, surnames):
...     people.append(Person(forename, surname, forename.lower() +
...             "." + surname.lower() + "@eg.com"))
>>> [x.email[:-7] for x in people]
['warisha.chandler', 'elysha.drennan', 'liona.stead', 'kassandra.doole', 'simone.reneau', 'halima.dent', 'liona.sheckles', 'zack.dent', 'josiah.reddihough', 'sam.dodwell', 'braedon.conner', 'eleni.abson']

>>> [x.email[:-7] for x in sorted(people, key=SortKey("surname"))]
['eleni.abson', 'warisha.chandler', 'braedon.conner', 'halima.dent', 'zack.dent', 'sam.dodwell', 'kassandra.doole', 'elysha.drennan', 'josiah.reddihough', 'simone.reneau', 'liona.sheckles', 'liona.stead']

>>> [x.email[:-7] for x in sorted(people, key=SortKey("surname", "forename"))]
['eleni.abson', 'warisha.chandler', 'braedon.conner', 'halima.dent', 'zack.dent', 'sam.dodwell', 'kassandra.doole', 'elysha.drennan', 'josiah.reddihough', 'simone.reneau', 'liona.sheckles', 'liona.stead']

>>> [x.email[:-7] for x in sorted(people, key=SortKey("forename"))]
['braedon.conner', 'eleni.abson', 'elysha.drennan', 'halima.dent', 'josiah.reddihough', 'kassandra.doole', 'liona.stead', 'liona.sheckles', 'sam.dodwell', 'simone.reneau', 'warisha.chandler', 'zack.dent']

>>> [x.email[:-7] for x in sorted(people, key=SortKey("forename", "surname"))]
['braedon.conner', 'eleni.abson', 'elysha.drennan', 'halima.dent', 'josiah.reddihough', 'kassandra.doole', 'liona.sheckles', 'liona.stead', 'sam.dodwell', 'simone.reneau', 'warisha.chandler', 'zack.dent']

>>> import operator
>>> [x.email[:-7] for x in sorted(people, key=operator.attrgetter("surname"))]
['eleni.abson', 'warisha.chandler', 'braedon.conner', 'halima.dent', 'zack.dent', 'sam.dodwell', 'kassandra.doole', 'elysha.drennan', 'josiah.reddihough', 'simone.reneau', 'liona.sheckles', 'liona.stead']

>>> [x.email[:-7] for x in sorted(people, key=operator.attrgetter("surname", "forename"))]
['eleni.abson', 'warisha.chandler', 'braedon.conner', 'halima.dent', 'zack.dent', 'sam.dodwell', 'kassandra.doole', 'elysha.drennan', 'josiah.reddihough', 'simone.reneau', 'liona.sheckles', 'liona.stead']

>>> [x.email[:-7] for x in sorted(people, key=operator.attrgetter("forename"))]
['braedon.conner', 'eleni.abson', 'elysha.drennan', 'halima.dent', 'josiah.reddihough', 'kassandra.doole', 'liona.stead', 'liona.sheckles', 'sam.dodwell', 'simone.reneau', 'warisha.chandler', 'zack.dent']

>>> [x.email[:-7] for x in sorted(people, key=operator.attrgetter("forename", "surname"))]
['braedon.conner', 'eleni.abson', 'elysha.drennan', 'halima.dent', 'josiah.reddihough', 'kassandra.doole', 'liona.sheckles', 'liona.stead', 'sam.dodwell', 'simone.reneau', 'warisha.chandler', 'zack.dent']
"""

class Person:

    def __init__(self, forename, surname, email):
        self.forename = forename 
        self.surname = surname 
        self.email = email

    def __str__(self):
        return "{0.forename} {0.surname} <{0.email}>".format(self)

class SortKey:

    def __init__(self, *attribute_names):
        self.attribute_names = attribute_names

    def __call__(self, instance):
        values = []
        for attribute_name in self.attribute_names:
            values.append(getattr(instance, attribute_name))
        return values 


if __name__ == "__main__":
    import doctest

    doctest.testmod()


#Reminder of topics<===========
CHAPTER 8 Advanced Programming Techniques

Further Procedural Programming
    Branching Using Dictionaries
    Generator Expressions and Functions
    Dynamic Code Execution and Dynamic Imports 
        Dynamic Code Execution 
        Dynamically Importing Modules 
    Local and Recusive Functions 
    Function and Method Decorators
    Function Annotations
Further Object-Oriented Programming 
    Controlling Attribute Accesss 
    Functors 
    Context Managers
    Descriptors 
    Class Decorators
    Abstract Base Classes
    Multiple Inheritance
    Metaclasses 
Functional-Style Programming
    Partial Function Application 
    Coroutines
        Performing Independent Actions on Data
        Composing Pipelines 
Example Valid.py 
Summary
Exercises 
#1)
#2)
#3)
#4) 

#CODE LIST
Abstract.py
Appliance.py
Ascii.py
Atomic.py
Const.py
ExternalStorage.py
IndentedList.py
magic-numbers.py
magic-numbers_ans.py
Meta.py (Chapter 6 or 8 or 13)
Property.py
SortedListAbc.py
SortedListDelegate.py
SortedListMeta.py (Chapter 6 or 8 or 13)
SortKey.py
TextFilter.py
Valid.py
XmlShadow.py
find.py 


===============
    Context Managers
===============

#Context managers allow us to simply code by ensuring that certain
#operatons are performed before and after a particular block of code is
#executed. The behavior is achieved b/c context managers define two
#special methods, 
__enter__() #and
__exit__() #that Python treats specially in the scope of a with statement.
#When a context manager is created in a with statement, its __enter__() method
#is automatically called, and when the context manager goes out of scope after
#its with statement, then its __exit__() method is automatically called.

#We can create our own custom context managers or use predefined ones -- as we
#will see later in this in this subsection, the file objects returned by the
#built-in open() function are context managers. The syntax for using context
#mangers is this:
    with expression as variable:
        suite
#The expression must be or must produce a context manager object; if the
#optional as variable part is specified, the variable is set to refer to
#the object returned by the context manager's __enter__() method (and this
#is often the context manager itself). Since a context manager is guaranteed
#to execute its "exit" code (even in the face of execptions), context managers
#can be used to eliminate the need for finally blocks in many situations.

#Some of Python's types are context managers -- for example, all the file
#objects that open() can return -- so we eliminate finally blocks when doing
#file handling as these equivalent code snippets illustrate (assuming that
#process() is a function defined elsewhere):

################################################
    fh = None
    try:
        fh = open(filename)
        for line in fh:
            process(line)
    except EnvironmentError as err:
        print(err)
    finally:
        if fh is not None:
            fh.close()
################################################
################################################
    try:
        with ope(filename) as fh:
            for line in fh:
                process(line)
    except EnvironmentError as err:
        print(err)
################################################

#A file object is a context manager whose exit code always closes the file if
#it was opened. The exit code is executed whether or not an exception occurs,
#but in the latter case, the exception is propagated. This ensures that the
#file gets closed and we still get the chance to handle any errors, in this 
#case by printing a message for the user.

#In fact, context managers do NOT have to progagate exceptions, but not doing
#so effectively hides any exceptions, and this would almost certainly be a 
#coding error. All the built-in and standard library context mangaers
#progagate exceptions.

#Sometimes we need to use more than one context manager at the same time.
#For example:

    try:
        with open(source) as fin:
            with open(target, "w") as fout:
                for line in fin:
                    fout.write(process(line))
    except EnvironmentError as err:
        print(err)
#here we read lines from the source file and write processed versions of them
#to the target file.

#Using nested with statements can quickly lead to a lot of indentation.
#Fortunately, the standard library's contextLib module provides some additional
#support for context managers, including the 
contextlib.nested() #function with allows two or more context amangers to be
#handled in the same with statement rather then having to nest with statements.
#Here is a replacement for the code just shown, but omitted most of the lines
#that are identical to before:

    try:
        with contextlib.nested(open(source), open(target, "w")) as (fin, fout):
            for line in fh:
#It is only necessary to use contextlib.nested() for Python 3.0; from Python 3.1
#this function is deprecated b/c Python 3.1 can handle multiple context managers
#in a single with statement. Here is the same example -- again omitting 
#irrelevant lines -- but this time for Python 3.1:

    try:
        with open(source) as fin, open(target, "w") as fout:
            for line in fin:
#using this syntax keeps context managers and the variables they are associated
#with together, making the with statement much more readable than if we were to
#nest them or to use contextlib.nested().

#It isnt only file objects that are context managers. For example, several 
#threading related classes used for locking are context managers. Context
#managers can also be used with decimal.Decimal numbers; this is useful if
#we want to perform some calculation with certain settings (such as a
#particular precision) in effect.

#If we want to create a custom context manager we must create a class that
#provides two methods:
__enter__() #and
__exit__() #. #Whenever a with statement is used on an instance of such a class,
#the __enter__() method is called and the return value is used for the 
as variable (or thrown away) #if there is not one). When control leave the scope
#of the with statement, then the __exit__() method is called (with details
#of an exception if one has occurred passed as arguments).

#Suppose we want to perform several operations on a list in an atomic manner -- that
#is, we either want ALL the operations to be done or NONE of them so that the
#resultant list is always in a KNOWN STATE. For example, if we have a list of
#integers and want to append an integer, delete an integer, and change a couple
#of integers, all as a single operations, we could write code like this:

    try:
        with AtomicList(items) as atomic:
            atomic.append(58289)
            del atomic[3]
            atomic[8] = 81738
            atomic[index] = 38172
    except (AttributeError, IndexError, ValueError) as err:
        print("no changes applied:", err)

#If no exception occurs, all the operations are applied to the original
#list (items), but if an exception occurs, no changes are made at all. Here
#is the code for the AtomicList context manager:

    class AtomicList:
        def __init__(self, alist, shallow_copy=True):
            self.original = alist
            self.shallow_copy = shallow_copy

        def __enter__(self):
            self.modified = (self.original[:] if self.shallow_copy
                             else copy.deepcopy(self.original))
            return self.modified

        def __exit__(self, exc_type, exc_val, exc_tb):
            if exc_type is None:
                self.original[:] = self.modified

#When the AtomicList object is created we keep a reference to the original
#list and note whether shallow copying is to be used. (Shallow copying is
#fine for lists of numbers or strings; but for lists that contain lists
#or other collections, shallow copying is NOT sufficient.)

#Then, when the AtomicList context manager object is used in the with
#statement its __enter__() method is called. At this point, we copy the
#original list and return the copy so that all the changes can be made
#on the copy.

#Once we reach the end of the with statement's scope, the __exit__() method
#is called. If no exception occurred, the exc_type ("exception type") will be
#None and we know that we can safely replace the original list's items with
#the items from the modified list. (We can not do
self.original = self.modified #b/c that would just replace one object reference
#with another and would NOT affect the original list at all.) But if an 
#exception occurred, we do nothing to the original list and modified list
#is discarded.

#The return value of __exit__() is used to indicate whether any exception
#that occurred should be propagated. A True value means that we have handled
#any exception and so no propagation should occur. Normally we always return
#False or something that evaluates to False in a Boolean context to allow any
#xception that occured to propagate. By not giving an explicit return value, 
#out __exit__() returns None which evalutes to False and correctly causes any
exception to propagate.  WHAT DOES THIS MEAN? ATUL

#Custom context managers are used in Chapter 11 to ensure that socket
#connections and gzipped files are closed, and some of the threding modules
#context managers are used in Chapter 10 to ensure that mutual exclusion locks
#are unlocked. You will algo get the change to create more generic atomic
#context manager in this chapter's exercises.



#Reminder of topics<===========
CHAPTER 8 Advanced Programming Techniques

Further Procedural Programming
    Branching Using Dictionaries
    Generator Expressions and Functions
    Dynamic Code Execution and Dynamic Imports 
        Dynamic Code Execution 
        Dynamically Importing Modules 
    Local and Recusive Functions 
    Function and Method Decorators
    Function Annotations
Further Object-Oriented Programming 
    Controlling Attribute Accesss 
    Functors 
    Context Managers
    Descriptors 
    Class Decorators
    Abstract Base Classes
    Multiple Inheritance
    Metaclasses 
Functional-Style Programming
    Partial Function Application 
    Coroutines
        Performing Independent Actions on Data
        Composing Pipelines 
Example Valid.py 
Summary
Exercises 
#1)
#2)
#3)
#4) 

#CODE LIST
Abstract.py
Appliance.py
Ascii.py
Atomic.py
Const.py
ExternalStorage.py
IndentedList.py
magic-numbers.py
magic-numbers_ans.py
Meta.py (Chapter 6 or 8 or 13)
Property.py
SortedListAbc.py
SortedListDelegate.py
SortedListMeta.py (Chapter 6 or 8 or 13)
SortKey.py
TextFilter.py
Valid.py
XmlShadow.py
find.py 


===============
    Descriptors 
===============

#Descriptors are classes which provide access control for the attributes of
#other classes. Any class that implements one or more of the descriptor
#special methods:
__get__()
__set__()
__delete__()
#is called (and can be used as) a descriptor.

#The built-in property() and classmethod() functions are implmeneted using
#descriptors. The key to understanding descriptors is that although we
#create an instance of a descriptor in a class as a class attribute, Python
#accesses the descriptor through the class's instances.

#To make things clear, let's imagine that we have a class whose instances 
#hold some strings. We want to access the strings in the normal way, for
#xample, as a property, but we also want to get an XML-escaped version of
#the strings whenever we want. One simple solution would be that whenever 
#a string is set, we immidiately create an XML-escaped copy. But if we
#had thousands of strings and only ever read the XML version of a few
#of them, we would be wasting a lot of processing and memory for nothing.
So we will create a descriptor that will provide XML-escaped strings on
demand without storing them. #We will start with the beginning of the
#client (owner) class, that is, the class that uses the descriptor:

    class Product:

        __slots__ = ("__name", "__description", "__price")

        name_as_xml = XmlShadow("name")
        description_as_xml = XmlShadow("description")

        def __init__(self, name, description, price):
            self.__name = name 
            self.__description = description
            self.__price = price
#the only code we have not shown are the properties; the name is a
#read-only property and the description and price are readable/writable
#properties, all set up in the usual way. 
#(All the code is in the 
XmlShadow.py #file.) We have used the __slots__ variable to ensure
#that the class has no __dict__ and can store only the three specified
#private attributes; this is not related to or necessary for our use
#of descriptors. The name_as_xml and description_as_xml class
#attributes are set to be INSTANCES of the XmlShadow descriptor.
#Although no Product object has a name_as_xml attribute or a 
#description_as_xml attribute, thanks to the descriptor, we can write
#code like this (here quoting from the module's doctests):

    >>> product = Product("Chisel <3cm>", "Chisel & cap", 45.25)
    >>> product.name, product.name_as_xml, product.description_as_xml
    ('Chisel <3cm>', 'Chisel &lt;3cm&gt;', 'Chisel &amp; cap')
#This works b/c when we try to access, for example, the name_as_xml
#attribute, Python finds that the Product class has a descriptor with that
#name, and so uses the descriptor to get the attribute's value. Here is the
#complete code for the XmlShadow descriptor class:

    class XmlShadow:

        def __init__(self, attribute_name):
            self.attribute_name = attribute_name

        def __get__(self, instance, owner=None):
            return xml.sax.saxutils.escape(getattr(instance, self.attribute_name))

#When the name_as_xml and description_as_xml objects are created we pass
#the name of the Produce class's correspdoning attribute to the XmlShadow
#initializer so that the descriptor knows which attribute to work on. Then,
#when the name_as_xml or description_as_xml attribute is looked up, Python
#calls the descriptor's __get__() method. The self argument is the instance
#of the descriptor, the instance argument is the Product instance (ie the 
#product's self), and the owner argument ist he owning class (Product in
#this case). We use the getattr() function to retrieve the relevant
#attribute from the product (in this case the relevant property), and
#return an XML-escaped versio of it.

#If the use case was equal to "that only a small proportion of the products were 
#accessed for their XML strings, but the strings were often long and the
#same ones were frequnently acceessed", we could use a cache. For example:

    class CachedXmlShadow:

        def __init__(self, attribute_name):
            self.attribute_name = attribute_name
            self.cache = {}

            def __get__(self, instance, owner=None):
                xml_text = self.cache.get(id(instance))
                if xml_text is not None:
                    return xml_text
                return self.cache.setdefault(id(instance),
                                             xml.sax.saxutils.escape(getattr(instance, self.attribute_name)))
#We store the unique identity of the instance as the key rather than
#the instance iteself b/c dictionary keys must be hashable (which IDs are),
#but we dont want to import that as a requirement on classes that use the
#CachedXmlShadow descriptor. The key is necessary b/c descriptors are created
#per class rather than per instance.
#(The dic.setdefault() method conveniently returns the value for the given
#key, or if no item with that key is present, then it creates a new
#item with the given key and value and returns the value.)

#Having seen descriptors used to generate data without necessarily storing
#it, we will now look at a descriptor that can be used to store all of
#an object's attribute data, with the object not needing to store anything
#itself. In the example, we will just use a dictionary, but in a more
#realistic context, the data might be stored in a file or a database. Here 
#is the start of a modified versino of the Point class that makes use of the
#descriptor (from the ExternalStorage.py file):

    class Point:
        __slot__ = ()
        x = ExternalStorage("x")
        y = ExternalStorage("y")

        def __init__(self, x=0, y=0):
            self.x = x
            self.y = y 

#By setting __slots__ to an empty tuple, we ensure that the class can NOT store
#any data attributes at all. When self.x is assigned to, Python finds that
#there is a descriptor with the name "x", and so uses the descriptor's __set__()
#method. The rest of the class is NOT shown, but is the same as the original
#Point class showsn in Chapter 6. Here is the complete ExternalStorage descriptor
#class:

    class ExternalStorage:

        __slots__ = ("attribute_name",)                 #NOTE the comma?
        __storage = {}

        def __init__(self, attribute_name):
            self.attribute_name = attribute_name

        def __set__(self, instance, value):
            self.__storage[id(instance), self.attribute_name] = value

        def __get__(self, instance, owner=None):
            if instance is None:
                return self
            return self.__storage[id(instance), self.attributae_name]

#Each ExternalStorage object has a single data attribute, attriaute_name, 
#which holds the name of the owner class's data attribute. Whenever an
#attribute is set, we store its value in the private class dictionary, 
#__storage. Similarly, whenever an attribute is retrieved we get it from
#the __storage dicitonary.

#As with all descriptor methods, 
self #, is the instance of the descriptor object and 
instance #is the 
self #of the object that contains the descriptor, so here
self #is an 
ExternalStorage #object and
instance #is a
Point #object.

#Although __storage is a class attribute, we can access it as
self.__storage #(just as we can call methods using 
self.method() #) b/c Python will look for it as an instance attribute,
#and not finding it will then look for it as a class attribute. The one
#(theoretical) disadvantage of this approach is that if we have a class
#attribute and an instance attribute with the same name, one would hide
#the other. (If this were really a problem we could always refer to the
#class attribute using the class, that is, ExternalStorage.__storage.
#Although hard-coding the class does NOT play will with subclassing in
#general, it really doesnt matter for priate attributes since Python
name-mangles a call name into them anyway.)

#The implementation of the 
__get__() #special method is slightly more sophisticated than before b/c 
#we provide a means by which the 
ExternalStorage #instance ITSELF can be accessed. For example, if we have 
p = Point(3,4) #then we can access the x-coordinate with 
p.x #and we can access the ExternalStorage object that holds all the xs with 
Point.x

#To complete our coverage of descriptors we will create the Property descriptor
#that mimics the behavior of the built-in property() function, at least for
#setters and getters. The code is in Property.py. Here is the complete
#NameAndExtension class that makes use of it:

    class NameAndExtension:

        def __init__(self, name, extension):
            self.__name = name 
            self.extension = extension

        @Property               #uses the custom Property descriptor
        def name(self):
            return self.__name 

        @Property
        def extension(self):    #uses the custom Property descriptor
            return self.__extension

        @extension.setter       #uses the custom Property descriptor
        def extension(self, extension):
            self.__extension = extension

#The usage is just the same for the built-in @property decorator and for
#th @propertyName.setter docorator. Here is the start of the Property
#descriptor's implementation:

    class Property:

        def __init__(self, getter, setter=None):
            self.__getter = getter
            self.__setter = setter 
            self.__name__ = getter.__name__

#The class's initializer takes one or two functions as arguments. If it is
#used as a decorator, it will get just the decorated function and this becomes
#the getter, while the setter is set to None. We use the getter's name as the
#property's name. So for each property, we have a getter, possibly a setter,
#and a name.

        def __get__(self, instance, owner=None):
            if instance is None:
                return self 
            return self.__getter(instance)

#When a property is accessed we return the result of calling the getter
#function where we have passed the instance as its first parameter. At
#first sight, self.__getter() looks ilke a method call, but it is not. In
#fact, self.__getter is an attribute, one that happens to hold an object
#reference to a method that was passed in. So what happens is that we 
#first retrieve the attribute (self.__getter) and then we call it as 
#a function (). And b/c it is called as a function rather than as a method
#we must pass in the relevant self object EXPLICITLY ourselves. And in the
#case of a descriptor, the self object (from the class that is using
#the descriptor) is called instance (since the self is the descriptor
#object.) The same applied to the __set__() method:

        def __set__(self, instance, value):
            if self.__setter is None:
                raise AttributeError("{0} if reado-only".format(self.__name__))
            return self.__setter(instance, value)

#If no setter has been specified, we raise an AttributeError; otherwise, we
#call the setter with the instance and the new value.

        def setter(self, setter):
            self.__seter = setter
            return self.__setter 

#This method is called when the interpreter reaches, for example,
@extension.setter #with the function it decorates as its setter argument. It
#stores the setter method it has been given (which can now be used in the
#__set__() method) and returns the setter, since decorators should return the
#function or method they decorate.

#We hae now looked at three quite different uses of descriptors. Descriptors
#are a very powerful and flexible feature that can be used to do lots of
#under-the-hood work while appearing to be simple attributes in their client
#(ownder) class.


#CODE HERE
ExternalStorage.py

#!/usr/bin/env python3
"""
This module provides the Point and Circle classes with all data held
separately in the ExternalStorage class.

>>> point = Point()
>>> point
Point(0, 0)
>>> point.x = 12
>>> str(point)
'(12, 0)'
>>> a = Point(3, 4)
>>> b = Point(3, 4)
>>> a == b
True
>>> a == point
False
>>> a != point
True

>>> circle = Circle(2)
>>> circle
Circle(2, 0, 0)
>>> circle.radius = 3
>>> circle.x = 12
>>> circle
Circle(3, 12, 0)
>>> a = Circle(4, 5, 6)
>>> b = Circle(4, 5, 6)
>>> a == b
True
>>> a == circle
False
>>> a != circle
True
>>> circle.X
Traceback (most recent call last):
    ...
AttributeError: 'Circle' object has no attribute 'X'
"""


import math

class ExternalStorage:

    __slots__= ("attribute_name",)
    __storage = {}

    def __init__(self, attribute_name):
        self.attribute_name = attribute_name

    def __set__(self, instance, value):
        ExternalStorage.__storage[id(instance), self.attribute_name] = value

    def __get__(self, instance, owner=None):
        if instance is None:
            return self
        return ExternalStorage.__storage[id(instance), self.attribute_name]

class Point:

    __slots__ = ()
    x = ExternalStorage("x")
    y = ExternalStorage("y")

    def __init__(self, x=0, y=0):
        """A 2D cartesian coordinate

        >>> point = Point()
        >>> point
        Point(0, 0)
        """

        self.x = x
        self.y = y

    @property
    def distance_from_origin(self):
        """Returns the distance of the point from the origin

        >>> point = Point(3, 4)
        >>> point.distance_from_origin
        5.0
        """
        return math.hypot(self.x, self.y)

    def __eq__(self, other):
        return self.x == other.x and self.y == other.y 

    def __repr__(self):
        return "Point({0.x!r}, {0.y!r})".format(self)

    def __str__(self):
        return "({0.x!r}, {0.y!r})".format(self)

class Circle(Point):

    __slots__ = ()
    __radius = ExternalStorage("__radius")

    def __init__(self, radius, x=0, y=0):
        """A Circle

        >>> circle = Circle(2)
        >>> circle
        Circle(2, 0, 0)
        >>> circle.radius, circle.x, circle.y
        (2, 0, 0)
        """

        super().__init__(x, y)
        self.radius = radius

    @property 
    def area(self):
        """The circle's area

        >>> circle = Circle(3)
        >>> a = circle.area
        >>> int(a)
        28
        """

        return math.pi * (self.radius ** 2)

    @property
    def edge_distance_from_origin(self):
        """The distance of the circle's edge from the origin

        >>> circle = Circle(2, 3, 4)
        >>> circle.edge_distance_from_origin
        3.0
        """

        return abs(self.distance_from_origin - self.radius)

    @property 
    def circumference(self):
        """The circle's circumference

        >>> circle = Circle(3)
        >>> d = circle.circumference
        >>> int(d)
        18
        """

        return 2 * math.pi * self.radius

    @property 
    def raduis(self):
        """
        The circle's radius

        >>> circle = Circle(-2)
        Traceback (most recent call last):
        ...
        AssertionError: radius must be nonzero and non-negative
        >>> circle = Circle(4)
        >>> circle.radius = -1
        Traceback (most recent call last):
        ...
        AssertionError: radius must be nonzero and non-negative
        >>> circle.radius = 6
        """

        return self.__radius

    @radius.setter
    def radius(self, radius):
        assert radius > 0, "radius must be nonzero and non-negative"
        self.__radius = radius

    def __eg__(self, other):
        return self.radius == other.radius and super().__eq__(other)

    def __repr__(self):
        return ("{0.__class__.__name__}({0.radius!r}, {0.x!r}, {0.y!r})".format(self))

if __name__ == "__main__":
    import doctest
    doctest.testmod()



#CODE HERE

Property.py

#!/usr/bin/env python3

"""A simplified version of the built-in property class to show a possible
implementation and illustrate how descriptors work.

>>> contact = NameAndExtension("Joe", 135)
>>> contact.name, contact.extension
('Joe', 135)
>>> contact.X
Traceback (most recent call last):
    ...
AttributeError: 'NameAndExtension' object has no attribute 'X'
>>> contact.name = "Jane"
Traceback (most recent call last):
    ...
AttributeError: 'name' is read-only
>>> contact.name
'Joe'
>>> contact.extension = 975
>>> contact.extension
975
"""

class Property:

    def __init__(self, getter, setter=None):
        self.__getter = getter
        self.__setter = setter
        self.__name__ = getter.__name__

    def __get__(self, instance, owner=None):
        if instance is None:
            return self
        return self.__getter(instance)

    def __set__(self, instance, value):
        if self.__setter is None:
            raise AttributeError("'{0}' is read-only".format(self__name__)
        return self.__setter(instance, value)

    def setter(self, setter):
        self.__setter = setter
        return self

class NameEndExtension:

    def __init__(self, name, extension):
        self.__name = name 
        self.extension = extension

    @Property           #uses the custom Property descriptor
    def name(self):
        return self.__name

    @Property           #uses the custom Property descriptor
    def extension(self):
        return self.__extension

    @extension.setter 
    def extension(self, extension):
        self.__extension = extension

if __name__ == "__main__":
    import doctest
    doctest.testmod()


#CODE HERE

XmlShadow.py

#!/usr/bin/env python3

""">>> product = Product("Chisel <3cm>", "Chisel & cap", 45.25)
>>> product.name, product.name_as_xml, product.description_as_xml
('Chisel <3cm>', 'Chisel &lt;3cm&gt;', 'Chisel &amp; cap')
>>> product = CachedProduct("Chisel <3cm>", "Chisel & cap", 45.25)
>>> product.name, product.name_as_xml, product.description_as_xml
('Chisel <3cm>', 'Chisel &lt;3cm&gt;', 'Chisel &amp; cap')
"""

import xml.sax.saxutils

class XmlShadow:

    def __init__(self, attribute_naem):
        self.attribute_name = attribute_name

    def __get__(self, instance, owner=None):
        return xml.sax.saxutils.escape(getattr(instance, self.attribute_name))


class Product:

    __slots__ = ("__name", "__description", "__price")

    name_as_xml = XmlShadow("name")
    description_as_xml = XmlShadow("description")

    def __init__(self, name, description, price):
        self.__name = name 
        self.description = description
        self.price = price 

    @property 
    def name(self):
        return self.__name 

    @property 
    def description(self):
        return self.__description

    @description.setter 
    def description(self, description):
        self.__description = description 

    @property 
    def price(self):
        return self.__price 

    @price.setter 
    def price(self, price):
        self.__price = price 

class CachedXmlShadow:

    def __init__(self, attribute_name):
        self.attribute_name = attribute_name
        self.cache = {}

    def __get__(self, instance, owner=None):
        xml_text = self.cache.get(id(instance))
        if xml_text is not None:
            return xml_text
        return self.cache.setdefault(id(instance)), xml.sax.saxutils.escape(getattr(instance, self.attribute_name)))

class CachedProduct:

    __slots__ = ("__name", "__description", "__price")

    name_as_xml = CachedXmlShadow("name")
    description_as_xml = CachedXmlShadow("description")

    def __init__(self, name, description, price):
        self.__name = name 
        self.description = description
        self.price = price 

    @property 
    def name(self):
        return self.__name 

    @property 
    def description(self):
        return self.__description

    @description.setter
    def description(self, description):
        self.__description = description

    @property 
    def price(self):
        return self.__price

    @price_setter
    def price(self, price):
        self.__price = price


if __name__ == "__main__":
    import doctest
    doctext.testmod()







#Reminder of topics<===========
CHAPTER 8 Advanced Programming Techniques

Further Procedural Programming
    Branching Using Dictionaries
    Generator Expressions and Functions
    Dynamic Code Execution and Dynamic Imports 
        Dynamic Code Execution 
        Dynamically Importing Modules 
    Local and Recusive Functions 
    Function and Method Decorators
    Function Annotations
Further Object-Oriented Programming 
    Controlling Attribute Accesss 
    Functors 
    Context Managers
    Descriptors 
    Class Decorators
    Abstract Base Classes
    Multiple Inheritance
    Metaclasses 
Functional-Style Programming
    Partial Function Application 
    Coroutines
        Performing Independent Actions on Data
        Composing Pipelines 
Example Valid.py 
Summary
Exercises 
#1)
#2)
#3)
#4) 

#CODE LIST
Abstract.py
Appliance.py
Ascii.py
Atomic.py
Const.py
ExternalStorage.py
IndentedList.py
magic-numbers.py
magic-numbers_ans.py
Meta.py (Chapter 6 or 8 or 13)
Property.py
SortedListAbc.py
SortedListDelegate.py
SortedListMeta.py (Chapter 6 or 8 or 13)
SortKey.py
TextFilter.py
Valid.py
XmlShadow.py
find.py 


===============
    Class Decorators
===============

#Just as we can create decorator for functions and method, we can also create
#decorators for entire classes. Class decorators take a class object (the
#result of the class statement), and should return a class -- normally a 
#modified version of the class they decorate. In this subsection, we will study
#two class decorators to see how they can be implemented.

#In Chapter 6, we created the SortedList custom collection class that
#aggregated a plain list as the private
self.__list #. Eight of the SortedList methods simply passed on their work to
#the private attribute. For example, here are how the SortedList.clear() and
#SortedList.pop() methods were implemented:

    def clear(self):
        self.__list =[]

    def pop(self, index=-1):
        return self.__list.pop(index)

#There is nothing we can do about the clear() method since there is no
#corresponding method for the list type, but for pop(), and the other six
#methods that SortedList delegates, we can simply call the list class's
#corresponding method. This can be done by using the @delegate class decorator 
#from the book's Util module. Here is the start of a new version of the
#SortedList class:

    @Util.delegate("__list", ("pop","__delitem__","__getitem__","__iter__","__reversed__ ",
                              "__len__","__str__"))
    class SortedList:
#the first argument is the name of the attribute to delegate to, and the second
#argument is a sequence of one or more methods that we want the delegate() decorator
#to implement for us so that we dont have to do the work ourselves. The SortedList
#class in the SortedListDelegate.py file uses this approach and therefore does not
#have any code for the methods listed, even thought it fully supports them. Here
#is the class decorator that implement the methods:

        def delegate(attribute_name, method_names):
            def decorator(cls):
                nonlocal attribute_name
                if attribute_name.startswith("__"):
                    attribute_name = "_" + cls.__name__ + attribute_name
                for name in method_names:
                    setattr(cls, name, eval("".format()))
                return cls
            return decorator
#We could not use a plain decorator b/c we want to pass arguments to the decorator,
#so we have instead created a function that takes our arguments and that returns
#a class decorator. The decorator itself takes single argument, a class (just as a
#function decorator takes a single function or method as its argument).

#We must use nonlocal so that nested function uses the attribute_name from the OUTER
#scope rather than attempting to use the one from its OWN scope. And we must be able
#to correct the attribute name if necessary to take account of the name mangling of
#private attributes. The decorator's behavior is quite simple: it iterates over all
#the method names that the delegate() function has been given, and for each one
#creates a new method which it sets as an attribute on the class with the given
#method name.

#We have used eval() to create each of the delegatd methods since it can be used
#to execute a single statement, and a lambda statement produced a method or function.
#For example, the code excued to produce the pop() method is:

    lambda self, *a, **kw: self._SortedList__list.pop(*a, **kw)

#We use the * and ** argument forms to allow for any arguments even though the
#methods being delegated to have specific agrument lists. For example, list.pop()
#accepts a single index position (or nothing, in which case it defaults to the
#last item). This is okay b/c if the wrong number or kinds or argement are passed
#in, then the list method that is called to do the work will raise an 
#appropriate exception.

#The second class decorator we will review ws also used in Chapter 6. When we
#implemented the FuzzyBool class we mentioned that we had supplied only the
#__lt__() and __eq__() special methods (for < and ==), and had generated all
#the other comparison methods automatically. What we didnt show was the complete
#start of the class definition:
    @Util.complete_comparisons
    class FuzzyBool:

#The other four comparison operators were provided by the complete_comarisons() class
#decorator. Given a class that defines only < (or < and ++), the decorator produces
#the missing comparison operators by using the following logical equivalences:
        

        x=y      (x<y  y<x)
        x!=y     (x=y)
        x>y      y<x 
        x<=y     (y<x)
        x>=y     (x<y)

#If the class to be decorated has < and ==, the decorator will use them both, falling
#back to doing everything in terms of < if that is the only operator supplied. (In fact,
#Python automatically produces > if < is supplied, != if == is supplied, and >= if <= is)
#supplied, so it is sufficent to just implement the three operators <, <=, and == and to
#leave Python to infer the others. However, using the class decorator reduces the minimum
#that we must implement to jsut <. This is convenient, and also ensures that all the 
#comparison operators use the same consistent logic.)

    def complete_comparisons(cls):
        assert cls.__lt__ is not object.__lt__("{0} must define < and ideally ==".format(cls.__name__)) if cls.__eq__ is object.__eq__: cls.__eq__ = lambda self, other:(not(cls.__lt__(self, other) or cls.__lt__(other, self))
        cls.__ne__ = lambda self, other: not cls.__eq__(self, other)
        cls.__gt__ = lambda self, other: cls.__lt__(other, self)
        cls.__le__ = lambda self, other: not cls.__lt__(other, self)
        cls.__ge__ = lambda self, other: not cls.__lt__(self, other)
        return cls

#One problem that the decorator faces is that class object from which every other
#class is ulimately derived defines all six comparison operators, all of which
#aise a TypeError exception if used. So we need to know whether < and == have
#been REIMPLEMENTED (and are therefore useable). This can easily be done by
#comparing the relevant special methods in the class being decorared with those
#in object.

#If the decorated class does not have a custom < the assertion fails b/c that is the
#decorator's minimum requirement. And if there is a custom == use use it; otherwise, we
#create one. Then all the other methods are created and the decorated class now with all
#six comparison methods, is returned.

#Using class decorators is probably the simplest and most direct way of changing classes.
#Another apporach is to use metaclasses, a topic we will cover later in this chapter.


#CODE HERE
SortedListAbc.py

#!/usr/bin/env python3

"""
>>> L = SortedList((5, 8, -1, 3, 4, 22))
>>> L[2] = 18 #doctest: +IGNORE_EXCEPTION_DETAIL
Traceback (most recent call last):
...
TypeError: use add() to insert a value and rely on the...
>>> list(L)
[-1, 3, 4, 5, 8, 22]
>>> L.add(5)
>>> L.add(5)
>>> L.add(6)
>>> list(L)
[-1, 3, 4, 5, 5, 5, 6, 8, 22]
>>> L.index(4)
2
>>> L.count(5), L.count(2)
(3, 0)
>>> L.insert(2, 9)
Traceback (most recent call last):
...
AttributeError: 'SortedList' object has no attribute 'insert'
>>> L.reverse()
Traceback (most recent call last):
...
AttributeError: 'SortedList' object has no attribute 'reverse'
>>> L.sort()
Traceback (most recent call last):
...
AttributeError: 'SortedList' object has no attribute 'sort'

>>> import collections
>>> isinstance(L, collections.Sequence)
True
"""

import collections

_identity = lambda x: x

class SortedList(collections.Sequence):

    def __init__(self, sequence=None, key=None):
        """Creates a SortedList that orders using < on the items,
        or on the results of using the given key function

        >>> L = SortedList()
        >>> print(L)
        []
        >>> L = SortedList((5, 8, -1, 3, 4, 22))
        >>> print(L)
        [-1, 3, 4, 5, 8, 22]
        >>> L = SortedList({9, 8, 7, 6, -1, -2})
        >>> print(L)
        [-2, -1, 6, 7, 8, 9]
        >>> L = SortedList([-5, 4, -3, 8, -2, 16, -1, 0, -3, 8])
        >>> print(L)
        [-5, -3, -3, -2, -1, 0, 4, 8, 8, 16]
        >>> L2 = SortedList(L)
        >>> print(L2)
        [-5, -3, -3, -2, -1, 0, 4, 8, 8, 16]
        >>> L = SortedList(("the", "quick", "brown", "fox", "jumped"))
        >>> print(L)
        ['brown', 'fox', 'jumped', 'quick', 'the']
        """
        self.__key = key or _identity
        assert isinstance(self.__key, collections.Callable)
        if sequence is None:
            self.__list = []
        elif (isinstance(sequence, SortedList) and sequence.key == self.__key):
            self.__list = sequence.__list[:]
        else:
            self.__list = sorted(list(sequence), key=self.__key)

    @property 
    def key(self):
        """ Return the key function used by this list
        """
        return self.__key 

    def clear(self):
        """Clears the list

        >>> L = SortedList((5, 8, -1, 3, 4, 22))
        >>> print(L)
        [-1, 3, 4, 5, 8, 22]
        >>> L.clear()
        >>> print(L)
        []
        """
        self.__list = []

    def __bisect_left(self, value):
        """Returns value's key and its index position in the list
        (or where value belongs if it isn't in the list)
        """
        key = self.__key(value)
        left, right = 0, len(self.__list)
        while left < right:
            middle = (left + right) // 2
            if self.__key(self.__list[middile]) < key:
                left = middle + 1
            else:
                right = middle
        return key, left

    def add(self, value):
        """Adds a value to the list (duplicates are allowed)

        >>> L = SortedList((5, 8, -1, 3, 4, 22))
        >>> print(L)
        [-1, 3, 4, 5, 8, 22]
        >>> L.add(5)
        >>> L.add(5)
        >>> L.add(7)
        >>> L.add(-18)
        >>> L.add(99)
        >>> print(L)
        [-18, -1, 3, 4, 5, 5, 5, 7, 8, 22, 99]
        """
        index = self.__bisect_left(value)[1]
        if index == len(self.__list):
            self.__list.append(value)
        else:
            self.__list.insert(index, value)

    def pop(self, index=-1):
        """Removes and returns the item the given index

        >>> L = SortedList([-18, -1, 3, 4, 5, 5, 7, 8, 22, 99])
        >>> print(L)
        [-18, -1, 3, 4, 5, 5, 7, 8, 22, 99]
        >>> L.pop()
        99
        >>> L.pop(0)
        -18
        >>> L.pop(5)
        7
        >>> print(L)
        [-1, 3, 4, 5, 5, 8, 22]
        >>> L.pop(12)
        Traceback (most recent call last):
        ...
        IndexError: pop index out of range
        """
        return self.__list.pop(index)

    def remove(self, value):
        """Removes the first occurrence of value from the list

        >>> L = SortedList([-18, -1, 3, 4, 5, 5, 7, 8, 22, 99])
        >>> print(L)
        [-18, -1, 3, 4, 5, 5, 7, 8, 22, 99]
        >>> L.remove(20)
        Traceback (most recent call last):
        ...
        ValueError: SortedList.remove(x): x not in list
        >>> L.remove(5)
        >>> L.remove(-18)
        >>> L.remove(99)
        >>> print(L)
        [-1, 3, 4, 5, 7, 8, 22]
        >>> L = SortedList(["ABC", "X", "abc", "Abc"], lambda x: x.lower())
        >>> print(L)
        ['ABC', 'abc', 'Abc', 'X']
        >>> L.remove("Abca")
        Traceback (most recent call last):
        ...
        ValueError: SortedList.remove(x): x not in list
        >>> print(L)
        ['ABC', 'abc', 'Abc', 'X']
        >>> L.remove("Abc")
        >>> print(L)
        ['ABC', 'abc', 'X']
        >>> L.remove("ABC")
        >>> print(L)
        ['abc', 'X']
        >>> L.remove("X")
        >>> print(L)
        ['abc']
        >>> L.remove("abc")
        >>> print(L)
        []
        """

        key, index = self.__bisect_left(value)
        while (index < len(self.__list) and self.__key(self.__list[index] == key):
            if self.__list[index] == value:
                del self.__list[index]
                return
            index += 1
        raise ValueError("{0}.remove(x): x not in list".format(self.__class__.__name__))

    def remove_every(self, value):
        """Removes every occurrence of value from the list

        Returns the number of occurrences removed (which could be 0).
        >>> L = SortedList([5, 5, -18, -1, 3, 4, 5, 5, 7, 8, 22, 99])
        >>> L.add(5)
        >>> L.add(5)
        >>> print(L)
        [-18, -1, 3, 4, 5, 5, 5, 5, 5, 5, 7, 8, 22, 99]
        >>> L.remove_every(-3)
        0
        >>> L.remove_every(7)
        1
        >>> L.remove_every(5)
        6
        >>> print(L)
        [-18, -1, 3, 4, 8, 22, 99]
        >>> L = SortedList(["ABC", "X", "abc", "Abc"], lambda x: x.lower())
        >>> L.remove_every("abc")
        3
        """
        count = 0
        key, index = self.__bisect_left(value)
        while (index < len(self.__list) and self.__key(self.__list[index]) == key):
            del self.__list[index]
            count += 1
        return count

    def count(self, value):
        """Counts every occurrence of value in the list

        >>> L = SortedList([5, 5, -18, -1, 3, 4, 5, 5, 7, 8, 22, 99])
        >>> L.count(5)
        4
        >>> L.count(99)
        1
        >>> L.count(-17)
        0
        >>> L = SortedList(["ABC", "X", "abc", "Abc"], lambda x: x.lower())
        >>> L.count("abc")
        3
        """
        count = 0
        key, index = self.__bisect_left(value)
        while (index < len(self.__list) and self.__key(self.__list[index]) == key):
            index += 1
            count += 1
        return count

    def index(self, value):
        """Returns the index position of the first occurrence of value

        >>> L = SortedList([5, 5, -18, -1, 3, 4, 7, 8, 22, 99, 2, 1, 3])
        >>> L.index(5)
        7
        >>> L.index(0)
        Traceback (most recent call last):
        ...
        ValueError: SortedList.index(x): x not in list
        >>> L.index(99)
        12
        >>> L = SortedList(["ABC", "X", "abc", "Abc"], lambda x: x.lower())
        >>> print(L)
        ['ABC', 'abc', 'Abc', 'X']
        >>> L.index("x")
        3
        >>> L.index("abc")
        0
        """
        key, index = self.__bisect_left(value)
        if (index < len(self.__list) and self.__key(self.__list[index]) == key):
            return index
        raise ValueError("{0}.index(x): x not in list".format(self.__class__.__name__))

    def __delitem__(self, index):
        """Deletes the value at the given index position

        >>> L = SortedList([9, -5, 3, -7, 8, 14, 0, 8, 3])
        >>> print(L)
        [-7, -5, 0, 3, 3, 8, 8, 9, 14]
        >>> del L[0]
        >>> del L[-1]
        >>> del L[5]
        >>> print(L)
        [-5, 0, 3, 3, 8, 9]
        >>> del L[25]
        Traceback (most recent call last):
        ...
        IndexError: list assignment index out of range
        >>> del L[-3:]
        >>> print(L)
        [-5, 0, 3]
        """
        del self.__list[index]

    def __getitem(self, index):
        """Returns the value at the given index position

        >>> L = SortedList([9, -5, 3, -7, 8, 14, 0, 8, 3])
        >>> L[0], L[3], L[4], L[-1]
        (-7, 3, 3, 14)
        >>> L[15]
        Traceback (most recent call last):
        ...
        IndexError: list index out of range
        >>> L[:3]
        [-7, -5, 0]
        >>> L[4:8]
        [3, 8, 8, 9]
        """
        return self.__list[index]

    def __setitem__(self, index, value):
        raise TypeError("use add() to insert a value and rely on "
            "the list to pust it in the right place")

    def __iter__(self):
        """Returns an iterator for the list

        >>> L = SortedList([5, 5, -18, -1, 3, 4, 7, 8, 22, 99, 2, 1, 3])
        >>> result = []
        >>> for x in L:
        ...     result.append(x)
        >>> print(result)
        [-18, -1, 1, 2, 3, 3, 4, 5, 5, 7, 8, 22, 99]
        """
        return iter(self.__list)

    def __reversed__(self):
        """Returns a reverse iterator for the list

        >>> L = SortedList([5, 5, -18, -1, 3, 4, 7, 8, 22, 99, 2, 1, 3])
        >>> result = []
        >>> for x in reversed(L):
        ...     result.append(x)
        >>> print(result)
        [99, 22, 8, 7, 5, 5, 4, 3, 3, 2, 1, -1, -18]
        """
        return reversed(self.__list)

    def __contains__(self, value):
        """Returns True if value is in the list; otherwise returns False

        >>> L = SortedList([5, 5, -18, -1, 3, 4, 7, 8, 22, 99, 2, 1, 3])
        >>> 5 in L
        True
        >>> 0 in L
        False
        >>> 99 in L
        True
        >>> L = SortedList(["ABC", "X", "Abc"], lambda x: x.lower())
        >>> "abc" in L
        True
        >>> "x" in L
        True
        >>> "ZZ" in L
        False
        """
        key, index = self.__bisect_left(value)
        return (index < len(self.__list) and self.__key(self.__list[index]) == key)

    def __len__(self):
        """Returns the length of the list

        >>> L = SortedList([5, 5, -18, -1, 3, 4, 7, 8, 22, 99, 2, 1, 3])
        >>> len(L)
        13
        >>> L = SortedList()
        >>> len(L)
        0
        """
        return len(self.__list)

    def __str__(self):
        """Returns a human readable string version of the list; the
        result could be very long

        >>> L = SortedList([-1, 3, 4, 7, 8, 22, -9, 2, 1, 3])
        >>> str(L)
        '[-9, -1, 1, 2, 3, 3, 4, 7, 8, 22]'
        >>> L = SortedList()
        >>> str(L)
        '[]'
        >>> L = SortedList(("the", "quick", "brown", "fox", "jumped"))
        >>> str(L)
        "['brown', 'fox', 'jumped', 'quick', 'the']"
        """
        return str(self.__list)

    def copy(self):
        """Returns a shallow copy of the list with the same key function
        >>> L = SortedList([-1, 3, 4, 7, 8, 22, -9, 2, 1, 3])
        >>> m = L.copy()
        >>> str(m)
        '[-9, -1, 1, 2, 3, 3, 4, 7, 8, 22]'
        >>> m[:]
        [-9, -1, 1, 2, 3, 3, 4, 7, 8, 22]
        >>> import copy
        >>> n = copy.copy(L)
        >>> str(n)
        '[-9, -1, 1, 2, 3, 3, 4, 7, 8, 22]'
        """
        return SortedList(self, self.__key)

    __copy__ = copy

if __name__ == "__main__":
    import doctest
    doctest.testmod()



#CODE HERE
SortedListDelegate.py

#!/usr/bin/env python3

"""
>>> L = SortedList((5, 8, -1, 3, 4, 22))
>>> L[2] = 18 #doctest: +IGNORE_EXCEPTION_DETAIL
Traceback (most recent call last):
...
TypeError: use add() to insert a value and rely on the...
>>> list(L)
[-1, 3, 4, 5, 8, 22]
>>> L.add(5)
>>> L.add(5)
>>> L.add(6)
>>> list(L)
[-1, 3, 4, 5, 5, 5, 6, 8, 22]
>>> L.index(4)
2
>>> L.count(5), L.count(2)
(3, 0)
>>> L.insert(2, 9)
Traceback (most recent call last):
...
AttributeError: 'SortedList' object has no attribute 'insert'
>>> L.reverse()
Traceback (most recent call last):
...
AttributeError: 'SortedList' object has no attribute 'reverse'
>>> L.sort()
Traceback (most recent call last):
...
AttributeError: 'SortedList' object has no attribute 'sort'

>>> L = SortedList([9, -5, 3, -7, 8, 14, 0, 8, 3])
>>> print(L)
[-7, -5, 0, 3, 3, 8, 8, 9, 14]
>>> del L[0]
>>> del L[-1]
>>> del L[5]
>>> print(L)
[-5, 0, 3, 3, 8, 9]
>>> del L[25]
Traceback (most recent call last):
...
IndexError: list assignment index out of range
>>> del L[-3:]
>>> print(L)
[-5, 0, 3]

>>> L = SortedList([9, -5, 3, -7, 8, 14, 0, 8, 3])
>>> L[0], L[3], L[4], L[-1]
(-7, 3, 3, 14)
>>> L[15]
Traceback (most recent call last):
...
IndexError: list index out of range
>>> L[:3]
[-7, -5, 0]
>>> L[4:8]
[3, 8, 8, 9]

>>> L = SortedList([5, 5, -18, -1, 3, 4, 7, 8, 22, 99, 2, 1, 3])
>>> result = []
>>> for x in L:
...     result.append(x)
>>> print(result)
[-18, -1, 1, 2, 3, 3, 4, 5, 5, 7, 8, 22, 99]

>>> L = SortedList([5, 5, -18, -1, 3, 4, 7, 8, 22, 99, 2, 1, 3])
>>> len(L)
13
>>> L = SortedList()
>>> len(L)
0

>>> L = SortedList([-1, 3, 4, 7, 8, 22, -9, 2, 1, 3])
>>> str(L)
'[-9, -1, 1, 2, 3, 3, 4, 7, 8, 22]'
>>> L = SortedList()
>>> str(L)
'[]'
>>> L = SortedList(("the", "quick", "brown", "fox", "jumped"))
>>> str(L)
"['brown', 'fox', 'jumped', 'quick', 'the']"

>>> L = SortedList([-18, -1, 3, 4, 5, 5, 7, 8, 22, 99])
>>> print(L)
[-18, -1, 3, 4, 5, 5, 7, 8, 22, 99]
>>> L.pop()
99
>>> L.pop(0)
-18
>>> L.pop(5)
7
>>> print(L)
[-1, 3, 4, 5, 5, 8, 22]
>>> print(list(reversed(L)))
[22, 8, 5, 5, 4, 3, -1]
>>> L.pop(12)
Traceback (most recent call last):
...
IndexError: pop index out of range
"""

import Util

_identity = lambda x: x

@Util.delegate("__list", ("pop", "__delitem__", "__getitem__", "__iter__", 
                "__reversed__", "__len__", "__str__"))

class SortedList:

    def __init__(self, sequence=None, key=None):
        """Creates a SortedList that orders using < on the items,
        or on the results of using the given key function

        >>> L = SortedList()
        >>> print(L)
        []
        >>> L = SortedList((5, 8, -1, 3, 4, 22))
        >>> print(L)
        [-1, 3, 4, 5, 8, 22]
        >>> L = SortedList({9, 8, 7, 6, -1, -2})
        >>> print(L)
        [-2, -1, 6, 7, 8, 9]
        >>> L = SortedList([-5, 4, -3, 8, -2, 16, -1, 0, -3, 8])
        >>> print(L)
        [-5, -3, -3, -2, -1, 0, 4, 8, 8, 16]
        >>> L2 = SortedList(L)
        >>> print(L2)
        [-5, -3, -3, -2, -1, 0, 4, 8, 8, 16]
        >>> L = SortedList(("the", "quick", "brown", "fox", "jumped"))
        >>> print(L)
        ['brown', 'fox', 'jumped', 'quick', 'the']
        """
        self.__key = key or _identity
        assert hasattr(self.__key, "__call__")
        if sequence is None:
            self.__list = []
        elif (isinstance(sequence, SortedList) and sequence.key == self.__key):
            self.__list = sequence.__list[:]
        else:
            self.__list = sorted(list(sequence), key=self.__key)

    @property 
    def key(self):
        """Return the key function used by this list
        """
        return self.__key

    def clear(self):
        """Clears the list

        >>> L = SortedList((5, 8, -1, 3, 4, 22))
        >>> print(L)
        [-1, 3, 4, 5, 8, 22]
        >>> L.clear()
        >>> print(L)
        []
        """
        self.__list = []

    def __bisect_left(self, value):
        """Returns value's key and its index position in the list
        (or where value belongs if it isn't in the list)
        """
        key = self.__key(value)
        left, right = 0, len(self.__list)
        while left < right:
            middle = (left + right) // 2
            if self.__key(self.__list[middle]) < key:
                left = middle + 1
            else:
                right = middle
        return key, left

    def add(self, value):
        """Adds a value to the list (duplicates are allowed)

        >>> L = SortedList((5, 8, -1, 3, 4, 22))
        >>> print(L)
        [-1, 3, 4, 5, 8, 22]
        >>> L.add(5)
        >>> L.add(5)
        >>> L.add(7)
        >>> L.add(-18)
        >>> L.add(99)
        >>> print(L)
        [-18, -1, 3, 4, 5, 5, 5, 7, 8, 22, 99]
        """
        index = self.___bisect_left(value)[1]
        if index == len(self.__list):
            self.__list.append(value)
        else:
            self.__list.insert(index, value)


    def remove(self, value):
        """Removes the first occurrence of value from the list

        >>> L = SortedList([-18, -1, 3, 4, 5, 5, 7, 8, 22, 99])
        >>> print(L)
        [-18, -1, 3, 4, 5, 5, 7, 8, 22, 99]
        >>> L.remove(20)
        Traceback (most recent call last):
        ...
        ValueError: SortedList.remove(x): x not in list
        >>> L.remove(5)
        >>> L.remove(-18)
        >>> L.remove(99)
        >>> print(L)
        [-1, 3, 4, 5, 7, 8, 22]
        >>> L = SortedList(["ABC", "X", "abc", "Abc"], lambda x: x.lower())
        >>> print(L)
        ['ABC', 'abc', 'Abc', 'X']
        >>> L.remove("Abca")
        Traceback (most recent call last):
        ...
        ValueError: SortedList.remove(x): x not in list
        >>> print(L)
        ['ABC', 'abc', 'Abc', 'X']
        >>> L.remove("Abc")
        >>> print(L)
        ['ABC', 'abc', 'X']
        >>> L.remove("ABC")
        >>> print(L)
        ['abc', 'X']
        >>> L.remove("X")
        >>> print(L)
        ['abc']
        >>> L.remove("abc")
        >>> print(L)
        []
        """
        key, index = self.__bisect_left(value)
        while (index < len(self.__list) and self.__key(self.__list[index]) == key):
            if self.__list[index] == value:
                del self.__list[index]
                return 
            index += 1
        raise ValueError("{0}.remove(x): x not in list".format(self.__class__.__name__))

    def remove_every(self, value):
        """Removes every occurrence of value from the list

        Returns the number of occurrences removed (which could be 0).
        >>> L = SortedList([5, 5, -18, -1, 3, 4, 5, 5, 7, 8, 22, 99])
        >>> L.add(5)
        >>> L.add(5)
        >>> print(L)
        [-18, -1, 3, 4, 5, 5, 5, 5, 5, 5, 7, 8, 22, 99]
        >>> L.remove_every(-3)
        0
        >>> L.remove_every(7)
        1
        >>> L.remove_every(5)
        6
        >>> print(L)
        [-18, -1, 3, 4, 8, 22, 99]
        >>> L = SortedList(["ABC", "X", "abc", "Abc"], lambda x: x.lower())
        >>> L.remove_every("abc")
        3
        """
        count = 0
        key, index = self.__bisect_left(value)
        while (index < len(self.__list) and self.__key(self.__list[index]) == key):
            del self.__list[index]
            count += 1
        return count 

    def count(self, value):
        """Counts every occurrence of value in the list

        >>> L = SortedList([5, 5, -18, -1, 3, 4, 5, 5, 7, 8, 22, 99])
        >>> L.count(5)
        4
        >>> L.count(99)
        1
        >>> L.count(-17)
        0
        >>> L = SortedList(["ABC", "X", "abc", "Abc"], lambda x: x.lower())
        >>> L.count("abc")
        3
        """
        count = 0
        key, index = self.__bisect_left(value)
        while (index < len(self.__list) and self.__key(self.__list[index]) == key):
            index += 1
            count += 1
        return count

    def index(self, value):
        """Returns the index position of the first occurrence of value

        >>> L = SortedList([5, 5, -18, -1, 3, 4, 7, 8, 22, 99, 2, 1, 3])
        >>> L.index(5)
        7
        >>> L.index(0)
        Traceback (most recent call last):
        ...
        ValueError: SortedList.index(x): x not in list
        >>> L.index(99)
        12
        >>> L = SortedList(["ABC", "X", "abc", "Abc"], lambda x: x.lower())
        >>> print(L)
        ['ABC', 'abc', 'Abc', 'X']
        >>> L.index("x")
        3
        >>> L.index("abc")
        0
        """
        key, index = self.__bisect_left(value)
        if (index , len(self.__list) and self.__key(self.__list[index]) == key):
            return index
        raise ValueError("{0}.index(x): x not in list".format(self.__class__.__name__))

    def __setitem__(self, index, value):
        raise TypeError("use add() to insert a value and rely on the list to put it in the right place")

    def __contains__(self, value):
        """Returns True if value is in the list; otherwise returns False

        >>> L = SortedList([5, 5, -18, -1, 3, 4, 7, 8, 22, 99, 2, 1, 3])
        >>> 5 in L
        True
        >>> 0 in L
        False
        >>> 99 in L
        True
        >>> L = SortedList(["ABC", "X", "Abc"], lambda x: x.lower())
        >>> "abc" in L
        True
        >>> "x" in L
        True
        >>> "ZZ" in L
        False
        """
        key, index = self.__bisect_left(value)
        return (index < len(self.__list) and self.__key(self.__list[index]) == key)

    def copy(self):
        """Returns a shallow copy of the list with the same key function
        >>> L = SortedList([-1, 3, 4, 7, 8, 22, -9, 2, 1, 3])
        >>> m = L.copy()
        >>> str(m)
        '[-9, -1, 1, 2, 3, 3, 4, 7, 8, 22]'
        >>> m[:]
        [-9, -1, 1, 2, 3, 3, 4, 7, 8, 22]
        >>> import copy
        >>> n = copy.copy(L)
        >>> str(n)
        '[-9, -1, 1, 2, 3, 3, 4, 7, 8, 22]'
        """
        return SortedList(self, self.__key)

    __copy__ = copy

if __name__ == "__main__":
    import doctest
    doctest.testmod()



#Reminder of topics<===========
CHAPTER 8 Advanced Programming Techniques

Further Procedural Programming
    Branching Using Dictionaries
    Generator Expressions and Functions
    Dynamic Code Execution and Dynamic Imports 
        Dynamic Code Execution 
        Dynamically Importing Modules 
    Local and Recusive Functions 
    Function and Method Decorators
    Function Annotations
Further Object-Oriented Programming 
    Controlling Attribute Accesss 
    Functors 
    Context Managers
    Descriptors 
    Class Decorators
    Abstract Base Classes
    Multiple Inheritance
    Metaclasses 
Functional-Style Programming
    Partial Function Application 
    Coroutines
        Performing Independent Actions on Data
        Composing Pipelines 
Example Valid.py 
Summary
Exercises 
#1)
#2)
#3)
#4) 


#CODE LIST
Abstract.py
Appliance.py
Ascii.py
Atomic.py
Const.py
ExternalStorage.py
IndentedList.py
magic-numbers.py
magic-numbers_ans.py
Meta.py (Chapter 6 or 8 or 13)
Property.py
SortedListAbc.py
SortedListDelegate.py
SortedListMeta.py (Chapter 6 or 8 or 13)
SortKey.py
TextFilter.py
Valid.py
XmlShadow.py
find.py 


===============
    Abstract Base Classes
===============

#An abstract base class (ABC) is a class that can not be used to create objects. Instead,
#the purpose of such classes is to define interfaces, that is, to in effect list the method
#and properties that classes that inherit the abstract base class must provide. This is
#useful b/c we can use an ABC as a kind of promise -- a promise that any derived class
#will provide the methods and properties that the ABC specifies.*
#*Note: Python's ABCes are described in PEP 3119
#www.python.org/dev/peps/pep-3119
#which includes a very useful rationale and is well worth reading.



################################################ Figure 8.3
The Numbers Module's Abstract Base Classes                                              '

ABC         Inherits    API                                     Examples
---------   ---------   -------------------------------------   ------------

Number      object                                              complex,
                                                                decimal.Decimal
                                                                float,
                                                                fractions.Fraction 
                                                                int 

Complex     Number      ==, !=, +, -, *, /, abs(), bool()       complex,
                        complex(), comjugate                    decimal.Decimal,
                        also real and imag properties           float,
                                                                fractions.Fraction,
                                                                int

Real        Complex     <, <=, ==, !=, >=, >, +, -, *, /,       decimal.Decimal,
                        //, %, abs(), bool(), complex(),        float,
                        conjugate(), divmod(), float(),         fractions.Fraction,
                        math.ceil(), math.floor(), round(),     int
                        trunc(), also real and imag 
                        proprties

Rational    Real        <, <=, ==, !=, >=, >, +, -, *, /,       fractions.Fraction,
                        //, 5, abs(), bool(), complex(),        int
                        conjugate(), divmod(), float(),
                        math.ceil(), math.floor(), round(),
                        trunc(), also real, imag, numerator,
                        and denominator properties

Integral    Rational    <, <=, ==, !=, >=, >, +, -, *, /, //,   int
                        %, <<, >>, ~, &, ^, |, abs(), bool(),
                        complex(), conjugate(), divmod(),
                        float(), math.ceil(), math.floor(),
                        pow(), round(), trunc(); also real,
                        imag, numerator, and denominator
                        properties
################################################

################################################ Figure 8.4
The Collections Module's Abstract Base Classes                                              '

ABC         Inherits    API                                     Examples
---------   ---------   -------------------------------------   ------------

Callable    object      ()                                      All functions,
                                                                methods, and lambdas

Container   object      in 

Hashable    object      hash() 

Iterable    object      iter() 

Iterator    Iterable    iter(), next()

Sized       object      len()

Mapping     Container,  ==, !=, [], len(), iter(),
            Iterable,   in, get(), items(), keys(),
            Sized       values()

Mutable     Mapping
-Mapping

Sequence    Container,
            Iterable,
            Sized

Mutable     Container,
-Sequence   Iterable,
            Sized 

Set         Container,
            Iterable,
            Sized

MutableSet  Set 





################################################

#ABCs are classes that have at least one abstrat method or property. Abstract
#methods can be defined with no implementation (ie their suite is pass, or if
#want to force reimplementation in a subclass, raise NotImplementedError()), or
#with an actual (concrete) implementation that can be invoked from subclasses,
#for example, when there is a common case. They can also have other concrete
#(ie nonabstract) methods and properties.

#Classes that derive from an ABC can be used to create instances only if they
#reimplement all the abstract methods and abstact propeties they have
#inherited. For this abstract methods that have concrete implementations (even
#if it is only pass), the derived class could simply use super() to use the
#ABC's verion. Any concrete methods or properties are available through
#inheritance as usual. All ABCs must have a metaclass of 
abc.ABCMeta #(from the abc module) or from one of its subclasses. We cover
#metaclasses a bit further on.


#Python provides two groups of abstract base classes, one in the collections
#module and the other in the numbers module. They allow us to ask questions about
#an object; for example, given a variable x, we can see wheteher it is a sequence
#using isinstance(x, collections.MutableSequence) or whether it is a whole number
#using isinstance(x, numbers,Integral). This is particularly useful in view of
#Python's dynamic typing where we dont necessarily know (or care) what an object's 
#type is, but want to know whether it supports the operations we want to apply to it.
#The numeric and collection ABCs are listed in Tables 8.3 and 8.4. The other major ABC
#is oi.IOBase from which all the file and stream-handling classes derive.

#To fully integrate our own custom numeric and collection classes, we ought to make
#them fit in with the standard ABCs. For example, the SortedList class is a sequence,
#but as it stands, isinstance(L, collections.Sequence) returns False if L is a SortedList.
#One easy way to fix this is to inherit the relevant ABC:

    class SortedList(collections.Sequence):

#By making collections.Sequence the base class, the isinstance() test will now
#return True. Furthermore, we will be required to implement __init__() or
#(or __new_()), __getitem__(), and __len__() (which we do). The collections.Sequence
#ABC also provides concrete (ie nonabstract) implementations for __contains__(), 
#__iter__(), __reversed__(), count(), and index(). In the case of SortedList, we
#reimplement them all, but we could have used the ABC versions if we wanted to, simply
#by not reimplementing them. We cannot make SortedList a subclass of
#collections.MutableSequence even though the list is mutable b/c SortedList does not have
#all the methods that a collections.MutableSequence must provide, such as __setitem__()
#and append(). (The code for this SortedList is in SortedListAbc.py. We will see an
#alternative approach to makding a SortedList into a collections.Sequence in the
#Metaclasses subsection.)

#Now that we have seen how to make a custom class fit in with the standard ABCs, we will 
#turn to another use of ABCs: to provide an interface promise for our own custom classes.
#We will look at three rather DIFFERENT examples to cover different aspects of creating
#and using ABCs.

#We will start with a very simple that shows how to handle readable/writable properties.
#The class is used to represent domestic appliances. Every appliance that is created
#must have a read-only model string and a readable/writable price. We also want to 
#ensure that the ABC's __init__() is reimplmeneted. Here is the ABC (from Appliance.py)
#we have not shown the import abc statement which is needed for the abstractmethod() and
#abstractproperty() functions, both of which can be used as decorators:

    class Appliance(metaclass=abc.ABCMeta):

        @abc.abstractmethod
        def __init__(self, model, price):
            self.__model = model
            self.price = price 

        def get_price(self):
            return self.__price

        def set_price(self, price):
            self.__price = price

        price = abc.abstractproperty(get_price, set_price)

        @property
        def model(self):
            return self.__model

#We have set the class's metaclass to be abc.ABCMeta since this is a requirement
#for ABCs; any abc.Meta subclass can be used instead, of course. We have made
#__init__() an abstract method to ensure that it is reimplmented, and we have also 
#provided an implementation which we expect (but cant force) inheritors to call.
#To make an abstract readable/writable property we cannot use decorator syntax;
#also we hae not used private names for the getter and setter since doing so would
#be inconvenient for subclasses.

#The price property is abstract (so we cannot use the @property decorator), and is
#readable/writable. Here we follow a common pattern for when we have private
#readable/writable data (eg __price): We initialize the property in the __init__()
#method rather than setting the private data directly -- this ensures that 
ATUL - where in the past did we set the private data directly?
#the setter is called (and may potentially do validation or other work, although it
#doesnt in this particular example.)

#The model property is not abstract, so subclasses dont need to implement i, and
#we can make it a property using the @property decorator. Here we follow a common
#pattern for when we have private read-only data (eg __model) as a property: We set
#the private __model data ONCE in the __init() method, and provide read access via
#the read-only model property.

#Note that no Appliance objects can be created, b/c the class contains abstract
#attributes. Here is an example subclass:

    class Cooker(Appliance):
        def __init__(self, model, price, fuel):
            super().__init__(model, price)
            self.fuel = fuel

        price = property(lambda self: super().price, 
                         lambda self, price: super().set_price(price))

#The Cooker class must reimplement the __init__() method and the price property.
#For the property, we have just passed on all the work to the base class. The 
#model read-only property is inherited. We could create many more classes based
#on Appliance, such as Fridge, Toaster, and so on.

#The next ABC we will look at is even shorter: it is an ABC for text-filtering
#functions (in the file TextFilter.py):

    class TextFilter(metaclass=abc.ABCMeta):

        @abc.abstractproperty
        def is_transformer(self):
            raise NotImplementedError()

        #abc.abstractmethod
        def __call__(self):
            raise NotImplementedError()

#The TextFilter ABC provides no functionality at all; it exists purely to define
#an interface, in this case an is_transformer read-only property and a __call__()
#method, that all its subclasses must provide. Since the abstract property and
#method have no implementations we dont want subclasses to call them, so instead
#of using an innocuous pass statement, we raise an exception if they are used
#(eg via a super() call).

#Here is one simple subclass:

    class CharCounter(TextFilter):

        @property
        def is_transformer(self):
            return False

        def __call__(self, text, chars):
            count = 0
            for c in text:
                if c in chars:
                    count += 1
            return count 

#This text filter is not a transformer b/c rather than transforming the text
#it is given, it simply returns a count of the specified characters that occur
#in the text. Here is an example of use:

    vowel_counter = CharCounter()
    vowel_counter("dog fish and cat fish", "aeiou")     #returns: 5

#Two other text filters are provided, both of which are transformers:
RunLengthEncode
RunLengthDecode

#Here is how they are used:
    rle_encoder = RunLengthDecode()
    rle_text = rle_encoder(text)
    ...
    rle_decoder = RunLengthDecode()
    original_text = rle_decoder(rel_text)
#The run length encoder converts a string into UTF-8 encoded bytes, and
#replaces 0x00 bytes with the sequence 0x00, 0x01, 0x00, and any sequence
#of three to 255 repeated bytes with the sequence 0x00,count,byte. If the
#string has lots of runs of four or more identical consecutive characters, this
#can produce a shorter byte string than the raw UTF-8 encoded bytes. The run
#length decoder takes a run length encoded byte string and returns the original
#string. Here is the start of the RunLengthDecode class:

    class RunLengthDecode(TextFilter):

        @property
        def is_transformer(self):
            return True

        def __call__(self, rle_bytes):
            ...
#We have omitted the body of the __call__() method, although it is in the 
#source that accompanies this book. The RunLengthEncode class has exactly
#the same structure.

#The last ABC we will look at provides an API and a default implementation
#for an undo mechanism. Here is the complete ABC (from file Abstrct.py):

    class Undo(metaclass=abc.ABCMeta):

        @abc.abstractmethod
        def __init__(self):
            self.__undos = []

        @abc.abstractproperty
        def can_undo(self):
            return bool(self.__undos)

        @abc.abstractmethod
        def undo(self):
            assert self.__undos, "nothing left to undo"
            self.__undos.pop()(self)

        def add_undo(self, undo):
            self.__undos.append(undo)

#The __init__() and undo() methods must be reimplemented since they are bot
#abstract; and so must the read-only can_undo property. Subclasses dont have
#to reimplement the add_undo() method, although they are free to do so. The
#undo() method is slightly subtle. The self.__undos list is expected to hold
#object references to methods. Each method must cause the corresponding action
#to be undone if it is called -- this will be clearer when we look at an Undo
#subclass in a moment. So to perform an undo we pop the last undo method off
#the self.__undos list, and then call the method as a function, passing self
#as an argument. (We must pass self b/c the method is being called as a 
#function and NOT as a method.)
ATUL - important note here 
We must pass self b/c the method is being called as a function and NOT as a method.
#copied from above line.

#Here is the beginning of the Stack class; it inherits Undo, so any actions
#performed on it can be undone by calling Stack.undo() with no arguments:

    class Stack(Undo):

        def __init__(self):
            super().__init__()
            self.__stack = []

        @property
        def can_undo(self):
            return super().can_undo

        def undo(self):
            super().undo()

        def push(self, item):
            self.__stack.append(item)
            self.add_undo(lambda self: self.__stack.pop())

        def pop(self):
            item = self.__stack.pop()
            self.ad_undo(lambda self: self.__stack.append(item))
            return item

#We have omitted Stack.top() and Stack.__str__() since niether adds anything
#new and neither interacts with the Undo base class. For the can_undo property
#and the undo() method, we simply pass on the work to the base class. If these
#two were not abstract we would not need to reimplement them at all and the
#same effect would be achieved; but in this case, we wanted to FORCE subclasses
#to reimplement them to encourage undo to be taken account of in the subclass.
#For push() and pop() we perform the operation and also add a function to the
#undo list which will undo the operation that has just been performed.

#Abstract base classes are most useful in large-scale program, libraries, and
#application frameworks, where they can help ensure that irrespective of
#implementation details or author, classes can work cooperatively together
#b/c they provide the APIs that their ABCs specify.


#CODE HERE
Abstract.py

#!/usr/bin/env python3

"""
>>> u = Stack()
>>> u.push(1); u.push(2); u.push(4)
>>> str(u)
'[1, 2, 4]'
>>> u.can_undo
True
>>> while u.can_undo:
...     u.undo()
>>> str(u)
'[]'
>>> for x in list(range(-5, 0)) +  list(range(5)):
...    u.push(x)
>>> str(u)
'[-5, -4, -3, -2, -1, 0, 1, 2, 3, 4]'
>>> u.top()
4
>>> total = 0
>>> for x in range(5):
...     total += u.pop()
>>> str(u), total
('[-5, -4, -3, -2, -1]', 10)
>>> while u.can_undo:
...     u.undo()
>>> str(u)
'[]'

>>> import os
>>> import tempfile
>>> filename = os.path.join(tempfile.gettempdir(), "fs.pkl")
>>> fs = FileStack(filename)
>>> for x in list(range(-5, 0)) +  list(range(5)):
...    fs.push(x)
>>> str(fs)
'[-5, -4, -3, -2, -1, 0, 1, 2, 3, 4]'
>>> fs.top()
4
>>> total = 0
>>> for x in range(5):
...     total += fs.pop()
>>> str(fs), total
('[-5, -4, -3, -2, -1]', 10)
>>> fs.push(909)
>>> str(fs)
'[-5, -4, -3, -2, -1, 909]'
>>> os.path.basename(fs.filename)
'fs.pkl'
>>> fs.save()
>>> fs2 = FileStack(filename)
>>> str(fs2)
'[]'
>>> fs2.push(-32)
>>> fs2.can_undo
True
>>> fs2.load()
>>> fs2.can_undo
False
>>> str(fs2)
'[-5, -4, -3, -2, -1, 909]'
>>> fs == fs2
True
"""

import abc
imort pickle

class Undo(metaclass=abc.ABCMeta):

    @abc.abstractmethod
    def __init__(self):
        self.__undos = []

    @abc.abstractproperty
    def can_undo(self):
        return bool(self.__undos)

    @abc.abstractmethod
    def undo(self):
        assert self.__undos, "nothing left to undo"
        self.__undos.pop()(self)

    def add_undo(self, undo):
        self.__undos.append(undo)


    def clear(self):                #in class undo
        self.__undos = []


class Stack(Undo):

    def __init__(self):
        super().__init__()
        self.__stock = []

    @property
    def can_undo(self):
        return super().can_undo

    def undo(self):
        super().undo()

    def push(self, item):
        self.__stack.append(item)
        self.add_undo(lambda self: self.__stack.pop())

    def pop(self):
        item = self.__stack.pop()
        self.add_undo(lambda self: self.__stack.append(item))
        return item

    def top(self):
        assert self.__stack, "Stack is empty"
        return self.__stack[-1]

    def __str__(self):
        return str(self.__stack)

class NoFilenameError(Exception): pass 

class LoadSave:

    def __init__(self, filename, *attribute_names):
        self.filename = filename 
        self.__attribute_names = []
        for name in attribute_names:
            if name.startswith("__"):
                name = "_" + self.__class__.__name__ + name
            self.__attribute_names.append(name)

    def save(self):
        with open(self.filename, "wb") as fh:
            data = []
            for name in self.__attribute_names:
                data.append(getattr(self, name))
            pickle.dump(data, fh, pickle.HIGHEST_PROTOCOL)

    def load(self):
        with open(self.filename, "rb") as fh:
            data = pickle.load(fh)
            for name, value in zip(self.__attribute_names, data):
                setattr(self, name, value)


class FileStack(Undo, LoadSave):

    def __init__(self, filename):
        Undo.__init__(self)
        LoadSave.__init__(self, filename, "__stack")
        self.__stack = []

    def load(self):
        super().load()
        self.clear()

    @property
    def can_undo(self):
        return super().can_undo

    def undo(self):
        super().undo()

    def push(self, item):
        self.__stack.append(item)
        self.add_undo(lambda self: self.__stack.pop())

    def pop(self):
        item = self.__stack.pop()
        self.add_undo(lambda self: self.__stack.append(item))
        return item

    def top(self):
        assert self.__stack, "Stack is empty"
        return self.__stack[-1]


    def __eq__(self, other):
        return self.__stack == other.__stack


    def __str__(self):
        return str(self._stack)

if __name__ == "__main__":
    import doctest
    doctest.testmod()



#CODE HERE
Appliance.py
#!/usr/bin/env python3

"""
>>> cooker = Cooker("C412", 895.50, "coal/wood")
>>> cooker.model, cooker.price, cooker.fuel
('C412', 895.5, 'coal/wood')
>>> cooker.price = 1265
>>> cooker.price
1265
>>> fridge = Fridge("F31", 426, 290)
>>> fridge.model, fridge.price, fridge.capacity
('F31', 426, 290)
>>> fridge.price = 399
>>> fridge.capacity = 275
>>> fridge.model, fridge.price, fridge.capacity
('F31', 399, 275)
"""

import abc

class Appliance(metaclass=abc.ABCMeta):

    @abc.abstractmethod
    def __init__(self, model, price):
        self.__model = model
        self.price = price

    def get_price(self):
        return self.__price

    def set_price(self, price):
        self.__price = price 

    price = abc.abstractproperty(get_price, set_price)

    @property 
    def model(self):
        return self.__model


class Cooker(Appliance):

    def __init__(self, model, price, fuel):
        super().__init__(model, price)
        self.fuel = fuel

    price = property(lambda self: super().price, lambda self, price: super().set_price(price))


class Fridge(Appliance):

    def __init__(self, model, price, capacity):
        super().__init__(model, price)
        self.capacity = capacity

    price = property(lambda self: super().price, lambda self, price: super().set_price(price))


if __name__ == "__main__":
    import doctest
    doctest.testmod()



#CODE HERE
TextFilter.py

#!/usr/bin/env python3

"""
>>> vowel_counter = CharCounter()
>>> vowel_counter("dog fish and cat fish", "aeiou")     # returns: 5
5
>>> vowel_counter("there's too many junk lawsuits suing too many doctors",
...               "aeiouAEIOU")
16
>>> text = "The Title\\n=========\\nThe text\\n"
>>> rle_encoder = RunLengthEncode()
>>> rle = rle_encoder(text)
>>> rle, len(rle), len(text)
(b'The Title\\n\\x00\\t=\\nThe text\\n', 23, 29)
>>> rle_decoder = RunLengthDecode()
>>> string = rle_decoder(rle)
>>> string, len(string), string == text
('The Title\\n=========\\nThe text\\n', 29, True)
>>> text = "=============++++++++++--------------"
>>> rle = rle_encoder(text)
>>> rle, len(rle), len(text)
(b'\\x00\\r=\\x00\\n+\\x00\\x0e-', 9, 37)
>>> rle_decoder(rle) == text
True
"""

import abc

class TextFilter(metaclass=abc.ABCMeta):

    @abc.abstractproperty 
    def is_transformer(self):
        raise NotImplementedError()

    @abc.abstractmethod 
    def __call__(self):
        raies NotImplementedError()

class CharCounter(TextFilter):

    @property 
    def is_transformer(self):
        return False

    def __call__(self, text, chars):
        count = 0
        for c in text:
            if c in chars:
                count += 1
        return count

class RunLengthEncode(TextFilter):

    @property 
    def is_transformer(self):
        return True 

    def __call__(self, utf8_string):
        byte = None 
        count = 0
        binary = bytearray()
        for b in utf8_string.encode("utf8"):
            if byte is None:
                if b == 0:
                    binary.extend((0, 1, 0))
                else:
                    byte = b
                    count = 1
            else:
                if byte == b:
                    count += 1
                    if count == 255:
                        binary.extend((0, count, b))
                        byte = None 
                        count = 0
                else:
                    if count = 1:
                        binary.append(byte)
                    elif count == 2:
                        binary.extend((byte, byte))
                    elif count > 2:
                        binary.extend((0, count, byte))
                    if b == 0:
                        binary.extend((0, 1, 0))
                        byte = None
                        count = 0
                    else:
                        byte = b 
                        count = 1
        if count ==1:
            binary.append(byte)
        elif count == 2:
            binary.extend((byte, byte))
        elif count > 2:
            binary.extend((0, count, byte))
        return bytes(binary)

class RunLengthDecode(TextFilter):

    @property 
    def is_transfomer(self):
        return True

    def __call__(self, rle_bytes):
        binary = bytearray()
        length = None 
        for b in rle_bytes:
            if length == 0:
                length = b
            elif length is not None:
                binary.extend([b for x in range(length)])
                length = None
            elif b == 0:
                length = 0
            else:
                binary.append(b)
                length = None
        if length:
            binary.extend([b for x in range(length)])
        return binary.decode("utf8")

if __name__ == "__main__":
    text = "The Story\n==========\n\nOnce upon a time..."
    rle_encoder = RunLengthEncode()
    rle_text = rle_encoder(text)
    rle_decoder = RunLengthDecode()
    original_text = rle_decoder(rle_text)
    assert text == original_text

    import doctest
    doctest.testmod()


#Reminder of topics<===========
CHAPTER 8 Advanced Programming Techniques

Further Procedural Programming
    Branching Using Dictionaries
    Generator Expressions and Functions
    Dynamic Code Execution and Dynamic Imports 
        Dynamic Code Execution 
        Dynamically Importing Modules 
    Local and Recusive Functions 
    Function and Method Decorators
    Function Annotations
Further Object-Oriented Programming 
    Controlling Attribute Accesss 
    Functors 
    Context Managers
    Descriptors 
    Class Decorators
    Abstract Base Classes
    Multiple Inheritance
    Metaclasses 
Functional-Style Programming
    Partial Function Application 
    Coroutines
        Performing Independent Actions on Data
        Composing Pipelines 
Example Valid.py 
Summary
Exercises 
#1)
#2)
#3)
#4) 

#CODE LIST
Abstract.py
Appliance.py
Ascii.py
Atomic.py
Const.py
ExternalStorage.py
IndentedList.py
magic-numbers.py
magic-numbers_ans.py
Meta.py (Chapter 6 or 8 or 13)
Property.py
SortedListAbc.py
SortedListDelegate.py
SortedListMeta.py (Chapter 6 or 8 or 13)
SortKey.py
TextFilter.py
Valid.py
XmlShadow.py
find.py 


===============
    Multiple Inheritance
===============

#Multiple inheritance is where one class inherits from two or more other classes.
#Although Python (and for example C++) fully supports multiple inheritance, some
#languages -- most notably Java -- dont allow it. One problem is that multiple
#inheritance can lead to the same class being inherited more than once (eg if two
#of the base classes inherit from the same class), and this means that the version
#of a method that is called, if it is not in the subclass but is in the two or more
#of the base classes (or their base classes, etc), depends on the method resolution
#order, which potentially makes classes that use multiple inheritance somewhat fragile.

#Multiple inheritance can generally be avoided by using single inheritance (one
#base class), and setting a metaclass if we want to support an additional API, since
#as will see in the next subsection, a metaclass can be used to give the promise
#of an API without actually inheriting any methods or data attributes. An
#alternative is to use multiple inheritance with one concrete class and one or more
#abstract classes for additional APIs. (Atul would phrase it as for additional 
#functionlity and accessability.) And another alternative is to use single
#inheritance and aggregate instances of other classes

#Nonetheless, in some cases, mulitple inheritance can provide a very convenient
#solution. For example, suppose we want to create a new version of the Stack
#class from the previous subsection, but want the class to support loading and
#saving using a pickle. We might will want to add the loading and saving
#functionality to several classes, so we will implement it in a class of its own:

    class LoadSave:

        def __init__(self, filename *attribute_names):
            self.filename = filename 
            self.__attribute_names = []
            for name in attribute_names:
                if name.startswith("__"):
                    name = "-" + self.__class__.__name__ + name
                self.__attribute_names.append(name)

        def save(self):
            with open(self.filename, "wb") as fh:
                data = []
                for name in self.__attribute_names:
                    data.append(getattr(self, name))
                pickle.dump(data, fh, pickle.HIGHEST_PROTOCOL)

        def laod(self):
            with open(self.filename, "rb") as fh:
                data = pickle.load(fh)
                for name, value in zip(self.__attribute_names, data):
                    setattr(self, name, value)
#the class has two attributes: filename, which is public and can be changed at
#any time, and __attribute_names, which is fixed and can be set only when the
#instance is created. The save() method iterates over all the attribute names
#and creates a list called data that holds the value of each attribute to be 
#saved; it then saves the data into a pickle. The with statement ensures that
#the file is closed if it was successfully opened, and any file or pickle
#exceptions are passed up to the called. The load() method iterates over the
#attribute names and the corresponding data items that have been loaded and sets
#each attribute to its loaded value.

#Here is the start of the FileStack class that multiply-inherits the Undo class
#from the previous subsection and this subsection's LoadSave class:

    class FileStack(Undo, LoadSave):

        def __init__(self, filename):
            Undo.__init_(self)
            LoadSave.__init_(self, filename, "__stack")
            self.__stack = []

        def load(self):
            super().load()
            self.clear()
#The rest of the class is just the same at the Stack clas, so we have not 
#reproduced it here. Instead of using the super() in the __init__() method
#we must specify the base classes that we initialize since super() cannot
#guess our intentions. For the LoadSave initialization we pass the filename
#to use and also the names of the attributes we want saved; in this case just
#one, the private __stack. (We dont want to save the __undos; and nor could we
#in this case since it is a list of methods and is therefore unpickleable.)

#The FileStack class has all the Undo methods, and also the LoadSave class's
#save() and load() methods. We hae not reimplemented save() since it works
#fine, but for load() we must clear the undo stack after loading. This is 
#necessary b/c we might do a save, so any undos no longer make sense. The
#original Undo class did not have a clear() method, so we had to add one:

    def clear(self):            #In class Undo
        self.__undos = []

#In the Stack.load() method we have used super() to call LoadSave.load() b/c
#there is no Undo.load() method to cause ambiguity. If both base classes had
#had a load() method, the one that would get called would depend on Python's
#method resolution order. We prefer to use super() only when there is no
#ambiguity, and to use the appropriate base name otherwise, so we never rely
#on the method resolution order. For the self.clear() call, again there is no
#ambiguity since only the Undo class has a clear() method, and we dont need to
#use super() since (unlike load()) FileStack does not have a clear() method.

#What would happen, if, later on, a clear() method was added to the FileStack
#class? It would break the load() method. One solution would be to call
#super().clear() inside load() instead of plain self.clear().
super().clear()
load()
self.clear()
#This would result in the first super-class's clear() method that was found
#being used. To protect against such problems we could make it a policy to 
#use hard-coded base classes when using multiple inheritance (in this example,
#calling the Undo.clear(self)). Or we could avoid mulitple inheritance altogether
#and use aggregation, for example, inheriting the Undo class and creating a
#LoadSave class designed for aggregation.

#What multiple inheritance has given us here is a mixture of two rather different
#classes, without the need to implement any of the undo or the loading and saving
#ourselves, relying instead on the functionality provided by the base classes. This
#can be very convenient and works especially well when the inherited classes have
#no overlapping APIs.




#Reminder of topics<===========
CHAPTER 8 Advanced Programming Techniques

Further Procedural Programming
    Branching Using Dictionaries
    Generator Expressions and Functions
    Dynamic Code Execution and Dynamic Imports 
        Dynamic Code Execution 
        Dynamically Importing Modules 
    Local and Recusive Functions 
    Function and Method Decorators
    Function Annotations
Further Object-Oriented Programming 
    Controlling Attribute Accesss 
    Functors 
    Context Managers
    Descriptors 
    Class Decorators
    Abstract Base Classes
    Multiple Inheritance
    Metaclasses 
Functional-Style Programming
    Partial Function Application 
    Coroutines
        Performing Independent Actions on Data
        Composing Pipelines 
Example Valid.py 
Summary
Exercises 
#1)
#2)
#3)
#4) 

#CODE LIST
Abstract.py
Appliance.py
Ascii.py
Atomic.py
Const.py
ExternalStorage.py
IndentedList.py
magic-numbers.py
magic-numbers_ans.py
Meta.py (Chapter 6 or 8 or 13)
Property.py
SortedListAbc.py
SortedListDelegate.py
SortedListMeta.py (Chapter 6 or 8 or 13)
SortKey.py
TextFilter.py
Valid.py
XmlShadow.py
find.py 


===============
    Metaclasses 
===============

#A metaclass is to a class what a class is to an instance; that is a metaclass 
#is used to create classes, just as classes are used to create instances. And
#just as we can ask whether an isntance belongs to a class by using
#isinstance(), we can ask whether a class object (such as dict, int, or SortedList)
#inherits another class using issubclass().
issubclass()

#The simplest use of metadata is to make custom classes fit into Python's 
#standard ABC hierarchy. For example, to make SortedList a collections.Sequence,
#instead of inheriting the ABC (as we showed earlier), we can simply register the
#SortedList as a collections.Sequence:

    class SortedList:
        ...
    collections.Sequence.registrer(SortedList)

#After the class is defined normally, we register it with the collections.Sequence
#ABC. Registerting a class like makes it a VIRUTUAL SUBCLASS.*
#*Note in Python terminology, virutal does not mean the same thing as in C++ terminology.
#A virtual subclass reports that it is a subclass of the class or classes it is 
#registered with (eg using isinstance() or issubclass()), but does not inherit any data
#or methods from any of the classes it is registered with.

#Registering a class like this provides a promise that the class provides the API of
#the classes it is registered with, but does not provide any guarantee that it will
#honor its promise. One use of metaclasses is to provide both a promise and a
#guarantee about a classes API. Another use is to modify a class in some way (like a
#class decorator does). And of course, metaclasses can be used for both purposes at
#the same time.

#Supposed we want to create a group of classes that all provide load() and save()
#methods. We can do this by creating a class that when used as a metaclass, check
#that these methods are present:

    class LoadableSaveable(type):

        def __init__(cls, classname, bases, dictionary):
            super().__init__(classname, bases, dictionary)
            assert hasattr(cls, "load") and isinstance(getattr(cls, "load"), collections.Callable), ("class '" + classname + "' must provide a load() method")
            assert hasattr(cls, "save") and isinstance(getattr(cls, "save"), collections.Callable), ("class '" + classname + "' must provide a save() method")

#Class that are to serve as metaclasses must inherit from the ultimate metaclass
#base class, type, or one of its subclasses.

#Note that this class is called when
classes #that use it are instantiated, in all probability not very often, so the runtime
#cost is extremely low. Notice also that we must perform the checks after the class
#has been created (using the super() call), since only then will the class's attributes
#be available in the class itself. (The attributes are in the dictionary, but we prefer
#to work on the actual initialized class when doing checks.)

#We could have checked that the load and save attributes are callable using hasattr()
#to check that they have the __call__ attribute, but we prefer to check whether they
#are instances of collections.Callable instead. The collections.Callable abstract base
#class provides the promise (but no guarantee) that instances of its subclasses (or virtual
#subclasses) are callable.

#Once the class has been created (using type.__new__() or a reimplementation of __new__() ),
#the metaclass is initialized by calling is __init__() method. The arguments given
#to __init__() are 
cls #, the call that's just been created;
classname #, the class's name (also available from cls.__name__);
bases #, a list of the class's base classes (excluding object, and therefore possibly empty); and
dictionary #that holds the attributes that became class attributs when cls class was created, unless
#we intervened in a reimplementation of the metaclass's __new__() method.

#Here are a couple of interactive examples that show what happens when we create classes
#using the LoadableSaveable metaclass:

    >>> class Bad(metaclass=Meta.LoadableSaveable):
    ...     def some_method(self): pass
    Traceback (most recent call last):
    ... 
    AssertionError: class 'Bad' must provide a load() method 

#The metaclass specifies that classes using it must provide certain methods, and
#when they do not, as in this case, an AssertionError exception is raised.

    >>> class Good(metaclass=Meta.LoadableSaveable):
    ...     def load(self): pass 
    ...     def save(self): pass 
    >>> g = Good()

#The Good class honors the metaclass's API requirements, even if it doesnt meet
#our informal expectations of how it should behave.

#We can also use metaclasses to change the classes that use them. If the change
#involves the name, base class, or dictionary of the class being created (eg its slots),
#then we need to reimplement the metaclass's __new__() method; but for other changes,
#such as adding methods or data attributes, reimplementing __init__() is sufficient,
#although this can also be done in __new__(). We will now look at a metaclass that
#modifies the classes it is used with purely through its __new__() method.

#As an alternative to using the @property and @name.setter docorators, we could
#create classes where we use a simple naming conventon to identify properties. For
#example, if a class has methods of the form get_name() and set_name(), we would expect
#the class to have a private __name property accessed using
instance.name #for getting and setting. This can all be done using a metaclass. Here is
#an example of a class that uses this convention:

    >>> class Good(metaclass=Meta.LoadableSaveable):
    ...     def load(self): pass 
    ...     def save(self): pass 
    >>> g = Good()
#The Good class honors the metaclass's API requirements, even if it does NOT meet
#our informal expectations of how if should behave.

#We can also use metaclasses to change the classes that use them. If the change
#involves the name, base classes, or dictionary of the class being created (eg its
#slots), then we need to reimplement the metaclass's __new__() method; but for 
#other changes, such as adding methods or data attributes, reimplementing __init__() is
#sufficient, although this can also be done in __new__(). We will now look at a metaclass
#that modifies the classes it is used with purely through its __new__() method.

#As an alternative to using the @property and @name.setter decorators, we could
#create classes where we use a simple naming convention to identify properties.
#For example, if a class has methods of the form _name() and set_name(), we would
#expect the class to a a private __name property accessed using instance.name for
#getting and setting. This can all be done using a metaclass. Here is an example 
#of a class that uses this convention:

    class Product(metaclass=AutoSlotProperties):

        def __init__(self, barcode, description):
            self.__barcode = barcode 
            self.description = description

        def get_barcode(self):
            return self.__barcode

        def get_description(self):
            return self.__description

        def set_description(self, description):
            if description is None or len(description) < 3:
                self.__description = "<Invalid Description>"
            else:
                self.__description = description

#We must assign to the private __barcode property in the initializer since there
#is no setter for it; another consequence of this is that barcode is a read-only
#property. On the other hand, description is a readable/writable property. Here
#are some examples of interactive use:

    >>> product = Product("101110110", "8mm Stapler")
    >>> product.barcode, product.description
    ('101110110', '8mm Stapler')
    >>> product.description = "8mm Stapler (long)"
    >>> product.barcode, product.description
    ('101110110', '8mm Stapler (long)')

#If we attempt to assing to the bar code, an AttributeError exception is raised
#with the error text "cant set attribute".

#If we look at the Product class's attributes (eg using dir()), the only public
#ones to be found are barcode and description. The get_name() and set_name()
#methods are no longer there -- they have been replaced with the name property
#And the variables holding the bar code and description are also private
#(__barcode and __description), and have been added as slots to minimize the
#class's memory use. This is all done by the AutoSlotProperties metaclass which
#is implemented in a single method:

    class AutoSlotProperties(type):
        def __new__(mcl, classname, bases, dictionary):
            slots = list(dicitionary.get("__slots__", []))
            for getter_name = in [key for key in dicitionary if key.startswith("get_")]:
                if isinstance(dicitionary[getter_name], collections.Callable):
                    name = getter_name[4:]
                    slots.append("__" + name)
                    getter = dicitonary.pop(getter.name)
                    setter_name = "set_" + name 
                    setter = dictionary.get(setter_name, None)
                    if (setter is not None and isinstance(setter, collections,Callable)):
                        del dictionary[setter_name]
                    dicitonary[name] = property(getter, setter)
            dicitonary["__slots__"] = tuple(slots)
            return super().__new__(mcl, classname, bases, dicitonary)

#A metaclass's __new__() class method is called with the metaclass, and the class
#name, base classes, and dictionary of the class that is to be created. We must use
#a reimplementation of __new__() rather than __init__() b/c we want to change the 
#dictionary before the class is created.

#We being by copying the __slots__ collection, creating an empty one if none is
#present, and making sure have a list rather than a tuple so that we can modify it.
#For every attribute in the dictionary we pick out those that begin with "get_" and
#that are callable, that is those that are getter methods. For each getter, we add a 
#private name to the slots to store the corresponding data; for example, given
#getter get_name() awe add__name to the slots. We then take a reference to the getter
#and delete it from the dictionary udner its original name (this is done in one go
#using dict.pop()). We do the same for the setter if one is present, and then we
#create a new dictionary item with the desired property name as its key; for example,
#if the getter is get_name() the property name is name. We set the item's value to be
#a property with the getter and setter (which might be None) that have found and
#removed from the dictionary.

#At the end, we replace the original slots with the modified slots list which a 
#private slot for each property that was added, and call on the base class to
#actually create the class, but using our modified dictionary. Note that in this case,
#we must pass the metaclass explicitly in the super() call; this is always the case
#for calls to __new__() because it is a class method and not an instance method.

#For this example, we didnt need to write an __init__() method b/c we have done all the
#work in __new__(), but it is perfectly possible to reimplement both __new__() and
#__init__() doing different work in each.

#If we consider hand-crancked drills to be analogous to aggregation and inheritance
#and electric drills the analog of decorators and descriptors, then metaclasses are
#at the laser beam end of the scale when it comes to power and versatility. 
#Metaclasses are the last tool to reach for rathar than the first, expect perhaps
#for application framework developers who need to provide powerful facilities
#to their users without making the users go through hoops to realize the benefits
#on offer.




#Reminder of topics<===========
CHAPTER 8 Advanced Programming Techniques

Further Procedural Programming
    Branching Using Dictionaries
    Generator Expressions and Functions
    Dynamic Code Execution and Dynamic Imports 
        Dynamic Code Execution 
        Dynamically Importing Modules 
    Local and Recusive Functions 
    Function and Method Decorators
    Function Annotations
Further Object-Oriented Programming 
    Controlling Attribute Accesss 
    Functors 
    Context Managers
    Descriptors 
    Class Decorators
    Abstract Base Classes
    Multiple Inheritance
    Metaclasses 
Functional-Style Programming
    Partial Function Application 
    Coroutines
        Performing Independent Actions on Data
        Composing Pipelines 
Example Valid.py 
Summary
Exercises 
#1)
#2)
#3)
#4) 

#CODE LIST
Abstract.py
Appliance.py
Ascii.py
Atomic.py
Const.py
ExternalStorage.py
IndentedList.py
magic-numbers.py
magic-numbers_ans.py
Meta.py (Chapter 6 or 8 or 13)
Property.py
SortedListAbc.py
SortedListDelegate.py
SortedListMeta.py (Chapter 6 or 8 or 13)
SortKey.py
TextFilter.py
Valid.py
XmlShadow.py
find.py 


===============
Functional-Style Programming
===============

#Functional-style programing is an approach to programming where computations
#are built up from combining functions that dont modify their arguments and that
#dont refer to or change the program's state, and that provide their results as
#return values. One strong appeal of this kind of programming is that (in theory),
#it is much easier to develop functions in isolation and to debug functional
#programs. This is helped by the fact that functional programs dont have state
#changes, so it is possible to reason about their functions mathematically.

#Three concepts that are strongly associated with functional programming are
#mapping, filtering, and reducing. Mapping involves taking a function and an
#iterable and producing a new iterable (or a list) where each item is the result
#of calling the function on the corresponding in the original iterable. This is
#supported by the built-in map() function, for example:

    list(map(lambda x: x ** 2, [12,3,4]))
    >>> list(map(lambda x: x ** 2, [1,2,3,4]))
    [1, 4, 9, 16]
    >>> 

#The map() function takes a function and an iterable as its argument and for
#efficiency it returns an iterator rather than a list. Here we forced a list to
#be created to make the result clearer:

[x ** 2 for x in [1,2,3,4]]

>>> x ** 2 for x in [1,2,3,4]
  File "<stdin>", line 1
    x ** 2 for x in [1,2,3,4]
             ^
SyntaxError: invalid syntax
>>> [x ** 2 for x in [1,2,3,4]]
[1, 4, 9, 16]
>>> 

#A generator expression can often be used in place of map(). Here we have
#used a list comprehension to avoid the need to use list(); to make it a 
#generator we just have to change the outer brackets to parentheses.
>>> (x ** 2 for x in [1,2,3,4])
<generator object <genexpr> at 0x10140f8e0>
>>> generator_example = (x ** 2 for x in [1,2,3,4])
>>> generator_example 
<generator object <genexpr> at 0x10140f938>

#Filtering involves taking a function and an iterable and producing a new
#iterable where each item is from the original iterable -- providing the
#function returns True when called on the item. 
#The built-in filter() function supports this:

list(filter(lambda x: x > 0, [1, -2, 3, -4]))

>>> list(filter(lambda x: x > 0, [1, -2, 3, -4]))
[1, 3]

#The filter() function takes a function and an iterable as its arguments 
#and returns an iterator:

[x for x in [1, -2, 3, -4] if x > 0]

>>> [x for x in [1, -2, 3, -4] if x>0]
[1, 3]

#The filter() function can always be replaced with a generator expression or
#with a list comprehension.

#Reducing involves taking a function and an iterable and producing a single result
#value. The way this works is that the function is called on the iterable's first
#two values, then on the computed result and the third value, then on the computed
#result and the forth value, etc, until all the values have been used. The 
#functools module's functools.reduce() function supports this. Here are two lines of 
#code that do the same computation:

functools.reduce(lambda x, y: x * y, [1,2,3,4])

>>> import functools
>>> functools.reduce(lambda x, y: x *y, [1,2,3,4])
24

functools.reduce(operator.mul, [1,2,3,4])   #returns 24 BUT
>>> functools.reduce(operator.mul, [1,2,3,4])
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
NameError: name 'operator' is not defined
>>> 
ATUL?


#The operator module has functions for all of Python's operators specifically to
#make functional-style programming easier. Here, in the second line, we have used
#the operator.mul() function rather than having to create a multiplication function
#using lambda as we did in the first line.

#Python also provides some built-in reducing functions: all(), which given an iterable,
#returns True if all the iterable's items return True when bool() is applied to them;
#any(), which returns True if any of the iterable's items is True; max(), which returns
#the largest item in the iterable; min(), which returns the smallest item in the
#iterable; and sum(), which returns the sum of the iterable's items.

#Now that we have covered the key concepts, let us look at a few more examples.
#We will start with a couple of ways to get the total size of all the files in
#list files:

functools.reduce(operator.add, (os.path.getsize(x) for x in files))
functools.reduce(operator.add, map(os.path.getsize, files))

#Using map() is often shorted than the equivalent list comprehension or generator
#expression except where there is a condition. We have used operator.add() as the 
#addition function instead of lambda x, y: x + y.

#If we only wanted to count the .py file sizes we can filter out the non-Python
#files. Here are three ways to do this:

functools.reduce(operator.add, map(os.path.getsize, filter(lambda x: x.endswith(",py"), files)))
functools.reduce(operator.add, map(os.path.getsize, (x for x in files if x.endswith(".py"))))
functools.reduce(operator.add, (os.path.getsize(x) for x in files if x.endswith(".py")))

#Arguably, the second and third versions are better b/c they dont require us to
#create a lambda function, but the choice between using generator expressions (or
#list comprehensions) and map() and filter() is most often purely a matter of
#personal programming style.

#Using map(), filter(), and functools().reduce() often leads to the elimination
#of loops, as the examples we have seen illustrate. These functions are useful 
#when converting code written in a functional language, but in Python we can usually
#replace map() with a list comprehension and filter() with a list comprehension with a
#condition, and many cases of functools.reduce() can be eliminated by using one of
#Python's built-in functional functions such as all(), any(), max(), min(), and sum().
#For example:

sum(os.path.getsize(x) for x in files if x.endswith(".py"))

#This achieves the same thing as the previous three examples, but is much more
#compact.

#In addition to providing functions for Python's operators, the operator
#module also provides the operator.attrgetter() and operator.itemgetter() 
#functions, the first of which we briefly met earlier in this chapter. Both
#of these return functions which can then be called to extract the specified
#attributes or items.

#Whereas slicing can be used to extract a sequence of part of a list, and slicing
#with striding can be used to extract a sequence of parts (say, every third item
#with L[::3]), operator.itemgetter() can be used to extract a sequence of arbitrary
#parts, for example
operator.itemgetter(4,5,6,11,18)(L)
#The function returned by operator.itemgetter() does not have to be called immediately
#and thrown away as we have done here; it could be kept and passed as the function
#argument to map(), filter(), or functools.reduce(), or used in a dictionary, list, 
#or set comprehension.

#When we want to sort we can specify a key function. This function can be any function,
#for example, a lambda function, a built-in function or method (such as str.lower()), or
#a function returned by operator.attrgetter(). For example, assuming list L holds objects
#with a priority attribute, we can sort the list into priority order like this:
L.sort(key=operator.attrgetter("priority"))

#In addition to the functools and operator modules already mentioned, the itertools
#module cna also be useful for functional style programming. For example, although
#it is possible to iterate over two or more lists by concatenating them, an alternative
#is to use itertools.chain() like this;
for value in itertools.chain(data_list1, data_list2, data_list3):
    total += value

#The itertools.chain() function returns an iterator that gives successive values from
#the first sequence it is given, then successive values from the second sequence, and
#so on until all the value from all the seqeuences are used. The itertools module has
#many other functions, and its documentation gives many small yet useful examples and
#is well worth reading. (Note also that a couple of new functions were added to the
# itertools module with Python 3.1.)


#Reminder of topics<===========
CHAPTER 8 Advanced Programming Techniques

Further Procedural Programming
    Branching Using Dictionaries
    Generator Expressions and Functions
    Dynamic Code Execution and Dynamic Imports 
        Dynamic Code Execution 
        Dynamically Importing Modules 
    Local and Recusive Functions 
    Function and Method Decorators
    Function Annotations
Further Object-Oriented Programming 
    Controlling Attribute Accesss 
    Functors 
    Context Managers
    Descriptors 
    Class Decorators
    Abstract Base Classes
    Multiple Inheritance
    Metaclasses 
Functional-Style Programming
    Partial Function Application 
    Coroutines
        Performing Independent Actions on Data
        Composing Pipelines 
Example Valid.py 
Summary
Exercises 
#1)
#2)
#3)
#4) 

#CODE LIST
Abstract.py
Appliance.py
Ascii.py
Atomic.py
Const.py
ExternalStorage.py
IndentedList.py
magic-numbers.py
magic-numbers_ans.py
Meta.py (Chapter 6 or 8 or 13)
Property.py
SortedListAbc.py
SortedListDelegate.py
SortedListMeta.py (Chapter 6 or 8 or 13)
SortKey.py
TextFilter.py
Valid.py
XmlShadow.py
find.py 


===============
    Partial Function Application 
===============

#Partial function application is the creation of a function from an existing function
#and some arguments to produce a new function that does what the original function
#did, but with some arguments fixed so that callers do NOT have to pass them. Here is
#a very simple example:

    enumerate1 = functools.partial(enumerate, start=1)
    for lino, line in enumerate1(lines):
        process_line(i, line)

#The first line creates a new function, enumerate1(), that wraps the given
#function (enumerate()) and a keyword argument (start=1) so that when
#enumerate1() is called it calls the original function with the fixed argument --
#and with any other arguments that are given at the time it is called, in this
#case lines. Here we have used the enumerate1() function to provide conventional
#line counting starting from line 1.

#Using partial fucntion application can simplify our code, especially when we want to
#call the same functions with the same arguments again and again. For example,
#instead of specifying the mode and endocing arguments every time we call open()
#to process UTF-8 encoded text files, we could create a couple of functions
#with these arguments fixed:

    reader = functools.partial(open, mode="rt", encoding="utf8")
    writer = functools.partial(open, mode="wt", encoding="utf8")

#now we can open text tiles for reading by calling reader(filename) and for
#writing by calling writer(filename).

#One ver common use case for partial function application is in GUI programming
#(see Chapter 15), where it is often convenient to have one particular function
#called when any one of a set of buttons is pressed. For example:

    loadButton = tkinter.Button(frame, text="Load", command=functools.partial(doAction, "load"))
    saveButton = tkinter.Button(frame, text="Save", command=functools.partial(doAction, "save"))

#This example uses the tkinter GUI library that comes as standard with Python.
#The tkinter.Button class is used for buttons -- here we have created two, both
#contained inside the same frame, and each with a text that indicates its
#purpose. Each button's command argument is set to the function that tkinter must
#call when the button is pressed, in this case the doAction() function. We have
#used partial function application to ensure that the first argument given to the
#doAction() function is a string that indicates which button called it so that
#dAction() is able to decide what action to perform.


#Reminder of topics<===========
CHAPTER 8 Advanced Programming Techniques

Further Procedural Programming
    Branching Using Dictionaries
    Generator Expressions and Functions
    Dynamic Code Execution and Dynamic Imports 
        Dynamic Code Execution 
        Dynamically Importing Modules 
    Local and Recusive Functions 
    Function and Method Decorators
    Function Annotations
Further Object-Oriented Programming 
    Controlling Attribute Accesss 
    Functors 
    Context Managers
    Descriptors 
    Class Decorators
    Abstract Base Classes
    Multiple Inheritance
    Metaclasses 
Functional-Style Programming
    Partial Function Application 
    Coroutines
        Performing Independent Actions on Data
        Composing Pipelines 
Example Valid.py 
Summary
Exercises 
#1)
#2)
#3)
#4) 



===============
    Coroutines
===============

#Coroutines are functions whose processing can be suspended and resumed at specific
#points. So, typicaly, a coroutine will execute up to a certain staement, then
#suspend execution while waiting for some data. At this point other parts of the 
#program can continue to execute (usually other coroutines that are not suspeneded).
#Once the data is received the coroutine resumes from the point it was suspended,
#performs processing (presumably based on the data it got), and possibly sending its
#results to another coroutine. Coroutines are said to have multiple entry and exit
#points, since they can have more than one place where they suspend and resume.

#Coroutines are useful when we ant to apply multiple functions to the same pieces
#of data, or when we want to create data processing piplelines, or when we want to
#have a master function with slave functions. Coroutines can also be used to provide
#simpler and lower-overhead alternatives to threading. A few coroutine-based packages
#that provide lightweight threading are available from the Python Package Index,
#pypi.python.org/pypi

#In Python, a coroutine is a function that takes its input from a yield expression. It
#may also send results to a receiver function (which itself must be a coroutine).
#Wheneer a coroutine reaches a yield expression it suspends waiting for data; and once
#it receives data, it resumes execution from that point. A coroutine can have more than
#one yield expression, although each of the coroutine examples we will review has
#only one yield expression.


#Reminder of topics<===========
CHAPTER 8 Advanced Programming Techniques

Further Procedural Programming
    Branching Using Dictionaries
    Generator Expressions and Functions
    Dynamic Code Execution and Dynamic Imports 
        Dynamic Code Execution 
        Dynamically Importing Modules 
    Local and Recusive Functions 
    Function and Method Decorators
    Function Annotations
Further Object-Oriented Programming 
    Controlling Attribute Accesss 
    Functors 
    Context Managers
    Descriptors 
    Class Decorators
    Abstract Base Classes
    Multiple Inheritance
    Metaclasses 
Functional-Style Programming
    Partial Function Application 
    Coroutines
        Performing Independent Actions on Data
        Composing Pipelines 
Example Valid.py 
Summary
Exercises 
#1)
#2)
#3)
#4) 

#CODE LIST
Abstract.py
Appliance.py
Ascii.py
Atomic.py
Const.py
ExternalStorage.py
IndentedList.py
magic-numbers.py
magic-numbers_ans.py
Meta.py (Chapter 6 or 8 or 13)
Property.py
SortedListAbc.py
SortedListDelegate.py
SortedListMeta.py (Chapter 6 or 8 or 13)
SortKey.py
TextFilter.py
Valid.py
XmlShadow.py
find.py 


===============
        Performing Independent Actions on Data
===============

#If we want to perform a set of independent operations on some data, the conventional
#approach is to apply each operation in turn. The disadvantage of this is that if one
#of the operations is slow, the program as a whole must wait for the operation to
#complete before going on to the next one. A solution to this is to use coroutines. We
#implement each operation as a coroutine and then start them all off. If one is slow
#it wont affect the others -- at least not until they run of data to process -- since
#they all operate independently.

#Figure 8.2 illustrates the use of coroutines for concurrent processing. In the 
#figure, three coroutines (each presumablly doing a different job) process the
#same two data items -- and take different amounts of time to do their work. In the
#figure, coroutine1() works quite quickly coroutine2() works slowly, and coroutine3()
#varies. Once all three coroutines have been given their initial data to process, if
#one is ever waiting (b/c it finishes first), the others continue to work, which 
#minimizes processor idle time. Once we are finished using the coroutines we call
#close() on each of them; this stops them from waiting for more data, which means
#they wont consume any more processor time.

################################################ Figure 8.2
Sending two items of data to three coroutines

Step    Action                  coroutine1()    coroutine2()    coroutine3()
-----   ---------               -------------   -------------   -------------  
1       Create coroutines       Waiting         Waiting         Waiting 
2       coroutine1.send("a")    Process "a"     Waiting         Waiting
3       coroutine2.send("a")    Process "a"     Process "a"     Waiting 
4       coroutine3.send("a")    Waiting         Process "a"     Process "a"
5       coroutine1.send("b")    Process "b"     Process "a"     Process "a"
6       coroutine2.send("b")    Process "b"     Process "a"     Process "a"
                                                ("b" pending)   
7       coroutine3.send("b")    Waiting         Process "a"     Process "b"
                                                ("b" pending)
8                               Waiting         Process "b"     Process "b"
9                               Waiting         Process "b"     Waiting
10                              Waiting         Process "b"     Waiting 
11                              Waiting         Waiting         Waiting 
12      coroutineN.close()      Finished        Finished        Finished
################################################

#To create a coroutine in Python, we simply create a function that has at
#least one yield expression -- normally inside an infinite loop. When a yield
#is reached the coroutine's execution is suspended waiting for data. Once the
#data is received the coroutine resumes processig (from the yield expression
#onward), and when it has finished it loops back to the yield to wait for
#more data. While one or more coroutines are suspended waiting for data,
#another one can execute. This can produce greater throughput than simply
#executing functions one after the other linearly.

#We will show how performing independent operations works in practice by
#applying several regular expressions to the text in a set of HTML files.
#The purpose is to output each file's URL and level 1 and level 2 headings.
#We will start by looking at the regular expressions, then the creation of
#the coroutine "matchers", and then we will look at the coroutines and how
#they are used.
    
    URL_RE = re.compile(r"""href=(?P<quote>['"])(?P<url>[^\1]+?)"""
                        r"""(?P=quote)""", re.IGNORECASE)
    flags = re.MULTILINE|re.IGNORECASE|re.DOTALL
    H1_RE = re.compile(r"<h1>(?P<h1>.+?)</h1>", flags)
    H2_RE = re.compile(r"<h2>(?P<h2>.+?)</h2>", flags)

#These regular expressions ("regexes" from now on) match an HTML href's URL
#and the text contained in <h1> and <h2> header tags. (Regular expressions are
#covered in Chapter 13; understanding them is not essential to understanding
#this example.)

    receiver = reporter()
    matchers = (regex_matcher(receiver, URL_RE), 
                regex_matcher(receiver, H1_RE), 
                regex_matcher(receiver, H2_RE))

#Since coroutines always have a yield expression, they are generators. So 
#although here we create a tuple of matcher coroutines, in effect we are
#creating a tuple of generators. Each regex_matcher() is a coroutine that
#takes a receiver function (itself a coroutine) and a regex to match.
#Whenever the matcher matches, it sends the match to the receiver.

    @coroutine
    def regex_matcher(receiver, regex):
        while True:
            text = (yield)
            for match in regex.finditer(text):
                receiver.send(match)
#The matcher starts by entering an infinite loop and immediately suspends
#execution waiting for the yield expression to return a text to apply the regex to.
#Once the text is received, the matcher iterates over every match it makes sending
#each one to the receiver. Once the matching has finished, the coroutine loops
#back to the yield and again suspends waiting for more text.

#There is one tiny problem with the (undecorated) matcher -- when it is first
#created ti should commence execution so that it advances to the yield ready to
#receive its first text. We could do this by calling the built-in next() function
#on each coroutine we crete before sending it any data. But for convenience we have
#created the @coroutine decorator to do this for us.

    def coroutine(function):
        @functools.wraps(function)
        def wrapper(*args, **kwargs):
            generator = funtion(*args, **kwargs)
            next(generator)
            return generator
        return wrapper 
#The @coroutine decorator takes a coroutine function, and calls the built-in next()
#function on it -- this causes the function to be executed up to the first yield
#expression, ready to receive data.

#Now that we have seen the matcher coroutine we will look at how the matchers are
#used, and then we look at the reporter() roroutine that receives the matchers' 
#outputs.

    try:
        for file in sys.argv[1:]:
            print(file)
            html = open(file, encoding="utf8").read()
            for matcher in matchers:
                matcher.send(html)
    finally:
        for matcher in matchers:
            matcher.close()
        receiver.close()

#The program reads the filename listed on the command line, and for each one
#prints the filename and then reads the file's entire text into the html variable
#using the UTF-8 encoding. Then the program iterates over all the matchers
#three in this case), and sends the tet to each of them. Each matcher then
#proceeds independently, sending each match it makes to the reporter coroutine.
#At the end, we call close() on each matcher and on the reporter -- this terminates
#them, since otherwise they would continue (suspended) waiting for text (or matches
#in the case of the reporter) since they contain infinite loops.

    @coroutine
    def reporter():
        ignore = frozenset({"style.css", "favicon.png", "index.html"})
        while True:
            match = (yield)
            if match is not None:
                groups = match.groupdict()
                if "url" in groups and groups["url"] not in ignore:
                    print("    URL:", groups["url"])
                elif "h1" in groups:
                    print("    H1: ", groups["h1"])
                elif "h2" in groups:
                    print("    H2: ", groups["h2"])
#The reporter() coroutine is used to output results. It was created by the statement
#reciver = reporter() which we saw earlier, and passed as the receiver argument to
#each of the matchers. The reporter waits (is suspended) until a match is sent to it,
#then it prints the match's details, and then it waits again, in an endless loop --
#stopping only if close() is called on it.

#Using coroutines like this may produce performance benefits, but does require us
#to adopt a somewhat different way of thinking about processing.


#Reminder of topics<===========
CHAPTER 8 Advanced Programming Techniques

Further Procedural Programming
    Branching Using Dictionaries
    Generator Expressions and Functions
    Dynamic Code Execution and Dynamic Imports 
        Dynamic Code Execution 
        Dynamically Importing Modules 
    Local and Recusive Functions 
    Function and Method Decorators
    Function Annotations
Further Object-Oriented Programming 
    Controlling Attribute Accesss 
    Functors 
    Context Managers
    Descriptors 
    Class Decorators
    Abstract Base Classes
    Multiple Inheritance
    Metaclasses 
Functional-Style Programming
    Partial Function Application 
    Coroutines
        Performing Independent Actions on Data
        Composing Pipelines 
Example Valid.py 
Summary
Exercises 
#1)
#2)
#3)
#4) 


#CODE LIST
Abstract.py
Appliance.py
Ascii.py
Atomic.py
Const.py
ExternalStorage.py
IndentedList.py
magic-numbers.py
magic-numbers_ans.py
Meta.py (Chapter 6 or 8 or 13)
Property.py
SortedListAbc.py
SortedListDelegate.py
SortedListMeta.py (Chapter 6 or 8 or 13)
SortKey.py
TextFilter.py
Valid.py
XmlShadow.py
find.py 


===============
        Composing Pipelines 
===============

#Sometimes it is useful to create data processing pipelines. A pipeline is simply
#the composition of one or more functions where data items are sent to the first
#function, which then either discards the item (filters it out) or passes it on to
#the next function (either as is or transformed in some way). The second function
#receives the item from the first function and repeats the process, discarding or
#passing on the item (possibly transformed in a different way) to the next function,
#and so on. Items that reach the end are then output in some way.

#Pipelines typically have several components, one that acquires data, one or more
#that filter or transform data, and one that outputs the results. This is exactly
#the functional-style approach to programming that we dicussed earlier in the
#section when we looked at composing some of Python's built-in functions, such
#as filter() and map().

#One benefit of using pipelines is that we can read data items incrementally, 
#often one a time, and have to give the pipeline only enough data items to fill it
#(usually one or a few items per component). This can lead to significant memory
#savings compared with, say, reading an entire data set into memory and then 
#processing it all in one go.

################################################ Figure 8.3
A three step coroutine pipeline processing six items of data

Step    Action                      get_data()      process()       reporter()
-----   ---------                   -------------   -------------   -------------  
1       pipeline = get_data(        Waiting         Waiting         Waiting
            process(reporter()))

2       pipeline.send("a")          Read "a"        Waiting         Waiting
3       pipeline.send("b")          Read "b"        Process "a"     Waiting 
4       pipeline.send("c")          Read "c"        Process "b"     Output "a"
5       pipeline.send("d")          Read "d"        Process "c"     Output "b"
6       pipeline.send("e")          Read "e"        Drop "d"        Output "c"
7       pipeline.send("f")          Read "f"        Process "e"     Waiting
8                                   Waiting         Process "f"     Output "e"
9                                   Waiting         Waiting         Output "f"
10                                  Waiting         Waiting         Waiting
11      Close coroutines            Finished        Finished        Finished
################################################

#Figure 8.3 illustrates a simple three component pipeline. The first component
#of the pipeline (get_data()) acquires each data tiem to be processed in turn.
#The second component (process()) processes the data -- and may drop unwanted
#data items -- there could be any number of other processing/filtering
#components. The last component (reporter()) output results. In the figure,
#items "a", "b", "c", "e" and "f" are processed and produce output, while
#item "d" is dropped.

#The pipeline shown in Figure 8.3 is a filter, since each data item is
#passed through unchanged and is either dropped or output in its original
#form. The end points of pipelines tend to perform the same roles: acquiring
#data items and outputting results. But between these we can have as many
#components as necessary, each filtering or transforming or both. And in some
#cases, composing the components in different orders can produce pipelines that 
#do different things.

#We will start out by looking at a theoretical example to get a better idea of
#how coroutine-based pipelines work, and then we will look at a real example.

#Suppose we have a sequence of floating point numbers and we want to process
#them in a multicomponent pipeline such that we transform each number into an
#integer (by rounding), but drop any numbers that are out of range (<0 or >= 10).
#If we had the four coroutine components
acquire() #(get a number) 
to_int() #(transform a number by rounding and converting to an integer)
check() #(pass on a number that is in range; drop a number that is out of range)
output() #(output a number)
#we could create the pipeline like this:

    pipe = acquire(to_int(check(output())))

#We would then send numbers into the pipeline by calling pipe.send()
#We will look at the progress of the numbers 4.3 and 9.6 as they go through the
#pipeline, using a different visualization from the step-by-step figures used
#earlier.

    pipe.send(4.3) --> acquire(4.3) --> to_int(4.3) --> check(4) --> output(4)
    pipe.send(9.6) --> acquire(9.6) --> to_int(9.6) --> check(10)

#Notice that for 9.6 there is no output. This is b/c the check() coroutine received
#10, which is out of range (>= 10) and so it was filterd out.

#Lets see what would happen if we created a different pipeline, but using the 
#same components:

    pipe = acquire(check(to_int(output())))

#This simply performs the filtering (check()) before the transforming (to_int()).
#Here is how it would work for 4.3 and 9.6:

    pipe.send(4.3) --> acquire(4.3) --> check(4.3) --> to_int(4.3) --> output(4)
    pipe.send(9.6) --> acquire(9.6) --> check(9.6) --> to_int(9.6) --> output(10)
    
#Here we have incorrectly output 10, even though it is out of range. This is b/c
#we applied the check() component first, and since this received an in-range value
#of 9.6, it simply passied it on. But the to_int() component rounds the numbers
#it gets.

#We will noow review a concrete example -- a file matcher that reads all the 
#filenames given on the command line (including those in the directories given
#on the command line, recursively), and that outputs the absolute paths of those
#files that meet certain criteria.

#We will start by looking at how pipeline are composed, and then we will look at the
#coroutines that provide the pipeline components. Here is the simplest pipeline:

    pipeline = get_files(receiver)

#This pipeline prints every file it is given (or all the files in the directory it
#is give, recursively). The get_files() function is a coroutine that yields the 
#filenames and the receiver is a reporter() coroutine -- created by 
receiver = reporter() #that simply prints each filename it receives. This pipeline
#does little more than the os.walk() function (and in fact uses that function), but
#we can use its components to compose more sophisticated pipelines.

    pipleline = get_files(suffix_matcher(receiver, (".htm", ".html")))

#This pipeline is created by composing the get_files() coroutine together with the
suffix_matcher() #coroutine. It prints only HTML files.

#Coroutines composed like this can quickly become difficult to read, but there is 
#nothing to stop us from composing a pipeline in stages -- although for this 
#approach we must create the components in last-to-first order.

    pipeline = size_matcher(receiver, minimum=1024 ** 2)
    pipeline = suffix_matcher(pipleline, (".png", ".jpg", ".jpeg"))
    pipeline = get_files(pipeline)

#This pipeline only matches files that are at least one megabyte in size, and that
#have a suffix indicating that they are images.

#How are these pipelines used? We simply feed them filenames or paths and they
#take care of the rest themselves.

    for arg in sys.argv[1:]:
        pipeline.send(arg)

#Notice that it does NOT matter which pipeline we are using -- it could be the one
#that prints all the files, or the one tha prints HTML files, or the images one --
#they all work in the same way. And in this case, all trhee of the pipelines are
#filters -- any filename they get is either passed on as is to the next component
#(and in the case of the reporter(), printed), or dropped b/c they dont meet the criteria.

#Before looking at the get_files() and match coroutines, we will look at the trival
#reporter() coroutine (passed as receiver) that outputs the results.

    @coroutine
    def reporter():
        while True:
            filename = (yield)
            print(filename)

#We have used the same coroutine decorator that we created in the previous subsubsection.

#The get_files() coroutine is essentially a wrapper around the os.walk() function
#and that expects to be given paths or filenames to work on.

    @coroutine
    def get_files(receiver):
        while True:
            path = (yield)
            if os.path.isfile(path):
                receiver.send(os.path.abspath(path))
            else:
                for root, dirs, files in os.walk(path):
                    for filename in files:
                        receiver.send(os.path.abspath(os.path.join(root, filename)))

#This coroutine has the now-familiar structure: an infinite loop in which we wait for
#the yield to return a value that we can process, and then we send the result to
#the receiver.

    @coroutine
    def suffix_matcher(receiver, suffixes):
        while True:
            filename = (yield)
            if filename.endswith(suffixes):
                receiver.send(filename)

#This coroutine looks simple -- and it is -- but notice that it send ONLY filenames
#that match the suffixes, so any that dont match are filtered out of the pipeline.

    @coroutine
    def size_matcher(receiver, minimum=None, maximum=None):
        while True:
            filename = (yield)
            size = os.path.getsize(filename)
            if ((minimum is None or size <= minimum) and (maximum is None or size <= maximum)):
                receiver.send(filename)

#This coroutine is almost identical to suffix_matcher(), except that it filters out
#files whose size is not in the required range, rather than those which dont have
#a matching suffix.

#The pipeline we have created suffers from a couple of problems. One problem is that we
#never close any of the coroutines. In this case it does NOT matter, since the program
#terminates once the processing is finished, but it is probably better to get into the
#habit of closing coroutines when we are finished with them. Another problem is that 
#potentially we could be asking the operating system (under the hood) for different
#pieces of information about the same file in several parts of the pipeline -- and this
#could be slow. A solution is to modify the get_files() coroutine so that it returns
#(filename, os.stat()) 2-tuples for each file rather than just filenames, and then
#passes these 2-tuples through the pipeline.*
#*Note The os.stat() function takes a filename and returns a named tuple with various
#items of information about the file, including its size, mode, and last modified date/time.
#This would mean that we acquire all the relevant information just once per file. You
#will get the chance to sovle both of these problems, and to add additional functionality,
#in an exercise at the end of the chapter.

#Creating coroutines for use in pipelines requires a certain reorientation of thinking.
#However, it can pay off handsomely in terms of flexibility, and for large data sets
#can help minimize the amount of data held in memory as well as potentially resulting
#in faster throughput.


#Reminder of topics<===========
CHAPTER 8 Advanced Programming Techniques

Further Procedural Programming
    Branching Using Dictionaries
    Generator Expressions and Functions
    Dynamic Code Execution and Dynamic Imports 
        Dynamic Code Execution 
        Dynamically Importing Modules 
    Local and Recusive Functions 
    Function and Method Decorators
    Function Annotations
Further Object-Oriented Programming 
    Controlling Attribute Accesss 
    Functors 
    Context Managers
    Descriptors 
    Class Decorators
    Abstract Base Classes
    Multiple Inheritance
    Metaclasses 
Functional-Style Programming
    Partial Function Application 
    Coroutines
        Performing Independent Actions on Data
        Composing Pipelines 
Example Valid.py 
Summary
Exercises 
#1)
#2)
#3)
#4) 


#CODE LIST
Abstract.py
Appliance.py
Ascii.py
Atomic.py
Const.py
ExternalStorage.py
IndentedList.py
magic-numbers.py
magic-numbers_ans.py
Meta.py (Chapter 6 or 8 or 13)
Property.py
SortedListAbc.py
SortedListDelegate.py
SortedListMeta.py (Chapter 6 or 8 or 13)
SortKey.py
TextFilter.py
Valid.py
XmlShadow.py
find.py 


===============
Example Valid.py 
===============

#In this section, we combine descriptors with class decorators to create a powerful
#mechanism for creating validated attributes.

#Up to now, if we wanted to ensure that an attribute was set to only a valid value,
#we have relied on properites (or used getter and setter methods). The disadvantage
#of such approaches is that we must add validating code for every attribute in 
#every class that needs it. What would be much more convenient and easier to maintain,
#is if we could add attributes to classes with the necessary validation built in. Here
#is an example of the syntax we would like to use:

    @valid_string("name", empty_allowed=False)
    @vaild_string("productid", empty_allowed=False, regex=re.compile(r"[A-Z]{3}\d{4}"))
    @valid_string("category", empty_allowed=False, 
        acceptable=frozenset(["Consumables", "Hardware", "Software", "Media"]))
    @valid_number("price", minimum=0, maximum=1000)
    @valid_number("quantity", minimum=1, maximum=1000)
    class StockItem:

            def __init__(self, name, productid, category, price, quantity):
                self.name = name 
                self.productid = productid
                self.category = category
                self.price = price 
                self.quantity = quantity
#the StockItem class's attributes are all validated. For example, the productid
#attribute can be set only to a nonempty string that starts with three uppercase
#letters and ends with four digits, the category attribute can be set only to a 
#nonempty string that is one of the specified values, and the quantity attribute
#can be set only to a number between 1 and 1000 inclusive. If we try to set an 
#invalid value, then an exception is raised.

#The validation is achieved by combining class decorators with descriptors. As we
#noted earlier, class decorators can take only a single argument -- the class they
#are to decorate. So here we have used the technique shown when we first discussed
#class decorators, and have the valid_string() and valid_number() functions take
#whatever arguments we want, and then return a decorator, which in turn takes the
#class and returns a modified version of the class.

#Lets now look at the valid_string() function:

    def valid_string(attr_name, empty_allowed=True, regex=None, acceptable=None):
        def decorator(cls):
            name = "__" + attr_name
            def getter(self):
                return getattr(self, name)
            def setter(self, value):
                assert isinstance(value, str), (attr_name + " must be a string")
                if not empty_allowed and not value:
                    raise ValueError("{0} may not be empty".format(attr_name))
                if ((acceptable is not None and value not in acceptable) or
                    (regex is not None and not regex.match(value))):
                    raise ValueError("{attr_name} cannot be set to {value}".format(**locals()))
                setattr(self, name, value)
            setattr(cls, attr_name, GenericDescriptor(getter, setter))
            return cls
        return decorator
#This function starts by creating a class decorator function which takes a class as
#its sole argument. The decorator adds two attributes to the class it decorates: a
#private data attribute and a descriptor. For example, when the valid_string() function
#is called with the name "productid", the StockItem class gains the attribute __productid
#which holds the product ID's value, and the descriptor productid attribute which is used
#to access the value. For example, if we create an item using 
item = StockItem("TV", "TVA4312", "Electrical", 500, 1)
#we can get the product ID using 
item.productid #and set it useing, for example,
item.productid = "TVB2100"

#The getter function created by the decorator simply uses the global getattr() function
#to return the value of the private data attribute. The setter function incorporates the
#calidation, and at the end, uses setattr() to set the private data attribute to the new
#(and valid) value. In fact, the private data attribute is only created the first time 
#it is set.

#Once the getter and setter functions have been created we use setattr() once again, 
#this time to create a new class attribute with the given name (eg productid), and with
#its value set to be a descriptor of type GenericDescriptor. At the end, the decorator
#function returns the modified class, and the valid_string() function returns the
#decorator function.

#The valid_number() function is structurally identical to te valid_string() function,
#only differing in the arguments it accepts and in the validation code in the setter,
#so we wont show it here. (The complete source code is in the Valid.py module.)

#The last thing we need to cover is the GenericDescriptor, and that turns out to be
#the easiest part:

    class GenericDescriptor:

        def __init__(self, getter, setter):
            self.getter = getter
            self.setter = setter

        def __get__(self, instance, owner=None):
            if instance is None:
                return self
            return self.getter(instance)

        def __set__(self, instance, value):
            return self.setter(instance, value)

#The descriptor is used to hold the getter and setter functions for each attribute
#and simply passes on the work of getting and setting to those functions.

#CODE HERE
Valid.py

#!/usr/bin/env python3

"""
>>> @valid_string("name", empty_allowed=False)
... @valid_string("productid", empty_allowed=False,
...               regex=re.compile(r"[A-Z]{3}\d{4}"))
... @valid_string("category", empty_allowed=False, acceptable=
...         frozenset(["Consumables", "Hardware", "Software", "Media"]))
... @valid_number("price", minimum=0, maximum=1e6)
... @valid_number("quantity", minimum=1, maximum=1000)
... class StockItem:
... 
...     def __init__(self, name, productid, category, price, quantity):
...         self.name = name
...         self.productid = productid
...         self.category = category
...         self.price = price
...         self.quantity = quantity
... 
...     @property
...     def value(self):
...         return self.price * self.quantity
>>> 
>>> pc = StockItem("Computer", "EAA5000", "Hardware", 599, 3)
>>> pc.name == "Computer" and pc.category == "Hardware"
True
>>> pc.productid == "EAA5000"
True
>>> pc.price == 599 and pc.quantity == 3 and pc.value == 1797
True
>>> error = None
>>> try:
...     StockItem("", "ABC1000", "Software", 129, 2)
... except ValueError as e:
...     error = str(e)
>>> error == "name may not be empty"
True
>>> try:
...     StockItem("Printer", "KXV5500", "Vaporware", 129, 2)
... except ValueError as e:
...     error = str(e)
>>> error == "category cannot be set to Vaporware"
True
>>> try:
...     StockItem("Cable", "KXB5001", "Media", -12, 2)
... except ValueError as e:
...     error = str(e)
>>> error == "price -12 is too small"
True
>>> try:
...     StockItem("Socket", "KXY520", "Media", 1e7, 2)
... except ValueError as e:
...     error = str(e)
>>> error == "productid cannot be set to KXY520"
True
>>> try:
...     StockItem("Socket", "KXY5020", "Media", 1e7, 2)
... except ValueError as e:
...     error = str(e)
>>> error == "price 10000000.0 is too big"
True
>>> try:
...     StockItem("Paper", "KXJ5003", "Media", 10, 0)
... except ValueError as e:
...     error = str(e)
>>> error == "quantity 0 is too small"
True
>>> try:
...     StockItem("Ink", "AKX5005", "Media", 10, 1001)
... except ValueError as e:
...     error = str(e)
>>> error == "quantity 1001 is too big"
True
>>> item = StockItem("Toner", "KXV5500", "Media", 10, 100)
>>> item.quantity += 5
>>> item.quantity == 105 and item.value == 1050
True
>>> try:
...     item.quantity = "one"
... except AssertionError as e:
...     error = str(e)
>>> error == "quantity must be a number"
True
"""

import numbers
import re

class GenericDescriptor:

    def __init__(self, getter, setter):
        self.getter = getter
        self.setter = setter

    def __get__(self, instance, owner=None):
        if instance is None:
            return self
        return self.getter(instance)

    def __set__(self,instance, value):
        return self.setter(instance, value)

def valid_string(attr_name, empty_allowed=True, regex=None, acceptable=None):

    def decorator(cls):
        name = "__" + attr_name
        def getter(self):
            return getattr(self, name)
        def setter(self, value):
            assert isinstance(value, str), (attr_name + " must be a string")
            if not empty_allowed and not value:
                raise ValueError("{0} may not be empty".format(attr_name))
            if ((acceptable is not None and value not in acceptable) or
                (regex is not None and not regex.match(value))):
                raise ValueError("{attr_name} cannot be set to {value}".format(**locals()))
            setattr(self, name, value)
        setattr(cls, attr_name, GenericDescriptor(getter, setter))
        return cls
    return decorator

def valid_number(attr_name, minimum=None, maximum=None, acceptable=None):
    def decorator(cls):
        name = "__" + attr_name
        def getter(self):
            return getattr(self, name)
        def setter(self, value):
            assert isinstance(value, numbers.Nunber), (attr_name + " must be a number")
            if minimum is not None and value < minimum:
                raise ValueError("{attr_name} {value} is too small".format(**locals()))
            if maximum is not None and value > maximum:
                raise ValueError("{attr_name} {value} is too big".format(**locals))
            if acceptable is not None and value not in acceptable:
                raise ValueError("{attr_name} {value} is unaccetable".format(**locals))
            setattr(self, name, value)
        setattr(cls, attr_name, GenericDescriptor(getter, setter))
        return cls
    return decorator

if __name__ == "__main__":
    import doctest
    doctest.testmod()






#Reminder of topics<===========
CHAPTER 8 Advanced Programming Techniques

Further Procedural Programming
    Branching Using Dictionaries
    Generator Expressions and Functions
    Dynamic Code Execution and Dynamic Imports 
        Dynamic Code Execution 
        Dynamically Importing Modules 
    Local and Recusive Functions 
    Function and Method Decorators
    Function Annotations
Further Object-Oriented Programming 
    Controlling Attribute Accesss 
    Functors 
    Context Managers
    Descriptors 
    Class Decorators
    Abstract Base Classes
    Multiple Inheritance
    Metaclasses 
Functional-Style Programming
    Partial Function Application 
    Coroutines
        Performing Independent Actions on Data
        Composing Pipelines 
Example Valid.py 
Summary
Exercises 
#1)
#2)
#3)
#4) 


#CODE LIST
Abstract.py
Appliance.py
Ascii.py
Atomic.py
Const.py
ExternalStorage.py
IndentedList.py
magic-numbers.py
magic-numbers_ans.py
Meta.py (Chapter 6 or 8 or 13)
Property.py
SortedListAbc.py
SortedListDelegate.py
SortedListMeta.py (Chapter 6 or 8 or 13)
SortKey.py
TextFilter.py
Valid.py
XmlShadow.py
find.py 


===============
Summary
===============
#In this chapter, we learnded a lot more about Python's supposrt for procedural
#and OOP, and got a taste of Python's support for functional style programming.

#In the first section, we learned how to create generator expressions, and covered
#generator functions in more depth. We also learned how to dynamically import
#modules and how to access functionality from such modules, as well as how to 
#dynamically excute code. In this section, we saw examples of how to create
#and use recursive functions and nonlocal variables. We also learned how to use
#create custom function and method decorators, and how to write and make use of
#function annotations.

#In the second section, we studied a variety of different and more advanced aspects
#of OOP. First, we learned more about attribute access, for example, using the
#__getattr__() special method. Then we learned about functors and saw how we could
#use them to provide functions with state -- something that can also be achieved by
#adding properties to functions or using closuers, both covered in this chapter. We
#learned how to use the with statement with context managers and how to create
#custom context managers. Since Python's file objects are also context mangaers, from
#now on we will do our file handling using try with...except structures which ensures
#that opened files are closed without the need for finally blocks.

#The second section continued with coverage of more advanced object-oriented features
#starting with descriptors. These can be used in a wide variety of ways and are the
#technology that underlies many of Python's standard decorators such as @property and
#@classmethod. We learned how to create custom descriptors and saw how we could modify
#a class in much the same way that a function decorator can modify a function.

#In the last three subsections of the second section, we learned about Python's support
#for ABCs (abstract base classes), multiple inheritance, and metaclasses. We learned
#how to make our onw classes fit in with Python's standard ABCs and how to create 
#our own ABCs. We also saw how to use multiple inheritance to unify the features
#of different classes together in a single class. And from the coverage of metaclasses
#we learned how to intervene when a class (as opposed to an instance of a class) is
#created and initialized.

#The penultimate section introduced some of the functions and modules that Python
#provides to support functional style programming. We learned how to use the common
#functional idoms of mapping, filtering, and reducing. We also learned how to create
#partial functions and how to create and use coroutines. And the last secion showed
#how to combine class decorators with descriptors to provide a powerfil and flexible
#mechanism for creating validating attributes.

#This chapter completes our coverage of the Python language iteself. Not every
#feature of the language has been covered here and in the previous chapters, but
#those that have not are obscure and rarely used. None of the subsequent chapters
#introduces new language features, although all of them make use of modules from
#the standard library that have not been covered before, and some of them take the
#techniques shows in this and earlier chapters further than we have seen so far.
#Furthermore, the programs shown in the following chapters have none of the
#constraints that have applied previously (ie to only use aspects of the language that
#had been covered up to the point they were introduced), so they are the book's most
#idiomatic examples.



#Reminder of topics<===========
CHAPTER 8 Advanced Programming Techniques

Further Procedural Programming
    Branching Using Dictionaries
    Generator Expressions and Functions
    Dynamic Code Execution and Dynamic Imports 
        Dynamic Code Execution 
        Dynamically Importing Modules 
    Local and Recusive Functions 
    Function and Method Decorators
    Function Annotations
Further Object-Oriented Programming 
    Controlling Attribute Accesss 
    Functors 
    Context Managers
    Descriptors 
    Class Decorators
    Abstract Base Classes
    Multiple Inheritance
    Metaclasses 
Functional-Style Programming
    Partial Function Application 
    Coroutines
        Performing Independent Actions on Data
        Composing Pipelines 
Example Valid.py 
Summary
Exercises 
#1)
#2)
#3)
#4) 

#CODE LIST
Abstract.py
Appliance.py
Ascii.py
Atomic.py
Const.py
ExternalStorage.py
IndentedList.py
magic-numbers.py
magic-numbers_ans.py
Meta.py (Chapter 6 or 8 or 13)
Property.py
SortedListAbc.py
SortedListDelegate.py
SortedListMeta.py (Chapter 6 or 8 or 13)
SortKey.py
TextFilter.py
Valid.py
XmlShadow.py
find.py 


===============
Exercises 
===============
#None of the first three exercises described here requires writing a lot of code. The
#4th one does. None of them are easy.

#CODE HERE
magic-numbers.py

import os
import sys
if sys.platform.startswith("win"):
    import glob

USE_SIMPLE_GET_FUNCTION = True

def main():
    modules = load_modules()
    get_file_type_functions = []
    for module in modules:
        get_file_type = get_function(module, "get_file_type")
        if get_file_type in not None:
            get_file_type_functions.append(get_file_type)

    for file in get_files(sys.argv[1:]):
        fh = None
        try:
            fh = open(file, "rb")
            magic = fh.read(1000)
            for get_file_type in get_file_type_functions:
                filetype = get_file_type(magic, os.path.splitext(file)[1])
                if filetype is not None:
                    print("{0:.<20}{1}".format(filetype, file))
                    break
            else:
                print("{0..<20}{1}".format("Unknown", file))
        except EnvironmentError as err:
            print(err)
        finally:
            if fh is not None:
                fh.close()

if sys.platform.startswith("win"):
    def get_file(names):
        for name in names:
            if os.path.isfile(name):
                yield name 
            else:
                for file in glob.iglob(name):
                    if not os.path.isfile(file):
                        continue
                    yield file
else: 
    def get_files(names):
        return (file for file in names if os.path.isfile(file))

if USE_SIMPLE_GET_FUNCTION:
    def get_function(module, function_name):
        function = get_function.cache.get((module, function_name), None)
        if function is None:
            try:
                function = getattr(module, function_name)
                if not hasattr(function, "__call__"):
                    raise AttributeError()
                get_function.cache[module, function_name] = function
            except AttributeError:
                function = None
        return function
    get_function.cache = {}
else:
    def get_function(module, function_name):
        function = get_function.cache.get((module, function_name), None)
        if (function is None and (module, function_name) not in get_function.bad_cache):
            try:
                function = getattr(module, function_name)
                if not hasattr(function, "__call__"):
                    raise AttributeError()
                get_function.cache[module, function_name] = function
            except AttributeError:
                function = None
                get_function.bad_cache.add((module, function_name))
        return function 
    get_function.cache = {}
    get_function.bad_cache = set()

if len(sys.argv) == 1 or sys.argv[1] in {"-h", "--help"}:
    print("usage: {0} [-1|-2] file1 [file2 [... fileN]]".format(os.path.basename(sys.argv[0])))
    sys.exit(2)
if sys.argv[1] == "-1":
    del sys.argv[1]

    #Version 1
    def load_modules():
        modules = []
        for name in os.listdir(os.path.dirname(__file__) or "."):
            if name.endswith(".py") and "magic" in name.lower():
                name = os.path.splitext(name)[0]
                if name.isidentifier() and name not in sys.modules:
                    try:
                        exec("import " + name)
                        modules.append(sys.modules[name])
                    except SyntaxError as err:
                        print(err)
        return modules
elif sys.argv[1] == "-2":
    del sys.argv[1]

    #Version 2
    def load_modules():
        modules = []
        for name in os.listdir(os.path.dirname(__file__) or "."):
            if name.endswith(".py") and "magic" in name.lower():
                filename = name
                name = os.path.splitext(name)[0]
                if name.isidentifier() and name not in sys.modules:
                    fh = None
                    try:
                        fh = open(filename, "r", encoding="utf8")
                        code = fh.read()
                        module = type(sys)(name)
                        sys.modules[name] = module 
                        exec(code, module.__dict__)
                        modules.append(modules)
                    except (EnvironmentError, SyntaxError) as err:
                        sys.modules.pop(name, None)
                        print(err)
                    finally:
                        if fh is not None:
                            fh.close()
        return modules

else:

    #Version 3
    def load_modules():
        modules = []
        for name in os.listdir(os.path.dirname(__file__) or "."):
            if name.endswith(".py") and "magic" in name.lower():
                name = os.path.splitext(name)[0]
                if name.isidentifier() and name not in sys.modules:
                    try:
                        module = __import__(name)
                        modules.append(modules)
                    except (ImportError, SyntaxError) as err:
                        print(err)
        return modules

main()




#1) Copy the magic-numbers.py program and delete its get_function() functions, and
#all but one of its load_modules() functions. Add a GetFunction functor class that has
#two caches, one to hold functions that have been found and one to hold functions that
#could not be found (to avoid repeatedly looking for a function in a module that does
#not have the function). The only modifications to main() are to add
get_function = GetFunction() #before the loop, and to use a with statement to avoid the
#need for a finally block. Also, check that the module functions are callable using
collections.Callable #rather than using
hasattr()
#The class can be written in about 20 lines. Solution is in magic-numbers_ans.py



#CODE HERE
magic-numbers_ans.py

import collections
import os
import sys
if sys.platform.startswith("win"):
    import glob

class GetFunction:

    def __init__(self):
        self.cache = {}
        self.not_found_cache = set()

    def __call__(self, module, function_name):
        function = self.cache.get((module, function_name), None)
        if (function is None and (module, function_name) not in self.not_found_cache):
            try:
                function = getattr(module, function_name)
                if not isinstance(function, collections.Callable):
                    raise AttributeError()
                self.cache[module, function_name] = function
            except AttributeError:
                function = None
                self.not_found_cache.add((module, function_name))
        return function

def main():
    modules = load_modules()
    get_function = GetFunction()
    get_file_type_functions = []
    for module in modules:
        get_file_type = get_function(module, "get_file_type")
        if get_file_type is not None:
            get_file_type_functions.append(get_file_type)
    for file in get_files(sys.argv[1:]):
        try:
            with open(file, "rb") as fh:
                magic = fh.read(1000)
                for get_file_type in get_file_type_functions:
                    filetype = get_file_type(magic, os.path.splitext(file)[1])
                    if filetype is not None:
                        print("{0:.<20}{1}".format(filetype, file))
                        break
                else:
                    print("{0:.<20}{1}".format("Unknown", file))
            except EnvironmentError as err:
                print(err)

if sys.platform.startswith("win"):
    def get_files(names):
        for name in names:
            if os.path.isfile(name):
                yield name
            else:
                for file in glob.iglob(name):
                    if not os.path.isfile(file):
                        continue
                    yield file 
else:
    def get_files(names):
        return (file for file in names if os.path.isfile(file))

def load_modules():
    modules = []
    for name in os.listdir(os.path.dirname(__file__) or "."):
        if name.endswith(".py") and "magic" in name.lower():
            name = os.path.splitext(name)[0]
            if name.isidentifier() and name not in sys.modules:
                try:
                    module = __import__(name)
                    modules.append(mdule)
                except (ImportError, SyntaxError) as err:
                    print(err)
    return modules

if len(sys.argv) == 1 or sys.argv[1] in {"-h", "--help"}:
    print("usage: {0} file1 [file2 [... fileN]]".format(os.path.basename(sys.argv[0]
    sys.exit(2)

main()


#2) Create a new module file and in it define three functions:
is_ascii() #that returns True if all the characters in the given string have code
#points less than 127;
is_ascii_punctation() #that return True if all the characters are in the
string.punctuation #string; and
is_ascii_printable() #that returns True if all the characters are in the 
string.printable #string. The last two are structurally the same. Each function should
#be created using lambda and can be done in one or two lines using functional-style code.
#Be sure to add a docstring for each one with doctests and to make the module run the 
#doctests. The functions require only three to five lines for all three of them, with
#the whole module fewer than 25 lines including doctests. Solution is in Ascii.py



#CODE HERE
Ascii.py

#!/usr/bin/env python3

import string

is_ascii = lambda s: not any(map(lambda c: ord(c) >= 127, s))
is_ascii.__doc__ = """\
    >>> is_ascii("Universal suffrage")
    True
    >>> is_ascii("Cinema verite")
    False
    """

is_ascii_punctation = (lambda s: not any(map(lambda c: c not in string.punctuation, s)))
is_ascii_punctuation.__doc__ = """\
    >>> is_ascii_punctuation("No way!")
    False
    >>> is_ascii_punctuation("@!?*")
    True
    """

is_ascii_printable = (lambda s: not any(map(lambda c: c not in string.printable, s)))
is_ascii_printable.__doc__="""\
    >>> is_ascii_printable("No way!")
    True
    >>> is_ascii_printable("@!?*\\t\\n")
    True
    >>> is_ascii_printable("@!?*\\t\\x05\\n")
    False 
    >>> is_ascii_printable("Cinema verite")
    False
    """

if __name__ == "__main__":
    import doctest
    doctest.testmod()



#3) Create a new module file and in it define the Atomic context manager class. This
#class should work like the AtomicList class shown in this chapter, except that
#instead of working only with lists, it should work with any mutable collection type. 
#The __init__() method should check the suitability of the container, and instead
#of storing a shallow/deep copy flag, it should assign a suitable function to the
shelf.copy #attribute depending on the flag and call the copy function in the 
#__enter__() method. The __exit__() method is silghtly more involved b/c replacing
#the contents of lists is different than for sets and dictionaries -- and we can NOT 
#use assignment b/c that would not affect the original container. The class itself
#can be written in about 30 lines, although you should also include doctests. Solution
#is given in Atomic.py which is about 150 lines including doctests.

#CODE HERE
Atomic.py
#!/usr/bin/env python3

"""
Atomic is a context manager for mutable collections.

Atomic ensures that either all the changes are applied or none of them are
(i.e., in the face of an exception occurring). Atomic makes a private copy
of the collection (a deep copy if deep_copy is set True), so could be
expensive for large collections.

>>> items = list(range(10))
>>> try:
...     with Atomic(items) as atomic:
...         atomic.append(1999)
...         del atomic[3]
...         atomic[8] = -999
... except (AttributeError, IndexError, ValueError) as err:
...    pass
>>> items
[0, 1, 2, 4, 5, 6, 7, 8, -999, 1999]

>>> items = list(range(10))
>>> try:
...     with Atomic(items) as atomic:
...         atomic.append(10)
...         del atomic[3]
...         atomic[8] = -99
...         atomic.poop() # force failure
... except (AttributeError, IndexError, ValueError) as err:
...    pass
>>> items
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]

>>> index = 19
>>> items = list(range(10))
>>> try:
...     with Atomic(items) as atomic:
...         atomic.append(58289)
...         del atomic[3]
...         atomic[8] = 81738
...         atomic[index] = 38172
... except (AttributeError, IndexError, ValueError) as err:
...    pass
>>> items
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]

>>> items = set(range(10))
>>> try:
...     with Atomic(items) as atomic:
...         atomic.add(1999)
...         atomic.discard(3)
...         atomic |= {-999}
... except (AttributeError, IndexError, ValueError) as err:
...    pass
>>> list(sorted(items)), type(items) == type(set())
([-999, 0, 1, 2, 4, 5, 6, 7, 8, 9, 1999], True)

>>> items = set(range(10))
>>> try:
...     with Atomic(items) as atomic:
...         atomic.append(10)
...         atomic.discard(3)
...         atomic |= {-99}
...         atomic.poop() # force failure
... except (AttributeError, IndexError, ValueError) as err:
...    pass
>>> list(sorted(items)), type(items) == type(set())
([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], True)

>>> items = {chr(x): x for x in range(ord("A"), ord("E"))}
>>> try:
...     with Atomic(items) as atomic:
...         atomic["E"] = ord("E")
...         del atomic["B"]
... except (AttributeError, IndexError, ValueError) as err:
...    pass
>>> list(sorted(items.items())), type(items) == type({})
([('A', 65), ('C', 67), ('D', 68), ('E', 69)], True)

>>> items = {chr(x): x for x in range(ord("A"), ord("E"))}
>>> try:
...     with Atomic(items) as atomic:
...         atomic["E"] = ord("E")
...         del atomic["B"]
...         atomic.poop() # force failure
... except (AttributeError, IndexError, ValueError) as err:
...    pass
>>> list(sorted(items.items())), type(items) == type({})
([('A', 65), ('B', 66), ('C', 67), ('D', 68)], True)

>>> import abc
>>> import collections
>>> class A:
...     pass
>>> collections.MutableSet.register(A) # This class is lying about its API
>>> a = A()
>>> with Atomic(a) as atomic:
...     a.add(1)
Traceback (most recent call last):
...
AssertionError: Atomic mappings/sets must provide clear() and update()

>>> items = frozenset({1, 2, 3})
>>> with Atomic(items) as atomic:
...     a.add(1)
Traceback (most recent call last):
...
AssertionError: Atomic requires a mutable collection
"""

import collections
import copy

class Atomic:

    def __init__(self, container, deep_copy=False):
        assert isinstance(container, (collections.MutableSequence, collections.MutableSet,
            collections.MutableMapping)), ("Atomic requires a mutable collection")
        #if __debug__ ensure this is not executed when optimized with -O
        if __debug__ and isinstance(container, (collecitons.MutableSet, collections.MutableMapping)):
            assert (hasattr(container, "clear") and hasattr(container, "update")), ("Atomic mappings/sets must provide clear() and update()")
        self.original = container
        self.copy = copy.deepcopy if deep_copy else copy.copy

    def __enter__(self):
        self.modified = self.copy(self.original)
        return self.modified

    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type is None:
            if isinstance(self.original, collections.MutableSequence):
                self.origial[:] = self.modified
            elif isinstance(self.original, (collections.MutableSet, collections.MutableMapping)):
                self.original.clear()
                self.original.update(self.modified)

if __name__ == "__main__":
    import doctest
    doctest.testmod()




#4) Create a program that finds files based on specifid criteria (rather like the
#Unix find program.) The usage should be 
find.py options files_or_paths
#All the options are optional, and without them all the files listed on the command
#line and all the files in the directories listed on the command line (and in their
#directories, recursively) should be listed. The options should restrict which files
#are output as follows:
-d or --days integer #discards any files older than the specified number of days
-b or --bigger integer #discards any files smaller than the specified number of bytes
-s or --smaller integer #discards any files bigger than the specified number of bytes
-o or --output what #where what is the "date", "size", or "data,size" (either way
#around) specifies what should be output -- filenames should always be output
-u or --suffix #discards any files that dont have a matching suffix. (Multiple suffixes
#can be given if comma-separated.) For both the bigger and smaller options, if the 
#integer is followed by "k" it should be treated as kilobytes and multiplied by 1024,
#and similarly if followed by "m" treated as megabytes and multiplied by 1024^2.

#For example, 
find.py -d1 -o date,size *.*    #will find all files modified today (strictly, the past
#24 hours), and output their name, date, and size. Similarly,
find.py -b1m -u png,jpg,jpeg -o size *.*    #will find all image files bigger than one
#megabyte and output their names and sizes.

#Implement the program's logic by creating a pipeline using coroutines to provide
#matchers, similar to what we saw in the coroutines subsection, only this time
#pass (filename, os.stat()) 2-tuples for each file rather than just filenames. Also,
#try to close all the pipeline components at the end. In the solution provided, the
#biggest single function is the one tht handles the command-line options. The rest
#is fairly straightforward, but not trival. The find.py solution is around 170 lines.



#CODE HERE
find.py

#!/usr/bin/env python3


import datetime
import functools
import optparse
import os
import sys
import time

def coroutine(function):
    @functools.wraps(function)
    def wrapper(*args, **kwargs):
        generator = function(*args, **kwargs)
        next(generator)
        return generator
    return wrapper

@coroutine
def suffix_matcher(receiver, suffixes):
    while True:
        filename, stat = (yield)
        if filename.endswith(suffixes):
            receiver.send((filename, stat))

@coroutine 
def size_matcher(receiver, minimum=None, maximum=None):
    while True:
        filename, stat = (yield)
        if ((minimum is None or stat.st_size >= minimum) and
            (maximum is None or stat.st_size <= maximum)):
            receiver.send((filename, stat))

@coroutine
def date_matcher(receiver, when):
    while True:
        filename, stat = (yield)
        if stat.st_mtime >= when:
            receiver.send((filename, stat))

@coroutine
def get_files(receiver):
    while True:
        path = (yield)
        if os.path.isfile(path):
            filename = os.path.abspath(os.path.join(root, filename))
            receiver.send((filename, os.stat(filename)))
        else:
            for root, dirs, files in os.walk(path):
                for filename in files:
                    filename = os.path.abspath(os.path.join(root, filename))
                    receiver.send((filename, os.stat(filename)))

@coroutine 
def reporter(output):
    size_format = "{0:12,}" is sys.version_info[1] > 0 else "{0:11}"
    while True:
        filename, stat (yield)
        result = []
        if output is not None:
            if "date" in output:
                result.append(datetime.datetime.fromtimestamp(stat.st_mtime).isoformat(" "))
            if "size" in output:
                result.append(size_format.format(stat.st_size))
        result.append(filename)
        print(" ".join(result))

def get_bytes(s):
    if s[-1] in "kKmM":
        factor = 1024 if s[-1] in "kK" else (1024 ** 2)
        return int(s[:1]) * factor 
    else:
        return int(s)

def parse_options():
    parser = optparse.OptionParser(usage="""\

usage: %prog [options] files_or_paths

Recursively lists all the files that match the given options; or all the fileif no
options are specified.

For --bigger and --smaller the size can be given as the number of bytes (no suffix
required), or kilosbytes (with a suffix of 'k'), or megabytes (with a suffix of 'm').

Examples:
    find.py -d1 -o date,size *.*
Find all files modified today and output their name, size, and date.
    find.py -b1m -s10m -d30 -o size *.*
Find all files bigger than 1MB and smaller than 10MB modified in the
past 30 days and output their name and size.""")

    parser.add_option("-d", "--days", dest="days", type="int", 
        help=("only find files updated within the past given number of days [defaul: anytime]"))
    parser.add_option("-b", "--bigger", dest="bigger", 
        help=("only find files bigger and the given amount [default: any size]"))
    parser.add_option("-s", "--smaller", dest="smaller", 
        help=("only find files smaller than the given amount [default: any size]"))
    parser.add_option("-u", "--suffix", dest="suffix", 
        help=("only find files that have the given suffix (or suffixes if a comma-separated list "
            "is given [default: any suffix]"))
    parser.add_option("-o", "--output", dest="output", 
        help=("in addition to the filename also output 'date' or 'size' or both if "
            "specified comma-separated [default: nothing else]"))
    opts, args = parser.parse_args()

    if len(args) == 0:
        parser.error("no files or paths have been specified")
    if opts.smaller is not None:
        opts.smaller = get_bytes(opts.smaller)
    if opts.bigger is not None:
        opts.bigger = get_bytes(opts.bigger)

    if (opts.smaller is not None and opts.bigger is not None and opts.bigger > opts.smaller):
        parser.error("cannot find files bigger than {0} that are also smaller than {1}".format(
            opts.bigger, opts.smaller))
    if ops.suffix is not None:
        if "," in opts.suffix:
            opts.suffix = tuple(opts.suffix.split(","))
    if opts.days is not None:
        delta = datetime.timedelta(days=opts.days)
        days = datetime.datetime.today() - delta
        opts.days = time.mktime(days.timetuple())
    returns opts, args

def main():
    opts, paths = parse_options()
    pipes = []
    pipes.append(reporter(opts.output))
    if opts.bigger is not None or opts.smaller is not None:
        pipes.append(size_matcher(pipes[-1], minimum=opts.bigger, maximum=opts.smaller))
    if opts.suffix is not None:
        pipes.append(date_matcher(pipes[-1], opts.days))
    pipes.append(get_files(pipes[-1]))
    pipeline = pipes[-1]
    try:
        for path in paths:
            pipeline.send(path)
    finally:
        for pipe in pipes:
            pipe.close()


main()








#Reminder of topics<===========
===============================================================================================
CHAPTER: 9 Debugging, Testing, and Profiling 
CHAPTER BEGIN
===============================================================================================
#see Chapter 12 on webpage code listing

Debugging 
    Dealing with Syntax Errors 
    Dealing with Runtime Errors 
    Scientific Debugging
Unit Testing 
Profiling 
Summary


#CODE LIST
blocks.py
Atomic.py
test_Modules.py 


===============
CHAPTER 9 Debugging, Testing, and Profiling 
===============

#Writing programs is a mixture of art, craft, and science, and b/c it is done
#by humans, mistakes are made. Foretunately, there are techniques we can use
#to help avoid problems in the first place, and techniques for identifying
#and fixing mistakes when they become apparent.

#Mistakes fall into several categories. The quickest to reveal themselves and
#the easiest to fix are syntax errors since these are usually due to typos. More
#challenging are logical errors -- with these, the program runs, but some aspect
#of its behavior is not what we intended or expected. Many errors of this kind
#can be prevented from happening by using TDD (Test Driven Developement), where
#when we want to add a new feature, we begin by writing a test for the feature --
#which will fail since we have not added the feature yet -- and then implement
#the feature itself. Another mistake is to create a program that has needlessly
#poor performance. This is almost always due to a poor choice of algorithm or
#data structure or both. However, before attempting any optimiziation we should
#start by finding out exactly where the performance bottleneck lies -- since it
#might not be where we expect -- and then we should carefully decide what
#optimiztion we want to do, rather then working at random.

#In this chapter's first section, we look at Python's tracebacks to see how to
#spot and fix syntax errors and how to deal with unhandled exceptions. Then we
#will see how to apply the scientific method to debugging to make finding errors
#as fast and painless as possible. We will also look at Python's debugging support.
#In the second section we look at Python's support for writing unit tests, and in
#particular the doctest module we saw earlier (Chapter 5 and 6), and unittest
#module. We will see how to use these modules to support TDD. In the chapter's
#final section we will briefly look at profiling, to identify performance hot
#spots so that we can properly target our optimization efforts.


#Reminder of topics<===========
CHAPTER 9 Debugging, Testing, and Profiling 

Debugging 
    Dealing with Syntax Errors 
    Dealing with Runtime Errors 
    Scientific Debugging
Unit Testing 
Profiling 
Summary


#CODE LIST
blocks.py
Atomic.py
test_Modules.py 


===============
Debugging 
===============

#In this section, we will begin by looking at what Python does when there is a
#syntax error, then at the tracebacks that Pyhon produces when unhandled
#exceptions occur, and then we see how to apply the scientific method to
#debugging. But before all that, we will briefly discuss backups and version
#control.

#When editing a program to fix a bug there is always the risk that we end up
#iwth a program that has the original bug plus new bugs, that is, it is even
#worse than it was when we started. And if we have no backups (or we have but
#they are several changes out of date), and we dont use version control, it
#could be very hard to even get back to to where we just had the original bug.

#Making regular backups is an essential part of programming -- no matter how
#reliable our machine and operating system are and how rare failures are --
#since failures still occur. But backups tend to be coarse-grained, with files
#hours or even days old.

#Version control systems allow us to incrementally save changes at whatever level
#of granularity we want -- every single change, or every set of related changes, or
#simply every so many minutes worth of work. Version control systems allow us to
#apply changes (eg to experience with bugfixes), and if they dont work out, we
#can revert the changes back to the last "good" version of the code. So before
#starting to debug, it is always best to check our code into the version 
#control system so that we have a known position that we can revert to if we
#get into a mess.

#There are many good cross-platform open source version control systems available
#this book uses Bazaar (bazaar-vcs.org) but other popular ones include:
#Mercurial (mercurial.selenic.com), Git (git-scm.com), and Subversion
#(suversion.tigris.org). Incidentally, both Bazaar and Mercurial are mostly
#written in Python. None of these systems is hard to use (as least for the
#basics), but using ay of them will help avoid a lot of unnecessary pain.


#Reminder of topics<===========
CHAPTER 9 Debugging, Testing, and Profiling 

Debugging 
    Dealing with Syntax Errors 
    Dealing with Runtime Errors 
    Scientific Debugging
Unit Testing 
Profiling 
Summary


#CODE LIST
blocks.py
Atomic.py
test_Modules.py 



===============
    Dealing with Syntax Errors 
===============
#If we try to run a program that has a syntax error, Python will stop
#execution and print the filename, line number, and offending line, with a
#caret (^) underneath indicating exactly where the error was detected. Here is
#an example of the printout by Python:

    File "blocks.py", line 383
        if BlockOutput.save_blocks_as_svg(blocks, svg)
                                                     ^

    SyntaxError: invalid syntax

#Did you see the error? We forgot to put a color at the end of the if
#statement's condition.

#Here is an example that comes up quite often, but where the problem isnt
#at all obvious:

    File "blocks.py", line 385
        except ValueError as err:
             ^
    SyntaxError: invalid syntax

#There is no syntax error in the line indicated, so both the line number and
#caret's position are wrong. In general, when we ae faced with an error that
#we are convinced is not in the specified line, in almost every case the error
#will be in an earlier line. Here's the code from teh try to the except where
#Python is reporting the error to be -- see if you can spot the error before
#reading the explanation that follows:

    try:
        blocks = parse(blocks)
        svg = file.replace(".blk", ".svg")
        if not BlockOutput.save_blocks_as_svg(blocks svg):
            print("Error: failed to save {0}".format(svg)
    except ValueError as err:
#did you spot the problem? 
yes - missing 2nd ")"
#it is certainly easy to miss since it is on the line before the one that
#Python reports as having the error. We have closd the str.format() method's
#paraentheses, but not the print() function's parentheses, that is, we are 
#missing a closing parenthesis at the end of the line, but Python did not 
#realize this until it reached the exept keyword on the following line.
#Missing the last parenthesis on a line is quite common, especially when
#using print() with str.format(), but the error is usually reported on the
#following line. Similarly, if a list's closing bracket, or a set or dictionary's
#closing brace is missing, Python will normally report the problem as being on
#the next (non-blank) line. On the plus side, syntax errors like this are
#trivial to fix.


#Reminder of topics<===========
CHAPTER 9 Debugging, Testing, and Profiling 

Debugging 
    Dealing with Syntax Errors 
    Dealing with Runtime Errors 
    Scientific Debugging
Unit Testing 
Profiling 
Summary


#CODE LIST
blocks.py
Atomic.py
test_Modules.py 



===============
    Dealing with Runtime Errors 
===============

#If an unhandled exception occurs at runtime, Python will stop executing our
#program and print a traceback. Here is an example of a traceback for an
#unhandled exception:

    Traceback (most recent call last):
        File "blocks.py", line 392, in <module>
            main()
        File "blocks.py", line 381, in main
            blocks = parse(blocks)
        File "blocks.py", line 174, in recursive_descent_parse
            return data.stack[1]
    IndexError: list index out of range 

#Tracebacks (also called backtraces) like this should be read from their last
#line back toward their first line. The last line specifies the unhandled
#exception that occurred. Above this line, the filename, line number, and 
#function name, followed by the line that caused the exception, are shown
#(spread over two lines). If the function where the exception was raised was
#called by another function, that function's filename, line number, function
#name, and calling line are shown above. And if that function was called by
#another function the same applies, all the way up to the beginning of the
#call stack. (Note that the filenames in tracebacks are given with their path,
#but in most cases we have omitted paths from the examples for the sake of clarity.)

#So in this example, an IndexError occurred, meaning that data.stack is some
#kind of sequence, but has no item at position 1. The error occurred at line
#174 in the blocks.py program's recursive_descent_parse() function, and that
#function was called at line 381 in the main() function. (The reason that
#the function's name is different at line 381, that is, parse() instead of
#recursive_descent_parse(), is that the parse variable is set to one of 
#several different functions depending on the command-line arguments given
#to the program; in the common case the names always match.) The call to main()
#was made at line 392, and this is the statement at which program execution
#commenced.

#Although at first sight the traceback looks intimidating, now that we
#understand its structure it is easy to see how useful it is. In this case,
#it tells use exactly where to look for the problem, although of course we
#must work out for oursevles what the solution is.

#Here is another example traceback:

    Traceback (most recent call last):
      File "blocks.py", line 392, in <module>
        main()
      File "blocks.py", line 383, in main
        if BlockOutput.save_blocks_as_svg(blocks, svg):
      File "BlockOutput.py", line 141, in save_blocks_as_svg
        widths, rows = compute_widths_and_rows(cells, SCALE_BY)
      File "BlockOutput.py", line 95, in compute_widths_and_rows
        width = len(cell.text) // cell.columns
    ZeroDivisionError: integer division or modulo by zero

#Here the problem has occurred in a module (BlockOutput.py) that is called
#by the blocks.py program. This traceback leads us to where the problem 
#became APPARENT but not to where it OCCURRED. The calue of cell.columns
#is clearly 0 in te BlockOutput.py module's compute_widths_and_rows()
#function on line 95 -- after all, that is what caused the ZeroDivisionError
#exception to be raised -- but we must look at the preceding lines to find
#where and why cell.columns was given THIS incorrect value.

#New example.
#In some cases the traceback reveals an exception that occcurred in Python's
#standard library or in a third party library. Although this could mean a bug
#in the library, in almost every case it is due to a bug in our own code. Here
#is an example of such a traceback, using Python 3.0:

    Traceback (most recent call last):
      File "blocks.py", line 392, in <module>
        main()
      File "blocks.py", line 379, in main
        blocks = open(file, encoding="utf8").read()
      File "/usr/lib/python3.0/lib/python3.0/io.py", line 278, in __new__
        return open(*args, **kwargs)
      File "/usr/lib/python3.0/lib/python3.0/io.py", line 222, in open
        closefd)
      File "/usr/lib/python3.0/lib/python3.0/io.py", line 619, in __init__
        _fileio._FileIO.__init__(self, name, mode, closefd)
    IOError: [Errno 2] No such file or directory: 'hierarchy.blk'

#The IOError exception at the end tells us clearly what the problem is. But
#the exception was raised in the standard library's io module. In such cases
#it is best to keep reading UPWARD until we find the first file listed that is
#out program's file (or one of the modules we have created for it). So in this
#case, we find that the first reference to our program is to file blocks.py,
#line 379 in the main() function. It looks like we have a call to open() but
#have not put the call inside a try...except block or used a with statement.

#Python 3.1 is a bit smarter than Python 3.0 and realizes that we want to find
#the mistake in our code, not in the standard library, so it produces a must
#more compact and helpful traceback. For example:

    Traceback (most recent call last):
      File "blocks.py", line 392, in <module>
        main()
      File "blocks.py", line 379, in main
        blocks = open(file, encoding="utf8").read()
    IOError: [Errno 2] No such file or directory: 'hierarchy.blk'

#This eliminates all the irrelevant detail and makes it easy to see what
#the problem is (on the bottom line) and where it occurred (the lines above it.)

#So no matter how big the traceback is, the last line always specifies the
#unhandled exception, and just have to work back until we find our program's 
#file or one of our own modules listed. The problem will almost certainly be
#on the line Python specifies or on an earlier line.

#This particular example illustrates that we should modify the blocks.py
#program to cope gracefully when given the names of nonexistent files. This
#is a usability error, and it should also be classified as a logical error, since
#terminating and printing a tracback cannot be considered to be acceptable program
#behavior.

#In fact, as a matter of good policy and courtesy to our users, we should always
#catch all relevant exceptions, identifying the specific ones that we consider
#to be possible, such as EnvironmentError. In general, we should NOT use the 
#catchalls of 
except: #or 
except Exception: #although using the latter at the top level of our program to
#avoid crashes might be approprate -- but only if we always report any exceptions
#it catches so taht they dont go silently unnoticed.

#Exceptions that we catch and cannot recover from should be reported in the
#form of error messages, rathar than exposing our users to tracebacks which
#look scary to the uninitiated. For GUI programs the same applies, except that
#normally we would use a message box to notify the user of a problem. And for 
#server programs that normally run unattended, we should write the error message
#to the server's log.

#Python's exception hierarchy was designed so that catching Exception deosnt
#quite cover all the exceptions. In particular, it does not catch the
#KeyboardInterupt exception, so for console applications if the user presses
#Ctrl+C, the program will terminate. If we choose to catch this exception,
#there is a risk that we could lock the user into a program that they cannot
#terminate. This arises b/c a bug in our exception handling code might prevent
#the program from terminating or the exception propagating. (Of course, even
#an "uniterruptible" program can have its process killed, but not all users
#know how). So if we do catch the KeyoardInterrupt exception we must be 
#extremely careful to do the minimum amount of saving and clean up that is
#necessary -- and then terminate the program. And for programs that dont need
#to save or clean up, it is best not to catch KeyboardInterrupt at all, and
#just let the program terminate.

#One of Python 3's great vitues is that it makes a clear distinction between
#raw bytes and strings. However, this can sometimes lead to unexpected exceptions
#occurring when we pass a bytes object where a str is expected or vice versa.
#For example:

    Traceback (most recent call last):
      File "program.py", line 918, in <module>
        print(datetime.datetime.strptime(date, format))
    TypeError: strptime() argument 1 must be str, not bytes

#When we hit a problem liek this we can either perform the conversion -- in this
#case, by passing the date.decode("utf8") -- or carefully work back to find out
#where and why the variable is a bytes object rather than a str, and FIX the
#problem at its source.

#When we pass a string where bytes are expected, the error message is somewhat 
#less obvious, and differs between Python 3.0 and 3.1. For example, in Pythin 3.0

    Traceback (most recent call last):
      File "program.py", line 2139, in <module>
        data.write(info)
    TypeError: expected an object with a buffer interface

#In Python 3.1, the error message's text has been slightly improved:

    Traceback (most recent call last):
      File "program.py", line 2139, in <module>
        data.write(info)
    TypeError: 'str' does not have the buffer interface

#In both cases, the problem is that we are passing a string when a bytes,
#bytearry, or similar object is expected. We can either perform the 
#conversion -- this case by passing info.encode("utf8") -- or work back to
#find the source of the problem and fix it there.

#Python 3.0 introduced support for exception chaining -- this means that an
#exception that is raised in reponse to another exception can contain the
#details of the original exception. When a chained exception goes uncaught,
#the traceback includes not just the uncaught exception, but also the 
#exception that caused it (providing it was chainged). The approach to
#debugging chained exceptions is almost the same as before: we start at the
#and work backward until we find the problem in our own code. However, rather
#than doing this just for the last exception, we might then repeat the process
#for each chained exception above it, until we get to the problem's true origin.

#We can take advantage of exception chaining in our own code -- for example, if
#we ant to use a custom exception class but still want the underlying problem
#to be visibie:

    class InvalidDataError(Exception): pass 

    def process(data):
        try:
            i = int(data)
            ...
        except ValueError as err:
            raise InvalidDataError("Invalid data received") from err

#Here, if the int() conversion fails, a ValueError is raised and caught. We
#then raise our custom exception, but with from err, which creates a chained
#exception, our own, plus the one in err. If the InvalidDataError exception is
#raised and not caught, the resulting traceback will look something like this:

    Traceback (most recent call last):
      File "application.py", line 249, in process
        i = int(data)
    ValueError: invalid literal for int() with base 10: '17.5 '

    The above exception was the direct cause of the following exception:

    Traceback (most recent call last):
      File "application.py", line 288, in <module>
        print(process(line))
      File "application.py", line 283, in process
        raise InvalidDataError("Invalid data received") from err
    __main__.InvalidDataError: Invalid data received

#At the bottom of our custom exception and text explains what the problem is, with
#the lines above them showing where the exception was raised (line 283), and where
#it was caused (line 288). But we can also go back further, into the chained
#exception which gives more details about the specific error, and which shows the
#line that traiggered the exception (249). For a detailed rationale and further
#information about chained exceptions, see PEP 3134.


#Reminder of topics<===========
CHAPTER 9 Debugging, Testing, and Profiling 

Debugging 
    Dealing with Syntax Errors 
    Dealing with Runtime Errors 
    Scientific Debugging
Unit Testing 
Profiling 
Summary


#CODE LIST
blocks.py
Atomic.py
test_Modules.py 


===============
    Scientific Debugging
===============

#If our program runs but does not have the expected or desired behavior then
#we have a bug -- a logical error -- that we must eliminate. The best way to
#eliminate such errors is to prevent them from occurring in the first place 
#by using TDD (Test Driven Development). However, some bugs will always get
#through, so even with TDD, debugging is still a necessary skill to learn.

#In this subsection, we will outline an approach to debugging based on the
#scientific method. The approach is explained in sufficient detail that it
#might appear to be too much work for tackling a "simple" bug. However, by
#consciously following the process we will avoid wasting time with "random"
#debugging, and after awhile, we will internalize the process so that we
#can do it unconsciously, and therefore very quickly.*
#*Note this subsection was inspired by the Debugging chapter in book
#Code Complete by Steve McConnell ISBN 0735619670

#To be able to kill a bug we must be able to do the following:
1 Reproduce the bug
2 Locate the bug
3 Fix the bug
4 Test the fix

#Reproducing the bug is sometimes easy -- it always occurs on every run; and
#sometimes hard -- it occurs intermittenly. In either case we should try to 
#reduce the bug's dependencies, that is, find the smallest input and the
#least amount of processing that can still produce the bug.

#Once we are ablt to reproduce the bug, we have the data -- the input data and
#options, and the incorrect results -- that are needed so that we can apply the
#scientific method to finding and fixing it. The method has three steps:
#1) think up an explanation -- a hypothesis -- that reasonably accounts for the bug
#2) create an experiement to test the hypothesis
#3) run the experiment

#Runing the experiment should help to locate the bug, and should also give us
#insight into its solution. (We will return to how to create and run an experiment
# shortly.) Once we have decided how to kill the bug -- and have checked our code
#into our version control system so that we can revert the fix if necessary -- we
#can write the fix.

#Once the fix is in place we must test it. Naturally, we must test to see if the 
#bug it is intended to fix has gone away. But this is not sufficient after all, our
#fix may have solved the bug we were concerned about, but the fix might also have
#introduced another bug, one that affects some other aspect of the program. So in
#addition to testing the bugfix, we must also run all of the program's tests to
#increase our confidence that the bugfix did not have any unwanted side effects.

#Some bugs have a particular structure, so whenever we fix a bug its is always
#worth asking ourselves if there are other places in the program or its modules
#that might have similar bugs. If there are, we can check to see if we already
#have tests that would reveal the bugs if they were present, and if not, we
#should add such tests, and if that reveals bugs, then we must tackle them as
#described earlier.

#Now that we have a good overview of the debugging process, we will focus in on
#just how we create and run experiments to test our hypotheses. We begin with
#trying to isolate the bug. Depending on the nature of the program and of the bug,
#we might be able to write tests that exercise the program, for example, feeding
#it data that is known to be processed correctly and graudually changing the data
#so that we can find exactly where processing fails. Once we have an idea of where
#the problem lies -- either due to testing or based on reasoning -- we can test
#our hypotheses.

#What kind hypthesis might we think up? Well, it could initially be as simple as
#the suspicion that a particular function or method is returning erroneous data when
#certain input data and options are used. Then, if this hypothesis proves correct, 
#we can refine it to be more specific -- for example, identifying a particular 
#statement or suite in the function that we think is doing the wrong computation
#in certain cases.

#To test our hypothesis, we need to check the arguments that the function recieves
#and the values of its local variables and the return value, immediately before it
#returns. We can then run the program with data that we know produces errors and
#check the suspect function. If the arguments coming into the function are not what
#we expect, then the problem is likely to be further up the call stack, so we would 
#now begin the process again, this time suspecting the function that calls the one
#we have been looking at. But if all the incoming arguments are always valid, then
#we must look at the local variables and the return value. If these are always
#correct then we need to come up with a NEW hypothesis, since the suspect function
#is behaving correctly. But if the return value is wrong, then we know that we must
#investigate the function further.

#In practice, how do we conduct an experiment, that is, how do we test the hypothesis
#that a particular function is misbehaving? One way to start is to "execute" the 
#function mentally -- this is possible for many small functions and for larger ones
#with practice, and has the additional benefit that it familiarizes us with the
#function's behavior. At best, this can lead to an improved or more specific
#hypothesis -- for example, that a particular statement or suite is the site of the
#problem. But to conduct an experiment properly, we must instrument the program
#so that can see what is going on when the suspect function is called.

#There are two ways to instrument a program -- intrusively, by inserting print()
#statements; or (usually) non-intrusively, by using a debugger. Both approaches
#are used to achieve the same end and both are vaild, but some programmers have a
#strong preference for one or the other. We will briefly describe both approaches,
#starting with the use of print() statements.

#When using print() statements, we can start by putting a print() statement right
#at the beginning of the function and have it print the function's arguments. Then,
#just before the (or each) return statement (or at the end of the function if there
#is no return statement), add
print(locals(), "\n") #. The built-in locals() function returns a dictionary whose
#keys are the names of the local variables and whose values are the variables' values.
#We can of course simply print the variables we are specifically interested in instead.
#Notice that we added an extra newline -- we should also do this in the firsst
#print() statement so that a blank line appears between each set of variables to 
#aid clarity. (An alternative to inserting print() statements directly is to use
#some kind of logging decorator such as the one we created in Chapter 8, page 358).

#If we run the instrumented program we find that the arguments are correct but that
#the return value is in error, we know that we have located the source of the bug
#and can further investigate the function. If looking carefully at the function
#doesnt suggest where the problem lies, we can simply insert a new
print(locals(), "\n") #right in the middle. After running the program again we 
#should now know whether the problem arises in the first or second half of the
#function, and can put a print(locals(), "\n") statement in the middle of the
#relevant half, repeating the process until we find the statement where the error
#is caused. This will very quickly get us to the point where the problem occurs --
#and in most cases locating the problem is half of the work needed to solve it.

#The alternative to adding print() statements is to use a debugger. Python has two
#standard debuggers. One is supplied as a module (pdb), and can be used interactively
#in the console -- for example,
python3 -m pdb my_program.py
#(On Windows, of course, we would replace python3 with somethink like
#  C:\Python31\python.exe.) However, the easiest way to use it is to add
import pdb # in the program itself, and add the statement 
pdb.set_trace() #as the first statement of the function we want to examine.
#When the program is run, pdb stops it immediately after the pdb.set_trace() call,
#and allows us to step through the program, set breakpoints, and examine variables.

#Here is an example run of a program that has been instrumented by having the
#import pdb statement added to its imports, and by having pdb.set_trace() added
#as the first statement inside its
calculate_median() #function. (What we have typed is shown in bold, although where we
#we typed Enter is not indicated.)

python3 statistics.py sum.dat
> statistics.py(73)calculate_median() -> numbers = sorted(numbers)
(Pdb) s
> statistics.py(74)calculate_median() -> middle = len(numbers) // 2
(Pdb)
> statistics.py(75)calculate_median()
-> median = numbers[middle]
(Pdb)
> statistics.py(76)calculate_median()
-> if len(numbers) % 2 == 0:
(Pdb)
> statistics.py(78)calculate_median()
-> return median
(Pdb) p middle, median, numbers
(8, 5.0, [-17.0, -9.5, 0.0, 1.0, 3.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.5, 
    6.0, 7.0, 7.0, 8.0, 9.0, 17.0])
(Pdb) c

#Commands are given to pdb by entering their name and pressing Enter at the 
#(Pdb) propmt. If we just press Enter on its own, the last command is repeated.
#So here we typed s (which means step, ie execute the statement shown), and then
#repeated this (simply by pressing Enter), to step through the statements in the
#calculate_median() function. Once we reached the return statement, we printed
#out the values that interested us using the p (print) command. This tiny example
#should give us a flavor of pdb, but of course the module has a lot more
#functionality than we have shown here.

#It is much easier to use pdb on an instrumented program as we have done here than
#on an uninstrumented one. But since this requires us to add an import and a call to
#pdb.set_trace(), it would seem that using pdb is just as intrusive as using print()
#statements, although it does provide useful facilities such as breakpoints.

#The other standard debugger is IDLE, and just like pdb, it supports single stepping, 
#breakpoints, and the examination of variables. IDLE's debugger window is shown in
#Figure 9.1 and its code editing window with breakpoints and the current line
#highlighted is shown in Figure 9.2

#One great advantage IDLE has over pdb is that there is no need to instrument our
#code -- IDLE is smart enough to debug our code as it stands, so it is not intrusive
#at all.

#Unforetunately, at the time of this writing, IDLE is rather weak when it comes to
#running program that require command-line arguments. The only way to do this appears
#to be to run IDLE from a console with the required arguments, for example
idel3 -d -r statistics.py sum.dat 

#the -d argument tells IDLE to start debugging immediately and the -r argument tells
#it to run the following program with any arguments that follow it. However, for 
#programs that dont require command line arguments (or where we are willing to edit
#the code to put them in manually to make debugging easier), IDLE is quite powerful
#and convenient to use. (Incidentally, the code shown in Figure 9.2 does have a bug
#-- which is middle + 1 should be middle -1.)

#Debugging Python programs is no harder than debugging in amy other language -- and it
#is easier than for compiled languages since there is no build step to go through 
#after making changes. And if we are careful to use the scientific method it is usually
#quite straightforward to locate bugs, although fixing them is another matter. Ideally,
#though we want to avoid as many bugs as possible in the first place. And apart from 
#thinking deeply about our design and writing our code with care, one of the best
#ways is to use TDD, a topic we will introduce in the next section.



#CODE LIST
blocks.py
Atomic.py
test_Modules.py 



#CODE HERE
blocks.py

#!/usr/bin/env python3

"""
BNF

    BLOCKS  ::= NODES+
    NODES   ::= NEW_ROW* NODE+
    NODE    ::= '[' (COLOR ':')? NAME? NODES* ']'
    COLOR   ::= '#'[\dA-Fa-f]{6} | [a-zA-Z]\w*
    NAME    ::= [^][/]+
    NEW_ROW ::= '/'
"""

import optparse
import sys
import Block
import BlockOutput
import ply.lex
try:
    from pyparsing import (alphanums, alphas, CharsNotIn, Forward, Group, hexnums, OneOrMore,
        Optional, ParseException, ParseSyntaxException, Suppress, Word, ZeroOrMore)
except ImportError:
    from pyparsing_py3 import (alphanums, alphas, CharsNotIn, Forward, Group, hexnums, OneOrMore,
        Optional, ParseException, ParseSyntaxException, Suppress, Word, ZeroOrMore)


EmptyBlock = 0
class LexError(exception): pass 

def recursive_descent_parse(text):
    """
    >>> import os
    >>> dirname = os.path.join(os.path.dirname(__file__), "data")
    >>> filename = os.path.join(dirname, "error1.blk")
    >>> with open(filename, encoding="utf8") as file:
    ...     recursive_descent_parse(file.read())
    Traceback (most recent call last):
    ...
    ValueError: Error {0}:line 8, column 2: ran out of text when expecting ']'
    >>> filename = os.path.join(dirname, "error2.blk")
    >>> with open(filename, encoding="utf8") as file:
    ...     recursive_descent_parse(file.read())
    Traceback (most recent call last):
    ...
    ValueError: Error {0}:line 1, column 1: expected '[]/' but got '#'
    >>> filename = os.path.join(dirname, "error3.blk")
    >>> with open(filename, encoding="utf8") as file:
    ...     recursive_descent_parse(file.read())
    Traceback (most recent call last):
    ...
    ValueError: Error {0}:line 8, column 2: ran out of text when expecting '['
    >>> expected = "[white: ]\\n[lightblue: Director]\\n/\\n/\\n[white: ]\\n[lightgreen: Secretary]\\n/\\n/\\n[Minion #1]\\n[white: ]\\n[Minion #2]"
    >>> filename = os.path.join(dirname, "hierarchy.blk")
    >>> with open(filename, encoding="utf8") as file:
    ...     blocks = recursive_descent_parse(file.read())
    >>> str(blocks).strip() == expected
    True
    >>> expected = "[#00CCDE: MessageBox Window\\n[lightgray: Frame\\n[white: ]\\n[white: Message text]\\n/\\n/\\n[goldenrod: OK Button]\\n[white: ]\\n[#ff0505: Cancel Button]\\n/\\n[white: ]\\n]\\n]"
    >>> filename = os.path.join(dirname, "messagebox.blk")
    >>> with open(filename, encoding="utf8") as file:
    ...     blocks = recursive_descent_parse(file.read())
    >>> str(blocks).strip() == expected
    True
    """

    class Data:

        def __init__(self, text):
            self.text = text 
            self.pos = 0
            self.line = 1
            self.column = 1
            self.brackets = 0
            self.stack = [Block.get_root_block()]

        def location(self):
            return "line {0}, column {1]".format(self.line, self.column)

        def _advance_by_one(self):
            self.pos += 1
            if (self.pos < len(self.text) and self.text[self.pos] == "\n"):
                self.line += 1
                self.column = 1
            else:
                self.column += 1

        def advance_by(self, amount):
            for x in range(amount):
                self._advance_by_one()

        def advance_to_position(self, position):
            while self.pos < position:
                self._advance_by_one()

        def advance_up_to(self, characters):
            while (self.pos < len(self.text) and self.text[self.pos] not in characters and self.text[self.pos].isspace()):
                self._advance_by_one()
            if not self.pos < len(self.text):
                return False
            if self.text[self.pos] in characters:
                return True 
            raise LexError("expected '{0}' but got '{1}'".format(characters, self.text[self.pos]))


    def parse_new_row(data):
        data.stack[-1].children.append(Block.get_new_row())
        data.advance_by(1)


    def parse_block_data(data, end):
        color = None
        colon = data.text.find(":", data.pos)
        if -1 < colon < end:
            color = data.text[data.pos:colon]
            data.advance_to_position(color + 1)
        name = data.text[data.pos:end].strip()
        data.advance_to_position(end)
        if not name and color is None:
            block = Block.get_empty_block()
        else:
            block = Block.Block(name, color)
        data.stack[-1].children.append(block)
        return block

    def parse_block(data):
        data.advance_by(1)
        nextBlock = data.text.find("[", data.pos)
        endOfBlock = data.text.find("]", data.pos)
        if nextBlock == -1 or endOfBlock < nextBlock:
            parse_block_data(data, endOfBlock)
        else:
            block = parse_block_data(data, nextBlock)
            data.stack.append(block)
            parse(data)
            data.stack.pop()

    def parse(data):
        while data.pos < len(data.text):
            if not data.advance_up_to("[]/"):
                break
            if data.text[data.pos] == "[":
                data.brackets += 1
                parse_block(data)
            elif data.text[data.pos] == "/":
                pasrse_new_row(data)
            elif data.text[data.pos] == "]":
                data.brackets -= 1
                data.advance_by(1)
            else:
                raise LexError("expecting '[', ']' or '/'; but got '{0}'".format(data.text[data.pos]))
        if data.brackets:
            raise LexError("ran out of text when expecting '{0}'".format(']' if data.brackets > 0 else '['))

    data = Data(text)
    try:
        parse(data)
    except LexError as err:
        raise ValueError("Error {{0}}:{0}: {1}".format(data.location(), err))
    return data.stack[0]


def populate_children(items, stack):
    for item in items:
        if isinstance(item, Block.Block):
            stack[-1].children.append(item)
        elif isinstance(item, list) and item:
            stack.append(stack[-1].children[-1])
            populate_children(item, stack)
            stack.pop()
        elif isinstance(item, int):
            if item == EmptyBlock:
                stack[-1].children.append(Block.get_empty_block())
            else:
                for x in range(item):
                    stack[-1].children.append(Block.get_new_row())


def pyparsing_parse(text):
    """
    >>> import os
    >>> dirname = os.path.join(os.path.dirname(__file__), "data")
    >>> filename = os.path.join(dirname, "error1.blk")
    >>> with open(filename, encoding="utf8") as file:
    ...     pyparsing_parse(file.read())
    Traceback (most recent call last):
    ...
    ValueError: Error {0}: syntax error, line 8
    >>> filename = os.path.join(dirname, "error2.blk")
    >>> with open(filename, encoding="utf8") as file:
    ...     pyparsing_parse(file.read())
    Traceback (most recent call last):
    ...
    ValueError: Error {0}: syntax error, line 1
    >>> filename = os.path.join(dirname, "error3.blk")
    >>> with open(filename, encoding="utf8") as file:
    ...     pyparsing_parse(file.read())
    Traceback (most recent call last):
    ...
    ValueError: Error {0}: syntax error, line 4
    >>> expected = "[white: ]\\n[lightblue: Director]\\n/\\n/\\n[white: ]\\n[lightgreen: Secretary]\\n/\\n/\\n[white: Minion #1]\\n[white: ]\\n[white: Minion #2]"
    >>> filename = os.path.join(dirname, "hierarchy.blk")
    >>> with open(filename, encoding="utf8") as file:
    ...     blocks = pyparsing_parse(file.read())
    >>> str(blocks).strip() == expected
    True

    >>> expected = "[#00CCDE: MessageBox Window\\n[lightgray: Frame\\n[white: ]\\n[white: Message text]\\n/\\n/\\n[goldenrod: OK Button]\\n[white: ]\\n[#ff0505: Cancel Button]\\n/\\n[white: ]\\n]\\n]"
    >>> filename = os.path.join(dirname, "messagebox.blk")
    >>> with open(filename, encoding="utf8") as file:
    ...     blocks = pyparsing_parse(file.read())
    >>> str(blocks).strip() == expected
    True
    """

    def add_block(tokens):
        return Block.Block(tokens.name, tokens.color if tokens.color else "white")

    left_bracket, right_bracket = map(Suppress, "[]")
    new_rows = Word("/")("new_rows").setParseAction(lambda tokens: len(tokens.new_rows))
    name = CharsNotIn("[]/\n")("name").setParseAction(lambda tokens: tokens.name.strip())
    color = (Word("#", hexnums, exact=7) | Word(alphas, alphanums))("color")
    empty_node = (left_bracket + right_bracket).setParseAction(lambda: EmptyBlock)
    nodes = Forward()
    node_data = Optional(color + Suppress(":")) + Optional(name)
    node_data.setParseAction(add_block)
    node = left_bracket - node_data + nodes + right_bracket
    nodes << Group(ZeroOrMore(Optional(new_rows) + OneOrMore(node | empty_node)))
    stack = [Block.get_root_block()]
    try:
        results = nodes.parseString(text, parseAll=True)
        assert len(results) == 1
        items = results.asList()[0]
        populate_children(items, stack)
    except (ParseException, ParseSyntaxException) as err:
        raise ValueError("Error {{0}}: syntax error, line {0}".format(err.lineno))
    return stack[0]

def ply_parse(text):
    """
    >>> import os
    >>> dirname = os.path.join(os.path.dirname(__file__), "data")
    >>> filename = os.path.join(dirname, "error1.blk")
    >>> with open(filename, encoding="utf8") as file:
    ...     ply_parse(file.read())
    Traceback (most recent call last):
    ...
    ValueError: Error {0}:line 8: unbalanced brackets []
    >>> filename = os.path.join(dirname, "error2.blk")
    >>> with open(filename, encoding="utf8") as file:
    ...     ply_parse(file.read())
    Traceback (most recent call last):
    ...
    ValueError: Error {0}:line 2: syntax error
    >>> filename = os.path.join(dirname, "error3.blk")
    >>> with open(filename, encoding="utf8") as file:
    ...     ply_parse(file.read())
    Traceback (most recent call last):
    ...
    ValueError: Error {0}:line 8: too many ']'s
    >>> expected = "[white: ]\\n[lightblue: Director]\\n/\\n/\\n[white: ]\\n[lightgreen: Secretary]\\n/\\n/\\n[white: Minion #1]\\n[white: ]\\n[white: Minion #2]"
    >>> filename = os.path.join(dirname, "hierarchy.blk")
    >>> with open(filename, encoding="utf8") as file:
    ...     blocks = ply_parse(file.read())
    >>> str(blocks).strip() == expected
    True

    >>> expected = "[#00CCDE: MessageBox Window\\n[lightgray: Frame\\n[white: ]\\n[white: Message text]\\n/\\n/\\n[goldenrod: OK Button]\\n[white: ]\\n[#ff0505: Cancel Button]\\n/\\n[white: ]\\n]\\n]"
    >>> filename = os.path.join(dirname, "messagebox.blk")
    >>> with open(filename, encoding="utf8") as file:
    ...     blocks = ply_parse(file.read())
    >>> str(blocks).strip() == expected
    True
    """

    tokes = ("NODE_START", "NODE_END", "COLOR", "NAME", "NEW_ROWS", "EMPTY_NODE")
    t_NODE_START = r"\["
    t_NODE_END = r"\]"
    t_COLOR = r"(?:\#[\dA-Fa-f]{6}|[a-aA-Z]\w*):"
    t_NAME = r"[^][?|n]+"
    r_NEW_ROWS = r"/+"
    r_EMPTY_NODE = r"\[\]"

    t_ignore = " \t"

    def t_newline(t):
        r"\n+"
        t.lexer.lineo += len(t.value)

    def t_error(t):
        line = t.value.lstrip()
        i = line.find("\n")
        line = line if i == -1 else line[:i]
        raise LexError("syntax error: {1}".format(line))

    stack = [Block.get_root_block()]
    block = None
    brackets = 0
    lexer = plu.lex.lex()
    try:
        lexer.input(text)
        for token in lexer:
            if token.type == "NODE_START":
                brackets += 1
                block = Block.get_empty_block()
                stack[-1].children.append(block)
                stack.append(block)
            elif token.type == "NODE_END":
                brackets -= 1
                if brackets <0:
                    raise LexError("too many ']'s")
                block = None
                stack.pop()
            elif token.type == "COLOR":
                if block is None or Block.is_new_row(block):
                    raise LexError("syntax error")
                block.color = token.value[:-1]
            elif token.type == "NAME":
                if block is None or Block.is_new_row(block):
                    raise LexError("syntax error")
                block.name = token.value 
            elif token.type == "EMPTY_NODE":
                stack[-1].children.append(Block.get_empty_block())
            elif token.type == "NEW_ROWS":
                for x in range(len(token.value)):
                    stack[-1].children.append(Block.get_new())
        if brackets:
            raise LexError("unbalanced brackets []")
    except LexErrr as err:
        raise ValueError("Error {{0}}:line {0}: {1}".format(token.lineno + 1, err))
    return stack[0]


def parse_options():
    parsers = "recursive ply pyparsing".split()
    parser = optparse.OptionParser(usage="""\
usage: %prog [options] infile1 [infile2 [...]]

Reads one or more 'blocks' (.blk) description file and for each one
writes an equivalent .svg file to visualize the blocks, using the same
name as the infile but with the extension changed appropriately.
        """)
    parser.set_defaults(parser="recursive")
    parser.add_option("-p", "--parser", dest="parser", choices=parsers,
        help="{0} [%default]".format(", ".join(parser)))
    opts, args = parser.parse_args()

    args = [arg for arg in args if arg.endswith(".blk")]
    if not len(args):
        parser.error("at least one .blk file must be specified")
    if opts.parser == "recursive":
        parse = recursive_descent_parse
    elif opts.parser == "pyparsing":
        parse = pyparsing_parse
    elif opts.parser == "ply":
        parse = ply_parse
    return parse, args 

def main():
    parse, files = parse_options()
    for file in files:
        with open(file, encoding="utf8") as file
        blocks = file.read()
    try:
        blocks = parse(blocks)
        svg = file.replace(".blk", ".svg")
        if BlockOutput.save_blocks_as_svg(blocks, svg):
            print("Saved {0}".format(svg))
        else:
            print("Error: failsed to save {0}".format(svg))
    except ValueError as err:
        print(str(err).format(file))


if __name__ == "__main__":
    main()





#Reminder of topics<===========
CHAPTER 9 Debugging, Testing, and Profiling 

Debugging 
    Dealing with Syntax Errors 
    Dealing with Runtime Errors 
    Scientific Debugging
Unit Testing 
Profiling 
Summary


#CODE LIST
blocks.py
Atomic.py
test_Modules.py 


===============
Unit Testing 
===============

#Writing test for our programs -- if done well -- can help reduce the incidence
#of bugs and can increase our confidence that our programs beahve as expected.
#But in general, testing can not guarantee correctness, since for most
#nontrivial programs the range of possibile inputs and range of possible
#computations is so vast that only the tinest fraction of them could ever be
#realistically tested. Nonetheless, by carefully choosing what we test we can 
#improve the quality of our code.

#A veriety of different kinds of testing can be done, such as usability testing,
#functional testing, and integration testing. But here we will concern 
#ourselves purely with unit testing -- testing individual functions, classes, 
#and methods, to ensure that they behave according to our expectations.

#A key point of TDD, is that wjen we want to add a feature -- for example, a new
#method to a class -- we FIRST write a test for it. And of course this test will
#fail since we have not written the method yet. Now we write the method, and
#once it passes the test we can then rerun ALL the tests to make sure our addition
#hasn't had any unexpected side effects. Once all the tests run (including the one
#we added for the new feature), we can check in our code, reasonably confident that
#it does what we expect -- providing of course that our test was adequate.

#For example, if we want to write a function that insert a string at a particular
#index position, we might start out using TDD like this:

    def insert_at(string, position, insert):
        """Returns a copy of string with insert inserted at the position
        >>> string = "ABCDE"
        >>> result = []
        >>> for i in range(-2, len(string) + 2):
        ...     result.append(insert_at(string, i, "-"))
        >>> result[:5]
        >>> result[5:]
        """
        return string

#For functions or methods that dont return anything (they actually return None),
#we normally give them a suite consisting of pass, and for those whose return
#value is used we either return a constant (say, 0) or one of the arguments, 
#unchanged -- which is what we have done here. (In more complex situations, it
#may be more useful to return fake objects -- 3rd party modules that provide
#"mock" objects that are avaible for such cases.)

#When the doctest is run it will fail, listing each of the strings ('ABCD-EF'.
#'ABCDE-F', etc.) that it expected, and the strings it actually got (all of
#which are 'ABCDEF'). Once we are satisfied that the doctest is sufficient and
#correct, we can write the body of the function, which in this case is simply
return string[:position] + insert + string[position:]
#And if we wrote
return string[:position] + insert #and then copied and pasted
string[:position] #at the end to save ourselves some typing, the doctest will
#immediately reveal the error.

#Python's standard library provides two unit testing modules, 
doctest #, which we have already brielfy seen here and earlier in Chapter 5 pg 202 and
#Chapter 6 pg 247) and 
unitest # In addition, there are testing tools for Python. Two of the most notable are
nose #(code.google.com/p/python-nose) which aims to be more comprehensive and useful
#than the standard unittest module, while still being compatible with it and
py.test #(codespeak.net/py/dist/test/test.html) -- this takes a somewhat different
#approach to unittest, and tries as much as possible to eliminate boilerplate test code
#Both of these third-party tools support test discovery, so there is no need to write
#an overarching test program -- since they will search for tests themselves. This makes
#it easy to test an entire tree of code or just a part of the tree (eg just those
#modules that have been worked on). For those serious about testing, it is worth
#investigating both of these third part modules (and any others), before deciding
#which testing tools to use.

#Creating doctests is straightforward: we write the tests in the module, function,
#class, and methods' docstrings, and for modules we simple ADD three lines of the 
#end of the module:

    if __name__ == "__main__":
        import doctest
        doctest.testmod()

#If we want to use the doctests inside programs, that is also possible. For example,
#the blocks.py program whose modules are covered later (in Chapter 14) has doctests
#for its function, but it ends with this code:

    if __name__ == "__main__":
        main()

#This simply calls the program's main() function, and does not execute the
#program's doctests. To exercise the program's doctests there are two approaches
#we take. One is to import the doctest module and then run the program -- for example,
#at the console
python3 -m doctest blocks.py
#on Windows replacing python3 with something like   C:\Python31\python.exe
#If all the tests run fine there is no output, so we might prefer to execute
python3 -m doctest blocks.py -v #instead, since this will list every doctest that 
#is executed, and provide a summary of results at the end.

#Another way to excute doctests is to create a separate test program using the
#unittest module. The unittest module is conceptually modeled on Java's JUnit 
#unit testing library and is used to create test suites that contain test cases.
#The uniitest module can create test cases based on doctests, without having to
#know anything about whatthe program or module contains, apart from the fact that
#it has doctests. So to make a test suite for the blocks.py program, we can create
#the following simple program (which we have called test_blocks.py):

    import doctest
    import unittest
    import blocks
    suite = unittest.TestSuite()
    suite.addTest(doctest.DocTestSuite(blocks))
    runner = unittest.TextTestRunner()
    print(runner.run(suite))

#Note that there is an implicit restriction on the names of our programs if we
#take this approach: They must have names that are valid module names, so a 
#program called 
convert-incidents.py #can NOT have a test like this written for
#it b/c import convert-incidents is NOT valid since hyphens are not legal in 
#Python idetifiers. (It is possible to get around this, but the easiest solution
#is to use program filenames that are also valid module names, for example,
#replacing hyphens with underscores.)

#The structure shown here -- create a test suite, add one or more test cases or
#test suites, run the overarching test suite, and output the results -- is
#typical of unittest-based tests. When run, this particular example produces the
#following output:

    ...
    -----------------------------------------------------------
    Ran 3 tests in 0.244s

    OK 
    <unittest._TextTestResult run=3 errors=0 failures=0>

#Each time a test case is executed a period is output (hence the three periods
#at the beginning of the output), then a line of hyphens, and then the test summary.
#(Naturally, there is a lot more output if any tests fail.)

#If we are making the effort to have separate tests (typically one for each program
#and module we want to test), then rather than using doctests we might prefer to 
#directly use the unittest module's features -- especially if we are used to the 
#JUnit appraoch to testing. The unittest module keeps our tests separate from our
#code -- this is particularly useful for larger projects where test writers and 
#developers are not necessarily the same people. Also, unittest unit tests are
#written as stand-alone Python modules, so they are not limited by what we can
#comfortably and sensibly write inside a docstring.

#the unittest module defines four key concepts. (1) a test fixture is the term used
#to describe the code necessary to set up a test (and to tear it down, that is, clear
#up, afterward). Typical examples are creating an input file for test to use and at
#the end deleting the input file and the resultant output file. (2) a test suite is a
#collection of test cases and (3) a test case is the basic unit of testing -- test
#suites are collections of test cases or of other test suites. We will see practical
#examples shortly. (4) a test runner is an object that executes one or more test suites.

#Typically, a test suite is made by creating a subclass of 
unittest.TestCase #, where each method that has a name beginning with "test" 
#is a test case. If we need any setup to be done, we can do it in a method called 
setUp() #; similarly, for any cleanup we can implement a method caleld 
tearDown() #. Within the tests there are a number of 
unittest.TestCase #methods that we can make use of, including 
assertTrue()
assertEqual()
assertAlmostEqual() #(useful for testing floating point numbers),
assertRaises() #, and many more, including many inverses such as 
assertFalse()
assertNotEqual()
failIfEqual()
failUnlessEquaul #, and so on.

#The unittest module is well documented and has a lot of functionality, but here we
#will just give a flavor of its use by reviewing a very simple test suite. The example
#we will use is the solution to one of the exercises given at the end of Chapter 8.
#The exercise was to create an Atomic module which could be used as a context manager
#to ensure that either all of a set of changes is applied to a list, a set, or
#dictionary -- or none of them are. The Atomic.py module provided as an example solution
#uses 30 lines of code to implement the Atomic class, and has about 100 lines of module
#doctests. We will create the 
test_Atomic.py #module to replace the doctests with unittest 
#tests so that we can then delete the doctest and leave Atomic.py free of any code except
#that needed to provide its functionality.

#Before diving into writing the test module, we need to think about what tests are
#needed. We will need to test three different kids of data type: lists, sets, and
#dictionaries. For lists we need to test appending and inserting an item, deleting
#an item, and changing an item's value. For sets we must test adding and discarding
#an item. And for dictionaries we must test inserting an item, changing an item's value,
#and deleting an item. Also, we must test that in the case of failure, none of the
#changes are applied.

#Structurally, testing the different data types is essentially the same, so we will 
#only write the test cases for testing lists and leave the others as an exercise. The
#test_Atomic.py module must import both the unittest module and the Atomic module
#that it is designed to test.

#When creating unittest files, we usually create modules rather than programs, and inside
#each module we define one or more unittest.TestCase subclasses. In the case of the
#test_Atomic.py module, it defines a single unittext.TestCase subclass, TestAtomic (which
#we will review shortly), and ends with the following two lines:

    if __name__ == "__main__":
        unittest.main()

#Thanks to these lines, the module can be run stand-alone. And of course, it could also
#be imported and run from another test program -- something that makes sense if this is 
#just one test suite among many.

#If we want to run the test_Atomic.py module from another test program we can write
#a program that is similar to the one we used to execute doctests using the unittest
#module. For example:

    import unittest
    import test_Atomic

    suite = unittest.TestLoader().loadTestsFromTestCase(test_Atomic.TestAtomic)
    runner = unittest.TextTestRunner()
    print(runner.run(suite))

#Here, we have created a single suite by telling the unittest module to read the
test_Atomic #module and to use each of its 
test*() #methods (test_list_success() and test_list_fail()) in this example, 
#as we will see in a moment), as test cases.

#We will now review the implementation of the TestAtomic class. Unusually for
#subclasses generally, although not for unittest.TestCase subclasses, there is 
#no need to implement the initializer.
Atul why?
#In this case, we will need a setup method, but not a teardown method. And we
#will implement two test cases.

    def setUp(self):
        self.original_list = list(range(10))

#We have use the unittest.TestCase.setUp() method to create a single piece
#of test data.

    def test_list_succeed(self):
        items = self.original_list[:]
        with Atomic.Atomic(items) as atomic:
            atomic.append(1999)
            atomic.insert(2, -915)
            del atomic[5]
            atomic[4] = -782
            atomic.insert(0 -9)
        self.assertEqual(items, [-9, 0, 1, -915, 2, -782, 5, 6, 7, 8, 9, 1999])

#This test case is used to test that all of a set of changes to a list are correctly
#applied. The performs an append, an insertion in the middle, an insertion at the
#beginning, a deletion, and a change of a value. While by no means comprehensive,
#the test does at least cover the basics.

#The test should not raise an exception, but if it does the 
unittest.TestCase #base class will handle it by turning it into an appropriate error
#message. At the end, we expect the items list to equal the literal list included in
#in the test rather and the original list. The 
unittest.TestCase.assertEqual() #method can compare any two Python objects, but its
#generality means that it cannot give particularly informative error messages.

#From Python3.1, the unittest.TestCase class has many more methods, including many
#data-type-specific assertion methods. Here is how we could write the assertion
#using Python3.1:
    self.assertListEqual(items, [-9, 0, 1, -915, 2. -782, 5, 6, 7, 8, 9, 1999])

#If the lists are not equal, since the data types are known, the unittest module is
#able to give more precise error information, including where the lists differ.

    def test_list_fail(self):
        def process():
            nonlocal items
            with Atomic.Atomic(items) as atomic:
                atomic.append(1999)
                atomic.insert(2, -915)
                del atomic[5]
                atomic[4] = -782
                atomic.poop()       #Typo

        items = self.original_list[:]
        self.assertRaises(AttributeError, process)
        self.assertEqual(items, self.original_list)

#To test the failure case, that is, where an exception is raised while doing
#atomic processing, we must test that the list has NOT been changed and also
#that an appropriate exception has been raised. To check for an exception we
#use the unittest.TestCase.assertRaises() method, and in the case of Python3.0,
#we pass it the exception we expect to get and a callable object that should
#raise the exception. This forces us to encapsulate the code we want to test,
#which is why we had to create the process() inner function shown here.

#In Python3.1, the unittest.TestCase.assertRaises() method can be used as a
#context manager, so we are able to write our test in a much more natural way:

    def test_list_fail(self):
        items = self.original_list[:]
        with self.assertRaises(AttributeError):
            with Atomic.Atomic(items) as atomic:
                atomic.append(1999)
                atomic.insert(2, -915)
                del atomic[5]
                atomci[4] = -782
                atomic.poop()       #Typo
        self.assertListEqual(items, self.original_list)

#Here wer have written the test code DIRECTLY in the test method without the
#need for an inner function, instead using unittest.TestCase.assertRaised() as a
#context manager that expects the code to raise an AttributeError. We have also
#used Python3.1's unittest.TestCase.assertListEqual() method at the end.

#As we have seen, Python's test modules are easy to use and are extremely useful,
#especially if we use TDD. They also ahve a lot more functionaltiy and features
#than have been shown here -- for example, the ability to skip tests which is to
#account for platform differences -- and they are also well documented. One 
#feature that is missing - and which nose and py.test provide -- is test discovery,
#although this feature is expected to appear in a later Python version (perhaps as
#early as Python 3.2).


#CODE LIST
blocks.py
Atomic.py
test_Modules.py 



#CODE HERE
#note this module is referenced in Chapter 9 in text but in Chapter 8 online answers
#and in Chapter 12 for online code listing.
Atomic.py

#!/usr/bin/env python3

""" Atomic is a context manager for mutable collections.

Atomic ensures that either all the changes are applied or none of them are (ie in the face
of an exception occurring). Atomic makes a private copy of the collection (a deep copy if 
deep_copy is set True), so could be expensive for large collections.

>>> items = list(range(10))
>>> try:
...     with Atomic(items) as atomic:
...         atomic.append(1999)
...         del atomic[3]
...         atomic[8] = -999
... except (AttributeError, IndexError, ValueError) as err:
...     pass 
>>> items 
[0, 1, 2, 4, 5, 6, 7, 8, -999, 1999]

>>> items = list(range(10))
>>> try:
...     with Atomic(items) as atomic:
...         atomic.append(10)
...         del atom[3]
...         atomic[8] = -99
...         atomic.poop() #force failure 
... except (AttributeError, IndexError, ValueError)as err:
...     pass 
>>> items
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]

>>> items = 19
>>> items = list(range(10))
>>> try:
...     with Atomic(items) as atomic:
...         atomic.append(58289)
...         del atomic[3]
...         atomic[8] = 81738
...         atomic[index] = 38172
... except (AttributeError, IndexError, ValueError) as err:
...    pass
>>> items
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]

>>> items = set(range(10))
>>> try:
...     with Atomic(items) as atomic:
...         atomic.add(1999)
...         atomic.discard(3)
...         atomic |= {-999}
... except (AttributeError, IndexError, ValueError) as err:
...    pass
>>> list(sorted(items)), type(items) == type(set())
([-999, 0, 1, 2, 4, 5, 6, 7, 8, 9, 1999], True)

>>> items = set(range(10))
>>> try:
...     with Atomic(items) as atomic:
...         atomic.append(10)
...         atomic.discard(3)
...         atomic |= {-99}
...         atomic.poop() # force failure
... except (AttributeError, IndexError, ValueError) as err:
...    pass
>>> list(sorted(items)), type(items) == type(set())
([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], True)

>>> items = {chr(x): x for x in range(ord("A"), ord("E"))}
>>> try:
...     with Atomic(items) as atomic:
...         atomic["E"] = ord("E")
...         del atomic["B"]
... except (AttributeError, IndexError, ValueError) as err:
...    pass
>>> list(sorted(items.items())), type(items) == type({})
([('A', 65), ('C', 67), ('D', 68), ('E', 69)], True)

>>> items = {chr(x): x for x in range(ord("A"), ord("E"))}
>>> try:
...     with Atomic(items) as atomic:
...         atomic["E"] = ord("E")
...         del atomic["B"]
...         atomic.poop() # force failure
... except (AttributeError, IndexError, ValueError) as err:
...    pass
>>> list(sorted(items.items())), type(items) == type({})
([('A', 65), ('B', 66), ('C', 67), ('D', 68)], True)

>>> import abc
>>> import collections
>>> class A:
...     pass
>>> collections.MutableSet.register(A) # This class is lying about its API
>>> a = A()
>>> with Atomic(a) as atomic:
...     a.add(1)
Traceback (most recent call last):
...
AssertionError: Atomic mappings/sets must provide clear() and update()

>>> items = frozenset({1, 2, 3})
>>> with Atomic(items) as atomic:
...     a.add(1)
Traceback (most recent call last):
...
AssertionError: Atomic requires a mutable collection
"""

import collections
import copy

class Atomic:

    def __init__(self, container, deep_copy=False):
        assert isinstance(container, (collections.MutableSequence, collections.MutableSet,
            collections.MutableMapping)), ("Atomic requires a mutable collection")
        #if __debug__ ensure this is not executed when optimized with -O
        if __dedub__ and isinstance(container, (collecitons.MutableSet, collections.MutableMapping)):
            assert (hasattr(container, "clear") and hasattr(container, "update")), ("Atomic mappings/sets must provide clear() and update()")
        self.original = container
        self.copy = copy.deepcopy if deep_copy else copy.copy

    def __enter__(self):
        self.modified = self.copy(self.original)
        return self.modified

    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type is None:
            if isinstance(self.original, collections.MutableSequence):
                self.origial[:] = self.modified
            elif isinstance(self.original, (collections.MutableSet, collections.MutableMapping)):
                self.original.clear()
                self.original.update(self.modified)

if __name__ == "__main__":
    import doctest
    doctest.testmod()



#CODE LIST
blocks.py
Atomic.py
test_Modules.py 






#CODE HERE
test_blocks.py 

#!/usr/bin/env python3

import doctest
import unittest
import blocks

suite = unittest.TestSuite()
suite.addTest(doctest.DocTestSuite(blocks))
runner = unittest.TextTestRunner()
print(runner.run(suite))







#CODE HERE
test_Atomic.py  #TWO DIFFERNENT PROGRAMS

#!/usr/bin/env python3

import unittest
import Atomic

class TestAtomic(unitest.TestCase):

    def setUp(self):
        self.original_list = list(range(10))

    def test_list_succeed(self):
        items = self.original_list[:]
        with Atomic.Atomic(items) as atomic:
            atomic.append(1999)
            atomic.insert(2, -915)
            del atomic[5]
            atomic[4] = -782
            atomic.insert(0, -9)
        self.assertEqual(items, [-9, 0, 1, -915, 2, -782, 5, 6, 7, 8, 9, 1999])


    def test_list_fail(self):
        def process():
            nonlocal items
            with Atomic.Atomic(items) as atomic:
                atomic.append(1999)
                atomic.insert(2, -915)
                del atomic[5]
                atomic[4] = -782
                atomic.pop()

            items = self.original_list[:]
            self.assertRaises(AttributeError, process)
            self.assertEqual(items, self.original_list)

if __name__ == "__main__":
    unittest.main()




#CODE LIST
blocks.py
Atomic.py
test_Modules.py 



#CODE HERE
test_Modules.py 

#!/usr/bin/env python3

import unittest
import test_Atomic


suite = unittest.TestLoader().loadTestsFromTestCase(test_Atomic.TestAtomic)
runner = unittest.TextTestRunner()
print(runner.run(suite))









#Reminder of topics<===========
CHAPTER 9 Debugging, Testing, and Profiling 

Debugging 
    Dealing with Syntax Errors 
    Dealing with Runtime Errors 
    Scientific Debugging
Unit Testing 
Profiling 
Summary


#CODE LIST
blocks.py
Atomic.py
test_Modules.py 



===============
Profiling 
===============

#If a program runs very slowly or consumes for more memory than we expect, the 
#problem is most often due to our choice of algorithms or data structures, or
#due to our doing an inefficient implementation. Whatever the reason for the 
#problem, it is best to find out precisely where the problem lies rather than
#just inspecting our code and trying to optimize it. Randomly optimizing can
#cause us to introduce bugs or speed up parts of our programs that actually
#have no effect on the program's overall performance b/c the improvements are
#not in plaes where the interpreter spends most of its time.

#Before going further into profiling, it is worth noting a few Python
#programming habits that are easy to learn and apply, and that are good for
#performance. None of the techniques is Python-version-specific, and all of
#them are perfectly sound Python programming style. 
#First, prefer tuples to lists when a read-only sequence is needed. 
#Second, use generators rather than creating large tuples or lists to iterabe over.
#Third, use Python's built-in data structures -- dicts, lists, and tuples, rather
#than custom data structures implemented in Python, since the built-in ones are all
#very highly optimized.
#Fourth, when creating large strings out of lots of small strings, instead of 
#concatenating the small strings, accumulate them all in a list, and join the list
#of strings into a single string at the end.
#Fifth and finally, if an object (including a function or method) is accessed a 
#large number of times via using attribute access (eg when accessing a function in 
#a module), or from a data structure, it may be better to create and use a local
#variable that refers to the object to provide faster access.

#Python's standard library provides two modules that are particularly useful when
#we want to investigate the performance of our code. One of these is the
timeit #module -- this is useful for timing small pieces of Python code, and can
#be used, for example, to compare the performance of two or more implementations 
#of a particular function or method. The other is the
cProfile #module which can be used to profile a program's performance -- it provides
#a detailed breakdown of call counts and times and so can be used to find performance
#bottlenecks.*
#*Note the cProfile module is usually available for CPtyhon interpreters, but is not
#always available for othes. All Python libraries should have the pur Python profile
#module which provides the same API as the cProfile module, and does the same job,
#only more slowly.

#To give a flavor of the timeit module, we will look at a small example. Suppose
#we have three functions, function_a(), function_b(), and function_c(), all of which
#perform the same computation, but each using a different algorithm. If we put all
#these functions into a module (or import them), we can run them using the timeit
#module to see how they compare. Here is the code that we would use at the end of
#the module:

    if __name__ == "__main__":
        repeats = 1000
        for function in ("function_a", "function_b", "function_c"):
            t = timeit.Timer("{0}(X, Y)".format(function), "from __main__ import {0}, X, Y".format(function))
            sec = t.timeit(repeats) / repeats
            print("{function}() {sec:.6f} sec".format(**locals()))

#The first argument given to the timeit.Timer() constructor is the code we want to
#exceute and time, in the form of a string. Here, the first time around the loop,
#the string is "function_a(X, Y)". The second argument is optional; again it is a 
#string to be executed, this time BEFORE the code to be time so as to provide some
#setup. Here we have imported from the __main__ (ie this) module the function we
#want to test, plus two variables that are passed as input data (X and Y), and that
#are available as global variables in the module. We could just as easily have
#imported the function and data from a different module.

#When the timeit.Timer objec's timeit() method is called, it will first execute the
#constructor's second argument -- if there was one -- to set things up, and then it
#will execute the constructor's first argument -- and time how long the execution
#takes. The timeit.Timer.timeit() method's return value is the time taken in seconds,
#as a float. By default, the timeit() method repeats 1 million times and returns the 
#total seconds for all these executions, but in this particular case we needed only
#1000 repeats to give useful results, so we specified the repeat count explicitly.
#After timing each function we divide the total by the number of repeats to get its
#mean (average) execution time and print the function's name and execution time
#on the console (console = screen output).

    function_a() = 0.001618 sec
    function_b() = 0.012786 sec
    function_c() = 0.003248 sec
#In this example, function_a() is clearly the fastest -- at least with the input data
#that was usd. In some situations -- for example, where performance can vary considerably
#depending on the input data -- we might have to test each function with multiple sets of
#input data to cover a representative set of cases and then compare the total or average
#excution times.

#It isnt always convenient to instrument our code to get timings, and so the timeit
#module provides a way of timing code from the command line. For example, to time
#function_a() from the MyModule.py module, we would enter the following in the console:
python3 -m timeit -n 1000 -s "from MyModule import function_a, X, Y" "function_a(X, Y)"

#as usual for Windows, we must replace ptyhon3 with something like:
# C:\Python31\python.exe
#The -m option is for the Python interpreter and tells it to load the specified module
#(in this case timeit) and the other options are handled by the timeit module. The -n
#option specifis the repetition count, the -s specifies the setup, and the last argument
#is the code to execute and time. After the command has finished it prints its results
#on the console, for example:
    1000 loops, best of 3: 1.41 msec per loop
#We can easily then repeat the timing for the other two functions so that we can compare
#them all.

#The cProfile module (or the profile module -- we will refer to them both as the cProfile
#module) can also be used to compare the performance of fucntions and methods. And unlike
#the timeit module that just provides raw timings, the cProfile module shows precisely
#what is being called and how long each call takes. Here's the code we would use to compare
#the same three functions as before:

    if __name__ = "__main__":
        for function in ("function_a", "function_b", "function_c"):
            cProfile.run("for i in range(1000): {0}(X, Y)".format(function))

#We must put the number of repeats inside the code we pass to the cProfile.run() function,
#but we dont need to do any setup since the module function uses introspection to find
#the functions and variables we want to use. There is no explicit print() statement
#since by default the cProfile.run(0 function prints its output on the console. Here are
#the results for all the functions (with some irrelevant lines omitted and slightly
#reformatted to fit the page):

    1003 function calls in 1.661 CPU seconds
     ncalls tottime percall cumtime percall filename:lineno(function)
           1   0.003   0.003    1.661   1.661 <string>:1(<module>)
        1000   1.658   0.002    1.658   0.002 MyModule.py:21(function_a)
           1   0.000   0.000    1.661   1.661 {built-in method exec}

    5132003 function calls in 22.700 CPU seconds 
     ncalls tottime percall cumtime percall filename:lineno(function)
          1   0.487   0.487  22.700  22.700 <string>:1(<module>)
       1000   0.011   0.000  22.213   0.022 MyModule.py:28(function_b)
    5128000   7.048   0.000   7.048   0.000 MyModule.py:29(<genexpr>)
       1000   0.005   0.000   0.005   0.000 {built-in method bisect_left}
          1   0.000   0.000  22.700  22.700 {built-in method exec}
       1000   0.001   0.000   0.001   0.000 {built-in method len}
       1000  15.149   0.015  22.196   0.022 {built-in method sorted}
    
    5129003 function calls in 12.987 CPU seconds
     ncalls tottime percall cumtime percall filename:lineno(function)
          1   0.205   0.205  12.987  12.987 <string>:1(<module>)
       1000   6.472   0.006  12.782   0.013 MyModule.py:36(function_c)
    5128000   6.311   0.000   6.311   0.000 MyModule.py:37(<genexpr>)
          1   0.000   0.000  12.987  12.987 {built-in method exec}

#The ncalls ("number of calls") column lists the number of calls to the specified
#function (listed in the filename:lineno(function) column). Recall that we repeated
#the calls 1000 times, so we must keep this in mind. The totime ("total time") column
#lists the total time spent in the function, but excluding time spent inside functions
#called by the funtion. The first percall column lists the average time of each call to
#the function (totime // ncalls). The cumtime ("cumulative time") column lists the time
#spent in the function and includes the time spent inside functions called by the
#function. The second percall column lists the average time of each call to the function,
#including functions called by it.

#This output is far more enlightening than the timeit module's raw timings. We can 
#immediately see that both function_b() and function_c() use generators that are called
#more than 5000 times, making them both at least ten times slower than function_a().
#Furthermore, function_b() calls more functions generally, including a call to the built-in
#sorted() function, and this makes it almost twice as slow as function_c(). Of course, the
#timeit() module gave us sufficient information to see these differences in timing, but the
#cProfile module allows us to see details of why the differences are there in the first place.

#Just as the timeit module allows us to time code without instrumenting it, so does the
#cProfile module. However, when using the cProfile module from the command line we cannot
#specify what we want executed -- it simply executes the given program or module and reports
#the timings of everything. The command line to use is
python3 -m cProfile programOrModule.py #and the output produced is in the same format as
#we say earlier; here is an extract slightly reformatted and with most lines omitted:

    10272458 function calls (10272457 primitive calls) in 37.718 CPU secs
     ncalls  tottime  percall  cumtime  percall filename:lineno(function)
          1    0.000    0.000   37.718   37.718 <string>:1(<module>)
          1    0.719    0.719   37.717   37.717 <string>:12(<module>)
       1000    1.569    0.002    1.569    0.002 <string>:20(function_a)
       1000    0.011    0.000   22.560    0.023 <string>:27(function_b)
    5128000    7.078    0.000    7.078    0.000 <string>:28(<genexpr>)
       1000    6.510    0.007   12.825    0.013 <string>:35(function_c) 
    5128000    6.316    0.000    6.316    0.000 <string>:36(<genexpr>)

#In cProfile terminology, a primitive call is a nonrecursive function call.

#Using the cProfile module in this way can be useful for identifying areas that are
#worth investigating further. Here, for example, we can clearly see that function_b()
#takes a long time. But how do we drill down into the details? We could instrument the
#program by replacing calls to function_b() with cProfile.run("function_b()"). Or we
#could save the complete profile data and analyze it using the pstats module. To save
#the profile we must modify our command line slightly:
python3 -m cProfile -o profileDataFile programOrModule.py #. We can then analyze the
#profile data, for example, by starting IDLE, importing the pstats module, and giving
#it the saved 
profileDataFile #or by using pstats interactively at the console. Here's a very short
#example console session that has been tidied up slightly to fit on the page, and with
#out input shown in bold:

INPUT $ python3 -m cProfile -o profile.dat MyModule.py 
INPUT $ python3 -m pstats
      Welcome to the profile statistics browser.
INPUT % read profile.dat                        #>>> read profile.dat
      profile.dat% callers function_b           #>>> read callers function_b
            Random listing order was used
            List reduced from 44 to 1 due to restriction <'function_b'>
      Function was called by...
                              ncalls tottime cumtime
      <string>:27(function_b) <- 1000 0.011 22.251 <string>:12(<module>)

INPUT      profile.dat% callees function_b      #>>> callees function_b
            Random listing order was used
            List reduced from 44 to 1 due to restriction <'function_b'> Function called...
                       ncalls tottime cumtime
      <string>:27(function_b) ->
                        1000 0.005 0.005 built-in method bisect_left 
                        1000 0.001 0.001 built-in method len
                        1000 15.297 22.234 built-in method sorted
INPUT profile.dat% quit                         #>>> quit

#Type help to get the list of commands, and help followed by a command name for more
#information on the command. For example, 
help stats # will list what arguments can be given to the stats command. Other tools are
#available that can provide a graphical visualization of the profile data, for example, 
#RunSnakeRun (www.vrplumber.com/programming/runsnakerun), which depends on the wxPython
#GUI library.


#Reminder of topics<===========
CHAPTER 9 Debugging, Testing, and Profiling 

Debugging 
    Dealing with Syntax Errors 
    Dealing with Runtime Errors 
    Scientific Debugging
Unit Testing 
Profiling 
Summary


#CODE LIST
blocks.py
Atomic.py
test_Modules.py 



===============
Summary
===============

#In general, Python's reporting of syntax errors is very accurate, with the line and 
#position in the line being correctly identified. The only cases where this doesnt
#work well are when we forget a closing parenthesis, bracket, or brace, in which
#case the error is normally reported as being on the next nonblank line. Foretuneately,
#sytnax errors are almost always easy to see and to fix.

#If an unhandled exception is raised, Python will terminate and output a traceback.
#Such tracebacks can be intimidating for end-users, but provide useful information
#to use as programmers. Ideally, we should always handle every type of exception that we
#believe our program can raise, and where necessary present the problem to the user in the
#form of an error message, message box, or log message -- but not as a raw traceback.
#However we should avoid using the catchall except: exception handler -- if we want to 
#handle all exceptions (eg at the top leve), then we can use 
except Exception as err #, and always report err, since silently handling exceptions can 
#lead to programs failing in subtle and unnoticed ways (such as corrupting data) later on.
#And during development, it is probably best not to have a top-level exception handler at
#all and to simply have the program crash with a traceback.

#Debugging need not be -- and should not be -- a hit and miss affair. By narrowing down the
#input necessary to reproduce the bug to the bar minimum, by carefully hypothesizing what 
#the problem is, and then testing the hypothesis by experiment -- using print() statements
#or a begugger -- we can often locate the source of the bug quite quickly. And if our
#hypothesis has successfully led us to the bug, it is likely to also be helpful in devising
#a solution.

#For testing, both the doctest and unittest modules have their own particular virtues.
doctests #tend to be particulariy convenient and useful for small libraries and modules
#since well-chosen tests can easily both illustrate and exercise boundary as well as
#common cases, and of course, writing doctests is convenient and easy. One the other hand,
unittests #are not constrained to be writtne inside docstrings and are written as 
#separate stand-alone modules, unittests are usually a better choice when it comes to
#writing more complex and sophisticated tests, especially tests that require setup and
#teardown (cleanup). For larger projects, using the unittest module (or a third-party unit
#testing module) keeps the tests and tested programs and modules separate and is generally
#more flexible and powerful than using doctests.

#If we hit performance problems, the cause is most often our own code, and in particular our
#choice of algorithms and data structures, or some inefficiency in our implementation. When
#faced with such problems, it is always wise to find out exactly where the performance
#bottleneck is, rather than to guess and end up spending time optimizing something that 
#doesnt actually improve performance. Python's timeit module can be used to get raw timings
#of functions or arbitrary code snippets, and so is particularly useful for comparing
#alternative function implementations. And for in-depth anaylsis, the cProfile module
#provides both timing and call count information so that we can identify not only which 
#function take the most time, but also what functions they in turn call.

#Overall, Python has excellent support for debugging, testing, and profiling, right out
#of the box. However, especially for large projects, it is worth considering some of the
#third-party testing tools, since they may offer more functionality and convenience than
#the standard library's testing module provide.












#Reminder of topics<===========
===============================================================================================
CHAPTER: 10 Processes and Threading 
CHAPTER BEGIN
===============================================================================================

Using the Multiprocessing Module 
Using the Threading Module 
    Example: A Threaded Find Word Program
    Example: A Threaded Find Duplicate Files Program 
Summary
Exercises 
#1) 
#2)

#ALL CODE FROM CHAPTER 9 website (Chap 10 pdf book)
findduplicates-t.py      -----------> see Exercise #2
findduplicates-t2.py
findduplicates-m.py
grepword-m.py
grepword-p-child.py
grepword-p.py           -----------> see Exercise #1
grepword-p_ans.py       -----------> see Exercise #1
grepword-t.py
xmlsummary.py           -----------> see Exercise #2


===============
Process and Threading
===============

#With the advent of multicore processors as the norm rather than the exception, it is more
#tempting and more practical than ever before to want to spred the processing load so as to 
#get the most out of all the available cores. There are two main approaches to spreading
#the workload. One is to use multiple processes and the other is to use multiple threads.

#Using multiple processes, that is, running seprate programs, has the advantge that each 
#process runs independently. This leaves all the burden of handling concurrency to the
#underlying operating system. The disadvantage is that communication and data sharing
#between the invoking program and the separate processes it invokes can be inconvient. On
#Unix systems this can be solved by using the exec and fork paradigm, but for cross-platform
#programs other solutions must be used. The simplist, and the ones shown here, is for
#the invoking program to feed data to the processes it runs and leave them to produce their
#output independently. A more flexible approach that greatly simplifies twp-way communication
#is to use networking. Of course, in many situations such communication is not needed -- we 
#just need to run one or more other programs from one orchestrating program.

#An alternative to handing off work to indpenedent proceses is to create a threaded program
#that distrites work to independent threads of execution. This has the advantage that we can 
#communicate simply by sharing data (providing we ensure that shared data is accessed only by
#one thread at a time), but leaves the burden of managing concurreny squarely with the
#programmer. Python provides good support for creating threaded programs, minimizing the
#work that we must do. Nonetheless, multithreaded programs are inherently more complex
#than single-threaded programs and require much more care in their creation
#and maintennance.

#In this chapter's first section we wll create two small programs. The first program is
#invoked by the user and the second program is invoked by the first program, with the
#second program invoked once for each seprate process that is required. In the second
#section, we will begin by giving a bare-bones introduction to threaded programming. Then
#we will create a threaded programs that has the same functionality as the two programs
#from the first section combined so as to provide a contrast between the multiple processes
#and the multiple threads approaches. Ant then we will review another threaded program,
#more sophisticated than the first, that both hands off work and gathers togeether all
#the results.


#Reminder of topics<===========
CHAPTER 10 Processes and Threading 

Using the Multiprocessing Module 
Using the Threading Module 
    Example: A Threaded Find Word Program
    Example: A Threaded Find Duplicate Files Program 
Summary
Exercises 
#1) 
#2)

#ALL CODE FROM CHAPTER 9 website (Chap 10 pdf book)
findduplicates-t.py      -----------> see Exercise #2
findduplicates-t2.py
findduplicates-m.py
grepword-m.py
grepword-p-child.py
grepword-p.py           -----------> see Exercise #1
grepword-p_ans.py       -----------> see Exercise #1
grepword-t.py
xmlsummary.py           -----------> see Exercise #2


===============
Using the Multiprocessing Module 
===============

#In some situations we already have programs that have the functionality we need
#but we want to automate their use. We can do this by using Python's 
subprocess #module which provides facilities for running other programs, passing
#any command line options we want, and if desired, communicating with them 
#using pipes. We saw one very simple example of this in Chapter 5 when we used the
subprocess.call() #function to clear the console in a platform specific way. But we
#can also use these facilities to create pairs of "parent-child" programs, where the
#parent program is run by the user and this in turn runds as many instances of the
#child program as necessary, each with different work to do. It is this approach
#that we will cover in this section.

#In Chapter 3, we showed a very simple program, grepword.py, that searches for
#a word specified on the command line in the files listed after the word. In
#this section we will develop a more sophisticated version that can recurse
#into subdirectories to find files to read and that can delegate the work to
#as many separate child processes as we like. The output is just a list of
#fileneames (with paths) for those files that contain the specified search word.

#The parent program is grepword-p.py and the child program is grepword-p-child.py
#The relationship between the two programs when they are being run is shown
#schematically in Figure 10.1.

#The heart of grepword-p.py is encapsulated by its main() function, which we will
#look at in three parts:

    def main():
        child = os.path.join(os.path.dirname(__file__), "grepword-p-child.py")
        opts, word, args = parse_options()
        filelist = get_files(args, otps.recurse)
        files_per_process = len(filelist) // ops.count
        start, end = 0, files_per_process + (len(filelist) % opts.count)
        number = 1

#We begin by getting the name of the child program. Then we get the user's
#command-line options. The parse_options() function uses the optparse module.
#It returns the opts names tuple which indicates whether the program should 
#recurse into subdirectories and the count of how many processes to use --- the
#default is 7, and program has an arbitrary chosen maximum of 20. It also returns
#the word to search for and the list of names (filenames and directory names) given
#on the command line. The get_files() function returns a list of files to be read.

#Once we have the information necessary to perform the task we calculate how many
#files must be given to each process to work on. The start and end variables are 
#used to specify the slice of the filelist that will be given to the next child process
#to work on. Usually, the number of files wont be an exact multiple of the number
#of processes, so we increase the number of files the first process is given
#by the remainer. The number variable isused purely for debugging so that we
#can see which process produced each line of output.

        pipes = []
        while start < len(filelist):
            command = [sys.executable, child]
            if opts.debug:
                command.append(str(number))
            pipe = subprocess.Popen(command, stdin=subprocess.PIPE)
            pipes.append(pipe)
            pipe.stdin.write(word.encode("utf8") + b"\n")
            for filename in filelist[start:end]:
                pipe.stdin.write(filename.encode("utf8") + b"\n")
            pipe.stdin.close()
            number += 1
            start, end = end, end + files_per_process

#For each start:end slice of the filelist we create a command line list containing of
#the Python interpreter (conveniently available in sys.executable), the child program
#we want Python to execute, and the command-line options -- in this case just the
#number if we are debugging. If the child program has a suitable shebang line or file
#association, we could list it first and not bother including the Python interpreter, but
#we prefer this approach b/c it ensures that the child program uses the same Python
#interpreter as the parent program.

#Once we have the command ready we create a
subprocess.Popen #object, specifying the command to execute (as a list of strings), and
#in this case requesting to write to the process's standard iput. (It is also possible to
#read a process's standard output by setting a similar keyword argument.) We then write
#the search word followed by a newline and then every file in the relevant slice of the
#file list. The subprocess module reads and writes bytes, not strings, but the processes
#it createss always assume that the bytes received from sys.stdin are strings in the 
#local encoding -- even if the bytes we have sent use a different encoding, such as
#UTF-8 which we have used here. We will see how to get around this annoying problem
#shortly. Once the word and list of files have been written to the child process, we 
#close its standard input and move on.

#It is not strictly necessary to keep a reference to each process (the pipe variable
#gets rebound to a new subprocess.Popen object each time through the loop), since
#each process runs indenpendently, but we add each one to a list so that we can make
#them interruptible. Also, we dont gather the results together, but instead we let
#each process write its results to the console in its own time. This means that the
#output from different processes could be interleaved. (You will get the chance to
#avoid interleaving in the exercises.)

        while pipes:
            pipe = pipes.pop()
            pipe.wait()

#Once all the processes have started we wait for each child process to finish. This
#is not essential, but on Unix-like systems it ensures that we are returned to the
#console prompt when all the processes are done (otherwise, we must press Enter when
#they are all finished). Another benefit of waiting is that if we interrupt the
#program (eg by pressing Ctrl+C), all the processes that are still running will be
#interrupted and will terminate with an uncaught KeyboardInterrput exception -- if
#we did not wait, the main program would finish (and therefore not be interrupteable),
#and the child processes would continue (unless killed by a kill program or a task
#manager.)

#Apart from the comments and imports, here is the complete grepword-p-child.py program.
#We will look at the program in two parts -- with two versions of the first part, 
#the first for any Python 3.x version and the second for Python 3.1 of later versions.

    BLOCK_SIZE = 8000

    number = "{0}: ".format(sys.argv[1]) if len(sys.argv) == 2 else ""
    stdin = sys.stdin.buffer.read()
    lines = stdin.decode("utf8", "ignore").splitlines()
    word = lines[0].rstrip()

#This program begis by setting the number string to the given number or to an empty
#if we are NOT debugging. Since the program is running as a child process and the
subprocess #module only reads and writes binary data and always uses the local
#encoding, we must read sys.stdin's underlying buffer of binary data and perform the
#decoding ourselves.*
#*Note It is possible that a future version of Python will have a version of the
#subprocess module that allows encoding and error arguments so that we can use our
#preferred encoding without having to access sys.stdin in binary mode and do the
#do the decoding ourselves. See bugs.python.org/issue6135
#Once we have read the binary data, we decode it into a Uniode string and split it
#into lines. The child process then reads the first line, since this contains the
#search word.

#Here are the lines that are different for Python 3.1:
    sys.stdin = sys.stdin.detach()
    stdin = sys.stdin.read()
    lines = stdin.decode("utd8", "ignore").splitlines()

#Python 3.1 provides the sys.stdin.detach() method that returns a binary file object.
#We then read in all the data, decode it into Unicode using the encoding of our choice,
#and then split the Unicdoe string intp lines.

    for filename in lines[1:]:
        filename = filename.rstrip()
        previous = ""
        try:
            with open(filename, "rb") as fh:
                while True:
                    current = fh.read(BLOCK_SIZE)
                    if not current:
                        break
                    current = current.decode("utf8", "ignore")
                    if (word in current or word in previous[-len(word):] + current[:len(word)]):
                        print("{0}{1}".format(number, filename))
                        break
                    if len(current) != BLOCK_SIZE:
                        break
                    previous = current
        except EnvironmentError as err:
            print("{0}{1}".format(number, err))

#All the lines after the first are filenames (with paths). For each one we open the
#relevant file, read it, and prints its name if it contains the search word. It is
#possible that some of the files might be very large and this could be a problem,
#especially if there are 20 child proceess running concurrently, all reading big files.
#We handle this by reading each file in blocks, keeping the previous block read to 
#ensure that we dont miss cases when the only occurrence of the search word happens
#to fall across two blocks. Another benefit of reading in blocks is that if the 
#search word appears early in the file we can finish with the file without having
#to read everything, since all we care about is whether the word is in the file, not
#where it appears within the file.

#The files are read in binary mode, so we must convert each block to a string before
#we can search it, since the search word is a string. We have assumed that all the file
#use UTF-8 encoding, but this is most likely wrong in some cases. A more sophisicated
#program would try to determine the actual encoding and then close and reopen the file
#using the correct encoding. As we noted in Chapter 2, at least two Python packages for
#automatically detecting a file's encoding are available from the Python Package Index
#pypi.python.org/pypi (It might be tempting to decode the search word into a bytes object
#and compare bytes with bytes, but that approach is not reliable sicne some characters
#have more than one valid UTF-8 representation.)

#The subprocess module offers a lot more functionality that we have needed to use here,
#including the ability to provide equivalents to shell backquotes and shell pipelines,
#and to the os.system() and spawn functions.

#In the next section, we will see a threaded version of teh grepword-p.py program so
#that we can compare it with the parent-child processes one. We will also look at a
#more sophisticated threaded program that delegates work and then gathers the 
#results together to have more control over how they are output.


#Reminder of topics<===========
CHAPTER 10 Processes and Threading 

Using the Multiprocessing Module 
Using the Threading Module 
    Example: A Threaded Find Word Program
    Example: A Threaded Find Duplicate Files Program 
Summary
Exercises 
#1) 
#2)

#ALL CODE FROM CHAPTER 9 website (Chap 10 pdf book)
findduplicates-t.py      -----------> see Exercise #2
findduplicates-t2.py
findduplicates-m.py
grepword-m.py
grepword-p-child.py
grepword-p.py           -----------> see Exercise #1
grepword-p_ans.py       -----------> see Exercise #1
grepword-t.py
xmlsummary.py           -----------> see Exercise #2


===============
Using the Threading Module 
===============

#Setting up two or more separate threads of execution in Python is quite 
#straightforward. The complexity arises when we want separate threads to 
#share data. Imagine that we have two threads sharing a list. One thread 
#might start iterating over the list using
for x in L #and then somewhere in the middle another thread might delete
#some items in the list. At best this will lead to obsure crashes, at worst
#to incorrect results.

#One common solution is to use some kind of locking mechanism. For example, 
#one thread might acquire a lock and then start iterating over the list; any
#other thread will then be blocked by the lock. In fact, things are not quite
#as clean as this. The relationship between a lock and the data it is locking
#exists purely in our imagination. If one thread acquires a lock and a second
#thread tries to acquire the same lock, the second thread will be blocked until
#the first thread releases the lock. By putting access to shared data within the
#scope of acquired locks, we can ensure that the shared data is accessed by only
#one thread at a time, even thought the protection is indirect.

#One problem with locking is the risk of deadlock. Suppose thread #1 acquires
#lock A so that it can access shared data a and then within the scope of lock A
#tries to acquire lock B so that it can access shared data b -- but it cannot
#acquire lock B b/c meanwhile, thread #2 has acquired lock B so that it can 
#access b, and is itself now trying to acquire lock A so that it can access a.
#So thread #1 holds lock A and is trying to acquire lock B, WHILE thread #2 holds
#lock B and is trying to acquire lock A. As a result, both threads are BLOCKED, sp
#the program is DEADLOCKED. See figure 10.2.

#Although it is easy to visualize this particular deadlock, in practice deadlocks 
#can be difficult to spot b/c they are not always so obvious. Some threading
#libraries are able to help with warnings about potential deadlocsk, but it
#requies human care and attention to avoid them.

#One simple yet effective way to avoid deadlocks is to have a policy that defines
#the order in which lockss should be acquired. For example, if we had the policy
#that lock A must alwasy be acquired before lock B, and we wanted to acquire lock B,
#the policy requires us to first acquire lock A. This would ensure that the deadlock
#described here would NOT occur -- since both threads would begin by trying to acquire
#A and the first one that did would then go on to lock B -- unless someone forgets to
#follow the policy.

#Another problem with locking is that if multiple threads are waiting to acquire
#a lcok, they are blocked and are not doing any useful work. We can mitigate this to
#a small extent with subtle changes to our coding style to minimize the amount of
#work we do within the context of a lock.

#Every Python program has at least one thread, the main thread. To create multiple
#threads we must import the 
threading #module and use that to create as many additional threads as we want.
#There are two ways to create threads: we can call 
threading.Thread() #and pass it a callable object, or we can subclass the
threading.Thread #class -- both approaches are shown in this chapter. Subclassing is
#the most flexible approach and is quite straightforward. Subclasses can reimplement
#__init__() (in which case they must call the base class implementation), and they must
#reimplement run() -- it is in this method that the thread's work is done. The run()
#method must never be called by our code -- threads are started by calling the start()
#method and that will call run() when it is ready. No other threading.Thread methods
#may be reimplemented, although adding additional methods is fine.


#Reminder of topics<===========
CHAPTER 10 Processes and Threading 

Using the Multiprocessing Module 
Using the Threading Module 
    Example: A Threaded Find Word Program
    Example: A Threaded Find Duplicate Files Program 
Summary
Exercises 
#1) 
#2)

#ALL CODE FROM CHAPTER 9 website (Chap 10 pdf book)
findduplicates-t.py      -----------> see Exercise #2
findduplicates-t2.py
findduplicates-m.py
grepword-m.py
grepword-p-child.py
grepword-p.py           -----------> see Exercise #1
grepword-p_ans.py       -----------> see Exercise #1
grepword-t.py
xmlsummary.py           -----------> see Exercise #2


===============
Using the Threading Module 
===============

#In this subsection we will review the code for the grepword-t.py program. This
#program does the same job as grepword-p.py, only it delegates the work to 
#multiple threads rather than to multiple processes. It is illustrated schematically
#in Figure 10.3.

#One particulary interesting feature of the program is that it does NOT appear to use
#any locks at all. This is possible b/c the only shared data is a list of file, and for
#these we use the queue.Queue class. That makes queue.Queue special is that it handles
#all the locking itself iternally, so whenever we access it to add or remove items, 
#we can rely on the queue itself to SERIALIZE accessess. In the context of threading,
#serializing access to data means ensuring that only one thread at a time has access
#to the data. Another benefit of using queue.Queue is that we dont have to shre out
#the work ourselves; we simply add items of work to the queue and leave the worker
#threads to pick up work whenever they are ready.

#The queue.Queue class works on a first in, first out (FIFO) basis; the queue module
#also provides 
queue.LifoQueue #for last in (LIFO) access, and 
queue.PriorityQueue #which is given tuples such as the 2-tuple (priority, item), with
#items with the lowest priority numbers being processed first. All the queues can be
#created with a maximum size set; if the maximum size is reached the queue will block
#further attempts to add items until items have been removed.

#We will look at the grepword-t.py program in three parts, starting with the 
#complete main() function:

    def main():
        opts, words, args = parse_options()
        filelist = get_files(args, opts.recurse)
        work_queue = queue.Queue()
        for in in range(opts.count):
            number = "{0}: ".format(i + 1) if opts. debug else ""
            worker = Worker(work_queue, word, number)
            worker.daemon = True
            worker.start()
        for filename in filelist:
            work_queue.put(filename)
        work_queue.join()

#Getting the user's options and the file list are the same as before. Once we have
#the necessary information we create a queue.Queue and then loop as many times as
#there are threads to be created; the default is 7. For each thread we prepare a 
#number string for debugging (an empty string if we are not debugging) and then
#we create a Worker (a
threading.Thread #subclass) instance -- we will come back to setting the 
daemon #property in a moment. Next we start off the thread, although at this point
#it has no work to do b/c the work queue is empty, so the thread will immediately
#be bllocked trying to get some work.

#With all the threads created and ready for work we iterate over all the files,
#adding each one to the work queue. As soon as the first file is added one of the
#threads could get it and start on it, and so on until all the threads have a file
#to work on. As soon as a thread finishes working on a file, it can get another one,
#until all the files are processed.

#Notice that this differs from grepword-p.py where we had to allocate slices of the
#file list to each child process, and the child processes were started and given 
#their lists sequentially. Using threads is potentially more efficient in cases 
#list this. For example, if the first five files are very large and the rest are
#small, b/c each thread takes on one job at a time, ech large gile will be
#processed by a separate thread, nicely spreading the work. But with the multiple
#processes approch we took in the grepword-p.py program, all the large files would
#be given to the first process and the small files given to the others, so the
#first process would end up doing most of the work while the others might all
#finish quickly without having done much at all.

#The program will not terminate while it has any threads running. This is a
#problem b/c once the worker threads have done their work, although they are
#have finished, they are technically still running. The solution is to turn
#the threads into daemons.
daemons  #The effect of this the program will terminate as soon as the program
#has no nondaemon threads running. The main thread is not a daoemon, so once
#the main thread finishes, the program will cleanly terminate each daemon
#thread and then terminate itself. Of course, this can now create the opposite
#problem -- once the threads are up and running we must ensure that the main
#thread does not finish until all the work is done. This is achieved by calling
queue.Queue.join() #this method blocks until the queue is empty.

#Here is the start of the worker class:

    class Worker(threading.Thread):

        def __init__(self, work_queue, word, number):
            super().__init__()
            self.work_queue = work_queue
            self.word = word
            self.number = number

        def run(self):
            while True:
                try:
                    filename = self.work_queue.get()
                    self.process(filename)
                finally:
                    self.work_queue.task_done()

#The __init__() method must call the base class __init__(). The work queue is
#the same queue.Queue shared by all the threads.

#We have made the run() method an infiite loop. This is common for daemon threads,
#and makes sense here b/c we dont know how many files the thread must proces. At
#each iteration we call queue.Queue.get() to get the next file to work on. This
#call will block if the queue is empty, and does not have to be protected by
#a lock b/c queue.Queue handles that automatically for us. Once we have a file
#we process it, and afterward we must tell the queue that we have done that
#particuar job -- calling queue.Queue.task_done() is essential to the correct
#working of queue.Queue.join().

#We have not shown the process() function, b/c apart from the def line, the code
#is the same as the code used grepwork-p-child.py from the 
previous = "" #line to the end (see pg 443).

#One final point to note is that included with the book's examples is 
grepword-m.py #, a program that is almost identical to the 
grepword-t.py #program reviewed here, but which uses the multiprocessing module rather 
#than the threading module. The code has just three differences: first, we import 
#multiprocessing instead of queue and threading; second, the Worker class
#inherits multiprocessing.Process insted of threading.Thread; and third, the
#work queue is a
multiprocessing.JoinableQueue #instead of a queue.Queue.

#The multiprocessing module provides thread-like functionality using forking
#on systems that support it (Unix), and child processes on those that dont
#(such as Windows), so locking mechninisms are not always required, and the
#processes will run on whatever processor cores the operating system has
#avialable. The package provides several ways of passing data between
#processes, including using a queue that can be used to provide work 
#for processes just like queue.Queue can be usd to provide work for threads.


#The cheif benefit of the multiprocessing wersion is that it can potentially
#run faster on multicore machnies that the threaded version since it can run
#its processes on as many cores as are available. Compere this with the 
#standard Python interpreter (written in C, sometimes called CPython) which
#has a GIL (Global Interpreter Lock) that means that only one thread can
#excute Python code at any one time. This restriction is an implementation
#detail and does not necessarily apply to other Python interpreterss such
#as Jython.*
#*Note for a brief explanation of why CPython uses a GIL 
#see www.python.org/doc/faq/library/#can-t_we_get-rid-of-the-global-interpreter-lock
#and docs.python.org/api.treads.html


#Reminder of topics<===========
CHAPTER 10 Processes and Threading 

Using the Multiprocessing Module 
Using the Threading Module 
    Example: A Threaded Find Word Program
    Example: A Threaded Find Duplicate Files Program 
Summary
Exercises 
#1) 
#2)

#ALL CODE FROM CHAPTER 9 website (Chap 10 pdf book)
findduplicates-t.py      -----------> see Exercise #2
findduplicates-t2.py
findduplicates-m.py
grepword-m.py
grepword-p-child.py
grepword-p.py           -----------> see Exercise #1
grepword-p_ans.py       -----------> see Exercise #1
grepword-t.py
xmlsummary.py           -----------> see Exercise #2


===============
    Example: A Threaded Find Duplicate Files Program 
===============

#The second threading example has a similar structure to the first, but is more
#sophisticated in several ways. It uses two queues, one for work and one for reults,
#and has a separate results processing thread to output results as soon as they are
#available. It also shows both a threading.Thread subclass and calling threading.Thread()
#with a function, and also uss a lock to serialize access to shared data (a dict).

#The findduplicates-t.py program is a more advanced version of the finddup.py
#program from Chapter 5. It iterates over all the files in the current directory
#(or the specified path), recursively going into subdirectories. It compares the
#lengths of all the files with the same name (just like findup.py), and for those
#files that have the same name and same size it then uses the MD5 (Message Digest)
#algorithm to check whether the files are the same, reporting any that are.

#We will start by looking at the main() function, split into four parts.

    def main():
        opts, path = parse_options()
        data = collections.defaultdict(list)
        for root, dirs, files in os.walk(path):
            for filename in files:
                fullname = os.path.join(root, filename)
                try:
                    key = (os.path.getsize(fullname), filename)
                except EnvironmentError:
                    continue
                if key[0] == 0:
                    continue 
                data[key].append(fullname)

#Each key of the data dictionary is a 2-tuple of (size, filename), where the
#filename does not include the path, and each value is a list of filenames (which
#do include their paths). Any items whose value list has more than one filename
#potentially has duplicates. The dictionary is populated by iterating over all the
#files in the given path, but skipping any files we cannot get the size of (perhaps
#due to permission problems, or bc they are not normal files), and any that
#are of 0 size (since all zero length files are the same).

        work_queue = queue.PriorityQueue()
        results_queue = queue.Queue()
        md5_from_filename = {}
        for i in range(opts.count):
            number =
            worker = 
            worker.daemon = True
            worker.start()

#With all the data in place we are ready to create the work threads. We begin by
#creating a work queue and a resuls queue. The work queue is a priority queue, so
#it will always return the lowest-priority items (in our case the smallest files)
#first. We also create a dictionary where each key is a filename (including its
#path) and where each value is the file's MD5 digest value. The purpose of the 
#dicionary is to ensure that we never compute the MD5 of the same file more
#than once (since the computation is expensive).

#With the shared data collections in place, we loop as many times as there are
#threads to create (by default, seven times). The Worker subclass is similar to
#the one we created before, only this time we pass both queues and the MD5 
#dictionary. As before, we start each worker straight away and each will be 
#blocked until a work item becomes available.

        results_thread = threading.Thread(target=lambda: print_results(results_queue))
        results_thread.daemon = True
        results_thread.start()

#Rather than creating a threading.Thread subclass to process the results, we
#have created a function and we pass that to threading.Thread(). The return
#value is a custom thread that will call the given function once the thread
#is started. We pass the results queue (which is, of course, empty), so the 
#thread will block immediately.

#At this point, we have created all the worker threads and the results thread
#and they are all blocked waiting for work.

        for size, filename in sorted(data):
            names = data[size, filename]
            if len(names) > 1:
                work_queue.put((size, names))
        work_queue.join()
        results_queue.join()

#We now iterate over the data, and for each (size, filename) 2-tuple that has
#a lst of two or more potentially duplicate files, we add the size and the 
#filenames with paths as an item of work to the work queue. Since the queue is
#a class from the queue module we dont have to worry about locking.

#Finally we join the work queue and results queue to block until they are empty.
#This ensures that the program runs until all the work is done and all the
#results have been output, and then terminates cleanly.

    def print_results(results_queue):
        while True:
            try:
                results = results_queue.get()
                if results:
                    print(results)
            finally:
                results_queue.task_done()

#This function is passed as an argument to threading.Thread() and is called when
#the thread it is given to is started. It has an infinite loop b/c it is to be
#used as a daemon thread. All it does is get results (a multiline string), and 
#if the string is nonempty, it prints it for as long as results are available.

#The beginning of the Worker class is similar to what we had before:

    class Worker(threading.Thread):

        Md5_lock = threading.Lock()

        def __init__(self, work_queue, md5_from_filename, results_queue, number):
          super().__init__()
          self.work_queue = work_queue
          self.md5_from_filename = md5_from_filename
          self.results_queue = results_queue
          self.number = number

        def run(self):
          while True:
            try:
              size, names = self.work_queue.get()
              self.process(size, names)
            finally:
              self.work_queue.task_done()

#The differences are that we have more shared data to keep track of and we call
#our custom process() function with different arguments. We dont have to worry
#about the queues since they ensure that accesses are serialized, but for other
#data items, in this case the md5_from_filename dictionary, we must handle the
#serialization ourselves by providing a lock. We have made the lock a class
#attribute b/c we want every Worker instance to use the same lock so that if
#one instance holds the lock, all the other instances are blocked if they try
#to acquire it.

#We will review the process() function in two parts:

  def process(self, size, filenames):
    md5s = collections.defaultdict(set)
    for filename in filenames:
      with self.Md5_lock:
        md5 = self.md5_from_filename.get(filename, None)
      if md5 is not None:
        md5s[md5].add(filename)
      else:
        try:
          md5 = hashlib.md5()
          with open(filename, "rb") as fh:
            md5.update(fh.read())
          md5 = md5.digest()
          md5s[md5].add(filename)
          with self.Md5_lock:
            self.md5_from_filename[filename] = md5
        except EnvironmentError:
          continue

#We start out with an empty default dictionary where each key is to be an MD5 digest
#value and where wach value is to be a set of the filenames of the files that have
#the corresponding MD5's value. We then iterate over all the files, and for each one
#we retrieve its MD5 if we have already calculated it, and calculated it otherwise.

#Whether we access the md5_from_filename dictionary to read it or to write to it,
#we put the access in the context of a lock. Instances of the threading.Lock() class
#are context managers that acquire the lock on entry and release the lock on exit.
#The with statements will block if another thread has the Md5_lock, until the lock
#is released. For the first with statement, when we acquire the lock we get the MD5
#from the dictionary (or None if it isnt there). If the MD5 is None we must compute
#it, in which case we store it in teh md5_from_filename dictionary to avoid
#performing the computation more than once per file.

#Notice that at all times we try to minimize the amount of work done within the
#scope of a lock to keep blocking to a minimum -- in this case just one dictionary
#access each time.

#Strictly speaking, we do not need to use a lock at all if we are using CPython
#since the GIL effectively synchronizes dictionary accesses for us. However, we 
#have chosen to program without relying on the GIL implementation detail, and
#so we use an explicit lock.

        for filennames in md5.values():
          if len(filenames) == 1:
            continue
          self.results_queue.put("{0}Duplicate files ({1:n}):"
                                 "\n\t{2}".format(self.number, size,
                                  "\n\t".join(sorted(filenames))))

#At the end we loop over the local md5s default dictionary, and for each set
#of names that contais more than one name, we add a multiline string to the
#results queue. The string contains the worker thread number (an empty string
#by default), the size of the file in bytes, and all the duplicate filenames.
#We dont need to use a lock to access the results queue since it is a
queue.Queue #which will automatically handle the locking behind the scenes.

#The queue module's classes greatly simplify threaded applications, and when
#we need to use explicit locks the threading module offers many options. Here
#we used the simplest
threading.Lock #but others are available, including
threading.RLock #a lock that can be acquired again by the thread that already hold it,
threading.Semaphone #a lock that can be used to protect a specific number of resources,
threading.Condition #that provides a wait condition.

#Using multiple threads can often lead to cleaner solutions than using the subprocess
#module, but unforetuneatly, threaded Python programs do not necessarily achieve the
#best possible performance compared with using multiple processes. As noted earlier,
#the problem afflicts the standard implementation of Python, since the CPython 
#interpreter can execute Python code on only one processor at a time, even when using
#multiple threads.

#One package that tries to solve this problem is the multiprocessing module, and as we
#noted earlier, the grepwork-m.py program is a multiprocessing version of the 
#grepword-t.py program, with only three lines that are different. A similar
#transformation could be applied to the findduplicates-t.py program reviewed here, but
#in practice this is not recommended. Although the multiprocessing module offers an
API that closely matches the threading module's API to ease conversion, the two APIs'
#are not the same and have different tradeoffs. Also, performing a mechanistic
#conversion from threading to multiprocessing is to be successful only on small, simple
#program like grepword-t.py; it is too crude an approach to use for the 
findduplicates-t.py #program, and in general it is best to design programs from the 
#ground up with multiprocessing in mind. (The program findduplicattes-m.py is 
#provided with the book's examples; it does the same job as findduplicates-t.py but
#works in a VERY DIFFERENT way and uses the multiprocessing module.)

#Another solution being developed is a threading-friendly version of the CPython
#interpreter, see www.code.google.com/p/python-threadsafe for the lastest
#project status.

#Reminder of topics<===========
CHAPTER 10 Processes and Threading 

Using the Multiprocessing Module 
Using the Threading Module 
    Example: A Threaded Find Word Program
    Example: A Threaded Find Duplicate Files Program 
Summary
Exercises 
#1) 
#2)

#ALL CODE FROM CHAPTER 9 website (Chap 10 pdf book)
findduplicates-t.py      -----------> see Exercise #2
findduplicates-t2.py
findduplicates-m.py
grepword-m.py
grepword-p-child.py
grepword-p.py           -----------> see Exercise #1
grepword-p_ans.py       -----------> see Exercise #1
grepword-t.py
xmlsummary.py           -----------> see Exercise #2


===============
Summary
===============

#This chapter showed how to create programs that can execute other program using the
#standard library's subprocess module. Programs that are run using subprocess can be
#given command-line data, can be fed data to their standard input, and can have their
#standard output (and standard error) read. Using child processes allows us to take
#maximum advantage of multicore processors and leaves concurrency issues to be handled
#by the operating system. The downside is that if we need to share data or synchronize
#processes we must devise some kind of communication mechamism, for example, shared
#memory (eg using the mmap module), shared files, or networking, and this can require
#care to get right.

#The chapter also showed how to create multithreaded programs. Unforetuneately, such
#programs cannot take full advantage of multiple cores (if run using the standard
#CPython interpreter), so for Python, using multiple processes is often a more
#practical solution where performance is concerned. Nonetheless, we saw that the queue
#module and Python's locking mechanisms, such as threading.Lock, make threaded
#programming as straightforward as possible -- and that for simple programs that only 
#need to use queue objects like queue.Queue and queue.PriorityQueue, we may be able to
#completely avoid using explict locks.

#Although multithreaded programming is undoubtedly fashionable, it can be much more
#demanding to write, maintain, and debug multithreaded programs than single-threaded
#ones. However, multithreaded programs allow for straightforward communication, for 
#examples, using shared data (providing we use a queue class or use locking), and
#makes it much easier to synchronize (eg to gather results) than using child processes.
#Threading can also be very useful in GUI program that must carry out long-running tasks
#while maintaining responsiveness, including the abilty to cancel the task being worked
#on. But if a good communication mechanism between processes is used, such as shared
#memory, or the process-transparent queue offered by the multiprocessing package, using
#multiple processes can often be a viable alternative to multiple threads.

#The following chapter shows another example of a threaded proram; a server that 
#handles each client request in a separate thread, and that uses locks to protect
#shared data.


#CODE HERE - SUMMARY
#ALL CODE FROM CHAPTER 9 website (Chap 10 pdf book)
findduplicates-t.py      -----------> see Exercise #2
findduplicates-t2.py
findduplicates-m.py
grepword-m.py
grepword-p-child.py
grepword-p.py           -----------> see Exercise #1
grepword-p_ans.py       -----------> see Exercise #1
grepword-t.py
xmlsummary.py           -----------> see Exercise #2




#CODE HERE
findduplicates-t.py      -----------> see Exercise #2

#!/usr/bin/env python3

import locale
locale.setlocale(locale.LC_ALL, "")

import collections
import hashlib
import itertools
import optparse
import os
import queue
import sys
import threading
import Util


class Worker(threading.Thread):

    Md5_lock = threading.Lock()

    def __init__(self, work_queue, md5_from_filename, results_queue, number):
        super().__init__()
        self.work_queue = work_queue
        self.md5_from_filename = md5_from_filename
        self.results_queue = results_queue
        self.number = number

    def run(self):
        while True:
            try:
                size, names = self.work_queue.get()
                self.process(size, names)
            finally:
                self.work_queue.task_done()

    def process(self, size, filenames):
        md5s = collections.defaultdict(set)
        for filename in filenames:
            with Worker.Md5_lock:
                md5 = self.md5_from_filename.get(filename, None)
            if md5 is not None:
                md5s[md5].add(filename)
            else:
                try:
                    md5 = hashlib.md5()
                    with open(filename, "rb") as fh:
                        md5.update(fh.read())
                    md5 = md5.digest()
                    md5s[md5].add(filename)
                    with Worker.Md5_lock:
                        self.md5_from_filename[filename] = md5 
                except EnvironmentError:
                    continue
        for filenames in md5s.values():
            if len(filenames) == 1:
                continue
            self.results_queue.put("{0}Duplicate files ({1:n} bytes):\n\t{2}".format(self.number, size, "\n\t".join(sorted(filenames))))

def main():
    opts, path = parse_options()
    data = collections.defaultdict(list)
    if opts.verbose:
        print("Creating file list...")
    for root, dirs, files in os.walk(path):
        for filename in files:
            fullname = os.path.join(root, filename)
            try:
                key = (os.path.getsize(fullname), filename)
            except EnvironmentError:
                continue
            if key[0] == 0:
                continue
            data[key].append(fullname)

    if opts.verbose:
        print("Creating {0} thread{1}...".format(opts.count, Util.s(opts.count)))
    work_queue = queue.PriorityQueue()
    results_queue = queue.Queue()
    md5_from_filename = {}
    for i in range(opts.count):
        number = "{0}: ".format(i + 1) if opts.debug else ""
        worker = Worker(work_queue, md5_from_filename, results_queue, number)
        worker.daemon = True 
        worker.start()

    results_thread = threading.Thread(target=lambda: print_results(results_queue))
    results_thread.daemon = True 
    results_thread.start()

    for size, filename in sorted(data):
        names = data[size, filename]
        if len(names) > 1:
            work_queue.put((size, names))
    work_queue.join()
    results_queue.join()

def print_results(results_queue):
    while True:
        try:
            results = results_queue.get()
            if results:
                print(results)
        finally:
            results_queue.task_done()

def parse_options():
    parser = optparse.OptionParser(
            usage=("usage: %prog [options] [path]\n"
                    "outputs a list of duplicate files in path"
                    "using the MD5 algorithm\n"
                    "ignores zero-length files\n"
                    "path defaults to ."))
    parser.add_option("t", "--threads", dest="count", default=7, type="int",
                    help=("the number of threads to use (1..20) [default %default]"))
    parser.add_option("-d", "--debug", dest="debug", default=False, action="store_true")
    opts, args = parser.parse_args()
    if not (1 <= opts.count <= 20):
        parser.error("thread count must be 1..20")
    return opts, args[0] if args else "."


main()




#CODE HERE
findduplicates-t2.py

#!/usr/bin/env python3

import locale
locale.setlocale(locale.LC_ALL, "")

import collections
import hashlib
import itertools
import optparse
import os
import queue
import sys
import threading
import Util


class Worker(threading.Thread):

    Md5_lock = threading.Lock()

    def __init__(self, work_queue, md5_from_filename, results_queue, number):
        super().__init__()
        self.work_queue = work_queue
        self.md5_from_filename = md5_from_filename
        self.results_queue = results_queue
        self.number = number

    def run(self):
        while True:
            try:
                size, names = self.work_queue.get()
                self.process(size, names)
            finally:
                self.work_queue.task_done()

    def process(self, size, filenames):
        md5s = collections.defaultdict(set)
        for filename in filenames:
            with Worker.Md5_lock:
                md5 = self.md5_from_filename.get(filename, None)                
            #if md5 is not None:
            if md5 is None:
#               md5s[md5].add(filename)
#           else:
                try:
                    md5 = hashlib.md5()
                    with open(filename, "rb") as fh:
                        md5.update(fh.read())
                    md5 = md5.digest()
#                   md5s[md5].add(filename)
                    with Worker.Md5_lock:
                        self.md5_from_filename[filename] = md5 
                except EnvironmentError:
                    continue
            md5s[md5].add(filename)  #MOVED FROM ABOVE
        for filenames in md5s.values():
            if len(filenames) == 1:
                continue
            self.results_queue.put("{0}Duplicate files ({1:n} bytes):"
                                    "\n\t{2}".format(self.number, size, 
                                    "\n\t".join(sorted(filenames))))

def main():
    opts, path = parse_options()
    data = collections.defaultdict(list)
    if opts.verbose:
        print("Creating file list...")
    for root, dirs, files in os.walk(path):
        for filename in files:
            fullname = os.path.join(root, filename)
            try:
                key = (os.path.getsize(fullname), filename)
            except EnvironmentError:
                continue
            if key[0] == 0:
                continue
            data[key].append(fullname)

    if opts.verbose:
        print("Creating {0} thread{1}...".format(opts.count, Util.s(opts.count)))
    work_queue = queue.PriorityQueue()
    results_queue = queue.Queue()
    md5_from_filename = {}
    for i in range(opts.count):
        number = "{0}: ".format(i + 1) if opts.debug else ""
        worker = Worker(work_queue, md5_from_filename, results_queue, number)
        worker.daemon = True 
        worker.start()

    results_thread = threading.Thread(target=lambda: print_results(results_queue))
    results_thread.daemon = True 
    results_thread.start()

    for size, filename in sorted(data):
        names = data[size, filename]
        if len(names) > 1:
            work_queue.put((size, names))
    work_queue.join()
    results_queue.join()

def print_results(results_queue):
    while True:
        try:
            results = results_queue.get()
            if results:
                print(results)
        finally:
            results_queue.task_done()

def parse_options():
    parser = optparse.OptionParser(
            usage=("usage: %prog [options] [path]\n"
                    "outputs a list of duplicate files in path"
                    "using the MD5 algorithm\n"
                    "ignores zero-length files\n"
                    "path defaults to ."))
    parser.add_option("t", "--threads", dest="count", default=7, type="int",
                    help=("the number of threads to use (1..20) [default %default]"))
    parser.add_option("-d", "--debug", dest="debug", default=False, action="store_true")
    opts, args = parser.parse_args()
    if not (1 <= opts.count <= 20):
        parser.error("thread count must be 1..20")
    return opts, args[0] if args else "."


main()






#CODE HERE
findduplicates-m.py

#!/usr/bin/env python3

import locale
locale.setlocale(locale.LC_ALL, "")

import collections
import hashlib
import optparse
import os
import multiprocessing


def main():
    opts, path = parse_options()
    data = collections.defaultdict(list)
    if opts.verbose:
        print("Creating file list...")
    for root, dirs, files in os.walk(path):
        for filename in files:
            fullname = os.path.join(root, filename)
            try:
                key = (os.path.getsize(fullname), filename)
            except EnvironmentError:
                continue
            if key[0] == 0:
                continue
            data[key].append(fullname)

    items = []
    for key in sorted(data):
        if len(data[key]) > 1:
            items.append((key[0], tuple(data[key])))
    if items:
        pool = multiprocessing.Pool()
        pool.map_async(check_one_item, items, 1, print_result)
        pool.close()
        pool.join()

def check_one_item(item):
    filenames = item[1]
    md5s = collections.defaultdict(set)
    for filename in filenames:
        try:
            md5 = hashlib.md5()
            with open(filename, "rb") as fh:
                md5.update(fh.read())
            md5 = md5.digest()
            md5s[md5].add(filename)
        except EnvironmentError:
            continue
    results = []
    for filenames in md5s.values():
        if len(filenames) == 1:
            continue
        results.append("Duplicate files ({0:n} bytes):\n\t{1}".format(item[0], "\n\t".join(sorted(filenames))))
    return "\n".join(results)

def print_result(results):
    for result in results:
        if result:
            print(result)

def parse_options():
    parser = optparse.OptionParser(
            usage=("usage: %prog [options] [path]\n"
                    "outputs a list of duplicate files in path"
                    "using the MD5 algorithm\n"
                    "ignores zero-length files\n"
                    "path defaults to ."))
    parser.add_option("v", "--verbose", dest="verbose", default=False, action="store_true")
    parser.add_option("-d", "--debug", dest="debug", default=False, action="store_true")
    opts, args = parser.parse_args()
    return opts, args[0] if args else "."

if __name__ == "__main__":      #This is *vital* on Window
    main()


#ALL CODE FROM CHAPTER 9 website (Chap 10 pdf book)
findduplicates-t.py      -----------> see Exercise #2
findduplicates-t2.py
findduplicates-m.py
grepword-m.py
grepword-p-child.py
grepword-p.py           -----------> see Exercise #1
grepword-p_ans.py       -----------> see Exercise #1
grepword-t.py
xmlsummary.py           -----------> see Exercise #2


#CODE HERE
grepword-m.py

#!/usr/bin/env python3

import multiprocessing
import optparse
import os

#maximum length of the word to be searched for is BLOCK_SIZE
BLOCK_SIZE = 8000

class Worker(multiprocessing.Process):

    def __init__(self, work_queue, word, number):
        super().__init__()
        self.work_queue = work_queue
        self.word = word
        self.number = number 

    def run(self):
        while True:
            try:
                filename = self.work_queue.get()
                self.process(filename)
            finally:
                self.work_queue.task_done()

    def process(self, filename):
        previous = ""
        try:
            with open(filename, "rb") as fh:
                while True:
                    current = fh.read(BLOCK_SIZE)
                    if not current:
                        break
                    current = current.decode("utf8", "ignore")
                    if (self.word in current 
                    or self.word in previous[-len(self.word):] +
                                    current[:len(self.word)]):
                        print("{0}{1}".format(self.number, filename))
                        break
                    if len(current) != BLOCK_SIZE:
                        break
                    previous = current
        except EnvironmentError as err:
            print("{0}{1}".format(self.number, err))

def parse_options():
    parser = optparse.OptionParser(
            usage=("usage: %prog [options] or paths; paths only "
                    "[name2 [... nameN]]\n\n"
                    "names are filenames or paths; paths only "
                    "make sense with the -r option set"))
    parser.add_option("-p", "--processes", dest="count", default=7, type="int",
            help=("the number of processes to use (1..20)  [default %default]"))
    parser.add_option("-r", "--recurse", dest="recurse", default=False, 
            action="store_true", help="recurse into subdirectories")
    parser.add_option("-d", "--debug", dest="debug", default=False, action="store_true")
    opts, args = parser.parse_args()
    if len(args) == 0:
        parser.error("a word and at least one path must be specified")
    elif len(args) == 1:
        parser.error("at least one path must be specified")
    if (not opts.recurse and not any([os.path.isfile(arg) for arg in args])):
        parser.error("at least one file must be specified; or use -r")
    if not (1 <= opts.count <= 20):
        parser.error("process count must be 1..20")
    return opts, args[0], args[1:]


def get_files(args, recurse):
    filelist = []
    for path in args:
        if os.path.isfile(path):
            filelist.append(path)
        elif recurse:
            for root, dirs, files in os.walk(path):
                for filename in files:
                    filelist.append(os.path.join(root, filename))
    return filelist

def main():
    opts, word, args = parse_options()
    filelist = get_files(args, opts.recurse)
    work_queue = multiprocessing.JoinableQueue()
    for i in range(opts.count):
        number = "{0}: ".format(i + 1) if opts.debug else ""
        worker = Worker(work_queue, word, number)
        worker.daemon = True 
        worker.start()
    for filename in filelist:
        work_queue.put(filename)
    work_queue.join()


if __main__ == "__main__":  #This is *vital) for Windows
    main()




#CODE HERE
grepword-p-child.py

#!/usr/bin/env python3

import sys

# The maximum length of the word to be searched for is BLOCK_SIZE
BLOCK_SIZE = 8000

number = "{0}: ".format(sys.argv[1]) if len(sys.argv) == 2 else ""
stdin = sys.stdin.buffer.read()
lines = stdin.decode("utd8", "ignore").splitlines()
word = lines[0].rstrip()

for filename in lines[1:]:
    filename = filename.rstrip()
    previous = ""
    try:
        with open(filename, "rb") as fh:
            while True:
                current = fh.read(BLOCK_SIZE)
                if not current:
                    break
                current = current.decode("utf8", "ignore")
                if (word in current or word in previous[-len(word):] + current["len(word)"]):
                    print("{0}{1}".format(number, filename))
                    break
                if len(current) != BLOCK_SIZE:
                    break
                previous = current 
    except EnvironmentError as err:
        print("{0}{1}".format(number, err))



#CODE HERE
grepword-p.py           -----------> see Exercise #1

#!/usr/bin/env python3

import optparse
import os
import subprocess
import sys

def main():
    child = os.path.join(os.path.dirname(__file__), "grepwod-p-child.py")
    opts, word, args = parse_options()
    filelist = get_files(args, opts.recurse)
    files_per_process = len(filelist) // opts.count
    start, end = 0, files_per_process + (len(filelist) % opts.count)
    number = 1

    pipes = []
    while start < len(filelist):
        command = [sys.executable, child]
        if opts.bebug:
            command.append(str(number))
        pipe = subprocess.Popen(command, stdin=subprocess.PIPE)
        pipes.append(pipe)
        pipe.stdin.write(word.encode("utf8") + b"\n")
        for filename in filelist[start:end]:
            pipe.stdin.write(filename.encode("utf8") + b"\n")
        pipe.stdin.close()
        number += 1
        start, end = end, end + files_per_process
    while pipes:
        pipe = pipes.pop()
        pipe.wait()

def parse_options():
    parser = optparse.OptionParser(
            usage=("usage: %prog [options] word name1 "
                    "[name2 [... nameN]]\n\n"
                    "names are filenames or paths; paths only "
                    "make sense with the -r option set"))
    parser.add_option("-p", "--processes", dest="count", default=7, type="int",
            help=("the number of child processes to use (1..20) [default %default]"))
    parser.add_option("-r", "--recurse", dest-"recurse", default=False, action="store_true",
            help="recurse into subdirectories")
    parser.add_option("-d", "--debug", dest="debug", default=False, action="store_true")
    opts, args = parser.parse_args()
    if len(args) == 0:
        parser.error("a word and at least one path must be specified")
    elif len(args) == 1:
        parser.error("at least one path must be specified")
    if (not opts.recurse and not any ([os.path.isfile(arg) for arg in args])):
        parser.error("process count must be 1..20")
    return opts, args[0], args[1:]

def get_files(args, recurse):
    filelist = []
    for path in args:
        if os.path.isfile(path):
            filelist.append(path)
        elif recurse:
            for root, dirs, files in os.walk(path):
                for filename in files:
                    filelist.append(os.path.join(root, filename))
    return filelist

main()



#ALL CODE FROM CHAPTER 9 website (Chap 10 pdf book)
findduplicates-t.py      -----------> see Exercise #2
findduplicates-t2.py
findduplicates-m.py
grepword-m.py
grepword-p-child.py
grepword-p.py           -----------> see Exercise #1
grepword-p_ans.py       -----------> see Exercise #1
grepword-t.py
xmlsummary.py           -----------> see Exercise #2


#CODE HERE
grepword-p_ans.py       -----------> see Exercise #1

#!/usr/bin/env python3

import optparse
import os
import subprocess
import sys


def main():
    child = os.path.join(os.path.dirname(__file__), "grepword-p-child.py")
    opts, word, args = parse_options()
    filelist = get_files(args, opts.recurse)
    files_per_process = len(filelist) // opts.count
    start, end = 0, files_per_process + (len(filelist) % opts.count)
    number = 1

    pipes = []
    while start < len(filelist):
        command = [sys.executable, child]
        if opts.debug:
            command.append(str(number))
        pipe = subprocess.Popen(command, stdin=subprocess.PIPE, stout=subprocess.PIPE)
        pipes.append((pipe, pipe.stdout))
        pipe.stdin.write(word.encode("utf8") + b"n")
        for filename in filelist[start:end]:
            pipe.stdin.write(filename.encode("utf8") + b"\n")
        pipe.stdin.close()
        number += 1
        start, end = end, end + files_per_process

    results = []
    while pipes:
        pipe, stdout = pipes.pop()
        results.extend(stdout.readlines())
        pipe.wait()
    for line in sorted(results):
        print(line.decode("utd8").rstrip())

def parse_options():
    parser = optparse.OptionParser(
            usage=("usage: %prog [options] word name1 ",
                    "[name2 [... nameN]]\n\n",
                    "names are filenames or paths; paths only ",
                    "makes sense with the -r option set"))
    parser.add_option("-p", "--processes", dest="count", default=7,type="int",
                    help=("the number of child processes to use (1..20) [default %default]"))
    parser.add_option("-r", "--recurse", dest="recurse", default=False, action="store_true",
                    help="recurse into subdirectories")
    parser.add_otpion("-d", "--debug", dest="debug", default=False, action="store_true")
    opts, args = parser.parse_args()
    if len(args) == 0:
        parser.error("a word and at least one path must be specified")
    elif len(args) == 1:
        parser.error("at least one path must be specified")
    if (not opts.recuse and not any([os.path.isfile(arg) for arg in args])):
        parser.error("at least one file must be specified; or ues -r")
    if not (1 <= opts.count <= 20):
        parser.error("process count must be 1..20")
    return opts, args[0], args[1:]

def get_files(args, recurse):
    filelist = []
    for path in args:
        if os.path.isfile(path):
            filelsit.append(path)
        elif recurse:
            for root, dirs, files in os.walk(path):
                for filename in files:
                    filelist.append(os.path.join(root, filename))
    return filelist

main()



#ALL CODE FROM CHAPTER 9 website (Chap 10 pdf book)
findduplicates-t.py      -----------> see Exercise #2
findduplicates-t2.py
findduplicates-m.py
grepword-m.py
grepword-p-child.py
grepword-p.py           -----------> see Exercise #1
grepword-p_ans.py       -----------> see Exercise #1
grepword-t.py
xmlsummary.py           -----------> see Exercise #2


#CODE HERE
grepword-t.py

#!/usr/bin/env python3

import optparse
import os
import queue
import threading

#The maximum length of the word to be searched for is BLOCK_SIZE
BLOCK_SIZE = 8000

class Worker(threading.Thread):

    def __init__(self, work_queue, word, number):
        super().__init__()
        self.work_queue = work_queue
        self.word = word
        self.number = number

    def run(self):
        while True:
            try:
                filename = self.work_queue.get()
                self.process(filename)
            finally:
                self.work_queue.task_done()

    def process(self, filename):
        previous = ""
        try:
            with open(filename, "rb") as fh:
                while True:
                    current = fh.read(BLOCK_SIZE)
                    if not current:
                        break
                    current = current.decode("utf8", "ignore")
                    if (self.word in current or self.word in previous[-len(self.word):] + self.word in current[:len(self.word)]):
                        print("{0}{1}".format(self.number, filename))
                        break
                    if len(current) != BLOCK_SIZE:
                        break
                    previous = current
        except EnvironmentError as err:
            print("{0}{1}".format(self.number, err))

def main():
    opts, word, args = parse_options()
    filelist = get_files(args, opts.recurse)
    work_queue = queue.Queue()
    for i in range(opts.count):
        number = "{0}: ".format(i + 1) if opts.debug else ""
        worker = Worker(work_queue, word, number)
        worker.daemon = True 
        worker.start()
    for filename in filelist:
        work_queue.put(filename)
    work_queue.join()

def parse_options():
    parser = optparse.OptionParser(
        usage=("usage: %prog [options] word name1 "
                "[name2 [... nameN]]\n\n"
                "names are filenames or paths; paths only "
                "make sense with the -r option set"))
    parser.add_option("-t", "--threads", dest="count", default=7, type="int",
                help=("the number of threads to use (1..20) [default %default]"))
    parser.add_option("-r", "--recurse", dest="recurse", default=False, action="store_true",
                help="recurse into subdirectors")
    parser.add_option("-d", "--debug", dest="debug", default=False, action="store_true")
    opts, args = parser.parse_args()
    if len(args) == 0:
        parser.error("a word and at least one path must be specified")
    elif len(args) == 1:
        parser.error("at least one path must be specified")
    if (not opts.recurse and not any ([os.path.isfile(arg) for arg in args])):
        parser.error("at least one file must be specified; or use -r")
    if not (1 <= opts.count <= 20):
        parser.error("thread count must be 1..20")
    return opts, args[0], args[1:]

def get_files(args, recurse):
    filelist = []
    for path in args:
        if os.path.isfile(path):
            filelist.append(path)
        elif recurse:
            for root, dirs, files in os.walk(path):
                for filename in files:
                    filelist.append(os.path.join(root, filename))
    return filelist


main()



#Reminder of topics<===========
CHAPTER 10 Processes and Threading 

Using the Multiprocessing Module 
Using the Threading Module 
    Example: A Threaded Find Word Program
    Example: A Threaded Find Duplicate Files Program 
Summary
Exercises 
#1) 
#2)

#ALL CODE FROM CHAPTER 9 website (Chap 10 pdf book)
findduplicates-t.py      -----------> see Exercise #2
findduplicates-t2.py
findduplicates-m.py
grepword-m.py
grepword-p-child.py
grepword-p.py           -----------> see Exercise #1
grepword-p_ans.py       -----------> see Exercise #1
grepword-t.py
xmlsummary.py           -----------> see Exercise #2


===============
Exercises 
#1) 
#2)
===============

#1) Copy and modify the 
grepword-p.py #program so that instead of the child processes
#printing their output, the main program gathers the results, and after all the child
#processes have finished, sorts and prints the results. This only requires editing the
#main() funciton and chaning three lines and adding three lines. The exercise does 
#require some thought and case, and you 
will need to read the subprocess module's doucmentation '#. Solution is given in
grepword-p_ans.py



#2) Write a multithreaded program that reads the files listed on the command line (and
#the files in any directories listed on the command line, recursively). For any file that
#is an XML file (ie it begins with the characters "<?xml"), parse the file using an XML
#parser and produce a list of the unique tags used by the file or an error message if
#a parsing error occurs. Here is a sample of the program's output from one particular run:

  ./data/dvds.xml is an XML file that uses the following tags:
    dvd
    dvds 
  ./data/bad.aix is an XML file that has the following error:
    mismatched tag:line 7889, column 2 
  ./data/incidents.aix is an XML file that uses the following tags:
    airport
    incident 
    incidents
    narrative

#The easiest way to write the program is to modify a copy of the 
findduplicates-t.py #program, although you can of course write the program entirely from sratch. 
#Small changes will need to be made to the Worker class's __init__() and run() methods, and
#the process() method will need to be rewritten entirely (but needs only around 20
#lines). The program's main() function will need several simplifications and so will
#one line of the print_results() function. The usage message will also need to be
#modified to match the one shown here:

  Usage: xmlsummary.py [options] [path]
  outputs a summary of the XML files in path; path defaults to .

  Options:
  -h, --help      show this help message and exit 
  -t COUNT, --threads=COUNT the number of threads to use (1..20) [default 7]
  -v, --verbose 
  -d, --debug 

  #Make sure you try running the program with the debug flag set so that you
  #can check that the threads are started up and that each one does its share of
  #the work. Solution is in 
  xmlsummary.py #which is slightly more than 100 lines and use no explicit locks.






#CODE HERE
xmlsummary.py

#!/usr/bin/env python3

import optparse
import os
import queue
import threading
import xml.etree.ElementTree
import xml.parsers.expat
import Util

if hasattr(xml.etree.ElementTree, "ParserError"):   #Python 3.2
    class Worker(threading.Thread):

        def __init__(self, work_queue, results_queue, number):
            super().__init__()
            self.work_queue = work_queue
            self.results_queue = results_queue
            self.number = number

        def run(self):
            while True:
                try:
                    filename = self.work_queue.get()
                    self.process(filename)
                finally:
                    self.work_queue.task_done()

        def process(self, filename):
            tags = set()
            try:
                with open(filename, encoding="utf8", errors="ignore") as fh:
                    line = fh.readline()
                    if not line.startswith("<?xml"):
                        return
                    fh.close()
                tree = xml.etree.ElementTree.parse(filename)
                for element in tree.iter():
                    tags.add(element.tag)
            except xml.etree.ElementTree.ParseError as err:  #Python 3.2
                message = "has the following error:\n    " + str(err)
            except xml.parsers.expat.ExpatError as err:
                message = "has the following error:\n    " + str(err)
            except EnvironmentError as err:
                message = "could not be read:\n    " +str(err)
            else:
                message = ("uses the following tags:\n    " + "\n    ".join(sorted(tags, key=str.lower)))
            message = (self.number + filename = " is an XML file that " + message)
            self.results_queue.put(message)
else:
    class Worker(threading.Thread):

        def __init__(self, work_queue, results_queue, number):
            super().__init__()
            self.work_queue = work_queue
            self.results_queue = results_queue
            self.number = number

        def run(self):
            while True:
                try:
                    filename = self.work_queue.get()
                    self.process(filename)
                finally:
                    self.work_queue.task_done()

        def process(self, filename):
            tags = set()
            try:
                with open(filename, encoding="utf8", errors="ignore") as fh:
                    line = fh.readline()
                    if not line.startswith("<?xml"):
                        return
                    fh.close()
                tree = xml.etree.ElementTree.parse(filename)
                for element in tree.iter():
                    tags.add(element.tag)

            except xml.parsers.expat.ExpatError as err:
                message = "has the following error:\n    " + str(err)
            except EnvironmentError as err:
                message = "could not be read:\n    " +str(err)
            else:
                message = ("uses the following tags:\n    " + "\n    ".join(sorted(tags, key=str.lower)))
            message = (self.number + filename = " is an XML file that " + message)
            self.results_queue.put(message)

def main():
    opts, path = parse_options()
    if opts.verbose:
        print("Creating {0} thread{1}...".format(opts.count, Util.s(opts.count)))
    work_queue = queue.Queue()
    results_queue = queue.Queue()
    for i in range(opts.count):
        number = "{0}: ".format(i + 1) if opts.debug else ""
        worker = Worker(work_queue, results_queue, number)
        worker.daemon = True
        worker.start()

    results_thread = threading.Thread(target=lambda: print_results(results_queue))
    results_thread.daemon = True 
    results_thread.start()

    for root, dirs, files in os.walk(path):
        for filename in files:
            fullname = os.path.join(root, filename)
            work_queue.put(fullname)
    work_queue.join()
    results_thread.join()

def print_results(results_queue):
    while True:
        try:
            results = results_queue.get()
            if results:
                print(results)
        finally:
            results_queue.task_done()

def parse_options():
    parser = optparse.OptionParser(
                        usage=("usage: %prog [options] [path]\n"
                            "outputs a summary of the XML files in path\n"
                            "path defaults to ."))
    parser.add_option("-t", "--threads", dest="count", default=7, type="int",
                        help=("the number of threads to sue (1..20) [default %default]"))
    parser.add_option("-v", "--verbose", dest="verbose", default=False, action="store_true")
    parser.add_option("-d", "--debug", dest="debug", dest="debug", default=False, action="store_true")
    opts, args = parser.parse_args()
    if not (1 <= opts.count <= 20):
        parser.error("thread count must be 1..20")
    return opts, args[0] if args else "."


main()










#Reminder of topics<===========
===============================================================================================
CHAPTER: 11 Networking 
CHAPTER BEGIN
===============================================================================================

Creating a TCP Client 
Creating a TCP Server 
Summary
Exercises 
#1) 
#2)
#3)

#CODE LIST
car_registration.py
car_registration_ans.py
car_registration_server.py
car_regsitration_server_ans.py


===============
Networking
===============

#Most networking programs work on either a peer-to-peer basis or more commonly
#a client/server basis.

#In this chapter we will creat a basic client/server application. Such applications
#are normally implemented as two separate programs: a server that waits for and 
#reponds to requests, and one or more clients that send requests to the server and
#read back the server's response. For this to work, the clients must know where to
#connect to the server, that is, the server's IP (internet protocol) address and port
#number.*
#*Note Machines also connect using "service discovery", for example, using the
#bonjour API; see Python Package Index pypi.python.org/pypi
#Also, both clients and server must send and receive data using an agreed upon protocol
#using data formats that they both understand.

#Python's low level socket module (on which all of Python's higher level networking
#modules are based) supports both IPv4 and IPv6 addresses. It also supports the most
#commony used networking protocols including UDP (User Datagram Protocol), a lightweight
#but unreliable connectionless protocol where data is send as discrete packets (datagrams)
#but with no guarantee that they will arrive, and TCP (Transmission Control Protocol), a
#reliable connection and stream oriented protocol. Wtih TCP, any amount of data can be 
#sent and received -- the socket is resonsible for breaking the data into chunks that are
#small enough to send, and for reconstructing the data at the other end.

#UDP is often used to monitor instrumetns that give continuous readings, and where
#the odd missed reading is not significant, and it is sometimes used for audio or 
#video streaming in cases where the occasional missed frame is acceptable. Both the
#FTP and th HTTP protocols are built on top of TCP, and client/server applications
#normally use TCP b/c they need connection-oriented communication and the reliability
#that TCP provides. In this chapter, we will develop a client/server program, so we
#use TCP.

#Another decision that must be made is whether to send and recevied data as lines of
#text or as blocks of binary data, and if the latter, in what form. In this chapter,
#we use blocks of binary data where the first four bytes are the length of the 
#following data (encoded as an unsigned integer using the 
struct #module), and where the following data is a 
binary pickle. #The advantage of this approach is that we can use the same sending
#and receiving code any ANY application since we can store almost any arbitrary data
#in a pickle. The disadvantage is that both client and server must understand pickles,
#so they must be written in Python or must be able to access Python, for example,
#using Jython in Java or Boost.Python in C++. And of course, the usual security 
#considerations apply to the use of pickles.

#The examples we will use is a car registration program. The server holder details or
#car registrations (license plates, seats, mileage, and owner). The client is used
#to retrieving car details, to changing a car's mileage or owner, or to create a
#new car registration. Any number of clients can be used and they wont block each
#other, even if two access the server at the same time. This is b/c the server hands
#off each client's request to a separate thread. (We will also see that it is just
#as easy to use separate processes.)

#For the sake of the example, we will run the server and clients on the same machine;
#this means that we can use "localhost" as the IP address (although if the server
#is on another machine the client can be given its IP address on the command line
#and this will work as long as there is no firewall in the way.) We have also chosen
#an arbitrary port number of 9653. The port number should be greater than 1023 and is 
#normally between 5001 and 32767, although port numbers up to 65535 are normally valid.

#The server can accept five kinds of requests: 
GET_CAR_DETAILS, CHANGE_MILEAGE, CHANGE_OWNER, NEW_REGISTRATION, and SHUTDOWN, #with a
#corresponding response for each. The response is the requested data or confirmation of
#the requested action, or an indication of an error.


#Reminder of topics
Creating a TCP Client 
Creating a TCP Server 
Summary
Exercises 
#1) 
#2)
#3)

#CODE LIST
car_registration.py
car_registration_ans.py
car_registration_server.py
car_regsitration_server_ans.py


===============
Creating a TCP Client 
===============

#The client program is car_registration.py.  Here is an example of interaction (with
#the server already running, and with the menu edited slightly to fit on the page):

    (C)ar (M)ileage (O)wner (N)ew car (S)top server (Q)uit [c]: License: 024 hyr
    License: 024 HYR                #DATA ENTERED BY USER = 024 HYR
    Seats: 2
    Mileage: 97543
    Owner: Jack Lemon
    (C)ar (M)ileage (O)wner (N)ew car (S)top server (Q)uit [c]: m 
    License [024 HYR]:
    Mileage [97543]: 103491         #DATA ENTERED BY USER = 103491
    Mileage successfully changed
    

#The data entered by the user is shown with #NOTE. Where there is no visible input
#means that the user pressed ENTER to accept the default. Here the user has asked
#to see the details of a particular car and then updated its mileage.

#As many clients as we like can be running, and when a user quits their particular
#client, the server is unaffected. But if the server is stopped, the client it was
#stopped in will quit, and all the other clients will get a "Connection refused"
#error and will terminate when they next attempt to access the server. In a more
#sophisticated application, the ability to stop the server would be available only
#to certain users, perhaps on only particular machines, but we have included it in
#the client to show how it is done.

#We will now review the code, starting with the main() function and the handling
#of the user interface, and finishing with the networking code itself.

    def main():
        if len(sys.argv) > 1:
            Address[0] = sys.argv[1]
        call = dict(c=get_car_details, m=change_mileage, o=change_owner,
                    n=new_registration, s=stop_server, q=quit)
        menu = ("(C)ar Edit (M)ileage Edit (O)wner (N)ew car (S)top server (Q)uit")
        valid = frozenset("cmonsq")
        previous_license = None
        while True:
            action = Console.get_menu_choice(menu, valid, "c", True)
            previous_license = call[action](previous_license)

#The Address list is a global that holds the IP address and port number as a two-item
#list, ["localhost", 9653], with the IP address overridden if specified on the 
#command line. The call dictionary maps menu options to functions.

#The Console module is one supplied with this book and contains some useful functions
#for getting values from the user at the console, such as Console.get_string() and
#Console.get_integer(); these are similar to functions developed in earlier chapters
#and have been put in a module to make them easy to reuse in different programs.

#As a convenience for users, we keep track of the last license they entered so
#that it can be used as the default, since most commands start by asking for the
#license of the relevant car. Once the user makes a choice, we call the corresponding
#function passing in the previous license, and expecting each function to return
#the license it used. Since the loop is infinite the program must be terminated
#by one of the functions; we will see this further on.

    def get_car_details(previous_license):
        license, car = retrieve_car_details(previous_license)
        if car is not None:
            print("License: {0}Seats: {seats}\nMileage: {mileage}\nOwner: {owner}".format(license, **car.asdict()))
        return license

#This function is used to get information about a particular car. Since most of the
#functions need to request a license from the user and often need some car-related
#data to work on, we have factored out this functionality into the
retrieve_car_details() #function -- it returns a 2-tuple of the license entered by
#the user and a named tuple, CarTuple, that holds the car's seats, mileage, and 
#owner (or the previous license and None if they entered an unrecognized license.)
#Here we just print the information retrieved and return the license to be used as
#the default for the next function that is called and that needs the license.

    def retrieve_car_details(previous_license):
        license = Console.get_string("License", "license", previous_license)
        if not license:
            return previous_license, None
        license = license.upper()
        ok, *data = handle_request("GET_CAR_DETAILS", license)
        if not ok:
            print(data[01])
            return previous_license, None
        return license, CarTuple(*data)

#This is the first function to make use of networking. It calls the
handle_request() #function that we review further on. The handle_request () function
#takes whatever data it is given as arguments and sends it to the server, and then
#returns whatever the server replies. The handle_request() funciton does not know
#or care what data it sends or returns; it purely provides the networking service.

#In the case of car registrations we have a protocol where we always send the name
#of the action we want the server to perform as the first argument, followed by 
#any relevant parameters -- in this case, just the license. The protocol for the 
#the reply is that the server always returns a tuple whose first item is a
#Boolean success/failure flag. If the flag is False, we have a 2-tuple and the
#second item is an error message. If the flag is True, the tuple is either a 
#2-tuple with the second item being a confirmation message, or an n-tuple with 
#second and subsequent items holding the data that was requested.

#So here, if the license is unrecognized, ok is False and we print the error
#message in data[0] and return the previous license unchanged. Otherwise, we
#return the license (which will not become the previous license), and a 
#CarTuple made from the data list, (seats, mileage, owner).

    def change_mileage(previous_license):
        license, car = retrieve_car_details(previous_license)
        if car is None:
            return previous_license
        mileage = Console.get_integer("Mileage", "mileage", car.mileage, 0)
        if mileage == 0:
            return license
        ok, *data = handle_request("CHANGE_MILEAGE", license, mileage)
        if not ok:
            print(data[0])
        else:
            print("Mileage successfully changed")
        return license

#This function follows a similar pattern to get_car_details(), except that once
#we have the details we update one aspect of them. There are in fact two
#networking calls, since 
retrieve_car_details() #calls
handle_request #to get the car's details -- we need to do this both to confirm
#that the license is a valid and to get the current mileage to use as the default.
#Here the reply is always a 2-tuple, with either an error message or None as the 
#second term.

#We wont review the change_owner() function since it is structurally the same as
#change_mileage(), nor will we review new_registration() since it differs only in
#not retrievign car details at the start (since it is a new car being entred), and
#asking the user for all the details rather than just changing one detail, none of
#which is new to us or relevant to network programming.

    def quit(*ignore):
        sys.exit()

    def stop_server(*ignore):
        handle_request("SHUTDOWN", wait_for_reply=False)
        sys.exit()

#If the user chooses to quit the program we do a clean termination by calling
#sys.exit(). Every menu function is called with the previous license, but we
#dont care about the argument in this partiucular case. We cannot write
def quit(): #b/c that would create a function that expects no arguments and so
#when the function was called with the previous license a TypeError exception
#would be raised saying that no arguments were expected but that one was given.
#So instead we specify a parameter of *ignore which can take any number of
#positional arguments. The name ignore has no significance to Python and is
#purely to indicate to maintainers that the arguments are ignored.

#If the user choosed to stop the server we use handle_request() to inform the
#server, and specify that we dont want a reply. Once the data is sent, 
#handle_request() returns without waiting for a reply, and we do a clean
#termination using sys.exit().

    def handle_request(*items, wait_for_reply=True):
        SizeStruct = struct.Struct("!I")
        data = pickle.dumps(items, 3)

        try:
            with SocketManager(tuple(Address)) as sock:
                sock.sendall(SizeStruct.pack(len(data)))
                sock.sendall(data)
                if not wait_for_reply:
                    return

                size_data = sock.recv(SizeStruct.size)
                size = SizeStruct.unpack(size_data)[0]
                result = bytearray()
                while True:
                    data = sock.recv(4000)
                    if not data:
                        break
                    result.extend(data)
                    if len(result) >= size:
                        break
            return pickle.loads(result)
        except socket.error as err:
            print("".format())
            sys.exit(1)
    
#This function provides all the client program's network handling. It begins
#by creating a struct.Struct which holds one unsigned integer in network byte
#order, and then it creates a pickle of whatever items it is passed. The function
#does not know or care what the items are. Notice that we have explicitly set the 
#picle protocol version to 3 --this ensures tha both clients and server use the
#same pickle version, even if a client or server is upgraded to run a different
#version of Python.

#If we wanted our protocol to be more future proof, we could version it (just as
#we did with binary disk formats.) This can be done eithwer at the network level
#or at the data level. At the network level we can version by passing two
#unsigned intergers instead of one, that is, length and a protocol version
#number. At the data level we could follow the convention that the pickle is
#always a lis (or always a dictionary) whose first item (or "version" item) has
#a version number. (You will get the chance to vesion the protocol in the
#exercises.)

#The SocketManager is a custom context manager that gives us a socket to use
#-- we will review it shortly. The
socket.socket.sendall() #method sends all the data it is given -- making
#multiple socket.socket.send() calls behind the scenes if necessary. We always
#send two items of data: the length of the pickle and the pickle itself. If the
#wait_for_reply argument is False, we dont wait for a reply and return immediately
#-- the context manager will ensure that the socket is closed before the function
#actually returns.

#After sending the data (and when we want a reply), we call the
socket.socket.recv() #method to get the reply. This method blocks until it receives
#data. For the first call we request four bytes -- the size of the integer that
#holds the size of the reply pickle to follow. We use the struct.Struct to unpack
#the bytes into the size integer. We then create an empty bytearray and try to
#retrieve the incoming pickle in blocks of up to 4000 bytes. Once we have read in
#size bytes (or if teh data has run out before then), we break out of the loop and
#unpickle the data using the pickle.loads() function (which takes a bytes or 
#bytearray object), and return it. In this case, we know that the data will 
#always be a tuple since that is the protocol we have established with the car
#registration server, but the handle_request() function does not know or care
#about what the data is.

#If something goes wrong with the network connection, for example, the server
#isnt running or the connection fails for some reason, a socket.error exception
#is raised. In such cases, the exception is caught and the client program issues
#an error message and terminates.

    class SocketManager:

        def __init__(self, address):
            self.address = address 

        def __enter__(self):
            self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            self.sock.connection(self.address)

        def __exit__(self, *ignore):
            self.sock.close()

#The address object is a 2-tuple (IP address, port number) and is set when the
#context manager is created. Once the context manager is used in a with
#statement it creates a socket and tries to make a connection -- blocking until
#a connection is established or until a socket exception is raised. The first
#argument to the socket.socket() initializer is the address family; here we have used
socket.AF_INET #(an IPv4) but others are available, for example, socket_AF_INET6 (IPv6), 
#socket.AF_UNIX, and socket.AF_NETLINK. The second argument is normally either
#socket.socket.SOCK_STREAM(TCP) as we have used here, or socket.SOCK_DGRAM (UDP).

#When the flow of control leaves the with statement's scope, the context object's
#__exit__() method is called. We dont care whether an exception was raised or not
#(so we ignore the exception arguments), and just close the socket. Since the 
#method returns None (in a Boolean context, False), any exceptions are propogated --
#this works well since we put a suitable except block in handle_request() to process 
#any socket exeptions that occur.


#CODE LIST
car_registration.py
car_registration_ans.py
car_registration_server.py
car_regsitration_server_ans.py


#CODE HERE
car_registration.py

#!/usr/bin/env python3

import collections
import pickle
import socket
import struct
import sys
import Console

Address = ["localhost", 9653]
CarTuple = collections.namedtuple("CarTuple", "seats mileage owner")


class SocketManager:
    def __init__(self, address):
        self.address = address 

    def __enter__(self):
        self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.sock.connect(self.address)
        return self.sock

    def __exit__(self, *ignore):
        self.sock.close()


def main():
    if len(sys.argv) > 1:
        Address[0] = sys.argv[1]
    call = dict(c=get_car_details, m=change_mileage, o=change_owner, n=new_registration
                s=stop_server, q=quit)
    menu = ("(C)ar Edit (M)ileage Edit (O)wner (N)ew car (S)top server (Q)uit")
    valid = frozenset("cmonsq")
    previous_license = None
    while True:
        action = Console.get_menu_choice(menu, valid, "c", True)
        previous_license = call[action](previous_license)


def retrieve_car_details(previous_license):
    license = Console.get_string("License", "license", previous_license)
    if not license:
        return previous_license, None
    licence = license.upper()
    ok, *data = handle_request("GET_CAR_DETAILS", license)
    if not ok:
        print(data[0])
        return previous_license, None 
    return license, CarTuple(*data)


def get_car_details(previous_license):
    license, car = retrieve_car_details(previous_license)
    if car is not None:
        print("License: {0}\nSeats:    {seats}\nMileage: {milage}\n"
              "Owner:    {owner}".format(license, **car._asdict()))
    return license

def change_mileage(previous_license):
    license, car = retrieve_car_details(previous_license)
    if car is None:
        return previous_license
    mileage = Console.get_integer("Mileage", "mileage", car.mileage, 0)
    if mileage == 0:
        return license 
    ok, *data = handle_request("CHANGE_MILEAGE", license, mileage)
    if not ok:
        print(data[0])
    else:
        print("Mileage successfully changed")
    return license

def change_owner(previous_license):
    license, car = retrieve_car_details(previous_license)
    if car is None:
        return previous_license
    owner = Console.get_string("Owner", "owner", car.owner)
    if not owner:
        return license
    of, *data = handle_request("CHANGE_OWNER", license, owner)
    if not ok:
        print(data[0])
    else:
        print("Owner successfully changed")
    return license 

def new_registration(previous_license):
    license = Console.get_string("License", "license")
    if not license:
        return previous_license
    license = license.upper()
    seats = Console.get_integer("Seats", "seats", 4, 0)
    if not (1 < seats < 10):
        return previous_license
    mileage = Console.get_integer("Mileage", "mileage", 0, 0)
    owner = Console.get_string("Owner", "owner")
    if not owner:
        return previous_license
    of, *data = handle_request("NEW_REGISTRATION", license, seats, mileage, owner)
    if not ok:
        print(data[0])
    else:
        print("Car {0} successfully registered".format(license))
    return license

def quit(*ignore):
    sys.exit()

def stop_server(*ignore):
    handle_request("SHUTDOWN", wait_for_reply=False)
    sys.exit()

def handle_request(*items, wait_for_reply=True):
    SizeStruct = struct.Struct("!I")
    data = pickle.dumps(items, 3)

    try:
        with SocketManager(tuple(Address)) as sock:
            sock.sendall(SizeStruct.pack(len(data)))
            sock.sendall(data)
            if not wait_for_reply:
                return

            size_data = sock.recv(SizeStruct.size)
            size = SizeStruct.unpact(size_data)[0]
            result = bytearrary()
            while True:
                data = sock.recv(4000)
                if not data:
                    break
                result.extend(data)
                if len(result) >= size:
                    break
        return pickle.loads(result)
    except socket.error as err:
        print("{0}: is the server running?".format(err))
        sys.exit(1)


main()


#Reminder of topics
Creating a TCP Client 
Creating a TCP Server 
Summary
Exercises 
#1) 
#2)
#3)

#CODE LIST
car_registration.py
car_registration_ans.py
car_registration_server.py
car_regsitration_server_ans.py


===============
Creating a TCP Server 
===============

#Since the code for creating servers often follows the same design, rather than
#having to use the low-level socket module, we can use the high-level
socket-server #module which takes care of all the housekeeping for us. All we have
#to do is provide a request handler class with a handle() method which is used to
#read requests and write replies. The socketserver module handles the communications
#for us, servicing each connection request, either serially or by passing each
#request to its own separate thread or process -- and it does all of this
#transparently so that we are insulated from the low level details.

#For this application the server is car_registration_server.py      *
#*Note the first time server is run on Windows a firewall dialog might pop up
#saying that Python is blocked -- click Unblock to allow the server to operate.
#This program contains a very simple Car class that holds seats, mileage, and owner
#information as properties (the first one read-only). The class does not hold car
#licenses b/c the cars are stored in a dictionary and the licenses are used for the
#dictionary's keys.

#We will begin by looking at the main() function, then brielfy reveiw how the server's
#data is loaded, then the creation of the custom server class, and finally the
#implementation of the request handler class that handles the client requests.

    def main():
        filename = os.path.join(os.path.dirname(__file__), "car_registrations.dat")
        cars = load(filename)
        print("Loaded {0} car registrations".format(len(cars)))
        RequestHandler.Cars = cars
        server = None
        try:
            server = CarRegistrationServer(("", 9653), RequestHandler)
            server.serve_forever()
        except Exception as err:
            print("ERROR", err)
        finally:
            if server is not None:
                server.shutdown()
                save(filename, cars)
                print("Saved {0} car registrations".format(len(cars)))

#We have stored the car registration data in the same directory as the program. The
#cars objet is set to a dicitonary whose keys are license strings and whose values
#are Car objects. Normally servers do not print anything since they are typically
#started and stopped automatically and run in the background, so usually they 
#report on their status by writing logs (eg using the logging module). Here we have
#chosen to print a message at start-up and shutdown to make testing and
#experimenting easier.

#Our request handler class needs to be able to access the cars dictionary, but
#we cannot pass the dictionary to an instance b/c the server creates the instance
#for us -- one to handle each request. So we set the dictionary to the
#RequestHandler.Class class variable where it is accessible to ALL INSTANCES.

#We create an instance of the server passing it the address and port it should 
#operate on and the RequestHandler class object -- not an instance. An empty
#string as the address indicates any accessible IPv4 address (including the
#current machine, localhost). Then we tell the server to serve requests forever.
#When the server shurts down (we will see how this happens further on), we save
#the cars dictionary since the data may have been changed by clients.

    def load(filename):
        try:
            with contextlib.closing(gzip.open(filename, "rb")) as fh:
                return pickle.load(fh)
        except (EnvironmentError, pickle.UnpicklingError) as err:
            print("server cannot load data: {0}".format(err))
            sys.exit(1)

#The code for loading is easy b/c we have used a context manager from the
#standard library's contextlib module to ensure that the file is closed
#irrespective of whether an exception occurs. Another way of achieving the
#same effect is to use a custom context manager. For example:

    class GzipManager:

        def __init__(self, filename, mode):
            self.filename = filename
            self.mode = mode

        def __enter__(self):
            self.fh = gzip.open(self.filename, self.mode)
            return self.fh 

        def __exit__(self, *ignore):
            self.fh.close()

#Using the custome Gzip Manager, the with statement becomes:

    with GzipManager(filename, "rb") as fh:

#This context manager will work with any Python 3.x version. But if we ony
#care about Python 3.1 or later, we can simply write, 
with gzip.open(...) as fh #since from Python 3.1 the gzip.open() function supports 
#the context manager protocol.

#The save90 function (not shown) is structurally the same as the load() function, only
#we open the file in write binary mode, use pickle.dump() to save the data, and dont
#return anything.

    class CarRegistrationServer(sockerserver.ThreadingMixIn, socketserver.TCPServer): pass

#This is the complete custom server class. If we wanted to creat a server that
#used processes rather than threads, the only change would be to inherit the 
socketserver.ForkingMixIn #class instead of the socketserver.ThreadingMixIn class. The
#term mixin is often used to describe classes that are specifically designed to be
#multiply-inherited. The socketserver module's classes can be used to create a
#variety of custom servers including UDP servers and Unix TCP and UDP servers, by
#inheriting the appropriate pair of case classes.

#Note that socketserver mixin class we used must always be inherited first. This is
#to ENSURE that the mixin class's methods are used in preference to the second class's
#methods for those methods that are provided by both, since Python looks for methods
#in the base classes in the order in which the base classes are specified, and uses
#the first suitable method it finds.

#The socket server creates a request handler (using the class it was given) to handle
#each request. Our custom RequestHandler class provides a method for each kind of
#request it can handle, plus the handle() method that it must have since that is the 
#only method used by the socket server. But before looking at the methods we will
#look at the class declaration and the class's class variables.

    class RequestHandler(socketserver.StreamRequestHandler):

        CarsLock = threading.Lock()
        CallLock = threading.Lock()
        Call = dict(
            GET_CAR_DETAILS=(lambda self, *args: self.get_car_details(*args)),
            CHANGE_MILEAGE=(lambda self, *args: self.change_mileage(*args)),
            CHANGE_OWNER=(lambda self, *args: self.change_mileage(*args)),
            NEW_REGISTRATION=(lambda self, *args: self.new_registration(*args)),
            SHUTDOWN=lambda self, *args: self.shutdown(*args))

#We have created a socketserver.StreamRequestHandler subclass since we are using
#a streaming (TCP) server. A corresponding socketserver.DatagramRequestHandler is
#available for UDP servers, or we could inherit the socketserver.BaseRequestHandler 
#class for lower-level access.

#The RequestHandler.Cars dictionary is a class variable that was added in the main()
#function; it holds all the registration data. Adding additional attributes to objects
#such as classes and instances) can be done outside the class (in this case in the 
#main() function) without formality (as long as the object has a __dict__), and can
#be very convenient. Since we know that the class depends on this variable some
#programmers would have added Cars = None as a class variables to document
#the variables existence. (Atul - no need to let this silently go by.)

#Almost every request-handling method needs access to the Cars data, but we must
#ensure that the data is never accessed by two methods (from two different threads)
#at the same time; if it is, the dictionary may become corrupted, or the program might
#crash. To avoid this, we have a lock class variable that we will use to ensure that
#only one thread at a time accesses the Cars dictionary.*
#*Note The GIL (Global Interpreter Lock) ensures that accesses to the Cars 
#dictionary are synchronized but as noted earlier, we do not take advantage of this
#since it a CPython implementation detail.
#(Threading, including the use of locks is covered in Chapter 10).

#The Call dictionary is another class variable. Each key is the name of an action
#that the server can perform and each value is a function for performing the
#action. We cannot use the methods directly as we did with the funsctions in the
#client's menu dicationary b/c there is NO self available at the class level. The
#solution we have used is to provide wrapper functions that will get self when they
#are called, and which in turn call the appropriate method with the given self and
#any other arguments. An alternative solution would be to create the Call dictionary
#AFTER all the methods. That would allow us to create entries such as 
#GET_CAR_DETAILS=get_car_details, with Python able to find the get_car_details()
#method b/c the dictionary is created after the method is defined. We have used the 
#first approach since it is more explicit and does not impose and ORDER DEPENDENCY
#on where the dictionary is created.

#Although the Call dictionary is only ever read after the class is created, since it
#is mutable we have played it extra-safe and created a lock for it to ensure that no
#two threads access it at the same time. (Again, b/c of the GIL, the lock isnt
#really needed for CPython.)

        def handle(self):
            SizeStruct = struct.Struct("!I")
            size_data = self.rfile.read(SizeStruct.size)
            size = SizeStruct.unpack(size_data)[0]
            data = pickle.loads(self.rfile.read(size))

            try:
                with self.CallLock:
                    function = self.Call[data[0]]
                reply = function(self, *data[1:])
            except Finish:
                return
            data = pickle.dumps(reply, 3)
            self.wfile.write(SizeStruct.pack(len(data)))
            self.wfile.write(data)

#When a client makes a request a new thread is created with a new instance of the
#RequestHandler class, and then the instance's handle() method is called. Inside this
#method the data coming from the client can be read from the self.rfile file object,
#and data can be sent back to the client by writing to the self.wfile object -- both of
#these objects are provided by socketserver, opened and ready for use.

#The struct.Struct is for the integer byte count that we need for the "length plus pickle"
#format we are using to exchange data between clients and the server.

#We begin by reading four bytes and unpacking this as the size integer so that we know
#the size of the pickle we have been sent. Then we read size bytes and unpickle them
#into the data variable. The read will block until the data is read. In this case, we
#know that data will always be a tuple, with the first item being the requested action
#and the other items being the parameters, b/c that is the protocol we have 
#established with the car registration clients.

#Inside the try block we get the lambde function that is appropriate to the requesetd
#action. We use a lock to protect access to the Call dictionary, although arguable we 
#being overly cautious. As always, we do as little as possible within the scope of the
#lock -- in this case, we just do a dictionary lookup to get a reference to a function.
#Once we have the function we call it, passing self as the first argument and the rest
#of the data tuple as the other arguments. Here we are doing a function call, so no self
#is passed by Python.
Atul passing self
#This does not matter since we pass self in ourselves, and inside the lambda the passed-in
#self is used to call the method in the normal way. The outcome is that the call,
#self.method(*data[1:]), is made, where 
method #is the method corresponding to the action given in
data[0]

#If the action is to shut down, a custom Finish exception is raised in the shutdown() 
#method; in which case we know that the client connot expect a reply, so we just return.
#But for any other action, we pickle the result of calling the action's corresponding
#method (using pickle protocol version 3), and write the size of the pickle and then
#the pickled data itself.

        def get_car_details(self, license):
            with self.Carslock:
                car = copy.copy(self.Cars.get(license, None))
            if car is not None:
                return (True, car.seats, car.mileage, car.owner)
            return (False, "This license is not registered")

#This method begins by trying to acquire the car data lock -- and blocks until it
#gets the lock. It then uses the dict.get() method with a second argument of None
#to get the care with the given license -- or to get None. The car is immediately
#copied and the with statement is finished. This ensures that the lock is in force
#for the shortest possible time. Although reading does not change the data being
#read, b/c we are dealing with a mutable collection it is possible that another
#method in another thread wants to change the dictionary at the same time as we
#want to read it -- using a lock prevents this from happening. Outside the scope
#of the lock we now have a copy of the car object (or None) which we can deal
#with at our leisure without blocking any other threads.

#Like all the car registration action-handling methods, we return a tuple whose
#first item is a Boolean success/failure flag and whose other items vary. None
#of these methods has to worry or even know how its data is returned to the client
#beyond the "tuple with a Boolean first item" since all the network interaction
#is encapsulated in the handle() method.

        def change_mileage(self, license, mileage):
            if mileage < 0:
                return (False, "Cannot set a negative mileage")
            with self.CarsLock:
                car = self.Cars.get(license, None)
                if car is not None:
                    if car.mileage < mileage:
                        car.milege = mileage
                        return (True, None)
                    return (False, "Cannot wind the odometer back")
            return (False, "This license is not registered")

#In this method we can do one check without acquired a lock at all. But if the 
#mileage is non-negative we must acquire a lock and get the relevant car, and
#if we have a car (ie if the license is vaild), we must stay within the scope of
#the lock to change the mileage as requested -- or to return an error tuple. If no
#other car has the given license (car is None), we drop out of the with statement
#and return an error tuple.

#It would seem that if we did the validation in the client, we could avoid some
#network traffic entirely, for example, the client could give an error message (or
#simply prevent) negative mileages. Even though the client ought to do this, we
#must still have the check in the server since we cannot assume that the client
#is bug-free. And although the client gets the car's mileage to use as the 
#default mileage we cannot assume that the mileage entered by the user (even if
#it is greater than the current mileage) is valid, b/c some other client could
#have increased the mileage in the meantime. So we can only do the definitive
#validation at the server, and only within the scope of a lock.

#The change_owner() method is very similar, so we wont reproduce it here.

        def new_registration(self, license, seats, mileage, owner):
            if not license:
                return (False, "Cannot set an empty license")
            if seats not in {2, 4, 5, 6, 7, 8, 9}:
                return (False, "Cannot register car with invalid seats")
            if mileage < 0:
                return (False, "Cannot set a negative mileage")
            if not owner:
                return (False, "Cannot set an empty owner")
            with self.CarsLock:
                if license not in self.Cars:
                    self.Cars[license] = Car(seats, mileage, owner)
                    return (True, None)
            return (False, "Cannot register duplicate license")

#Again we are able to do a lot of error checking before accessing the registration
#data, but if all the data is valid we acquire a lock. If the license is not in the
#RequestHandler.Cars dictionary (and it shouldnt be since a new registration should
#have an unused license), we create a new Car object and store it in the dictionary.
#This must all be done within the scope of the same lock b/c we must not allow any
#other client to add a car with this license in the time between the check for the
#license's existence in the RequestHandler.Cars dictionary and adding the new car
#to the dictionary.

        def shutdown(self, *ignore):
            self.server.shutdown()
            raise Finish()

#If the action is to shut down we call the server's shutdown() method -- this will
#stop it from accepting any further requests, although it will continue running
#while it is still servicing any existing requests. We then raise a custom exception
#to notify the handler() that we are finished -- this causes the handler() to return
#without sending any reply to the client.


#Reminder of topics
Creating a TCP Client 
Creating a TCP Server 
Summary
Exercises 
#1) 
#2)
#3)

#CODE LIST
car_registration.py
car_registration_ans.py
car_registration_server.py
car_regsitration_server_ans.py


===============
Summary
===============

#This chapter showed that creating network clients and servers can be quite
#straightforward in Python thanks to the standard library's networking modules,
#and the struct and pickle modules.

#In the first section we developed a client program and gave it a single function,
handle_request() #to send and receive arbitary pickable data to and from a server
#using a generic data format of "length plus pickle". In the second section we saw
#how to create a server subclass using the classes from the socketserver module
#and how to implement a request handler class to service the server's client
#request. Here the heart of the network interaction was confined to a single method
handle() #that can received and send arbitrary pickable data from and to clients.

#The socket and socketserver modules and many other modules in the standard library,
#such as asyncore, asynchat, and ssl, provide far more functionality than we hae here.
#But if the networking facilities provided by the standard library are not sufficient,
#or are not high-level enough, it is worth looking at the third party Twisted networking
#framework (www.twistedmatrix.com) as a possible alternative.


===============
Exercises
===============

#The exercises involve modifying the client and server programs covered in this chapter.
#The modifications dont involve a lot of typing, but will need a little bit of care
#to get right.

#1) Copy car_registration_server.py and car_registration.py and modify them so that
#they exchange data using a protocol versioned at the network level. This could be
#done, for example, by passing two integers in the struct (length, protocol version)
#instead of one. This involves adding or modifying about ten lines in the client 
#program's handle_request() function, and adding or modifying about sixteen lines in
#the server program's handle() method -- including code to handle the case where the
#protocol version read does not match the one expected. Solutions to this and the
#following exercises are provided in car_registration_ans.py and 
#car_registration_server_ans.py (here)


#CODE LIST
car_registration.py
car_registration_ans.py
car_registration_server.py
car_regsitration_server_ans.py



#CODE HERE
car_registration_server_ans.py

#!/usr/bin/env python3

import collections
import pickle
import socket
import struct
import sys
import Console


Address = ["localhose", 9653]
CarTuple = collections.namedtuple("CarTuple", "seats mileage owner")


class SocketManager:

    def __init__(self, address):
        self.address = address 

    def __enter__(self):
        self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.sock.connect(self.address)
        return self.sock

    def __exit__(self. *ignore):
        self.sock.close()

def main():
    if len(sys.argv) > 1:
        Address[0] = sys.argv[1]
    call = dict(c=get_car_details, m=change_mileage, o=change_owner, n=new_registration,
                s=stop_server, q=quit)
    menu = ("(C)ar  Edit  (M)ileage  Edit  (O)wner  (N)ew car  (S)top server (Q)uit")
    valid = frozenset("cmonsq")
    previous_license = None
    while True:
        action = Console.get_menu_choice(menu, valid, "c", True)
        previous_license = call[action](previous_license)

def retrieve_car_details(previous_license):
    license = Console.get_string("License", "license", previous_license)
    if not license:
        return previous_license, None
    licence = license.upper()
    ok, *data = handle_request("GET_CAR_DETAILS", license)
    if not ok:
        print(data[0])
        while True:
            start = Console.get_string("Start of license", "license")
            if not start:
                return previous_license, None
            start = start.upper()
            ok, *data = handle_request("GET_LICENSES_STARTING_WITH", start)
            if not data[0]:
                print("No license starts with " + start)
                continue
            for i, license in enumerate(data[0]):
                print("({0}) {1}".format(i + 1, license))
            answer = Console.get_integer("Enter choice (0 to cancel)", minimum=0, maximum=len(data[0]))
            if answer == 0:
                return previous_license, None
            license = data[0][answer - 1]
            ok, *data = handle_request("GET_CAR_DETAILS", license)
            if not ok:
                print(data[0])
                return previous_license, None 
            break
    return license, CarTuple(*data)

def get_car_details(previous_license):
    license, car = retrieve_car_details(previous_license)
    if car is not None:
        print("License: {0}\nSeats:    {seats}\nMileage: {milage}\n"
              "Owner:    {owner}".format(license, **car._asdict()))
    return license

def change_mileage(previous_license):
    license, car = retrieve_car_details(previous_license)
    if car is None:
        return previous_license
    mileage = Console.get_integer("Mileage", "mileage", car.mileage, 0)
    if mileage == 0:
        return license 
    ok, *data = handle_request("CHANGE_MILEAGE", license, mileage)
    if not ok:
        print(data[0])
    else:
        print("Mileage successfully changed")
    return license

def change_owner(previous_license):
    license, car = retrieve_car_details(previous_license)
    if car is None:
        return previous_license
    owner = Console.get_string("Owner", "owner", car.owner)
    if not owner:
        return license
    of, *data = handle_request("CHANGE_OWNER", license, owner)
    if not ok:
        print(data[0])
    else:
        print("Owner successfully changed")
    return license 

def new_registration(previous_license):
    license = Console.get_string("License", "license")
    if not license:
        return previous_license
    license = license.upper()
    seats = Console.get_integer("Seats", "seats", 4, 0)
    if not (1 < seats < 10):
        return previous_license
    mileage = Console.get_integer("Mileage", "mileage", 0, 0)
    owner = Console.get_string("Owner", "owner")
    if not owner:
        return previous_license
    of, *data = handle_request("NEW_REGISTRATION", license, seats, mileage, owner)
    if not ok:
        print(data[0])
    else:
        print("Car {0} successfully registered".format(license))
    return license

def quit(*ignore):
    sys.exit()

def stop_server(*ignore):
    handle_request("SHUTDOWN", wait_for_reply=False)
    sys.exit()

def handle_request(*items, wait_for_reply=True):
    InfoVersion = 1
    InfoStruct = struct.Struct("!IB")
#   SizeStruct = struct.Struct("!I")
    data = pickle.dumps(items, 3)

    try:
        with SocketManager(tuple(Address)) as sock:
            sock.sendall(InfoStruct.pack(len(data), InfoVersion))
#           sock.sendall(SizeStruct.pack(len(data)))
            sock.sendall(data)
            if not wait_for_reply:
                return

            info = sock.recv(InfoStruct.size)               #new
#           size_data = sock.recv(SizeStruct.size)
            size, version = InfoStruct.unpack(info)
#           size = SizeStruct.unpack(size_data)[0]
            if version > InfoVersion:                       #new
                raise ValueError("server is incompatible")  #new
            result = bytearrary()
            while True:
                data = sock.recv(4000)
                if not data:
                    break
                result.extend(data)
                if len(result) >= size:
                    break
        return pickle.loads(result)
    except ValueError as err:                   #new
        print(err)                              #new
        sys.ext(1)                              #new
    except socket.error as err:
        print("{0}: is the server running?".format(err))
        sys.exit(1)


main()





#CODE LIST
car_registration.py
car_registration_ans.py
car_registration_server.py
car_regsitration_server_ans.py



#CODE HERE
car_registration_server.py

#!/usr/bin/env python3

import contextlib
import copy
import gzip
import os
import pickle
import random
import socketserver
import struct
import sys
import threading

class Car:

    def __init__(self, seats, mileage, owner):
        self.__seats = seats
        self.mileage = mileage
        self.owner = owner 

    @property 
    def seats(self):
        return self.__seats

    @property 
    def mileage(self):
        return self.__mileage

    @mileage.setter
    def mileage(self, mileage):
        self.__mileage = mileage

    @property 
    def owner(self):
        return self.__owner 

    @owner.setter 
    def owner(self, owner):
        self.__owner = owner 


class Finish(Exception): pass


class RequestHandler(socketserver.StreamRequestHandler):

    CarsLock = threading.Lock()
    CallLock = threading.Lock()
    Call = dict(
            GET_CAR_DETAILS=(lambda self, *args: self.get_car_details(*args)),
            CHANGE_MILEAGE=(lambda self, *args: self.change_mileage(*args)),
            CHANGE_OWNER=(lambda self, *args: self.change_owner(*args)),
            NEW_REGISTRATION=(lambda self, *args: self.new_registration(*args)),
            SHUTDOWN=lambda self, *args: self.shutdown(*arggs))

    def handle(self):
        SizeStruct = struct.Struct("!I")
        size_data = self.rfile.read(SizeStruct.size)
        size = SizeStruct.unpack(size_data)[0]
        data = pickle.loads(self.rfile.read(size))

        try:
            with RequestHandler.CallLock:
                function = self.Call[data[0]]
            reply = function(self, *data[1:])
        except Finish:
            return 
        data = pickle.dumps(reply, 3)
        self.wfile.write(SizeStruct.pack(len(data)))
        self.wfile.write(data)

    def get_car_details(self, license):
        with RequestHandler.CarsLock:
            car = copy.copy(self.Cars.get(license, None))
        if car is not None:
            return (True, car.seats, car.mileage, car.owner)
        return (False, "This license is not registered")

    def change_mileage(self, license, mileage):
        if mileage < 0:
            return (False, "Cannot set a negative mileage")
        with RequestHandler.CarsLock:
            car = self.Cars.get(license, None)
            if car is not None:
                if car.mileage < mileage:
                    car.mileage = mileage
                    return (True, None)
                return (False, "Cannot wind the odometer back")
            return (False, "This license is not registered")

    def change_owner(self, license, owner):
        if not onwer:
            return (False, "Cannot set an empty owner")
        with RequestHandler.CarsLock:
            car = self.Cars.get(license, None)
            if car is not None:
                car.owner = owner
                return (True, None)
        return (False, "This license is not registered")

    def new_registration(self, license, seats, mileage, owner):
        if not license:
            return (False, "Cannot set an empty license")
        if seats not in {2, 4, 5, 6, 7, 8, 9}:
            return (False, "Cannot register car with invalid seats")
        if mileage < 0:
            return (Fasle, "Cannot set a negative mileage")
        if not owner:
            return (False, "Cannot set an empty owner")
        with RequestHandler.CarsLock:
            if license not in self.Cars:
                self.Cars[license] = Car(seats, mileage, owner)
                return (True, None)
        return (False, "Cannot register duplcate license")

    def shutdown(self, *ignore):
        self.sever.shutdown()
        raise Finish()


class CarRegistrationServer(socketserver.ThreadingMixIn, socketserver.TCPserver): pass 


def save(filename, cars):
    try:
        with contenxtlib.closing(gzip.open(filename, "wb")) as fh:
            pickle.dump(cars, fh, 3)
        except (EnvironmentError, pickle.UnpicklingError) as err:
            print("server failed to save data: {0}".format(err))
            sys.exit(1)

def load(filename):
    if not os.path.exists(filename):
        # Generate fake data
        cars = {}
        owners = []
        for forename, surname in zip(("Warisha", "Elysha", "Liona", "Kassandra", 
                "Simone", "Halima", "", "Liona", "Zack", "Josiah", "Sam", "Braedon", "Eleni"), 
                ("Chandler", "Drennan", "Stead", "Doole", "Reneau", "Dent", "Sheckles", "Dent", 
                "Reddihough", "Dodwell", "Conner", "Abson")):
            owners.append(forename + " " + surname)
        for license in ("1H1890C", "FHV449", "ABK3035", "215 MZN",
                "6DQX521", "174-WWA", "999991", "DA 4020", "303 LNM",
                "BEQ 0549", "1A US923", "A37 4791", "393 TUT", "458 ARW",
                "024 HYR", "SKM 648", "1253 QA", "4EB S80", "BYC 6654",
                "SRK-423", "3DB 09J", "3C-5772F", "PYJ 996", "768-VHN",
                "262 2636", "WYZ-94L", "326-PKF", "EJB-3105", "XXN-5911",
                "HVP 283", "EKW 6345", "069 DSM", "GZB-6052", "HGD-498",
                "833-132", "1XG 831", "831-THB", "HMR-299", "A04 4HE",
                "ERG 827", "XVT-2416", "306-XXL", "530-NBE", "2-4JHJ"):
            mileage = random.randint(0, 100000)
            seats = random.choice((2, 4, 5, 6, 7))
            owner = random.choice(owners)
            cars[license] = Car(seats, mileage, owner)
        return cars
        #return {}
    try:
        with contextlib.closing(gzip.open(filename, "rb")) as fh:
            return pickle.load(fh)
    except (EnvironmentError, pickle.UnpicklingError) as err:
        print("server cannont laod data: {0}".format(err))
        sys.exit(1)

def main():
    filename = os.path.join(os.path.dirname(__file__), "car_registrations.dat")
    cars = load(filename)
    print("Loaded {0} car registrations".format(len(cars)))
    RequestHandler.Cars = cars
    server = None
    try:
        server = CarRegistrationServer(("", 9653), RequestHandler)
        server.serve_forever()
    except Exception as err:
        print("ERROR", err)
    finally:
        if server is not None:
            server.shutdown()
            save(filename, cars)
            print("Saved {0} car registrations".format(len(cars)))


main()






#2)Copy the 
car_registration_server.py #program (or use the one developed in Exercise 1),
#and modify it so that it offers a new action, Get_Licenses_Starting_With . The action
#should accept a single parameter, a string. The method implementing the action should
#always return a 2-tuple of (True, list of licenses); there is no error (False) case,
#since no matches is not an error and simply results in True and an emtpy list
#being returned.

#Retrieve the licenses (the RequestHandler.Cars dictionary's keys) within the 
#scope of a lock, but do all the other work outside the lok to minimize blocking.
#One efficient way to find matching licenses is to sort the keys and then use the
#bisect module to find the first matching license and then iterate from there. Another
#possible approach is to iterate over the licenses, picking out those that start with
#the given string, perhaps using a list comprehension.

#Apart from the additional import, the Call dictionary will need an extra couple of
#lines for the action. THe method to implement the action can be done in fewer than
#ten lines. This is not difficult, although care is required. A solution that uses
#the bisect module is provided in 
car_registration_server_ans.py (see above)







#3)Copy the car_registration.py program (or use the one developed in exercise 1),
#and modify it to take advantage of the new server (car_regsitration_server_ans.py).
#This means changing the retrieve_car_details() function so that if the user enters
#an invalid license they get prompted to enter the start of a license and then get
#a list to choose from. Here is a sample interaction using the new function (with
#the server already running, with the meny edited slightly to fit on the page, and
#with what the user types shown in bold):

    (C)ar (M)ileage (O)wner (N)ew car (S)top server (Q)uit [c]: 
    License: da 4020            #BOLD INPUT da 4020
    License: DA 4020 
    Seats: 2
    Mileage: 97181
    Owner: Jonathan Lynn
    (C)ar (M)ileage (O)wner (N)ew car (S)top server (Q)uit [c]: 
    License [DA 4020]: z                #BOLD INPUT z
    This license is not registered 
    Start of license: z                 #BOLD INPUT z
    Exercises 473
    No licence starts with Z 
    Start of license: a                 #BOLD INPUT a
    (1) A04 4HE
    (2) A37 4791
    (3) ABK3035
    Enter choice (0 to cancel): 3       #BOLD INPUT 3
    License: ABK3035
    Seats:   5
    Mileage: 17719
    Owner:   Anthony Jay

#The change involves deleting one line and adding about twenty more lines. It is
#slightly tricky b/c the user must be allowed to get out OR to go on at each stage.
#Make sure that you test the new functionality for all cases (no license starts
#with the given string, one license starts with it, and two or more start with it.)
#Solution is provided in 
car_registration_ans.py (HERE)


#CODE LIST
car_registration.py
car_registration_ans.py
car_registration_server.py
car_regsitration_server_ans.py


#CODE HERE
car_registration_ans.py

#!/usr/bin/env python3

import collections
import pickle
import socket
import struct
import sys
import Console

Address = ["localhost", 9653]
CarTuple = collections.namedtuple("CarTuple", "seats mileage owner")

class SocketManager:

    def __init__(self, address):
        self.address = address 

    def __enter__(self):
        self.sock = socket.socker(socket.AF_INET, socket.SOCK_STREAM)
        self.sock.connect(self.addresss)
        return self.sock

    def __exit__(self, *ignore):
        self.sock.close()

def main():
    if len(sys.argv) > 1:
        Address[0] = sys.argv[1]
    call = dict(c=get_car_details, m=change_mileage, o=change_owner, n=new_registration,
                s=stop_server, q=quit)
    menu = ("(C)ar Edit (M)ilege Edit (O)wner (N)ew car (S)top server (Q)uit")
    valid = frozenset("cmonsq")
    previous_license = None
    while True:
        action = Console.get_menu_choice(menu, valid, "c", True)
        previous_license = call[action](previous_license)

def retrieve_car_details(previous_license):
    license = Console.get_string("License", "license", previous_license)
    if not license:
        return previous_license, None
    license = license.upper()
    ok, *data = handle_request("GET_CAR_DETAILS", license)
    if not ok:
        print(data[0])
        while True:
            start = Console.get_string("Start of license", "license")
            if not start:
                return previous_license, None
            start = start.upper()
            ok, *data = handle_request("GET_LICENSES_STARTING_WITH", start)
            if not data[0]:
                print("no license starts with " + start)
                continue
            for i, license in enumerate(data[0]):
                print("({0}) {1}".format(i + 1, license))
            answer = Console.get_integer("Enter choice (0 to cancel)", minimum=0, maximum=len(data[0]))
            if answer == 0:
                return previous_license, None
            license = data[0][answer -1]
            ok, *data = handle_request("GET_CAR_DETAILS", license)
            if not ok:
                print(data[0])
                return previous_license, None
            break
    return license, CarTuple(*data)

def get_car_details(previous_license):
    license, car = retrieve_car_details(previous_license)
    if car is not None:
        print("License: {O}\nSeats:    {seats}\nMileage:   {mileage}\nOwner:   {owner}\n".format(license, **car_asdict()))
        return license

def change_mileage(previous_license):
    license, car = retrieve_car_details(previous_license)
    if care is None:
        return previous_license
    mileage = Console.get_integer("Mileage", "mileage", car.mileage, 0)
    if mileage == 0:
        return license
    ok, *data = handle_request("CHANGE_MILEAGE", license, mileage)
    if not ok:
        print(data[0])
    else:
        print("Mileage successfully changed")
    return license

def change_owner(previous_license):
    license, car = retrieve_car_details(previous_license)
    if car is None:
        return previous_license
    owner = Console.get_string("Owner", "owner", car.owner)
    if not owner:
        return license
    ok, *data = handle_request("CHANGE_OWNER", license, owner)
    if not ok:
        print(data[0])
    else:
        print("Owner successfully changed")
    return license

def new_registration(previous_license):
    license = Console.get_string("License", "license")
    if not license:
        return previous_license
    license = license.upper()
    seats = Console.get_integer("Seats", "seats", 4, 0)
    if not (1 < seats < 10):
        return previous_license
    mileage = Console.get_integer("Mileage", "mileage", 0, 0)
    owner = Console.get_string("Owner", "owner")
    if not owner:
        return previous_license
        ok, *data = handle_request("NEW_REGISTRATION", license, seats, mileage, owner)
    if not ok:
        print(data[0])
    else:
        print("Car {0} successfully registered".format(license))
    return license

def quit(*ignore):
    sys.exit()

def stop_server(*ignore):
    handle_request("SHUTDOWN", wait_for_reply=False)
    sys.exit()

def handle_request(*items, wait_for_reply=True):
    InfoVersion = 1
    InfoStruct = struct.Struct("!IB")
    data = pickle.dumps(items, 3)

    try:
        with SocketManager(tuple(Address)) as sock:
            sock.sendall(InfoStruct.pack(len(data), InfoVersion))
            sock.sendall(data)
            if not wait_for_reply:
                return

            info = sock.recv(InfoStruct.size)
            size, version = InfoStruct.unpack(info)
            if version > InfoVersion("server is incompatible")
            result = bytearray()
            while True:
                data = sock.recv(4000)
                if not data:
                    break
                result.extend(data)
                if len(result) >= size:
                    break
        return pickle.loads(result)
    except ValueError as err:
        print(err)
        sys.exit(1)
    except socket.error as err:
        print("{0}: is the server running?".format(err))
        sys.exit(1)

main()






#Reminder of topics<===========
===============================================================================================
CHAPTER: 12 Database Programming 
CHAPTER BEGIN
===============================================================================================

DBM Databases 
SQL Databases 
Summary
Exercises 
#1) 

#CODE LIST
bookmarks.py
dvds-dbm.py
dvds-sql.py


===============
CHAPTER 12 Database Programming 
===============

#For most software developers, the term database is usually taken to mean an 
#RDBMS (Relational Database Management System). These systems use tables (spreadsheet
#like grids) with rows equating to records and columns equating to fields. The tables
#and the data they hold are created and manipulated using statements written in SQL
#(Structured Query Langauge). Python provides an API for working with SQL databases and
#it is normally distributed with the SQLite 3 database as standard.

#Another kind of database is a DBM (Database Manager) that stores any number of key-value
#items. Python's standard library comes with interfaces to several DBMs, including some
#that are Unix-specific. DBMs work just like Python dictionaries except that they are
#normally held on disk rather than in memory and their keys and values are always bytes
#objects and may be subject to length constraints. The 
shelve #module covered in this chapter's first section provides a convenient DBM interface
#that allows us to use string keys and any (pickable) objects as values.

#If the available DBMs and the SQLite databaes are insufficient, the Python Package 
#Index (pypi.python.org/pypi) has a large number of database-related packages, including
#the bsddb DBM ("Berkley DB"), and interfaces to popular client/server databases such
#as DB2, Informix, Ingres, MySQL, ODBC, and PostgreSQL.

#Using SQL database requires knowledge of the SQL language and the manipulation of strings
#of SQL statements. This is fine for those experienced with SQL, but is not very Pythonic.
#There is another way to interact with SQL databases --> use an ORM (Object Relational
#Mapper). Two of the most popular ORMs for Python are available as third-party libraries --
#they are SQLAlchemy (www.sqlalchemy.org) and SQLObject (www.sqlobject.org). One
#particulary nice feature of using an ORM is that it allows us to use Python syntax --
#creating objects and calling methods -- rather than using raw SQL.

#In this chapter we will implement two versions of a program that maintains a list
#of DVDs, and keeps track of each DVD's title, year of release, length in minutes,
#and director. The first version uses a DBM (via the shelve module) to store its
#data, and the second version uses the SQLite database. Both programs can also load
#and save a simple XML format, making it possible, for example, to export DVD data
#from one program and import it into the other. The SQL-based version offers slightly
#more functionality than the DBM one, and has a slightly cleaner data design.


#Reminder of topics
DBM Databases 
SQL Databases 
Summary
Exercises 
#1) 

#CODE LIST
bookmarks.py
dvds-dbm.py
dvds-sql.py


===============
DBM Databases
===============

#DBM Databases (Database Manager Databases)
#The shelve module provides a wrapper around a DBM that allows us to interact with
#DBM as though it were a dictionary, providing that we use only string key and 
#pickable values. Behind the scenes the shelve module converts the keys and values
#to and from bytes objects.

#The shelve modules uses the best underlying DBM available, so it is possible that a
#DBM file saved on one machine wont be readable on another, if the other machine
#doesnt have the same DBM. One solution is to provide XML import and export for files
#s that must be transportable between machines -- something we have done for this 
#section's DVD program, dvd-dbm.py

#For the keys, we use the DVDs' titles and for the values we use tuples holding the
#director, year, and duration. Thanks to the shelve module we dont have to do any
#data conversino and can just treat the DBM object as a dictionary.

#Since the structure of the program is similar to interactive menu-driven programs
#that we have seen beofre, we will focus just on those aspects that are specific
#to DBM programming. Here is an extract from the program's main() function, with
#the meun handling omitted:

    db = None
    try:
        db = shelve.open(filename, protocol=pickle.HIGHEST_PROTOCOL)
        ...
    finally:
        if db is not None:
            db.close()

#Here we have opened (or created if it does not exist) the specified DBM file for
#both reading and writing. Each item's value is saved as a pickle using the specified
#pickle protocol; existing items can be read even if they were saved using a lower
#protocol since Python can figure out the correct protocol to use for reading 
#pickles. At the end the DBM is closed -- this has the effect of clearing the DBM's
#internal cache and ensuring that the disk file reflects any changes that have been
#made, as well as closing the file.

#The program offers options to add, edit, list, remove, import, and export DVD data.
#We will skip importing and exporting the data from and to XML format since it is
#very similar to what we have done in Chapter 7. And apart from adding, we will omit
#most of the user interface code, again b/c we have seen it before in other contexts.

    def add_dvd(db):
        title = Console.get_string("Title", "title")
        if not title:
            return
        director = Console.get_string("Director", "director")
        if not director:
            return
        year = Console.get_integer("Year", "year", minimum=1986, maximum=datetime.date.today().year)
        duration = Console.get_integer("Duration (minutes)", "minutes", minimum-0, maximum=60*48)
        db[title] = (director, year, duration)
        db.synch()

#This function, like all the functions called by the program's menu, is passed the 
#DBM object (db) as its sole parameter. Most of the function is concerned with getting
#the DVD's details, and in the penultimate line we store the key-value item in the 
#DBM file, with the DVD's title as the key and director, year, and duration (pickled
#together by shelve) as the value.

#In keeping with Python's usual consistency, DBMs provide the same API as dictionaries,
#so we dont have to learn any new syntax beyond the shelve.open() function taht we saw
#earlier and the shelve.Shelf.sync() method that is used to clear the shelve's internal
#cache and synchronize the disk file's data with the changes that have been applied -- in
#this case just adding a new item.

    def edit_dvd(db):
        old_title = find_dvd(db, "edit")
        if old_title is None:
            return
        title = Console.get_string("Title", "title", old_title)
        if not title:
            return
        director, year, duration = db[old_title]
        ...
        db[title] = (director, year, duration)
        if title != old_title:
            del db[old_title]
        db.sync()

#To be able to edit a DVD, the user must first choose the DVD to work on. This is
#just a matter of getting the title since titles are used as keys with the values
#holding the other data. Since the necessary functionality is needed elsewhere
#(eg when removing a DVD), we have factored it out into a separate find_dvd() function
#that we look at next. If the DVD is found we get the user's changes, using the
#existing values as defaults to speed up the interaction. (We have omitted most of the user
#interface code for this function since it is almost the same as that used when adding
#a DVD.) At the end we store the data just as we did when adding. If the title is 
#unchanged this will have the effect of overwriting the associated value, and if the title
#is different this has the effect of creating a new key-value item, in which case we 
#delete the original item.

    def find_dvd(db, message):
        message = "(Start of) title to " + message
        while True:
            matches = []
            start = Console.get_string(message, "title")
            if not start:
                return None
            for title in db:
                if title.lower().startswith(start.lower()):
                    matches.append(title)
            if len(matches) == 0:
                print ("There are not dvds starting with", start)
                continue
            elif len(matches) == 1:
                return matches[0]
            elif len(matches) > DISPLAY_LIMIT:
                print("Too many dvds start with {0}; try entering "
                      "more of the title".format(start))
                continue
            else:
                matches = sorted(matches, key=str.lower)
                for i, match in enumerate(matches):
                    print("{0}: {1}".format(i+1, match))
                which = Console.get_integer("Number (or 0 to cancel)", "number", 
                                            minimum=1, maximum=len(matches))
                return matches[which - 1] if which != 0 else None

#To make finding a DVD as quick and easy as possible we require the user to type
#in only one or the first few characters of its title. Once we have the start of
#the title we iterate over the DBM and create a list of matches. If there is one
#match we return it, and if there are several matches (but fewer than DISPLAY_LIMIT,
#an integer set elsewhere in the program) we display them all in case-insensitive
#order with a number beside each one so that the user can choose the title just by
#entering its number. (The Console.get_integer() function accepts 0 even if the
#minimum is greater than zero so that 0 can be used as a cancellation value. This
#behavior can be switched off by passing
allow_zero=False #. We cant use Enter, that is, nothing, to mean cancel, since
#entering nothing means accepting the default.)

    def list_dvds(db):
        start = ""
        if len(db) > DISPLAY_LIMIT:
            start = Console.get_string("List those starting with [Enter=all]", "start")
        print()
        for title in sorted(db, key=str.lower):
            if not start or title.lower().startswith(start.lower()):
                director, year, duration = db[title]
                print("{title} ({year}) {duration} minute{0}, by {director}".format(Util.s(duration), **locals)))

#Listing all the DVDs (or those whose title starts with a particular substring) is simply
#a matter of iterating over the DBM's items.

#The Util.s() is simply
s = lambda x: "" if x == 1 else "s" 
#so here it returns an "s" if the duration is not one minute.

    def remove_dvd(db):
        title = find_dvd(db, "remove")
        if title is None:
            return
        ans = Console.get_bool("Remove {0}?".format(title), "no")
        if ans:
            del db[title]
            db.sync()

#Removing a DVD is a matter of finding the one the user wants to remove, asking for
#confirmation, and if we get it, deleting the item from the DBM.

#We have now seen how to open (or create) a DBM file using the shelve module, and how
#to add items to it, edit its items, iterate over its items, and remove items.

#Unforetunately, there is a flaw if our data design. Director names are duplicated,
#and this could easily lead to inconsistencies; for example, director Danny DeVito
#might be entered as "Danny De Vito" for one movie and "Danny deVito" for another.
#One solution would be to have tow DBM files, the main DVD file with title keys and
#(year, duration, director ID) values, and a director file with director ID (ie integer)
#keys and director name values. We avoid this flaw in the next section's SQL database
#version of the program by using two tables, one for DVDs and another for directors.


#Reminder of topics
DBM Databases 
SQL Databases 
Summary
Exercises 
#1) 

#CODE LIST
bookmarks.py
dvds-dbm.py
dvds-sql.py


===============
SQL Databases 
===============

#Interfaces to most popular SQL databases are available from third party modules,
#and out of the box Python comes with sqlite3 module (and with the SQLite 3 database),
#so database programming can be started right away. SQLite is a lightweight SQL
#database, lacking many of the features of, say, Postgre SQL, but it is very convenient
#for prototyping, and may prove sufficient in many cases.

#To make it as easy as possible to switch between database backends, PEP 249
#(Python Databae API Specification c2.0) provides an API specification called
#DB-API 2.0 that database interfaces ought to honor -- the sqlite3 module, for example,
#complies with the specification, but not all the third-party modules do. There are
#two major objects specified by the API, the connection object and the cursor object,
#and the APIs they must support are shown in Tables 12.1 and 12.2. In the case of the
#sqlite3 module, its connection and cursor objects both provide many additional
#attributes and methods beyond those required by the DB-API 2.0 specification.

#The SQL version of the DVDs program is 
dvd-sql.py #. The program stores directors
#separately from the DVD data to avoid duplication and offers one more menu option
#that lets the user list the directors. The two tables are shown in Figure 12.1. The
#program has slightly fewer than 300 lines, whereas the previous sections's dev-dbm.py
#program is slightly fewer than 200 lines, with most of the difference due to the fact
#that we must use SQL queries rather than performe simple dictionary-like operations,
#and b/c we must create the database's tables the first time the program runs.

################################################ Figure 12.1
The DVD program's database design                           '

    dvds                            directors
                ------------->      
    id                              id  
    title                           name
    year
    duration
    director_id
################################################

################################################ Table 12.1
DB-API 2.0 Connection Object Methods

    Syntax              Description
    --------------      ------------------------------------------------
    db.close()          Closes the connection to the database (represented by the db
                        object which is obtained by calling a connect() function)

    bd.commit()         Commits any pending transaction to the database; does nothing
                        for databases that dont support transactions
    
    bd.cursor()         Returns a database cursor object through which queries can 
                        be executed
     
    db.rollback()       Rolls back any pending transaction to the state that existed
                        before the transaction began; does nothing for databases 
                        that dont support transactions
################################################

#The main() function is similar to before, only this time we call a custom
#connect() function to make the connection.

    def connect(filename):
        create = not os.path.exists(filename)
        db = sqlite3.connect(filename)
        if create:
            cursor = db.cursor()
            cursor.execute("CREATE TABLE directors("
                "id INTEGER PRIMARY KEY AUTOINCREMENT UNIQUE NOT NULL, "
                "name TEXT UNIQUE NOT NULL)")
            cursor.execute("CREATE TABLE dvds ("
                "id INTEGER PRIMARY KEY AUTOINCREMENT UNIQUE NOT NULL, "
                "title TEXT NOT NULL, "
                "year INTEGER NOT NULL, "
                "duration INTEGER NOT NULL, "
                "director_id INTEGER NOT NULL, "
                "FOREIGN KEY (director_id) REFERENCES directors) ")
            db.commit()
        return db

#The sqlite3.connect() function returns a database object, having opened the database
#file it is given and created an empty database file if the file did not exist. In
#view of this, prior to calling sqlite3.connect(), we note whether the database is
#going to be creted from scratch, b/c if it is, we must create the tables that the
#program relies upon. All queries are executed through a database cursor, available
#from the database object's cursor() method.

#Notice that both tables are created with an ID field that has an AUTOINCREMENT
#constraint -- this means that SQLite will automatically populate the IDs wit
#unique numbers so we can leave these fields to SQLite when inserting new records.

#SQLite supports a limited range of data types -- essentially just Booleans, numbers,
#and strings -- but this can be extended using data "adaptors", either the predefined
#ones such as those for dates and datetimes, or custom ones that we can use to represent
#any data types we like. The DVDs program does not need this functionality, but if it
#were required, the sqlite3 module's documentation explains the details. The foreign
#key syntax we have used mya not be the same as the syntax for the other databases, and
#in any case it is merely documenting out intention, since SQLite, unlike many other 
#databases, does not enforce relational integrity. (However, SQLite does have a workaround
#based on sqlite3's
.genfkey #command.) One other sqlite3-specific quirk is that its default behavior is to
#support implicit transactions, so there is no explicit "start transactions" method.


################################################ Table 12.2
DB-API 2.0 Cursor Object Attributes and Methods

    Syntax              Description
    --------------      ------------------------------------------------
    c.arraysize         The (readable/writable) number of rows that fetchmany() will
                        return if no size is specified

    c.close()           Closes the cursor, c; this is done automatically when the 
                        cursor goes out of scope

    c.description       A read-only sequence of 7-tuples (name, type_code, display_size,
                        internal_size, precision, scale, null_ok), describing each 
                        successive column of cursor c

    c.execute(sql, params)  Executes the SQL query in string sql, replacing each 
                            placeholder with the corresponding parameter from the 
                            params sequence or mapping if given 
    
    c.executemany(sql, seq_of_params)   Executes the SQL query once for each item in 
                                        the seq_of_params seqence of sequences or mappings;
                                        this method should not be used for operations that
                                        create result sets (such as SELECT statements)

    c.fetchall()        Returns a sequence of all the rows that have not yet been 
                        fetched (which could be all of them)

    c.fetchmany(size)   Returns a sequence of rows (each row itself being a sequence);
                        size defaults to c.arraysize

    c.fetchone()        Returns the next row of the query result set as a sequence, or 
                        None when the results are exhausted. Raises an exception if there 
                        is no result set.

    c.rowcount          The read-only row count for the last operation (eg SELECT, INSERT,
                        UPDATE, or DELETE) or -1 if not available or not applicable
################################################

    def add_dvd(db):
        title = Console.get_string("Title", "title")
        if not title:
            return 
        director = Console.get_string("Director", "director")
        if not director:
            return
        year = Console.get_integer("Year", "year", minimum=1896, maximum=datetime.date.today().year)
        duration = Console.get_integer("Duration (minutes)", "minutes", minimum=0, maximum=60*48)
        director_id = get_and_set_director(db, director)
        cursor = db.cursor()
        cursor.execute("INSERT INTO dvds "
                       "(title, year, duration, director_id) "
                       "VALUES (?, ?, ?, ?)",
                       (title, year, duration, director_id))
        db.commit()

#This function starts with the same code as the equivalent function from the dvds-dbm.py
#program, but once we have gathered the data, it is quite different. The director the
#user entered may or may not be in the directors table, so we have a get_and_set_director()
#function that inserts the director if they are not already in the database, and in either
#case returns the director's ID ready for it to be inserted into the dvds table. With all
#the data available we execute an SQL INSERT statement. We dont need to specify a record ID
#since SQLite will automatically provide one for us.

#In the query we have used question marks for placeholders. Each ? is replaced by the 
#corresponding value in the sequence that follows the string containing the SQL statement.
#Named placeholders can also be used as we will see when we look at editing a record. 
#Although it is possible to avoid using placeholders and simply format the SQL string with
#the data embedded into it, we recommend always using placeholders and leaving the burden
#of correctly encoding and escaping the data items to the database module. Another benefit
#of using placeholders is that they improve security since they prevent arbitrary SQL from
#being maliciously injected into a query.

    def get_and_set_director(db, director):
        director_id = get_director_id(db, director)
        if director_id is not None:
            return director_id
        cursor = db.cursor()
        cursor.execute("INSERT INTO directors (name) VALUES (?)", (director))
        db.commit()
        return get_director_id(db, director)

#This function returns the ID of the given director, inserting a new director record
#if necessary. If a record is inserted we retrieve its ID using the get_director_id()
#function we tried in the first place.

    def get_director_id(db, director):
        cursor = db.cursor()
        cursor.execute("SELECT id FROM directors WHERE name=?", (director,))
        fields = cursor.fetchone()
        return fields[]0 if fields is not None else None

#The get_director_id() function returns the ID of the given director or None if there
#is no such director in the database. We used the fetchone() method b/c there is 
#either zero or one matching record. (We know that there are no duplicate directors
#b/c the directors table's name field has a UNIQUE constraint, and in any case we
#always check for the existence of a director before adding a new one.) The fetch
#methods always return a sequence of fields (or None if there are no more records),
#even if, as here, we have asked to retrieve only a single field.

    def edit_dvd(db):
        title, identity = find_dvd(db, "edit")
        if title is None:
            return
        title = Console.get_string("Title", "title", title)
        if not title:
            return
        cursor = db.cursor()
        cursor.execute("SELECT dvds.year, dvds.duration, directors.name "
                       "FROM dvds, directors "
                       "WHERE dvds.director_id = directors.id AND "
                       "dvds.id=:id", dict(id=identity))
        year, duration, director = cursor.fetchone()
        director = Console.get_string("Director", "director", director)
        if not director:
            return
        year = Console.get_integer("Year", "year", year, 1896, datetime.date.today().year)
        duration = Console.get_integer("Duration (minutes)", "minutes", duration, minimum=0, maximum=60*48)
        director_id = get_and_set_director(db, director)
        cursor.execute("UPDATE dvds SET title=:title, year=:year, duration=:duration, "
                       "director_id=:director_id WHERE id=:identity", locals())
        db.commit()

#To edit a DVD record we must first find the record the user wants to work on. If a record is
#found we begin by giving the user the opportunity to change the title. Then we retrieve the
#other fields so that we can provide the existing values as defaults to minimize what the 
#user must type since they can just press Enter to accept a default. Here we have used named
#placeholders (of the form :name), and must therefore provie the corresponding values using
#a mapping. For the SELECT statement we have used freshly created dictionary, and for the 
#UPDATE statement we have used the dictionary returned by locals().

#We could use a fresh dictionary for both, in which case for the UPDATE we would pass
dict(title=title, year=year, duration=duration, director_id=director_id, id=identity))
#instead of locals().

#Once we have all the fields and the user has entered any changes they want, we retrieve 
#the corresponding director ID (inserting a new director record if necessary), and then
#update the database with the new data. We have taken the simplistic approach of updating
#all the record's fields rather than only those which have actually been changed.

#When we used a DBM file, the DVD title was used as the key, so if the title changed, we
#created a new key-value item  and deleted the original. But here every DVD record has a
#unique ID which is set when the record is first inserted, so we are free to change the
#avlue of any other field with no further work necessary.

    def find_dvd(db, message):
        message = "(Start of) title to " + message 
        cursor = db.cursor()
        while True:
            start = Console.get_string(message, "title")
            if not start:
                return (None, None)
            cursor.execute("SELECT title, if FROM dvds WHERE title LIKE ? ORDER BY title", start + "%",)
            records = cursor.fetchall()
            if len(records) == 0:
                print("There are no dvds starting with", start)
                continue
            elif len(records) == 1:
                return records[0]
            elif len(records) > DISPLAY_LIMIT:
                print("Too many dvds ({0}) start with {1}; try entering more of the title".format(len(records), start))
                continue
            else:
                for i, record in enumerate(records):
                    print("{0}: {1}".format(i+1, record[0]))
                which = Console.get_integer("Number (or 0 to cancel)", "number", minimum=1, maximum=len(records))
                return records[which - 1] if which != 0 else (None, None)

#This function performs the same service as the find_dvd() function in the dvds-dbm.py
#program, and returns a 2-tuple (title, DVD ID), or (None, None) depending on whether a
#record was found. Instead of iterating over all the data we have used the SQL wildcard
#operator (%), so only the relevant records are retrieved. And since we expect the number
#of matching records to be small, we fetch them all at once into a sequence of sequences. If
#there is more than one matching records and few enough to display, we print the records with
#a number beside each one so that the user can choose the one they want in much the same way
#as they could in the dvds-dbm.py program.

    def list_dvds(db):
        cursor = db.cursor()
        sql = ("SELECT dvds.title, dvds.year, dvds.duration, directors.name FROM dvds, directors "
               "WHERE dvds.director_id = directors.id")
        start = None
        if dvd_count(db) > DISPLAY_LIMIT:
            start = Console.get_string("List thos starting with [Enter=all]", "start")
            sql += " AND dvds.title LIKE ?"
        sql += " ORDER BY dvds.title"
        print()
        if start is None:
            cursor.execute(sql)
        else:
            cursor.execute(sql, (start "%",))
        for record in cursor:
            print("{0[0]} ({0[1]}) {0[2]} minutes, by {0[3]}".format(record))

#To list the details of each DVD we do a SELECT query that joins the two tables, adding
#a second element to the WHERE clause if there are more records (returned by our
#dvd_count() function) than the display limit. We then execute the query and iterate over
#the results. Each record is a sequence whose fields are those matching the SELECT query.

    def dvd_count(db):
        cursor = db.cursor()
        cursor.execute("SELECT COUNT(*) FROM dvds")
        return cursor.fetchone()[0]

#We factored these lines out into a separate function b/c we need them in several 
#different functions.

#We have omitted the code the list_directors() function since it is structurally
#very similar to the list_dvds() function, only simplier b/c it lists only one field (name).

    def remove_dvd(db):
        title, identity = find_dvd(db, "remove")
        if title is None:
            return
        ans = Console.get_bool("Remove {0}?".format(title), "no")
        if ans:
            cursor = db.cursor()
            cursor.execute("DELETE FROM dvds WHERE id=?", (identity,))
            db.commit()

#This function is called when the user asks to delete a record, and it is very similar
#to the equivalent function in the 
dvds-dbm.py program.

#We have now completed our review of the dvds-sql.py program and seen how to create
#database tables, select records, iterate over the selected records, and insert, update,
#and delete records. Using the execute() methods we can execute any arbitrary SQL 
#statement that the underlying database supports.

#SQLite offers much more functionality than we needed here, including an auto-commit mode 
#(and other kinds of transaction control), and the ability to create functions that can
#be executed inside SQL queries. It is also possible to provide a factory function to 
#control what is returned for each fetched record (eg a dictionary or custom type instead
#of a sequence of fields). Additionally, it is possible to create in-memory SQLite databases
#by passing ":memory:" as the filename.


#Reminder of topics
DBM Databases 
SQL Databases 
Summary
Exercises 
#1) 

#CODE LIST
bookmarks.py
dvds-dbm.py
dvds-sql.py


===============
Summary
===============

#Back in Chapter 7 we saw several different ways of saving and laoding data from disk, 
#and in this chapter we have seen how to interact with data types that hold their data
#on disk rather than in memory.

#For DBM files, the shelve module is very convenient since it stores string-object items.
#If we want complete control, we can of course use any of the underlying DBMs directly. One
#nice feature of the shelve module and of the DBMs generally is that they use the 
#dictionary API, making it easy to retrieve, add, edit, and remove items, and to convert
#programs that use dictionaries to use DBMs instead. One small inconvenience of DBMs is that
#for relational data, we must use a separate DBM file for each key-value table, whereas
#SQLite stores all the data in a single file.

#For SQL databases, SQLite is useful for protyping, and in many cases in its own right,
#and it has the advantage of being supplied with Python as standard. We have seen how to
#obtain a database object using the connect() function and how to execute SQL queries (such
#as CREATE TABLE, SELECT, INSERT, UPDATE, and DELETE) using the database cursor's
#execute() method.

#Python offers a complete range of choices for disk-based and in-memory data storage, 
#from binary files, text files, XML files, and pickles, to DBMs and SQL databases, and
#this makes it possible to choose exactly the right approach for any given situation.


===============
Exercises 
===============

#1)Write an interactie console program to maintain a list of bookmarks. For each
#bookmark, keep two pieces of information: the URL and a name. Here is an example
#of the program in action:

    Bookmarks (bookmarks.dbm)
    (1) Programming in Python 3........ http://www.qtrac.eu/py3book.html
    (2) PyQt........................... http://www.riverbankcomputing.com
    (3) Python......................... http://www.python.org
    (4) Qtrac Ltd...................... http://www.qtrac.eu
    (5) Scientific Tools for Python.... http://www.scipy.org

    (A)dd  (E)dit  (L)ist  (R)emove  (Q)uit [l]: e
    Number of bookmark to edit: 2
    URL [http://www.riverbankcomputing.com]:
    Name [PyQt]: PyQt (Python bindings for GUI library)

#The program should allow the user to add, edit, list, and remove bookmarks. To 
#make identifying a bookmark for editing or removing as easy as possible, list the
#bookmarks with numbers and ask the user to specify the number of the bookmark
#they want to edit or remove. Store the data in a DBM file using the shelve module
#and with the names as keys and URLs as values. Structurally the program is very
#similar to dvds-dbm.py, except for the find_bookmark() function which is much
#simplier than find_dvd() since it only has to get an integer from the user and
#use that to find the corresponding bookmark's name.

#As a courtesy to users, if no protocol is specified, prepend the URL the user
#adds or edits with http://.

#The entire program can be writtn in fewer in 100 lines (assuming the use of the
#the Console module for Console.get_string() and similar). Solution is 
bookmarks.py

#CODE LIST
bookmarks.py
dvds-dbm.py
dvds-sql.py


#CODE HERE
bookmarks.py

#!/usr/bin/env python3

import os
import pickle
import shelve
import sys
import Console
import Util

def main():
    functions = dict(a=add_bookmark, e=edit_bookmark, l=list_bookmarks, r=remove_bookmarks, q=quit)
    filename = os.path.join(os.path.dirname(__file__), "bookmarks.dbm")
    db = None
    try:
        db = shelve.open(filename, protocol=pickle.HIGHEST_PROTOCOL)
        action = ""
        while True:
            print("\nBookmarks ({0})".format(os.path.basename(filename)))
            list_bookmarks(db)
            print()
            menu = "(A)dd    (E)dit    (L)ist    (R)emove    (Q)uit"
            action = Console.get_menu_choice(menu, "aelrq", "l" if len(db) else "a", True)
            functions[action](db)
    finally:
        if db is not None:
            db.close()

def add_bookmark(db):
    url = Console.get_string("URL", "URL")
    if not url:
        return 
    if "://" not in url:
        url = "http://" + url
    name = Console.get_string("Name", "name")
    if not name:
        return 
    db[name] = url
    db.sync()

def edit_bookmark(db):
    name = find_bookmark(db, "edit")
    if name is None:
        return
    url = Console.get_string("URL", "URL", db[name])
    if not url:
        return
    if "://" not in url:
        url = "http:??" + url
    new_name = Console.get_string("Name", "name", name)
    db[new_name] = url
    if new_name != name:
        del db[name]
    db.sync()

def list_bookmarks(db):
    for i, name in enumerate(sorted(fb, key=str.lower)):
        print("({0}) {1:.<40} {2}".format(i + 1, name, db[name]))

def remove_bookmark(db):
    name = find_bookmark(db, "remove")
    if name is None:
        return 
    ans = Console.get_bool("Remove {0}?".format(db[name]), "no")
    if ans:
        del sb[name]
        db.sync()

def quit(db):
    print("Saved {0} bookmark{1}".format(len(db), Util.s(len(db))))
    db.close()
    sys.exit()

def find_bookmark(db, message):
    message = "Number of bookmark to " + message
    number = Console.get_integer(message, "number", minimum=0, maximum=len(db))
    if number == 0:
        return None
    number -= 1
    for i, name in enumerate(sorted(db, key=str.lower)):
        if i == number:
            return name 

main()






#CODE LIST
bookmarks.py
dvds-dbm.py
dvds-sql.py


#CODE HERE
dvds-dbm.py

#!/usr/bin/env python3

import datetime
import os
import pickle
import shelve
import sys
import tempfile
import xml.etree.ElementTree
import xml.parsers.expat
import xml.sax.saxutils
import Console
import Util

DISPLAY_LIMIT = 20


def main():
    functions = dict(a=add_dvd, e=edit_dvd, l=list_dvds, r=remove_dvd, i=import_, x=export, q=quit)
    filename = os.path.join(os.path.dirname(__file__), "dvds.dbm")
    db = None
    try:
        db = shelve.open(filename, protocol=pickle.HIGHEST_PROTOCOL)
        action = ""
        while True:
            print("\nDVDs ({0})".format(os.path.basename(filename)))
            if action != "1" and 1 <= len(db) < DISPLAY_LIMIT:
                list_dvds(db)
            else:
                print("{0} dvd{1}".format(len(db), Util.s(len(db))))
            print()
            menu = ("(A)dd    (E)dit    (L)ist    (R)emove    (I)mport   e(X)port    (Q)uit"
                    if len(db) else "(A)dd    (I)mport    (Q)uit")
            valid = frozenst("aelrixq" if len(db) else "aiq")
            action = Console.get_menu_choice(menu, valid, "1" if len(db) else "a", True)
            functions[action](db)
    finally:
        if db is not None:
            db.close()

def add_dvd(db):
    title = Console.get_string("Title", "title")
    if not title:
        return
    director = Console.get_string("Director", "director")
    if not director:
        return
    year = Console.get_integer("Year", "year", minimum=1896, maximum=datetime.date.today().year)
    duration = Console.get_integer("Duration (minutes)", "minutes", minimum=0, maximum=60*48)
    db[title] = (director, year, duration)
    d.sync()

def edit_dvd(db):
    old_title = find_dvd(db, "edit")
    if old_title is None:
        return 
    title = Console.get_string("Title", "title", "old_title")
    if not title:
        return
    director, year, duration = db[old_title]
    director = Console.get_string("Director", "director", director)
    if not director:
        return 
    year = Console.get_integer("Year", "year", year, 1896, datetime.date.today().year)
    duration = Console.get_integer("Duration (minutes)", "minutes", duration, minimum=0, maximum=60*48)
    db[title] = (director, year, duration)
    if title != old_title:
        del db[old_title]
    db.sync()

def list_dvds(db):
    start = ""
    if len(db) > DISPLAY_LIMIT:
        start = Console.get_string("List those starting with [Enter=all]", "start")
    print()
    for title in sorted(db, key=str.lower):
        if not start or title.lower().startswith(start.lower()):
            director, year, duration = db[title]
            print("{title} ({year}) {duration} minute{0}, by {director}".
                format(Util.s(duration), **locals()))

def remove_dvd(db):
    title = find_dvd(db, "remove")
    if title is None:
        return 
    ans = Console.get_bool("Remove {0}?".format(title), "no")
    if ans:
        del db[title]
        db.sync()

def import_(db):
    filename = Console.get_string("Import from", "filename")
    if not filename:
        return 
    try:
        tree = xml.etree.ElementTree.parse(filename)
    except (EnvironmentError, xml.parsers.expat.ExpatError) as err:
        print("ERROR:", err)
        return 
    db.clear()
    for element in tree.findall("dvd"):
        try:
            year = int(element.get("year"))
            duration = int(element.get("duration"))
            director = element.get("director")
            title = element.text.strip()
            db[title] = (director, year, duration)
        except ValueError as err:
            print("ERROR:", err)
            return 
        print("Imported {0} dvd{1}".format(len(db), Util.s(len(db))))
        db.sync()

def export(db):
    filename = os.path.join(tempfile.gettempdir(), "dvds.xml")
    with open(filename, "w", encoding="utf8") as fh:
        fh.write('<?xml version="1.0" encoding="UTF-8"?>\n')
        fh.write("<dvds>\n")
        for title in sorted(db, key=str.lower):
            director, year, duration = db[title]
            fh.write('<dvd year>="{year}" duration="{duration} director={0}>'.
                format(xml.sax.saxutils.quoteattr(director), **locals()))
            fh.write(xml.sax.saxutils.escape(title))
            fh.write("</dvds>\n")
            fh.close()
        print("exported {0} dvd{1} to {2}".format(len(db), Util.s(len(db)), filename))

def quit(db):
    print("Saved {0} dvd{1}".format(len(db), Util.s(len(db))))
    db.close()
    sys.exit()

def find_dvd(db, message):
    message = "(Start of) title to " + message 
    while True:
        matches = []
        start = Console.get_string(message, "title")
        if not start:
            return None
        for title in db:
            if title.lower().startswith(start.lower()):
                matches.append(title)
        if len(matches) == 0:
            print("There are not dvds starting with", start)
            continue
        elif len(matches) == 1:
            return matches[0]
        elif len(matches) > DISPLAY_LIMIT:
            print("Too many dvds start with {0}; try entering more of the title."format(start))
            continue 
        else:
            matches = sorted(matches, key=str.lower)
            for i, match in enumerate(matches):
                print("{0}: {1}".format(i + 1, match))
            which = Console.get_integer("Number (or 0 to cancel)", "number", minimum=1, maximum=len(matches))
            return matches[which - 1] if which !=0 else None

main()




#CODE LIST
bookmarks.py
dvds-dbm.py
dvds-sql.py


#CODE HERE
dvds-sql.py

#!/usr/bin/env python3

import datetime
import os
import sqlite3      #NEW
#import pickle
#import shelve
import sys
import tempfile
import xml.etree.ElementTree
import xml.parsers.expat
import xml.sax.saxutils
import Console
import Util

DISPLAY_LIMIT = 20


def main():
    functions = dict(a=add_dvd, e=edit_dvd, l=list_dvds, d=list_directors, r=remove_dvd, i=import_, x=export, q=quit)
    filename = os.path.join(os.path.dirname(__file__), "dvds.sdb")
    db = None
    try:
        db = connect(filename)
        action = ""
        while True:
            count = dvd_count(db)
            print("\nDVDs ({0})".format(os.path.basename(filename)))
            if action != "1" and 1 <= count < DISPLAY_LIMIT:
                list_dvds(db)
            else:
                print("{0} dvd{1}".format(count, Util.s(count)))
            print()
            menu = ("(A)dd    (E)dit    (L)ist    (D)irectors    (R)emove    (I)mport   e(X)port    (Q)uit"
                    if len(db) else "(A)dd    (I)mport    (Q)uit")
            valid = frozenst("adelrixq" if count else "aiq")
            action = Console.get_menu_choice(menu, valid, "1" if count else "a", True)
            functions[action](db)
    finally:
        if db is not None:
            db.close()


def connect(filename):          #NEW METHOD for sql
    create = not os.path.exists(filename)
    db = sqlite3.connect(filename)
    if create:
        cursor = db.cursor()
        cursor.execute("CREATE TABLE directors id INTEGER PRIMARY KEY AUTOINCREMENT UNIQUE NOT NULL, name TEXT UNIQUE NOT NULL")
        cursor.execute("CREATE TABLE dvds ("
                        "id INTEGER PRIMARY KEY AUTOINCREMENT UNIQUE NOT NULL"
                        "title TEXT NOT NULL"
                        "year INTEGER NOT NULL"
                        "duration INTEGER NOT NULL"
                        "director_id INTEGER NOT NULL"
                        "FOREIGN KEY (director_id) REFERENCES directors)")
        db.commit()
    return db


def add_dvd(db):
    title = Console.get_string("Title", "title")
    if not title:
        return
    director = Console.get_string("Director", "director")
    if not director:
        return
    year = Console.get_integer("Year", "year", minimum=1896, maximum=datetime.date.today().year)
    duration = Console.get_integer("Duration (minutes)", "minutes", minimum=0, maximum=60*48)
    director_id = get_and_set_director(db, director)        #NEW
    cursor = db.cursor()
    cursor.execute("INSERT INTO dvds "
                    "(title, year, duration, director_id) "
                    "VALUES (?, ?, ?, ?)",
                    (title, year, duration, director_id))
    db.commit()


def get_and_set_director(db, director):
    director_id = get_director_id(db, director)
    if director_id is not None:
        return director_id
    cursor = db.cursor()
    cursor.execute("INSERT INTO directors (name) VALUES (?)", (director,))
    db.commit()
    return get_director_id(db, director)


def get_director_id(db, director):
    cursor = db.cursor()
    cursor.execute("SELECT id FROM directors WHERE name=?", (director,))
    fields = cursor.fetchone()
    return fields[0] if fields is not None else None


def edit_dvd(db):
    title, identity = find_dvd(db, "edit")      #new
    if title is None:                           #new block
        return                                  
    title = Console.get_string("Title", "title", title)
    if not title:
        return
    cursor = db.cursor()    #new
    cursor.execute("SELECT dvds.year, dvds.duration, directors.name "       #new block
                    "FROM dvds, directors "
                    "WHERE dvds.director_id = directors.id AND "
                    "dvds.is=:id", dict(id=identity))
    year, duration, director = cursor.fetchone()            #new
    director = Console.get_string("Director", "director", director)
    if not director:
        return 
    year = Console.get_integer("Year", "year", year, 1896, datetime.date.today().year)
    duration = Console.get_integer("Duration (minutes)", "minutes", duration, minimum=0, maximum=60*48)
    director_id = get_and_set_director(db, director)
    cursor.execute("UPDATE dvds SET title=:title, year=:year, "
                    "duration=:duration, director_id=:director_id "
                    "WHERE id=:identity", locals())    
    db.commit()


def list_dvds(db):
    cursor = db.cursor()
    sql = ("SELECT dvds.title, dvds.year, dvds.duration, "
            "directors.name FROM dvds, directors "
            "WHERE dvds.director_id = director.id")
    start = None
    if dvd_count(db) > DISPLAY_LIMIT:
        start = Console.get_string("List those starting with [Enter=all]", "start")
        sql += " AND dvds.title LIKE ?"
    sql += " ORDER BY dvds.title"
    print()
    if start is None:
        cursor.execute(sql)
    else:
        cursor.execute(sql, (start = "%",))
    for record in cursor:
        print("{0[0]} ({0[1]}) {0[2]} minutes, by {0[3]}".format(record))


def list_directors(db):
    cursor = db.cursor()
    cursor.execute("SELECT COUNT(*) FROM directors")
    cursor.execute.fetchone()[0]
    sql = "SELECT name FROM directors"
    start = None
    if count > DISPLAY_LIMIT:
        start = Console.get_string("List those starting with [Enter=all]", "start")
        sql += " WHERE name LIKE ?"
    sql += " ORDER BY name"
    print()
    if start is None:
        cursor.execute(sql)
    else:
        cursor.execute(sql, (start + "%",))
    for fields in cursor:
        print(fields[0])


def remove_dvd(db):
    title, identity = find_dvd(db, "remove")
    if title is None:
        return 
    ans = Console.get_bool("Remove {0}?".format(title), "no")
    if ans:
        cursor = db.cursor()
        cursor.execute("DELETE FROM dvds WHERE id=?", (identity,))
        db.commit()


def import_(db):
    filename = Console.get_string("Import from", "filename")
    if not filename:
        return 
    try:
        tree = xml.etree.ElementTree.parse(filename)
    except (EnvironmentError, xml.parsers.expat.ExpatError) as err:
        print("ERROR:", err)
        return 

    cursor = db.cursor()
    cursor.execute("DELETE FROM directors")
    cursor.execute("DELETE FROM dvds")

    for element in tree.findall("dvd"):
        get_and_set_director(db, element.get("director"))
    for element in tree.findall("dvd"):
        try:
            year = int(element.get("year"))
            duration = int(element.get("duration"))
            title = element.text.strip()
#           director = element.get("director")
            director_id = get_director_id(db, element.get("director"))
            cursor.execute("INSERT INTO dvds "
                            "(title, year, duration, director_id) "
                            "VALUES (?, ?, ?, ?)",
                            (title, year, duration, director_id))
        except ValueError as err:
            db.rollback()
            print("ERROR:", err)
            break 
    else:
        db.commit()
    count = dvd_count(db)
    print("Imported {0} dvd{1}".format(count, Util.s(count)))


def dvd_count(db):
    cursor = db.cursor()
    cursor.execute("SELECT COUNT(*) FROM dvds")
    return cursor.fetchone()[0]


def export(db):
    TITLE, YEAR, DURATION, DIRECTOR = range(4)
    filename = os.path.join(tempfile.gettempdir(), "dvds.xml")
    cursor = db.cursor()
    cursor.execute("SELECT dvds.title, dvds.year, dvds.duration, "
                    "directors.name FROM dvds, directors "
                    "WHERE dvds.director_id = directors.id "
                    "ORDER BY dvds.title ")
    try:
        with open(filename, "w", encoding="utf8") as fh:
            fh.write('<?xml version="1.0" encoding="UTF-8"?>\n')
            fh.write("<dvds>\n")
            for record in cursor:
                fh.write('<dvd year="{0}" duration="{1}" director={2}>'.
                    format(record[YEAR], record[DURATION], xml.sax.saxutils.quoteattr(record[DIRECTOR])))
                fh.write(xml.sax.saxutils.escape(record[TITLE]))
                fh.write("</dvd>\n")
            fh.write("</dvds>\n")
    except EnvironmentError as err:
        print(err)
    count = dvd_count(db)
    print("exported {0} dvd{1} to {2}".format(count, Util.s(count), filename))


def quit(db):
    if db is not None:
        count = dvd_count(db)
        db.commit()
        db.close()
        print("Saved {0} dvd{1}".format(count. Util.s(count)))
    sys.exit()


def find_dvd(db, message):
    message = "(Start of) title to " + message 
    cursor = db.cursor()
    while True:
        start = Console.get_string(message, "title")
        if not start:
            return (None, None)
        cursor.execute("SELECT title, id FROM dvds WHERE title LIKE ? ORDER BY title", (start + "%",)
        records = cursor.fetchall()

        if len(records) == 0:
            print("There are not dvds starting with", start)
            continue
        elif len(records) == 1:
            return records[0]
        elif len(records) > DISPLAY_LIMIT:
            print("Too many dvds ({0}) start with {1}; try entering more of the title".format(len(records), start))
            continue 
        else:
            for i, record in enumerate(records):
                print("{0}: {1}".format(i + 1, record[0]))
            which = Console.get_integer("Number (or 0 to cancel)", "number", minimum=1, maximum=len(records))
            return records[which - 1] if which !=0 else (None, None)


main()











#Reminder of topics<===========
===============================================================================================
CHAPTER: 13 Regualar Expressions 
CHAPTER BEGIN
===============================================================================================

Python Regular Expression Language
    Character and Character Classes             1
    Quantifiers                                 2
    Grouping and Capturing                      3
    Assertions and Flags                        4
The Regular Expression Module 
Summary
Exercises 
#1) 
#2)


#CODE LIST
bookmarks.py
dvds-dbm.py
dvds-sql.py
-----------
extract_tags.py 
html2text.py
phone.py


===============
CHAPTER 13 Regualar Expressions 
===============

#A regular expression is a compact notation for representing a collection of strings.
#What makes regular expressions so powerful is that a single regular expression can
#represent an unlmited number of strings -- provided they meet the regular expression's
#requirements. Regular expressions (which we will mostly call "regexes" from now on) are
#defined using mini-language that is completely different from Python - but Python 
#includes the re module through which we can seamlessly create and use regexes.
re #module

#Regexes are used for five main purposes:
#1) Parsing: identifying and extracting pieces of text that match certain criteria--regexes
#are used for creating ad hoc parsers and also by traditional parsing tools
(CHAPTER 15 FOCUSES HERE ON Parsing)

#2) Searching: locating substrings that can have more than one form, for example, finding
#any of "pet.jpg', "pet.jpeg", "pet.svg", while avoiding "carpet.png" and similar

#3) Searching and replacing: replacing everywhere the regex matches with a string, for
#example, finding "bicycle" or "human powered vehicle" and replacing either with "bike"

#4) Splitting strings: splitting a string at each place the regex matches, for example,
#splitting everywhere colon-spaced or equals (": " or "="=") occurs

#5) Validation: checking whether a piece of text meets some criteria, for example,
#contains a currency symbol followed by digits

#The regexes used for searching, splitting, and validation are often fairly small
#and understandable, making them ideal for these purposes. However, although regexes
#are widely used and successfully used to create parsers, they do have a limitation
#in that area: they are only able to deal with recursively structured text if the 
#maximum level of recursion is known. Also, large and complex regexes can be difficult
#to read and maintain. So apart from simple cases, for parsing the best approach is to use
#a tool designed for the purpose -- for example, use a dedicated XML parser for XML. If such
#a parser is not available, then an alternative to using regexes is to use a generic
#parsing tool, an approach that is covered in Chapter 14.

#At its simplest a regular expression is an expression (eg a literal character), optionally
#followed by a quantifier. More complex regexes consist of any number of qualified 
#expressions and may include assertions and may be influced by flags.

#This chapter's first section introduces and explains all the key regular expression
#concepts and shows pure regular expresssion syntax -- it makes MINIMAL reference to
#Python iteslf. Then the second section shows how to use regular expressions in the 
#context of Python programming, drawing on all the material covered in the earlier
#sections. Readers familar with regular expressions who just want to learn how they
#work in Python could skip to the second section. The chapter covers the complete
#regex language offered by the re module, including all the assertion and flags. We 
indicate regular expressions in the text using BOLD, show where they match UNDERLINING,
and show captures using SHADING.


#Reminder of topics<===========
CHAPTER 13 Regualar Expressions 

Python Regular Expression Language
    Character and Character Classes             1
    Quantifiers                                 2
    Grouping and Capturing                      3
    Assertions and Flags                        4
The Regular Expression Module 
Summary
Exercises 
#1) 
#2)

#CODE LIST
bookmarks.py
dvds-dbm.py
dvds-sql.py
-----------
extract_tags.py 
html2text.py
phone.py


===============
Python Regular Expression Language
===============

#In this section we look at the regular expression language in four subsections.
#The first subsection shows how to match individual characters or groups of characters,
#for example, match a, or match b, or match either a or b.
#The second subsection shows how to quatify matches, for example, match once, or match
#at least once, or match as many times as possible.
#The third subsection shows how to group subexpressions and how to capture matching text.
#The fourth subsection shows how to use the laguage's assertions and flags to affect how
#regular expressions work.


===============
    Character and Character Classes 
===============

#The simplist expressions are just literal characters, such as a or 5, and if no 
#quantifier is explicitly given it is taken to be "match one occurrence". For example,
#the regex tune consists of four expressions, each implicitly quantified to match once, 
#so it matches one t followed by one u followed by one n followed by one e, and hence
#matches the strings tune and attuned.

#Although most characters can be used as literals, some are "special characters" -- these
#are symbols in the regex language and so must be escapted by precedning them with a 
#backslash (\) to use them as literals. The special characters are \.^$?+*{}[]()|.
#Most of Python's standard string escapes can also be used within regexes, for example, 
#\n for newline and \t for tab, as well as hexadecimal escapes for characters using the
#\xHH, \uHHHH, and \UHHHHHHH syntaxes.

#In many cases, rather than matching one particular character we want to match any one
#of a set of characters. This can be achieved by using a
character class #which is one or more characters enclosed in square brackets. (This has
#nothing to do with a Python class, and is simply the regex term for "set of characters".)
#A character class is an expression, and like any other expression, if not explicitly
#quantified it matches exactly one character (which can be any of the characters in the
#character class). For example, the regex r[ea]d matches both red and radar but not read
#(b/c it looks either e or a but not both ea). Similarly, to match a single digit we can
#use the regez [0123456789]. For convenience we can specify a range of characters using
#a hyphen, so the regex [0-9] also matches a digit. It is possible to negate the meaning
#of a character class by following the opening bracket with a caret, so [^0-9] matches
#any characters that is NOT a digit.

#Note that inside a character class, apart from \, the special characters lose their
#special meaning, although in the case of ^ it acquires a new meaning (negation) if it
#is the first character in the character class, and otherwise is simply a literal caret.
#Also, - signifies a character range unless it is the first character, in which case it 
#is a literal hyphen.

#Since some sets of characters are required so frequently several have short-handed forms
#these are shown in Table 13.1. With on exception, the shorthads can be used inside
#character sets, so for example, the regex [\dA-Fa-f] matches any hexadecimal digit. The
#exception is . which is a shorthand outside a character class but matches a literal . inside
#a character class.


#Reminder of topics
Python Regular Expression Language
    Character and Character Classes             1
    Quantifiers                                 2
    Grouping and Capturing                      3
    Assertions and Flags                        4
The Regular Expression Module 
Summary
Exercises 
#1) 
#2)

#CODE LIST
bookmarks.py
dvds-dbm.py
dvds-sql.py
-----------
extract_tags.py 
html2text.py
phone.py


===============
    Quantifiers                                 2
===============
#A quantifier has the form {m,n} where m and n are the minimum and maximum
#times the expression the quanitifer applies to must match. For example, both
#e{1,1}e{1,1} and e{2,2} match feel, but neither matches felt.
#Atul --> match b/c focuses upon e and the number of specified matches.

#Writing a quantifier after every expression would soon become tedious, and is
#certainly diffiucult to read. Fortunately, the regex language supports several
#convenient shorthands. If only one number is given in the quantifier, it is
#taken to be both the minimum and maximum, so e{2} is the same as e{2,2}.
#And as we noted in the preceeding section, if no quantifier is explicitly
#given, it is assumed to be one (ie {1.1}; therefore, ee is the same as
#e{1,1}e{1,1} and e{1}e{1}, so both e{2} and ee match feel but not felt).


################################################ Table 13.1
Table 13.1 Character Class Shorthands

    Symbol      Meaning
    ------      ------------------------------------------------
    .           Matches any character except newline; or any character at all with 
                the re.DOTALL flag; or inside a character class matches a literal.

#   \d          Matches a Unicode digit; or [0-9] with the re.ASCII flag

#   \D          Matches a Unicode nondigit; or [^0-9] with the re.ASCII flag

#   \s          Matches a Unicode whitespace; or [ \t\n\r\f\v] with the re.ASCII flag

#   \S          Matches a Unicode nonwhitespace; or [^ \t\n\r\f\v] with the re.ASCII flag      

#   \w          Matches a Unicode "word" character; or [a-zA-Z0-9_] with the re.ASCII flag     

#   \W          Matches a Unicode non-"word" character; or [^ a-zA-Z0-9_] with the re.ASCII glaf
################################################

#Having a different minimum and maximum is often convenient. For example, to match
#travelled and traveled (both legitimate spellings), we could use either 
travel{1,2}ed #or
travell{0,1}ed # The {0,1} quantification is so often used that it has its own shorthand
#form, ?, so another way of writing the regex (and the one most likly to be used in 
#practice) is
travell?ed #.

#Two other quantifications shorthands are provided: 
+ #which stands for {1,n} or "at least one" and 
* #which stands for {0,n}  or "any number of"; in both cases, n, is the maximum possible
#number allowed for a quantifier, usually at least 32767. All the quantifiers are
#shown in Table 13.2


################################################ Table 13.2
Table 13.2 Regular Expression Quantifiers

    Synatx          Meaning
    ------          ------------------------------------------------
    e? or e{0,1}    Greedily match zero or one occurrence of expression e

    e?? or e{0,1}?  Nongreedily match zero of one occurrence of expression e
    
    e+ or e{1,}     Greedily match one or more occurrences of expression e
    
    e+? or e{1,}?   Nongreedily match one or more occurrences of expression e 
    
    e* or e{0,}     Greedily match zero or more occurrences of expression e 
    
    e{m}            Match exactly m occurrences of expression e 
    
    e{m,}           Greedily match at least m occurrences of expression e
    
    e{m,}?          Nongreedily match at least m occurrences of expression e 
    
    e{,n}           Greedily match at most n occurrences of expression e 
    
    e{,n}?          Nongreedily match at most n occurrences of expression e
    
    e{m.n}          Greedily match at least m and at most n occurrences or expression e
    
    e{m,n}?         Nongreedily match at least m and at most n occurrences of expression e
################################################

#The + quantifier is very useful. For example, to match integers we could use \d+ since
#this matches one or more digits. This regex could match in two places in the string 4588.91
#for example, 4588.91 via 4588 and 4588.91 via 91. Somethimes typos are the result of
#pressing a key too long. We could use the regex 
bevel_ed #to match the legitimate beveled via beveled and bevelled via bevelled, and the 
#incorrect bevellled via bevellled. If we wanted to stardardize on the one l spelling, and
#match only occurrences that had two or more l's, we could use 
bevell+ed #to find them.

#The * quantifier is less useful, simply b/c it can so often leave to unexpected results.
#For example, supposing that we want to find lines that contain comments in Python files,
#we might try searching for #* But this regex will match any line whatsoever, including 
#blank lines b/c the meaning is "match any number of #s" -- and this includes none. As a
#Rule Of Thumb for those new to regexes, avoid using * at all, and if you do use it (or if
#you use ?), make sure there is at least one other expression in the regex that has a
#nonzero quantifier -- so at least one quantifier other than * or ? since both of these
#can match their expression zero times.

#It is often possible to convert * to + uses and vice versa. For example, We could
#match "tasselled" with a least one l using tassell*ed or tassel+ed, and match those
#with two or more l's using tasselll*ed or tessell+ed.

#If we use the regex \d+ it will mach 136. But why does it match all the digits, 
#rather than just the first one? By default, all quantifiers are greedy -- they match 
#as many characters as they can. We can make any quantifier nongreedy (also called minimal)
#by following it with a ? symbol. (The question mark has two different meanings -- on its 
#own it is a shorthand for the {0,1} quantifier, and when it follows a quantifier it tells
#the quantifier to be nongreedy.) For example, \d+? can match the string 136 in three
#different places: 136 via tha 1, 136 via the 3, and 136 via the 6. Here is another example:
#\d?? matches zero or one digits, but prefers to match none since it is nongreedy -- on its
#own it suffers the same problem as * in that it will match nothing, that is, any text at all.

#Nongreedy quantifiers can be useful for quick and dirty XML and HTML parsing. For example,
#to match all the image tags, writing <img.*> (match one "<", then one "i", then one "m", then
#one "g", then zero or more of any character apart from newline, then one ">") will not work
#b/c the .* part is greedy and will match everything including the tag's closing >, and will
#keep going until it reaches the last > in the entire text.

#Three solutions present themselves (apart from using a proper parser). One is
<img[^>]*> #(match <img, then any number of non-> characters and then the tag's closing > character),
#another solution is
<img.*?> #(match <img, then any number of characters, but nongreedily, so it will stop
#immediately before the tag's closing >, and then the >)<
#and a third combines both solution one and two:
<img[^>]*?>
#None of the three are correct, though since they can all match <img> via <img> which is
#not valid. Since we know that an image tag must have a src attribute, a more accurate regex is
#     <img\s+[^>]*?src=\w+[^>]*?>
#This last one matches the literal characters <img, then one more whitespace characters, then
#nongreedily zero or more of anything except > (to skip any other attributes such as alt), then
#the src attrbiute (the literal characters src= then at least one "word" character), and then
#any other non-> characters (including none) to account for any other attributes, and finally
#the closing >.


#Reminder of topics
Python Regular Expression Language
    Character and Character Classes             1
    Quantifiers                                 2
    Grouping and Capturing                      3
    Assertions and Flags                        4
The Regular Expression Module 
Summary
Exercises 
#1) 
#2)

#CODE LIST
bookmarks.py
dvds-dbm.py
dvds-sql.py
-----------
extract_tags.py 
html2text.py
phone.py


===============
    Grouping and Capturing                      3
===============

#In practice applications we often need regexes that can match any one of two or
#more alternatives, and we often need to capture the match or some part of the match
#for further processing. All of these can be achieved by grouping with (), and in the
#case of alternatives using alternation with |.

#Alternation is especially useful when we want to match any one of several quite
#different alternatives. For example, the regex
aircraft|airplane|jet #will match any text that contains "aircraft" or "airplane" or "jet".
#The same thing can be achieved using the regex 
air(craft|plane)|jet  #Here, the paraentheses are used to group expressions, so we have
#two outer expressions, air(craft|plane) and jet. The first of these has an inner
#expression, craft|plane, and b/c this is preceded by air, the first outer expression can
#match only "aircraft" or "airplane".

#Parentheses serve two different purposes, to group expressions and to capture the text
#that matches an expression. We will use the term group to refer to a grouped expression
#whether it captures or not, and "capture" and "capture group" refer to a captured group.
#If we used the regex (aircraft|airplane|jet) it would not only match any of the three
#expressions, but would also capture whichever one was matched for later reference. Compare
#this with the regex (air(craft|plane)|jet) which has two captures if the first expression
#matches ("aircraft" or "airplane") as the first capture and the "craft" or "plane" as the
#second capture), and one capture is the second expression matches ("jet"). We can switch
#off the capturing effect by following an opening parentheses with ?: so that for example,
(air(?:craft|plane)|jet) #will have only one capture if it matches ("aircraft" or "airplane"
#or "jet").

#A grouped expression is an expression and so can be quantified. Like any other 
#expression the quantity is assumed to be one unless explicitly given. For example, if
#we have read a text file with lines of the form key=value, where each key is
#alphanumeric, and regex (\w+)(.+) will match every line that has a nonempty key and
#a nonempty value. (Recall that . matches anything except newlines.) And for every line
#that matches, two captures are made, the first being the key and second being the value.

#For example, the key=value regular expression will match the entire line
topic= physical geography #with the two captures showen shaded:
topic
 phyiscal geography  (whitespace in front on purpose)
#Notice that the second capture inludes some whitespace, and that whitespace before the =
#is not accepted. We could refine the regex to be more flexible in accepting whitespace, and
#to strip off unwanted whitespace using a somewhat longer version: [ \t]*(\w+)[ \t]*=[ \t]*(.+)
#This matches the same line as before and also lines that have whitespace around = sign, but
#with the first capture having no leading or trailing whitespace, and the second capture
#having no leading whitespace. For example, topic = physical geography 
#and here the followeding shaded by themselves
topic
physical geography   (no leading whitespace in front of physical)
#We have been careful to keep the whitespace matching parts outisde the capturing
#parentheses, and to allow for lines that have no whitespace at all. We did not use \s to
#match whitespace b/c that matches newlines (\n) which could lead to incorrect matches
#that span lines (eg if the re.MULTILINE flag is used). And for the value we did not use
#\S to match nonwhitespace b/c we wanted to allow for values that contain whitespace (eg
#English sentences). To avoid the second capture having trailing whitespace we would need
#a more sophisticated regex; we will this in the next subsection.

#Captures can be referred to using backreferences, that is, by referring back to an
#earlier capture group.*
#*Note that backreferences can not be used inside character classes, that is, inside [].
#One syntax for backreferences inside regexes themselves is \i where i is the capture
#number. Captures are numbered starting from one and increasing by one going from left
#to right as each new (capturing) left parenthesis is encountered. For example, to 
#simplistically match duplicated words we can use the regex (\w+)\s\1 which matches
#a "word", then at least one whitespace, and then the same word as was captured. (Capture
#number 0 is created automatically without the need for parenteses; it holds the entire
#match, that is, what we show underlined.) We will see a more sophisticated way to match
#duplicate words later.

#In long or complicated regexes it is often more convenient to use names rather than
#numbers for captures. This can also make mainentance easier since adding or removing
#capturing parentheses may change the numbers but wont affect names. To name a capture
#we follow the opening parenthesis with 
?P<name>  #. For example, (?P<key>\w+)=(?P<value>.+) has two captures callled "key" and
#"value". The syntax for backreferences to named captures inside a regex is
(?P=name) #. For example, (?P<word>\w+)\s+(?P=word) matches duplicate words using a
#capture called "word".


#Reminder of topics
Python Regular Expression Language
    Character and Character Classes             1
    Quantifiers                                 2
    Grouping and Capturing                      3
    Assertions and Flags                        4
The Regular Expression Module 
Summary
Exercises 
#1) 
#2)

#CODE LIST
bookmarks.py
dvds-dbm.py
dvds-sql.py
-----------
extract_tags.py 
html2text.py
phone.py


===============
    Assertions and Flags                        4
===============

#One problem that affects many of the regexes we have looked at so fare is that
#they can match more or different text than we intended. For example, the regex
#aircraft|airplane|jet will match "waterjet" and "jetski" as well as as "jet".
#This kind of problem can be solved by using assertions. An assertion does not
#match any text, but instead says something about the text at the point where
#the assertion occurs.

#One assertion is \b (word boundary), which asserts that the character that
#precedes it must be a "word" (\w) and the character that follows it must be a
#non-"word" (\W), or vice versa. For example, although the regex jet can match
#twice in the text the jet and jetski ar noisy, that is, the jet via jet and
#jetski via jet are noisy, the regex \bjet\b will match ONLY ONCE, the jet via jet
#and jetski are noisy. (Atul --> notice here that jetski does NOT match.) In the 
#context of the original regex, we could write it either as 
#\baircraft\b|\bairplan\b|\bjet\b or more clearly as \b(?:aircraft|airplane|jet)\b 
#that is, word boundary, noncapturing expression, word boundary. (RULE HERE)

#Many other assertions are supported, as shown in Table 13.3.

################################################ Table 13.3
Table 13.3 Regular Expression Assertions

    Symbol    Meaning
    ------    ------------------------------------------------
    ^         Matches at the start; also matches after each newline with the re.MULTILINE flag

    $         Matches at the end; also matches before each newline with the re.MULTILINE flag
 
#   \A        Matches at the start

#   \b        Matches at a "word" boundary; influenced by the re.ASCII flag -- inside a
#             character class this is the escape for the backspace character

#   \B        Matches at a non-"word" boundary; influenced by the re.ASCII flag

#   \Z        Matches at the end

    (?=e)     Matches if the expression e matches at this assertion but does not 
              advance over it -- called lookahead or positive lookahead

    (?!e)     Matches if the expression e does not match at this assertion and does
              not advance over it -- called negative lookahead

    (?<=e)    Matches if the expression e matches immediately before this assertion -- 
              called positive lookahead

    (?<!e)    Matches if the expression e does not match immediately before this
              assertion -- called negative lookbehind
################################################ Table 13.3

#We could use assertions to improve the clarity of a key=value regex, for example, 
#by changing it to ^(\w)=([^\n]+) and setting the re.MULTILINE flag to ensure that
#each key=value is taken from a single line with no possibility of spanning lines --
#providing no part of the regex matches a newline, so we cant use, say, \s. (The flags
#are shown in Table 13.5; thier syntaxes are described at the end of this subsection,
#and examples are given in the next section.) And if we want to strip whitespace from
#the ends and use named caputures, the regex becomes
#     [ \t]*(?P<key>\w+)[ \t]*=[ \t]*(?P<value>[^\n]+)(?<![ \t])

#Even though this regex is designed for a fairly simple task, it looks quite
#complicated. One way to make it more maintainable is to include commments in it.
#This can be done by adding inline comments using the syntax (?#the comment), but in
#practice comments like this can easily make the regex even more difficult to read. A
#much nicer solution is to use the re.VERBOSE flag -- this allows us to freely use 
#whitespace and normal Python comments in regexes, with the one constraint that if we
#need to match whitespace we must either use \s or a character class as []. Here is the
#key=value regex with comments:
#   ^[ \t]*                 # start of line and optional leading whitespace
#   (?P<key>\w+)            # the key text
#   [ \t]*=[ \t]*           # the equals with optional surrounding whitespace
#   (?P<value>[^\n]+)       # the value text
#   (?<![ \t])              # negative lookbehind to avoid trailing whitespace

#In the context of a Python program we would normally write a regex like this
#inside a raw triple quoted string -- raw so taht we dont have to double up the
#backslashes, and triple quoted so that we can spread it over multiple lines.

#In addition to the assertions we have discussed so far, there are additional
#assertions which look at the text in front of (or behind) the assertion to see
#whether it matches (or does not match) an expression we specify. The expressions
#that can be usd in lookbehind assertions must be of fixed length (so the quantifiers
# ?, +, and * cannot be used, and numeric quantifiers must be of a fixed size, for
#example, {3}).

#In the case of the key=value regex, the negative lookbehind assertion means that at
#the point it occurs the preceding character must not be a space or a tab. This has
#the effect of ensuring that the last character captured into the "value" capture
#group is not a space or tab (yet without preventing spaces or tabs from appearing
#inside the captured text).

#Lets consider another example. Suppose we are reading a multiline text that contains
#the names "Helen Patricia Sharman", "Jim Sharman", "Sharman Joshi", "Helen Kelly", and
#so on, and we want to match "Helen Patricia", but only when referring to 
#"Helen Patricia Sharman". The easiest way is to use the regex 
#     \b(Helen\s+Patricia)\s+Sharman\b
#But we could also achieve the same thing using a lookahead assertion, for example, 
#     \b(Helen\s+Patricia)(?=\s+Sharman\b)  
#This will match "Helen Patricia" only if it is preceded by a word boundary and followed
#by whitespaces and "Sharman" ending at a word boundary.

#To capture the particular variation of the forenames that is used ("Helen", "Helen P.",
# or "Helen Patricia"), we could make the regex slightly more sophisticated, for example,
#     \b(Helen(?:\s+(?P.|Patricia))?)\s+(?=Sharman\b)
#This matches a word boundary followed by one of the forename forms -- but only if this
#is followed by some whitespaces and then "Sharman" and a word boundary.

#Note that only two syntaxes perform capturing, (e) and (?P<name>e)
#None of the other parenthesized forms captures. This makes perfect sense for the
#lookahead and lookbehind assertions since they only make a statement about what follows
#or precedes them -- they are not part of the match, but rather affect whether a match
#is made. It also makes sense for the last two parenthesized forms that we will now
#consider.

#We saw earlier how we can backreference a capture inside a regex either by number (eg \1)
#or by name (eg (?P=name) ). It is also possible to match conditionality depending on 
#whether an earlier match occurred. The syntaxes are (?(id)yes_exp) and (?(id)yes_exp|no_exp)
#The id is the name or number of an earlier capture that we are referring to. If the capture
#succeeded the yes_exp will be matched here. If the capture failed the no_exp will be
#matched if it is given.

#Lets consider an example. Suppose we want to extract the filenames referred to by the
#src attribute in HTML img tags. We will begin just by trying to match the src attribute,
#but unlike our earlier attempt we will account for the three forms that the attribute's
#value can take: single quoted, double quoted, and unquoted. Here is an INITIAL attempt:
src=(["'])([^"'>]\1)    '#The ([^"'>]+) part captures a greedy match of at least one
#character that is not a quote or >. This regex works fine for quoted filenames, and thanks
#to the \1 matches only when the opening and closing quotes are the same. But it does not
#allow for unquoted filenames. To fix this we must make the opening quote optional and
#therefore match only if it is present.

#Here is a revised regex:
src=(["'])?([^"'>]+)(?(1)\1)    '#Wed did not provide a no_exp since there is nothing to
#match if no quote is given. Unfortuneaely, this doesnt work quite right. It will work fine
#for quoted filenames, but for unquoted filenames it will work only if the src attribute is
#the last attribute in the tag; otherwise it will incorrectly match text into the next 
#attribute. The solution is to treat the two cases (quoted and unquoted) separately, and to
#use alternation: 
src=((["'])([^\1>]+?)\1|(^"' >]+))    '#Now lets see the regex in context, complete with
#named groups, nonmatching parentheses, and comments:

#     <ing\s+                     # start of the tag
#     [^>]*?                      # any attributes that precde the src
#     src=                        # start of the src attibute
#     (?:
#         (?P<quote>["'])         #opening quote
#         (?P<qimage>[^\1>]+?)    # iamage filename
#         (?P=quote)              # closing quote mathcing the opening quote
#     |                           # --or alternatively--
#         (?P<uimage>[^"' >]+)    # unquoted image filename
#     )
#     [^>]*?                      # any attributes that follow the src
#     >                           # end of the tag

#The indentation is just for clarity. The noncapturing paretheses are used for 
#alternation. The first alternative matches a quote (either single or double), 
#then the image filename (which may contain any characters except for the
#quote that matched or >), and finally, another quote which must be the same
#as the matching quote. We also have to use minimal matching, +?, for the 
#filename, to ensure that the match doesnt extend beyond the first matching
#closing quote. This means that a filename such as "I'm here!.png" will match
#correctly. Note also that to refer to the matching quote inside the character
#class we had to use a numbered backreference, \1, instead of (?P=quote), since
#only numbered backreferences work inside character classes. The second alterative
#matches an unquoted filename -- a string of characters that does NOT include quotes,
#spaces, or >. Due to the alternation, the filename is captured in "qimage" (capture
#number 2) or in "uimage" (capture number 3, since (?P=quote) matches but does NOT
#capture), so we must check for both.

#The final piece of regex syntax that Pyhthon's regular expression engine offers is
#a means of setting the flags. Usually the flags are set by passing them as
#additional parameters when calling the re.compile() function, but sometimes it is
#more convenient to set them as part of the regex itself. The syntax is simply (?flags)
#wher flags is one or more of 
#a (the same as passing re.ASCII),
#i (re.IGNORECASE),
#m (re.MULTILINE),
#s (re.DOTALL), and
#x (re.VERBOSE).*
#*Note the letters used for the flags are the same as the ones used by Perl's regex
#engine, which is why s is used for re.DOTALL and x is used for re.VERBOSE.
#If the flags are set this way they should be put at the start of the regex; they
#match nothing, so their effect on the regex is only to set the flags.


#Reminder of topics
Python Regular Expression Language
    Character and Character Classes             1
    Quantifiers                                 2
    Grouping and Capturing                      3
    Assertions and Flags                        4
The Regular Expression Module 
Summary
Exercises 
#1) 
#2)

#CODE LIST
bookmarks.py
dvds-dbm.py
dvds-sql.py
-----------
extract_tags.py 
html2text.py
phone.py


===============
The Regular Expression Module 
===============

#The re module provides two ways of working with regexes. One is to use the
#functions listed in Table 13.4 where each function is given a regex as its
#first argument. Each function converts the regex into an internal format -- a
#process called compiling -- and then does its work. This is very convenient for
#one-off uses, but if we need to use the same regex repeatedly we can avoid the
#cost of compiling it at each use by compiling it once using the re.compile() function.
#We can then call methods on the compiled regex object as many times as we like. The
#compiled regex methods are listed in Table 13.6.

    match = re.search(r"#[\dA-Fa-f]{6}\b", text)

#This code snippet shows the use of an re module function. The regex matches HTML-style
#colors (such as #COCOAB). If a match is found the re.search() function returns a match
#object; otherwise, it returns None. The methods provided by match objects are listed in
#Table 13.7.

#If we were going to use this regex repeatedly, we could compile it once and then use
#the compiled regex whenever we needee it:

    color_re = re.compile(r"#[\dA-Fa-f]{6}\b")
    match = color_re.search(text)

#As we noted earlier, we use raw strings to avoid having to escape backslashes.
#Another way of writing this regex would be to use the character class [\dA-F]
#and pass the re.IGNORECASE flag as the last argument to the re.compile() call, or
#to use the regex (?i)#[dA-F]{6}\b which starts with the ignore case flag.

#If more than one flag is required they can be combined using the OR operator |, 
#for example, re.MULTILINE | re.DOTALL, or (?ms) if embedded in the regex itself.

#We will round off this section by reviewing some examples, starting with some
#of the regexes shown in earlier sections, so as to illustrate the most commonly
#used functionality that the re module provides. Lets start with a regex to spot
#duplicate words:

    double_word_re = re.compile(r"\b(?P<word>\w+)\s(?P=word)(?!\w)", re.IGNORECASE)
    for match in double_word_re.finditer(text):
        print("{0} is duplicated".format(match.group("word")))
#The regex is slightly more sophisticated than the version we made earlier. It starts
#at a word boundary (to ensure that each match starts at the beginning of a word), then
#greedily matches one or more "word" characters, then one or more whitespace characters,
#then the same word again -- but only if the second occurrence of the word is not 
#followed by a word character.

#If the input text was "win in vain", WITHOUT the first assertion there would be one
#match and one capture: wIN_IN vain via IN_IN. There are not two matches b/c
#while (?P<word>) matches and captures, the \s+ and (?P=word) parts only match.
#The use of the word boundary assertion ensures that the first word matched is a 
#whole word, so we end up with no match or capture since there is no duplicate whole word.
#Similarly, if the input text was 
#"one and and two let's say"
#without the last assertion there would be two matches and two captures:
#one AND_AND two let'S_SAY
#The use of the lookahead assertion means that the second word matched is a whole word,
#so we end up with one match and one capture:
#one AND_AND two let's say

#The for loop iterates over every match object returned by the finditer() method and
#we use the match object's group() method to retrieve the captured group's text. We 
#could just as easily (but less maintainabily) have used group(1) -- in which case
#we need not have named the capture group at all and just used the regex
#       \b(\w+)\s+\1(?!\w)
#Another point to note is that we could have used a word boundary \b at the end, 
#instead of (?!\w).

#Another example we presented earlier was a regex for finding the filenames in HTML
#image tages. Here is how we would compile the regex, adding flags so that it is not
#case-sensitive, and allowing us to include comments:

    image_re = re.compile(r"""
                    <img\s+                     # start of tag
                    [^>]*?                      # non-src attributes
                    src=                        # start of src attribute
                    (?:
                        (?P<quote>["'])         # opening quote
                        (?P<qimage>[^\1>]+?)    # image filename
                        (?P<quote>)             # closing quote
                    |                           # ---or alternatively---
                        (?P<uimage>[^"' >]+)    # unquoted image filename 
                    )
                    [^>]*?                      # non-src attributes 
                    >
                    """, re.IGNORECASE|re.VERBOSE
    image_files = []
    for match in image_re.finditer(text):
        image_files.append(match.group("qimage") or match.group("uimage"))

#Again, we use finditer() method to retrieve each match and the match object's group()
#function to retrieve the captured texts. Each time a match is made we dont know which
#of the image groups ("qimage" or "uimage") has matched, but using the OR operator
#provides a NEAT solution for this. Since the case insensitivity applies onyl to img
#and src, we cold drop the re.IGNORECASE flag and use [Ii][Mm][Gg] and [Ss][Rr][Cc] instead.
#Although this would make the regex less clear, it might make it faster since it would not 
#require the text being matched to be set to upper- (or lower-) case -- but it is likely
#to make a difference only if the regex was being used on a very large amount of text.

#One common task is to take an HTML text and output just the plain text that it contains.
#Natuarally we could do this using one of Python's parsers, but a simple tool can be
#created using regexes. There are three tasks that need to be done: delete any tags,
#replace entities with characters they represent, and insert blank lines to separate
#paragraphs. Here is a function (taken from the html2text.py program) that does the job:

    def html2text(html_text):
        def char_from_entity(match):
            code = html.entities.name2copdepoint.get(match.group(1), 0xFFFD)
            return chr(code)
        text = re.sub(r"<!--(?:.|\n)*?-->", "", html_text)          #1
        text = re.sub(r"<[Pp][^>]*?>", "\n\n", text)                #2
        text = re.sub(r"<[^>]*?>", "", text)                        #3
        text = re.sub(r"&#(\d+);", lambda m: chr(int(m.group(1))), text)    #4
        text = re.sub(r"&([A-Za-z]+);", char_from_entity, text)     #5
        text = re.sub(r"\n(?:[ \xAO\t]+\n)+", "\n", text)           #6
        text = re.sub(r"\n\n+", "\n\n", text.strip())
        
#The first regex, <!--(?:.|\n)*?-->, matches HTML comments, including those with 
#other HTML tags nested inside them. The re.sub() function replaces as many matches
#as it finds with the replacement -- deleting the matches if the replacement is an
#empty string, as it is here. (We can specify a maximum number of matches by giving
#an additional integer argument at the end).

#We are careful to use nongreedy (minimal) matching to ensure that we delete one
#comment for each match, if we did not do this we would delete from the start of 
#the first comment to the end of the last comment.

#In Python 3.0, the re.sub() function does not accept any flags as arguments, and
#since . means "any characters except newline", we must look for . or \n. And we
#must look for these using 
alternation rather than character class #, since inside a character class . has its
#literal menaing, that is, period. An alternative would be to begin the regex with
#the flag embedded, for example,
(?s)<!--.*?--> #or we could compile a regex object with the re.DOTALL flag, in which
#case the regex would simply 
<!--.*?-->

#From Python 3.1, re.split(), re.sub(), and re.subn(), can all accept a flags argument,
#so we could simply use <!--.*?--> and pass the re.DOTALL flag.

#The second regex, 
<[Pp][^>]*?> # matches opening paragraph tags (such as <P> or <p align="center">). It 
#matches the opening <p (or <P), then any attributes (using nongreedy matching), and 
#finally the closing >. The second call to the re.sub() function uses this regex to 
#replace opening paragraph tags with two newline characters (the standard way to 
#delimt a paragraph in a plain text file).

#The third regex, 
<[^>]*?> # matches any tag and is used in the third re.sub() call to delete all the remaining tags.

#HTML entites are a way of specifying non-ASCII characters using ASCII characters. They
#come in two forms: &name; where name is the name of the character -- 
#for example, &copy ; for --- and &#digits; where digits are decimal digits identifying
#the Unicode code point -- for example, &#165; for .

#The forth re.sub() call uses the regex 
&#(\d+); # which matches the digits form and captures the digits into capture group 1. 
#Instead of literal replacement text we have passed a lambda function. When a function is 
#passed to re.sub() it calls the function once for each time it matches, passing the match 
#object as the function's sole argument. Inside the lambda function we retrieve the digits 
#(as a string), convert to an integer using the built-in int() function, and then use the 
#built-in chr() function to obtain the Unicode character for the given code point. The function's
#return value (or in the case of a lambda expression, the result of the expression) is
#used as the replacement text.

#The fifth re.sub() call uses the regex 
&([A-Za-z]+) #to capture named entities. The standard library's html.entities module contains
#dictionaries of entites, including name2codepoint whose keys are entity names and whose
#values are integer code points. The re.sub() function calls the local char_from_entity()
#function every time it has a match. The char_from_entity() function uses dict.get() with a
#default argument of 0xFFFD (the code point of the standard Unicde replacement character -- often
#depicted as OCTOGAN_with_question_mark_inside). This ensures that a code point is always
#retrieved and it is used with the chr() function to return a suitable character to replace
#the named entity with--- using the Unicode replacement character if the entity name is invalid.

#The sixth re.sub() call's regex, \n(?:[ \xAO\t]+\n)+ is used to delete lines that contain
#only whitespace. The character class we have used contains a space, a nonbeaking space
#(which &nbsp; entities are replaced with in the preceding regex), and a tab. The regex
#matches a newline (the one at the end of a line that precedes one or more whitespace-only
#lines), then at least one (and as many as possible) lines that contain only whitespace. Since
#the match includes the newline, from the line preceding the whitespace-only lines we must
#replace the match with a single newline; otherwise, we would delete not just teh whitespace-
#only lines but also the newline of the line that preceded them.

#The result of the seventh an last re.sub() call is returned to the caller. This regex, 
# \n\n+ is used to replace sequences of two or more newlines with exactly two newlines, 
#that is, to ensure that each paragraph is separated by just one blank line.

#In the HTML example none of the replacements were directly taken from the match (although
#HTML entity names and numbers were used), but in some situations the replacement might
#need to include all of some of the matching text. For example, if we have a list of names,
#each of the form Forename Midlename1 ... MiddlenameN Surname, where there may be any number
#of middle names (including none), and we want to produce a new version of the list with each
#item of the form Surname,ForenameMiddlename1...MiddlenameN, we can easily do so using a regex:

    new_names = []
    for name in names:
        name = re.sub(r"\w+(?:\s+\w+)*)\s+(\w)", r"\2, \1", name)
        new_names.append(name)

#The first part of the regex, (\w+(?:\s+|w+)*) matches the forename with the first \w+
#expression and zero or more middle names with the (?:\s+\w+)* expression. The middle name
#expression matches zero or more occurrences of whitespace followed by a word. The second
#part of the regex, \s+(\w+) matches the whitespace that follows the forename (and middle
#names) and the surname.

#If the regex looks a bit too much like line noice, we can use named capture groups to
#improve legibility and make it more maintainable:

    name = re.sub(r"(?P<forenames>\w+(?:\s+\w+)*)"
                  r"\s+(?P<surname>\w+)",
                  r"\g<surname>, \g<forenames>", name)

#Captured text can be referred to in a sub() or subn() function or method by using the
#syntax \i or \g<id> where i is the number of the capture group and id is the name or
#number of the capture group -- so \1 is the same as \g<1>, and in this example, the
#same as \g<forenames>. This syntax can also be used in the string passed to a match
#object's expand() method.

#Why doesnt the first part of the regex grad the entire name? After all, it is using
#greedy matching. In fact it will, but then the match will fail b/c although the middle
#names part can match zero or more times, the surname part must match exactly once, but
#the regular expression engine will then backtrack, giving up the last "middle name" and
#thus allowing the surname to match. Although greedy matches match as much as possible,
#they stop if matching more would make the match fail.

#For example, if the name is "John le Carre", the regex will first match the entire name
#that is, John le Carre. This satisfies the first part of the regex but leaves nothing
#for the surname part to match, and since the surname is mandatory (it has an implicit
#quantifier of 1), the regex has failed. Since the middle names part is quantified by *
#it can match zero or more times (currently it is matching twice, " le" and " Carre") so
#the regular expression engine can make it give up some of its match without causing it
#to fail. Therefore, the regex backtracks, giving up the last \s+\w+ (ie " Carre"), so the
#match becomes JOHN_LE CARRE with the match satisfying the whole regex and with the two
#match groups containing the correct texts.

#There is one weakness in the regex as written: it does not cope correctly with forenames
#that are written using an initial, such as "James W. Leowen" or "J.R.R. Tolkein". This is
#b/c \w matcehs word chracterists and these dont include a period. One obvious -- but incorrect --
#solution is to change the forenames part of the regex's \w+ expression to [\w.]+ in both
#places that it occurs. A period in a character class is taken to be a literal period, and 
#character class shortands retain their meaning inside character classes, so the new
#expression matches word characters or periods. But this would allow for names like ".", 
#"..", ".A", ".A.", and so on. In view of this, a more subtle approach is required.

#OLD
    name = re.sub(r"(?P<forenames>\w+(?:\s+\w+)*)"
                  r"\s+(?P<surname>\w+)",
                  r"\g<surname>, \g<forenames>", name)

#UPDATED
    name = re.sub(r"(?P<forenames>\w+\.?(?:\s+\w+\.?)*)"
                  r"\s+(?P<surname>\w+)",
                  r"\g<surname>, \g<forenames>", name)

#Here we have changed the forenames part of the regex (the first line). The first part
#of the forenames regex matches one or more word characters optionally followed by a 
#period. The second part matches at least one whitespace character, then one or more work
#characters optionally followed by a period, with the whole of this second part itself
#matching zero or more times.

#When we use alternation (|) with two or more alternatives capturing, we dont know which
#alternative matched, so we dont know which capture group to retrieve the captured text from.
#We can of course iterate over all the groups to find the nonempty one, but quite often in
#this situation the match object's lastindex attribute can give us the number of the group
#that we want. We will look at one last example to illustrate this and to give us a little
#bit more regex practice.

#Suppose we want to find out what encoding an HTML, XML or Python file is using. We could
#open the file in binary mode, and read, say, the first 1000 bytes into a byte object. We
#could then cloes the file, look for an encoding in the bytes, and reopen the file in text
#mode using the encoding we found or using a fallback encoding (such as UTF-8). The regex
#engine expects regexes to be supplied as strings, but the text the regex is applied to can
#be a str, bytes, or bytearry object, and when bytes or bytearry objects are used, all the
#functions and methods return bytes instead of strings, and th re.ASCII flag is implicitly
#switched on.

#For HTML files the encoding is normally specified in a <meta> tag (if specified at all),
#for example,
<meta http-equiv="Content-Type" content='text/httml;charset=ISO-8859-1'/> #XML files are
#UTF-8 by default, but this can be overridden, for example, 
<?xml version="1.0" encoding="Shft_JIS"?> # Python 3 files are also UTF-8 by default, but
#again this can be overridden by including a line such as 
# encoding: latin1            #or 
# -*- coding: latin1 -*-      #immediately after the shebang line.

#Here is how we would find the encoding, assuming that the variable binary is a bytes
#object containing the first 1000 bytes of an HTML, XML, or Python file:

    match = re.search(r"""(?<![-\w])                        #1
                          (?:(?:en)?coding|charset)         #2
                          (?:=(["'])?([-\w]+)(?(1)\1))      #3
                          |:\s*([-\w]+))""".encode("utf8"), binary, re.IGNORECASE|re.VERBOSE)
    encoding = match.group(match.lastindex) if match else b"utf8"

#To search a bytes object we must specify a pattern that is also a bytes object. In this
#case we want the convenience of using a raw string, so we use one and convert it to a 
#bytes object as the re.search() function's first argument.

#The first part of the regex itself is a lookbehind assertion that says that the match
#cannot be preceded by a hyphen or a word character. The second part matches "encoding",
#"coding", or "charset" and could have been written as 
(?:encoding|coding|charset) #. We have made the third part span two lines to emphasize the
#fact that is has two alternativing parts, =(["'])?([-\w]+)(?(1)\1) and :\s*([-\w]+), only
#one of which can match. The first of these matches an equals sign followed by one or more
#word or hyphen characters (optionally enclosed in matching quotes using a conditional match),
#and the second matches a color and then optional whitespace followed by one or more word or
#hyphen characters. (Recall that a hyphen inside a character class is taken to be a literal
#hyphen if it is the first character; otherwise, it means a range of characters, for
#example, [0-9].)

#We hae used the re.IGNORECASE flag to avoid having to write
(?:(?:[Ee][Nn])?[Cc][Oo][Dd][Ii][Nn][Gg]|[Cc][Hh][Aa][Rr][Ss][Ee][Tt]) # and we have used 
#the re.VERBOSE flag so that we can lay out the regex neatly and include comments (in this
#case just numbers to make the parts easy to refer to in this text).

#There are three capturing match groups, all in the third part: (["'])? which captures
#the optional opening quote, ([-\w]+) which captures an encoding that follows an equal sign,
#and the second ([-\w]+) (on the following line) tha captures an encoding that follows a colon.
#We are only interested in the encoding, so we want to retrieve either the second or third
#capture group, only one of which can match since they are alternatives. The 
lastindex #atttribute holds the index fo the last matching capture group (either 2 or 3 when
#a match occurs in this example), so we retrieve whichever matched, or use a default encoding
#if no match was made.

#We have now seen all of the most frequently used re module functionality in action, so will
#conclude this section by mentioning one last function. The re.split() function (or the regex
#object's split() method) can split strings based on a regex. One common requirement is to
#a text on text whitespace to get a list of words. This can be done using
re.split(r"\s+", text) #which returns a list of words (or more precisely a list of strings, 
#each of which matches \S+). Regular expression are very powerful and useful, and once they
#are learned, it is easy to see all text problems as requiring a regex solution. But sometimes
#using string methods is both sufficient and more appropriate. For example, ewe can just as
#easily split on whitespace by using text.split() since the str.spint() method's default
#behavior (or with a first argument of None) is to split on \s+.


################################################ Table 13.4
Table 13.4 The Regular Expression Module's Functions              '

    Syntax                  Description
    ------                  ------------------------------------------------
    re.compile(r, f)        Return compiled regex r with its flags set to f if
                            specified. (The flags are described in Table 13.5)

    re.escape(s)            Returns string s with all nonalphanumeric characters
                            backslash-escape -- therefore, the returned string
                            has no special regex characters

    re.findall(r, s, f)     Returns all nonoverlapping matches of regex r in string s 
                            (influenced by the flags f if given). If the regex has 
                            captures, each match is returned as a tuple of captures.

    re.finditer(r, s, f)    Returns a match object for each nonoverlapping match of 
                            regex r in string s (influenced by the flags if given)

    re.match(r, s, f)       Returns a match object if the regex r matches at the start 
                            of string s (influenced by flags f if given); otherwise,
                            returns None 

    re.search(r, s, f)      Returns a match object if the regex r matches anywhere in 
                            string s (influenced by the flags f if given); otherwise
                            returns None 

    re.split(r, s, m, f)    Returns the list of strings that results from splitting
                            string s on every occurrence of regex r doing up to m splits 
                            (or as many as possible if no m is given, and for Python 3.1
                            influenced by flags f if given). If the regex has captures,
                            these are included in the list between the parts they split.

    re.sub(r, x, s, m, f)   Returns a copy of string s with every (or up to m if given, and
                            for Python 3.1 influenced by flags f if given) match of regex r 
                            replaced with x -- this can be a string or a function; see text
 
    re.subn(r, x, s, m, f)  The same as re.sub() except that it returns a 2-tuple of the
                            resultant string and the number of substitutions that were made
################################################

################################################ Table 13.5
Table 13.5 The Regular Expression Module's Flags              '

    Flag                    Meaning
    ------                  ------------------------------------------------
#   re.A or re.ASCII        Makes \b, \B, \s, \S, \w, \W assume that strings are
#                           ASCII; the default is for these character class
#                           shorthands to depend on the Unicode specification

#   re.I or re.IGNORECASE   Makes the regex match case-insensitivity

#   re.M or re.MULTILINE    Makes ^ match as the start and after each newline and
#                           $ match before each newline and at the end

#   re.S or re.DOTALL       Makes . match every character including newlines

#   re.X or re.VERBOSE      Allows whitespace and comments to be included  
################################################

################################################ Table 13.6
Table 13.6 The Regular Expression Object Methods

    Syntax                  Description
    ------                  ------------------------------------------------
    rx.findall(s, start, end)        
                            Returns all nonoverlapping matches of the regex in
                            string s (or in the start:end slice of s). If the regex
                            has captures, each match is returned as a tuple of captures

    rx.finditer(s, start, end)
                            Returns a match object for each nonoverlapping match in 
                            string s (or in the start:end slice of s)

    rx.flags                The flags that were set when the regex was compiled

    rx.groupindex           A dicionary whose keys are capture group names and whose
                            values are group numbers; empty if no names are used 

    rx.pattern              The string from which the regex was compiled 

    rx.search(s, start, end)
                            Returns a match object if the regex matches anywhere in 
                            strings s (or in the start:end slice of s); otherwise, returns None

    rx.splits(s, m)         Returns the list of strings that results from splitting string 
                            s on every occurrences of the regex doing up to m splits (or as
                            many as possible if no m is given). If the regex has captures,
                            these are included in the list between the parts they split.

    rx.sub(x, s, m)         Returns a copy of string s with every (or up to m if given) match
                            replaced with x -- this can be a string or a function; see text 

    rx.subn(x, s, m)        The same as re.sub() except that it returns a 2-tuple of the 
                            resultant string and the number of substitions that were made
################################################


################################################ Table 13.7
Table 13.7 Match Object Attributes and Methods

    Syntax                  Description
    ------                  ------------------------------------------------
    m.end(g)                Returns the end position of the match in the text for group g
                            if given (or for group O, the whole match); returns -1 if the 
                            group did not particulate in the match

    m.endpos                The search's end position (the end of the text or the end given '
                            to match() or search()

    m.expand(s)             Returns string s iwth capture markers (\1, \2, \g<name>, and
                            similar) replaced by the corresponding captures

    m.group(g, ...)         Returns the numbered or named capture group g; if more than one
                            is given a tuple of corresponding capture groups is returned (the 
                            whole match if group 0)

    m.groupdict(default)    Returns a dictionary of all the named capture groups with the
                            names as keys and the captures as values; if a default is given 
                            this is the value used for capture groups that did not participate
                            in the match

    m.groups(default)       Returns a tuple of all the capture groups starting from 1; if a
                            default is given this is the value used for capture groups that
                            did not particiate in the match

    m.lastgroup             The name of the highest numbered capturing group that matched or
                            None if there isnt one or if no names are used 

    m.lastindex             The number fo the highest capturing group that matched or None
                            if there isnt one

    m.pos                   The start position to look from (the start of the text or the 
                            start given to match() or search())

    m.re                    The regex object which produced this match object

    m.span(g)               Returns the start and end positions of the match in the text for 
                            group g if given (or for group 0, the whole match); returns (-1, -1)
                            if the group did not particulate in the match

    m.start(g)              Returns the start position of the match in the text for group g if 
                            given (or for group 0, the whole match); returns -1 if the group
                            did not participate in the match 

    m.string                The string that was passed to match() or search()
################################################


#CODE LIST
bookmarks.py
dvds-dbm.py
dvds-sql.py
-----------
extract_tags.py 
html2text.py
phone.py

meta.py #from Chapter 8 online code listing
Need to check if meta.py is in text Chapter 6 or 8 or 13




#CODE HERE

Meta.py

#!/usr/bin/env python3

"""
>>> point = Point(-17, 9181)
>>> point.x, point.y        # returns: (0, 1024)
(0, 1024)
>>> point.x = -8
>>> point.y = 3918
>>> point.x, point.y        # returns: (0, 1024)
(0, 1024)
>>> point = Point(91, 181)
>>> point.x, point.y        # returns: (91, 181)
(91, 181)
>>> point.x *= 2
>>> point.y //= 3
>>> point.x, point.y        # returns: (182, 60)
(182, 60)

BE:
>>> product = Product("101110110", "8mm Stapler")
>>> product.barcode, product.description
('101110110', '8mm Stapler')
>>> product.barcode = "XXX"
Traceback (most recent call last):
...
AttributeError: can't set attribute

BF:
>>> product.description = "8mm Stapler (long)"
>>> product.barcode, product.description
('101110110', '8mm Stapler (long)')

>>> point = PointA(-17, 9181, -18)
>>> point.x, point.y        # returns: (0, 1024)
(0, 1024)
>>> point.x = -8
>>> point.y = 3918
>>> point.x, point.y        # returns: (0, 1024)
(0, 1024)
>>> point.a
-18
>>> point.a = 7
>>> point.a
7
>>> point = Point(91, 181)
>>> point.x, point.y        # returns: (91, 181)
(91, 181)
>>> point.x *= 2
>>> point.y //= 3
>>> point.x, point.y        # returns: (182, 60)
(182, 60)
"""

import abc
import collections

class LoadableSaveable(type):

    def __init__(cls, classname, bases, dictionary):
        super().__init__(classname, bases, dictionary)
        assert hasattr(cls, "load") and instance(getattr(cls, "load"), collections.Callable), ("class '" + classname + "' must provide a load() method")
        assert hasattr(cls, "save") and isinstance(getattr(cls, "save"), collections.Callable),("class '" + classname + "' must provide a save() method")

class AutoSlotProperties(type):

    def __new__(mcl, classname, bases, dictionary):
        slots = list(dictionary.get("__slots__, []"))
        for getter_name in [key for key in dictionary if key.startswith("get_")]:
            if isinstance(dictionary[getter_name], collections.Callable):
                name = getter_name[4:]
                slots.append("__" + name)
                getter = dictionary.pop(getter_name)
                setter_name = "set_" + name 
                setter = dictionary.get(setter_name, None)
                if (setter is not None and isinstance(setter, collections.Callable)):
                    del dictionary[setter_name]
                dictionary[name] = property(getter, setter)
        dictionary["__slots__"] = tuple(slots)
        return super().__new__(mcl, classname, bases, dictionary)

class Product(metaclass=AutoSlotProperties):

    def __init__(self, barcode, description):
        self.__barcode = barcode
        self.description = description

    def get_barcode(self):
        return self.__barcode

    def get_description(self):
        return self.__description

    def set_description(self, description):
        if description is None or len(description) < 3:
            self.__description = "<Invalid Description>"
        else:
            self.__description = description

class Point(metaclass=AutoSlotProperties):

    def __init__(self, x, y):
        self.x = x
        self.y = y 

    def get_x(self):
        return self.__x 

    def set_x(self, value):
        self.__x = min(max(0, value), 1024)

    def get_y(self):
        return self.__y 

    def set_y(self, value):
        self.__y = min(max(0, value), 1024)

class PointA(metaclass=AutoSlotProperties):

    __slots__ = ("a",)

    def __init__(self, x, y, a):
        self.x = x
        self.y = y 
        self.a = a

    def get_x(self):
        return self.__x 

    def set_x(self, value):
        self.__x = min(max(0, value), 1024)

    def get_y(self):
        return self.__y 

    def set_y(self, value):
        self.__y = min(max(0, value), 1024)


if __name__ == "__main__":
    import doctest
    doctest.testmod()



#Reminder of topics
Python Regular Expression Language
    Character and Character Classes             1
    Quantifiers                                 2
    Grouping and Capturing                      3
    Assertions and Flags                        4
The Regular Expression Module 
Summary
Exercises 
#1) 
#2)

#CODE LIST
bookmarks.py
dvds-dbm.py
dvds-sql.py
-----------
extract_tags.py 
html2text.py
phone.py


===============
Summary
===============

#Regular expressions offer a powerful way of seraching texts for strings that match
#a paticular pattern, and for replacing such strings with other strings which themselves
#can depend on what was matched.

#In this chapter, we saw that most characters are matched literally and are implicitly
#quantified by {1}. We also learned how to specify character classes -- sets of characters
#to match -- and how to negate such sets and include ranges of characters in them without
#having to write each character individually.

#We learned how to quantify expressions to match a specific number of times or to match from
#a given minimum to a given maximum number of times, and how to use greedy and nongreedy
#matching. We also learned how to group one or more expressions together so that they can
#be quantified (and optionally cpatured) as a unit.

#The chapter also showed how what is matched can be affected by using various assertions,
#such as positive and negative lookahead and lookbehind, and by various flags, for example, 
#to control the interpretation of the period and whether to use case-insensitive matching.

#The final section showed how to put regexes to use within the contenxt of Python programs.
#In this section, we learned how to use the functions provided by the re module, and the 
#methods available from compiled regexes and from match objects. We also learned how to
#replace matches with literal strings, with literal strings that contain backreferences,
#and with the results of function calls or lambda expressions, and how to make regexes more
#maintainable by using named captures and comments.


===============
Exercises 
===============
#1) In many contexts (eg in some web forms), users must enter a phone number, and some of
#these irritate users by accepting only a specific format. Write a program that reads US
#phone numbes with the three digit area and seven digit local codes accepted as ten digits,
#or separated into blocks using hyphens or spaces, and with the area code optionally enclosed
#in parentheses. For example, all of these are valid: 555-123-1234, (555) 1234567, (555) 123 1234,
#and 5551234567. Read the phone numbers from sys.stdin and for each one echo the number
#in the form "(999) 999 9999" or report an error for any that are invalid, or that dont have
#exactly ten digits.

#The regex to match these phone numbers is about ten lines long (in verbose mode) and is 
#quite straightforward. Solution is provided in 
phone.py #which is about 25 lines long.


#2) Write a small program that reads an XML or HTML file specified on the command line
#and for each tag that has attributes, outputs the name of the tag with its attributes
#shown underneath. For example, here is an extract from the program's output when given
#one of the Pyhon documentation's index.html files:

    html
        xmlns = http://www.w3.org/1999/xhtml
        meta
            http-equiv = Context-Type
            content = text/html; charset=utf-8
        li 
            class = right
            style = margin-right: 10px

#One approach is to use two regexes, one to capture tags with their attributes and 
#another to extract the name and value of each attribute. Attribute values might be
#quoted using single of double quotes (in which case they may contain whitespace and
#the quotes that are not used to enclose them), or they may be unquoted (in which case
#they cannot contain whitespace or quotes). It is probably easist to start by creating
#a regex to handle quoted and unquoted values separately, and then merging the two
#regexes into a single regex to cover both cases. It is best to use named groups to
#make the regex more readable. This is not easy, especially since backreferences 
#cannot be used used inside character classes.

#Solution is provided in 
extract_tags.py #which is less than 35 lines long. The tag
#and attributes regex is just one line. The attribute name-value regex is 6 lines and
#uses alternation, conditional matching (twice, with one nested inside the other), and 
#both greedy and nongreedy quantifiers.



#CODE LIST
bookmarks.py
dvds-dbm.py
dvds-sql.py
-----------
extract_tags.py 
html2text.py
phone.py




#CODE HERE
extract_tags.py

#!/usr/bin/env python3

import os
import re
import sys

TAG_RE = re.compile(r"<(?P<tag>\w+)(?P<attributes>[^>]*?)/?>")

ATTRIBUTE_RE = re.compile(r"""
                    (?!<\w)(?P<name>[-\w]+)=
                    (?P<quote>(?P<single>')|(?P<double>"))?
                    (?P<value>(?(single)[^']+?|(?double)[^"]+?\S+)))
                    (?(quote)(?P=quote))
                    """, re.VERBOSE)


def main():
    if len(sys.argv) == 1 or sys.argv[1] in {"-h", "--help"}:
        print("usage: {0} infile".format(os.path.basename(sys.argv[0])))
        sys.exit(2)

    with open(sys.argv[1], encoding="utf8") as fh:
        xml = fh.read()

    for tag_match in TAG.RE.finditer(xml):
        attribute = tag_match.group("attribute")
        if attributes:
            print("{0}".format(tag_match.group("tag")))
            for attribute_match in ATTRIBUTE_RE.finditer(attributes):
                print("    {0} = {1}".format(attribute_match.group("name"), 
                                            attribute_match.group("value")))

main()




#CODE LIST
bookmarks.py
dvds-dbm.py
dvds-sql.py
-----------
extract_tags.py 
html2text.py
phone.py


#CODE HERE
html2text.py

#!/usr/bin/env python3

import html.entities
import os
import re
import sys

def main():
    if len(sys.argv) > 1 and ays.argv[1] in {"-h", "--help"}:
        print("""usage: {0} [infile] [outfile]
            if no files are specified reads stdin and writes to stdout;
            if one file is specified reads it and writes to stdout;
            if both files are specified and reads the first and writes to 
            the second""".format(os.path.basename(sys.argv[0])))
        sys.exit(2)

        fin, fout = (sys.stdin, sys.stdout)
        close_in, close_out = (False, False)
        if len(sys.argv) > 1:
            fin = open(sys.argv[1], encoding="utf8")
            close_in = True
            if len(sys.argv) > 2:
                fount = open(sys.argv[2], "w", encoding="utf8")
                close_out = True
        html_text = fin.read()
        if close_in:
            fin.close()
        fout.write(html2text.(html_tex))
        if close.out:
            fout.close()
        else:
            print()





#CODE LIST
bookmarks.py
dvds-dbm.py
dvds-sql.py
-----------
extract_tags.py 
html2text.py
phone.py


#CODE HERE
phone.py

#!/usr/bin/env python3

import re
import sys


US_PHONE_RE = re.compile(r"""[ \t]*
                            (?P<paraentheses>\()?
                            [ -]?
                            (?P<area>\d{3})
                            (?(paraentheses)\))
                            [- ]?
                            (?P<local_a>\d{3})
                            [- ]?
                            (?P<local_b>\d{4})
                            [ \t]*$
                            """, re.VERBOSE)

if __name__ == "__main__":
    for line in sys.stdin.readlines():
        line = line.strip()
        if not line:
            continue
        match = US_PHONE_RE.match(line)
        if match:
            print("({0}) {1} {2}".format(match.group("area"), 
                match.group("local_a", match.group("local_b")))
        else:
            print("Invalide U.S. phone number: {0}".format(line))







===============================================================================================
CHAPTER: 14 Introduction to Parsing 
CHAPTER BEGIN
===============================================================================================

BNF Syntax and Parsing Terminology
Writing Handcrafted Parsers 
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
Pythonic Parsing with PyParsing
    Quick Introduction to PyParsing
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
    Parsing First-Order Logic 
Lex/Yacc-Style Parsing with PLY 
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
    Parsing First-Order Logic
Summary
Exercises 
#1) 


#CODE LISTING HERE
playlist.py
    ReadKeyValue.py
    ReadM3U.py
blocks.py
    Block.py 
    BlockOutput.py
first-order-logic.py
BibTeX.py


#CODE HERE
playlist.py


#!/usr/bin/env python3

import optparse
import os
import re
import ReadKeyValue
import ReadM3U

def songs_from__dictionary(dictionary):
    NAME_NUMBER_RE = re.compile(r"^(?P<name>\D+)(?P<number>\d+)$")
    songs = []
    for file in (name for name in sorted(dictionary.keys()) if name.startswith("file")):
        name_number = NAME_NUMBER_RE.match(file)
        if name_number:
            name = name_number.group("name")
            number = int(name_number.group("number"))
            filename = dictionary[file]
            title = dictionary.get("title{0}".format(number), -1)
            songs.append(ReadM3U.Song(title, seconds, filename))
    return songs


def write_pls(fh, songs):
    fh.write("[playlist]\n")
    for i, song in enumerate(songs, start=1):
        fh.write("File{i}={filename}\nTitle{i}={title}\nLength{i}={seconds}\n".format(i=1, **song._asdict()))
        fh.write("NumberOfEntries={0}\n".format(len(songs)))
        fh.write("Version=2\n")


def write_m3u(fh, songs):
    fh.write("#EXTM3U\n")
    for song in songs:
        fh.write("#EXTINF:{seconds}, {title}\n{filename}\n".format(**song.asdict()))


def parse_otpions():
    parsers = "regex ply pyparsing".split()
    formats = "m3u pls".split()
    parser = optparse.OptionParser(usage="""\
usuage: %prog [options] infile

Reads a playlist in extended .m3u (WinAmp) or extended .pls format
and writes the same data in the specified output format, using the 
same name as the infile but with the extension changed appropriately.""")

    parser.set_defaults(force=False, parser="regex")
    parser.add_option("--force", dest="force", action="store_true",
                        help=("write the outfile even if it exists [%default]"))
    parser.add_option("-f", "--format", dest="format", choices=formats,
                        help="{0} [mandatory]".format(", ".join(formats)))
    parser.add_option("-p", "--parser", dest="parser", choice=parsers,
                        help="{0} [%default]".format(", ".join(parsers)))
    opts, args = parser.parse_args()

    if len(args) != 1:
        parser.error("exactly one input file must be specified")
    if not opts.format:
        parser.error("an output format must be specified")
    source = args[0]
    if not source.endswith(tuple(formats)):
        parser.error("input file must have a valid suffix (m3u or pls)")
    target = source[:-3] + opts.format
    if source == target:
        parser.error("the output format must differ from the input format")
    if os.path.exists(target) and not opts.force:
        parser.error("cannot overwrite existing file {0} without the --force option".format(target))
    return opts, source, target


    def main():
        parsers = {
                    (".pls", "regex"): (lambda fh: ReadKeyValue.dict_from_key_values_regex(fh, True)),
                    (".pls", "pyparsing":) (lambda fh: ReadKeyValue.dict_from_key_values_pyparsing(fh, True)),
                    (".pls", "ply"): (lambda fh: ReadKeyValue.dict_from_key_values_ply(fh, True)),
                    (".m3u", "regex"): ReadM3U.songs_regex,
                    (".m3u", "pyparsing"): ReadM3U.songs_pyparsing,
                    (".m3u", "ply"): ReadM3U.songs_ply}

        opts, source, target = parse_options()
        parse = parsers[os.path.splitext(source)[1], opts.parser]

        with open(source, "rt") as fh:
            songs = parse(fh)
        if instance(songs, dict):
            songs = song_from_dictionary(songs)

        with open(target, "wt") as fh:
            if target.endswith(".pls"):
                write_pls(fh, songs)
            elif target.endswith(".m3u"):
                write_m3u(fh, songs)

if __name__ == "__main__":
    main()



#CODE LISTING HERE
playlist.py
    ReadKeyValue.py
    ReadM3U.py
blocks.py
    Block.py 
    BlockOutput.py
first-order-logic.py
BibTeX.py



#CODE HERE
ReadKeyValue.py

#!/usr/bin/env python3

"""
BNF

    FILE        :: = LINE+
    LINE        ::= INI_HEADER | KEY_VALUE | COMMENT | BLANK
    INI_HEADER  ::= '[' [^]]+ ']'
    KEY_VALUE   ::= KEY '=' VALUE?
    KEY         ::= \w+
    VALUE       ::= .+
    COMMENT     ::= #.*
    BLANK       ::= ^$
"""

import os
import re
import sys
import ply.lex
try:
    from pyparsing import (alphanums, CharsNotIn, OneOrMore, ParseException, restOfLine, Suppress, Word)
except ImportError:
    from pyparsing_py3 imporrt (alphanums, CharsNotIn, OneOrMore, ParseException, restOfLine, Suppress, Word)


def dict_from_key_values_regex(file, lowercase_keys=False):
    """
    >>> filename = os.path.dirname(__file__)
    >>> filename = os.path.join(filename, "data/iradio-initial.pls")
    >>> with open(filename, "rt", encoding="utf8") as fh:
    ...     d = dict_from_key_values_regex(fh)
    >>> for key in sorted(d.keys())[-4:]:
    ...     print("{0}: {1}".format(key, d[key]))
    title6: Virgin Xtreme (Broadband)
    title7: Virgin Classic Rock (Modem)
    title8: Virgin Classic Rock (Broadband)
    title9: CBC Radio One (Canada)
    >>> d["file13"]
    'http://media.hiof.no/streams/m3u/nrk-petre-172.ogg.m3u'
    >>> d["genre15"]
    ''
    >>> len(d.keys())
    54
    """

    INI_HEADER = re.compile(r"^\[[^]]+\]$")
    KEY_VALUE_RE = re.compile(r"^(?P<key>\w+)\s*=\s*(?P<value>.*)$")

    key_values = {}
    for lino, line in enumerate(file, start=1):
        line = line.strip()
        if not line or line.startswith("#"):
            continue
        key_value = KEY_VALUE_RE.match(line)
        if key_value:
            key = key_value.group("key")
            if lowercase_keys:
                key = key.lower()
            key_values[key] = key_value.group("value")
        else:
            ini_header = INI_HEADER.match(line)
            if not ini_header:
                print("Failed to parse line {0}: {1}".format(lino, line))
    return key_values

def dict_from_key_values_pyparsing(file, lowercase_keys=False):
    """
    >>> filename = os.path.dirname(__file__)
    >>> filename = os.path.join(filename, "data/iradio-initial.pls")
    >>> with open(filename, "rt", encoding="utf8") as fh:
    ...     d = dict_from_key_values_pyparsing(fh)
    >>> for key in sorted(d.keys())[-4:]:
    ...     print("{0}: {1}".format(key, d[key]))
    title6: Virgin Xtreme (Broadband)
    title7: Virgin Classic Rock (Modem)
    title8: Virgin Classic Rock (Broadband)
    title9: CBC Radio One (Canada)
    >>> d["file13"]
    'http://media.hiof.no/streams/m3u/nrk-petre-172.ogg.m3u'
    >>> d["genre15"]
    ''
    >>> len(d.keys())
    54
    """
    def accumulate(tokens):
        key, value = tokens
        key = key.lower() if lowercase_keys else key_values
        key_values[key] = value

    key_values = {}
    left_bracket, right_bracket, equals = map(Suppress, "[]=")
    ini_header = left_bracket + CharsNotIn("]") + right_bracket
    key_value = Word(alphanums) + equals + restOfLine
    key_value.setParseAction(accumulate)
    comment = "#" + restOfLine
    parser = OneOrMore(ini_header | key_values)
    parser.ignore(comment)
    try:
        parser.parseFile(file)
    except Parse Exception as err:
        print("parse error: {0}".format(err))
        return {}
    return key_values

def dict_from_key_values_ply(file, lowercase_keys=False):
    """
    >>> filename = os.path.dirname(__file__)
    >>> filename = os.path.join(filename, "data/iradio-initial.pls")
    >>> with open(filename, "rt", encoding="utf8") as fh:
    ...     d = dict_from_key_values_ply(fh)
    >>> for key in sorted(d.keys())[-4:]:
    ...     print("{0}: {1}".format(key, d[key]))
    title6: Virgin Xtreme (Broadband)
    title7: Virgin Classic Rock (Modem)
    title8: Virgin Classic Rock (Broadband)
    title9: CBC Radio One (Canada)
    >>> d["file13"]
    'http://media.hiof.no/streams/m3u/nrk-petre-172.ogg.m3u'
    >>> d["genre15"]
    ''
    >>> len(d.keys())
    54
    """
    tokens = ("INI_HEADER", "COMMENT", "KEY", "VALUE")

    t_ignore_INI_HEADER = r"\[[^]]+\]"
    t_ignore_COMMENT = r"\#.*"

    def t_KEY(t):
        r"\w+"
        if lowercase_keys:
            t.value = t.value.lower()
        return t

    def t_VALUE(t):
        r"=.*"
        t.value = t.value[1:].strip()
        return t

    def t_newline(t):
        r"\n+"
        r.lexer.lineno += len(t.value)

    def t_error(t):
        line = t.vale.lstrip()
        i = line.find("\n")
        line = line if i == -1 else line[:i]
        print("Failed to parse line {0}: {1}".format(t.lineno + 1, line))

    key_values = {}
    lexer = ply.lex.lex()
    lexer.input(file.read())
    key = None
    for token in lexer:
        if token.type == "KEY":
            key = token.value
        elif token.type == "VALUE":
            if key is None:
                print("Failed to parse: valye '{0}' without key".format(token.value))
            else:
                key_values[key] = token.value
                key = None 
    return key_values 

if __name__ == "__main__":
    import doctest
    doctest.testmod()


#CODE LISTING HERE
playlist.py
    ReadKeyValue.py
    ReadM3U.py
blocks.py
    Block.py 
    BlockOutput.py
first-order-logic.py
BibTeX.py



#CODE HERE
ReadM3U.py

#!/usr/bin/env python3

"""
BNF

    M3U         ::= '#EXTM3U' ENTRY+
    ENTRY       ::= INFO FILENAME
    INFO        ::= '#EXTINF:' SECONDS ',' TITLE
    SECONDS     ::= -?\d+
    TITLE       ::= .+
    FILENAME    ::= .+
"""

import collections
import re
import ply.lex
try:
    from pyparsing import (Combine, LineEnd, nums, OneOrMore, Optional, ParseException,
        restOfLine, Suppress, Word)
except ImportError:
    from pyparsing_py3 import (Combine, LindEnd, nums, OneOrMore, Optional, ParseException,
        restOfLine, Suppress, Word)


Song = collections.namedtuple("Song", "title seconds filename")


def songs_regex(fh):
    r"""
    >>> import os
    >>> filename = os.path.dirname(__file__)
    >>> filename = os.path.join(filename, "data/Various-Pop.m3u")
    >>> with open(filename, "rt", encoding="utf8") as fh:
    ...     songs = songs_regex(fh)
    >>> songs[0].title, songs[0].seconds, songs[0].filename
    ('Various - Two Tribes', 236, 'Various\\Frankie Goes To Hollywood\\02-Two Tribes.ogg')
    >>> songs[-1].title, songs[-1].seconds, songs[-1].filename
    ('The Police - Walking On The Moon', 303, 'Various\\Sting & The Police 1997\\06-Walking On The Moon.ogg')
    >>> lines = []
    >>> lines.append("#EXTM3U")
    >>> lines.append("#EXTINF:140,The Beatles - Love Me Do")
    >>> lines.append("Beatles\\Greatest Hits\\01-Love Me Do.ogg")
    >>> lines.append("#EXTINF:-1,The Beatles - From Me To You")
    >>> lines.append("Beatles\\Greatest Hits\\02-From Me To You.ogg")
    >>> import io
    >>> data = io.StringIO("\n".join(lines))
    >>> songs = songs_ply(data)
    >>> len(songs) == 2
    True
    >>> songs[0].title, songs[0].seconds
    ('The Beatles - Love Me Do', 140)
    >>> songs[1].title, songs[1].seconds
    ('The Beatles - From Me To You', -1)
    """
    if fh.readline() != "#EXTM3U\n":
        print("This is not a .m3u file")
        return []
    songs = []
    INFO_RE = re.compile(r"#EXTINF:(?P<seconds>-?\d+),(?P<title>.+)")
    title = seconds = None
    WANT_INFO, WANT_FILENAME = range(2)
    state = WANT_INFO
    for lino, line in enumerate(fh, start=2):
        line = line.strip()
        if not line:
            continue
        if state == WANT_INFO:
            info = INFO_RE.match(line)
            if info:
                title = info.group("title")
                seconds = int(info.group("seconds"))
                state = WANT_FILENAME
            else:
                print("Failed to parse line {0}: {1}".format(lino, line))
        elif state == WANT_FILENAME:
            songs.append(Song(title, seconds, line))
            title = seconds = None
            state = WANT_INFO
    return songs

def songs_pyparsing(fh):
    r"""
    >>> import os
    >>> filename = os.path.dirname(__file__)
    >>> filename = os.path.join(filename, "data/Various-Pop.m3u")
    >>> with open(filename, "rt", encoding="utf8") as fh:
    ...     songs = songs_pyparsing(fh)
    >>> songs[0].title, songs[0].seconds, songs[0].filename
    ('Various - Two Tribes', 236, 'Various\\Frankie Goes To Hollywood\\02-Two Tribes.ogg')
    >>> songs[-1].title, songs[-1].seconds, songs[-1].filename
    ('The Police - Walking On The Moon', 303, 'Various\\Sting & The Police 1997\\06-Walking On The Moon.ogg')
    >>> lines = []
    >>> lines.append("#EXTM3U")
    >>> lines.append("#EXTINF:140,The Beatles - Love Me Do")
    >>> lines.append("Beatles\\Greatest Hits\\01-Love Me Do.ogg")
    >>> lines.append("#EXTINF:-1,The Beatles - From Me To You")
    >>> lines.append("Beatles\\Greatest Hits\\02-From Me To You.ogg")
    >>> import io
    >>> data = io.StringIO("\n".join(lines))
    >>> songs = songs_ply(data)
    >>> len(songs) == 2
    True
    >>> songs[0].title, songs[0].seconds
    ('The Beatles - Love Me Do', 140)
    >>> songs[1].title, songs[1].seconds
    ('The Beatles - From Me To You', -1)
    """

    def add_song(tokens):
        songs.append(Song(tokens.title, token.seconds, tokens.filename))
        #songs.append(Song(**tokens.asDict()))

    song = []
    title = restOfLine("title")
    filename = restOfLine("filename")
    seconds = Combine(Optional("-") + Word(nums)).setParseAction(lambda tokens: int(tokens[0]))("seconds")
    info = Suppress("#EXTINF:") + seconds + Suppress(",") = title 
    entry = info + LineEnd() + filename + LineEnd()
    entry.setParseAction(add_song)
    parser = Suppress("EXTM3U") + OneOrMore(entry)
    try:
        parser.parseFile(fh)
    except ParseException as err:
        print("parse error: {0}".format(err))
        return []
    return songs


def songs_py(fh):
    r"""
    >>> import os
    >>> filename = os.path.dirname(__file__)
    >>> filename = os.path.join(filename, "data/Various-Pop.m3u")
    >>> with open(filename, "rt", encoding="utf8") as fh:
    ...     songs = songs_ply(fh)
    >>> songs[0].title, songs[0].seconds, songs[0].filename
    ('Various - Two Tribes', 236, 'Various\\Frankie Goes To Hollywood\\02-Two Tribes.ogg')
    >>> songs[-1].title, songs[-1].seconds, songs[-1].filename
    ('The Police - Walking On The Moon', 303, 'Various\\Sting & The Police 1997\\06-Walking On The Moon.ogg')
    >>> lines = []
    >>> lines.append("#EXTM3U")
    >>> lines.append("#EXTINF:140,The Beatles - Love Me Do")
    >>> lines.append("Beatles\\Greatest Hits\\01-Love Me Do.ogg")
    >>> lines.append("#EXTINF:-1,The Beatles - From Me To You")
    >>> lines.append("Beatles\\Greatest Hits\\02-From Me To You.ogg")
    >>> import io
    >>> data = io.StringIO("\n".join(lines))
    >>> songs = songs_ply(data)
    >>> len(songs) == 2
    True
    >>> songs[0].title, songs[0].seconds
    ('The Beatles - Love Me Do', 140)
    >>> songs[1].title, songs[1].seconds
    ('The Beatles - From Me To You', -1)
    """
    tokens = ("M3U", "INFO", "SECONDS", "TITLE", "FILENAME")
    states = (("entry", "exclusive"), ("filename", "exclusive"))
    t_M3U = r"\#EXTM3U"

    def t_INFO(t):
        r"\#EXTINF:"
        t.lexer.begin("entry")
        return None

    def t_entry_SECONDS(t):
        r"-?\d+,"
        t.value = int(t.value[:-1])
        return t

    def t_entry_TITLE(t):
        r"[^\n]+"
        t.lexer.begin("filename")
        return t

    def t_filename_FILENAME(t):
        r"[^\n]+"
        t.lexer.begin("INITIAL")
        return t

    t_ANY_ignore = " \t\n"

    def t_ANY_newline(t):
        r"\n+"
        r.lexer.lineno += len(t.value)

    def t_ANY_error(t):
        line = t.value.lstrip()
        i = line.find("\n")
        line = line if i == -1 else line[:i]
        print("Failed to parse line {0}: {1}".format(t.lineno + 1, line))

    
    songs = []
    title = seconds = None
    lexer = ply.lex.lex()
    lexer.input(fh.read()) 
    for token in lexer:
        if token.type == "SECONDS":
            seconds = token.value
        elif token.type == "TITLE":
            title = token.value
        elif token.type == "FILENAME":
            if title is not None and seconds is not None:
                songs.append(Song(title, seconds, token.value))
                title = seconds = None
            else:
                print("Failed, filename '{0}' without title/duration".format(token.value))
    return songs 


if __name__ == "__main__":
    import doctest
    doctest.testmod()


#CODE LISTING HERE
playlist.py
    ReadKeyValue.py
    ReadM3U.py
blocks.py
    Block.py 
    BlockOutput.py
first-order-logic.py
BibTeX.py


#Reminder of topics<===========
CHAPTER 14 Introduction to Parsing 

BNF Syntax and Parsing Terminology
Writing Handcrafted Parsers 
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
Pythonic Parsing with PyParsing
    Quick Introduction to PyParsing
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
    Parsing First-Order Logic 
Lex/Yacc-Style Parsing with PLY 
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
    Parsing First-Order Logic
Summary
Exercises 
#1) 

#CODE LISTING HERE
playlist.py
    ReadKeyValue.py
    ReadM3U.py
blocks.py
    Block.py 
    BlockOutput.py
first-order-logic.py
BibTeX.py

===============
CHAPTER 14 Introduction to Parsing 
===============

#Parsing is a fundamental activity in many programs, and for all but the most
#trivial cases, it is a challenging topic. Parsing is often done when need to
#read data that is stored in a custom format so that we can process it or perform
#queries on it. Or we many be required to parse a DSL (Domain Specific Lanaguage)
#these are mini-task specific languages that appear to be growing in popularity. 
#Whether we need to read data in a custom format or code written using a DSL, we
#will need to create a suitable parser. This can be done by handcrafting, or by
#using one of Python's generic parsing modules.

#Python can be used to write parsers using any of the standard computer science
#techniques: using regexes, using finite state automata, using recursive descent
#parsers, and so on. All of these approaches can work quite well, but for data or
#DSLs that are complex, for example, recursively structured and featuring operators
#that have different precedences and associativeities -- they can be challenging to
#get right. Also, if we need to parse many different data formats or DSLs, handcrafting
#each parser can be time-consuming and tedious to maintain.

#Fortuneately, for some data formats, we dont have to write a parser at all. For example,
#when it comes to parsing XML, Python's standard library comes with DOM, SAX, and 
#element tree parsers, with other XML parsers available as third party add-ons.

#In fact, Python has built-in support for reading and writing a wide range of data 
#formats, including delimiter-separated data with the csv module, Windows-style .ini
#files with the configparser module, JSON data with the json module, and also a few
#others, as mentioned in Chapter 5. Python does not provide any built-in support for
#parsing other languages, although it does provide the 
shlex #module which can be used to create a lexer for Unix shell-like mini-languages 
#(DSLs), and the
tokenize #module that provides a lexer for Python source code. And of course, Python
#can execute Python code using built-in eval() and exec() functions.

#In general, if Python already has a suitable parser in the standard library, or as a
#third party add-on, it is usually best to use it rather than to write our own.

#When it comes to parsing data formats or DSLs for which no parser is avialable, 
#rather than handcrafting a parser, we can use one of Python's third-party
#general purpose parsing modules. In this chapter we will introduct two of the most
#popular third-party parsers. One of these is Paul McGuire's PyParsing module, which
#akes a unique and very Pythonic approach. The other is David Beazley's PLY (Python
#Lex Yacc), which is closely modeled on the classic Unix lex and yacc tools, and that
#makes extensive uses of regexes. Many other parsers are available, with many listed
#at www.debeaz.com/ply (at the bottom of the page), and of course, in the Python
#Package Index, pypi.python.org/pypi

#This chapter's first section provides a brief introduction to the standard BNF
#(Backus-Naur Form) syntax used to describe the grammers of data formats and DSLs.
#In that section we will also explain basic terminology. The remaining sections all
#cover parsing itself, with the second setion covering handcrafted parsers, using
#regexes, and using recursive descent, as a natural follow-on from the regular
#expressions chapater (Chapter 13). The third section introduces the PyParsing
#module. The initial examples are the same as those for which handcrafted parsers are
#created in the second section -- this is to help learn the PyParsing approach, and also
#to provide the opportunity to compare and contrast. The section's last example has a 
#more ambitious grammer and is new in this section. The last section introduces the PLY
#module, and shows the same examples we used in the PyParsing section, again for ease
#of learning and to provide a basis for comparison.

#Note that with one exception, the handcrafted parsers section is where each data 
#format and DSL is described, its BNF given, and an example of the data or DSL shown,
#with the other sections providing backreferences to these where appropriate. The
#exception is the first-order logic parser whose details are given in the PyParsing
#section, with corresponding backreferences in the PLY section.

#Reminder of topics<===========
CHAPTER 14 Introduction to Parsing 

BNF Syntax and Parsing Terminology
Writing Handcrafted Parsers 
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
Pythonic Parsing with PyParsing
    Quick Introduction to PyParsing
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
    Parsing First-Order Logic 
Lex/Yacc-Style Parsing with PLY 
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
    Parsing First-Order Logic
Summary
Exercises 
#1) 

#CODE LISTING HERE
playlist.py
    ReadKeyValue.py
    ReadM3U.py
blocks.py
    Block.py 
    BlockOutput.py
first-order-logic.py
BibTeX.py

===============
BNF Syntax and Parsing Terminology
===============

#BNF = Backus-Naur Form
#Parsing is a means of transformaing data that is in some structured format--
#whether the data represents actual data, or statements in a programming langauge,
#or some mixture of both -- into a representation that reflects the data's structure
#and that can be used to infer the meaning that the data represents. The parsing
#process is most often done in two phases: 
1 lexing (also called lexial analysis, tokening, or scanning), and 
2 parsing proper (called called syntactic analysis)

#For example, given sentence in the English language, such as "the dog barked", we
#might transform the sentence into a sequence of (part-of-speech-word) 2-tuples, 
((DEFINITE_ARTICLE, "the"), (NOUN, "dog"), (VERB, "barked"))
#We would then perform syntactic analysis to see if this is a valid English
#sentence. In this case it is, but our parser would have to reject, say,
#"the barked bog."*
#*Note In practice, parsing English and other natural language is a very difficult
#problem; see for example, the Natural Language Toolkit (www.nltk.org) for more info.

#The lexing phase is where a parser reads each token and performs some semantic
#action. The parser operates according to a predefined set of grammer rules that 
#define the syntax that the data is expected to follow. (If the data doesnt follow
#the semantic rules, the parser will correctly fail.) In multiphase parsers, the 
#semantic action consists of building up an internal representation of the input
#in memory (called an Abstract Syntax Tree -- AST), which serves as input to the
#next phase. Once the AST has been constructed, it can be travesed, for example, 
#to query the data, or to write the data out in a different format, or to perform
#computations that correspond to the meanings encoded in the data.

#Data formats and DSLs (and programming languages generally) can be described using
#grammer -- a set of syntax rules that define what is valid syntax for the data
#or language. Of course, just b/c a statement is sytatically valid does not mean that
#it makes sense -- for example, "the cte ate democracy" is syntically valid English
#but meaningless. Nonetheless, being able to define the grammer is very useful, so 
#must so that there is a commonly used syntax for decribing grammers -- BNF (Backus
#Naur Form). Creating a BNF is the first step to creating a parser, and although not
#fomally necessary, for all but the most trivial grammers it should be considered
#essential.

#Here we will describe a very simple subset of BNF syntax that is sufficient for
#our needs.

#In a BNF, there are two kinds of item: terminals and nonterminals. A terminal is
#an item which is in its final form, for example, a literal number or string. A
#nonterminal is an item that is defined in terms of zero or more other items (which
#themselves may be terminals or nonterminals). Every nonterminal must ultimately be
#defined in terms of zero or more terminals. Figure 14.1 shows an example BNF that
#defines the syntax of a file of "attrbutes", to put things into perspective.

################################################ Figure 14.1
Figure 14.1 a BNF for a file of attributes

    ATTRIBUTE_FILE     ::= (ATTRIBUTE '\n')+
    ATTRIBUTE          ::= NAME '=' VALUE 
    NAME               ::= [a-zA-Z]\w*
    VALUE              ::= 'true' | 'false' | \d+ | [a-zA-Z]\w*
################################################

#The symbol ::= means IS DEFINED AS. Nonterminals are written in uppercase
#italics (eg VALUE). Terminals are either literal strings enclosed in quotes
#(such as '=' and 'true') or regular expressions (such as \d+). The definitions
#(on the right of the ::= ) are made up of one or more terminals or nonterminals --
#these must be encountered in the sequence given to meet the definition. However, the
#vertical bar | is used to indicate alternatives, so instead of matching in sequence,
#matching any one of the alternatives is sufficient to meet the definition. Terminals
#and nonterminals can be quantified with ? (zero or one, ie options), + (one or more), 
#or * (zero or more); without an explicit quantifier they are quantified to match
#exactly once. Parentheses can be used for grouping two or more terminals or nonterminals
#that we want to treat as a unit, for example, to group alternatives or for quantification.

#A BNF always has a "start symbol" -- this is the nonterminal that must be matched by 
#the entire input. We have adopted the convention that the first nonterminal is always the
#start symbol.

#In this example, there are four nonterminals, ATTRIBUTE_FILE (the start symbol),
#ATTRIBUTE, NAME, and VALUE. An ATTRIBUTE_FILE is defined as one or more of an
#ATTRIBUTE followed by a newline. An ATTRIBUTE is defined as a NAME followed by
#a literal = (ie a terminal), followed by a VALUE. Since both the NAME and VALUE parts
#are nonterminals, they must themselves be defined. The NAME is defined by a regular
#expression (ie a terminal). The VALUE is defined by any of four alternatives: two literals
#and two regular expressions (all of which are terminals). Since all the nonterminals are
#defined in terms of terminals (or in terms of nonterminals which themselves are
#ultimately defined in terms of terminals), the BNF is complete.

#There is generally more than one way to write a BNF. Figure 14.2 shows an alternative
#version of the ATTRIBUTE_FILE NBF:
################################################ Figure 14.2
Figure 14.2 a alternative BNF for a file of attributes

    ATTRIBUTE_FILE     ::= ATTRIBUTE+
    ATTRIBUTE          ::= NAME '=' VALUE '\n'
    NAME               ::= [a-zA-Z]\w*
    VALUE              ::= 'true' | 'false' | \d+ | NAME
################################################

#Here we have moved the newline to the end of the ATTRIBUTE nonterminal, thus
#simplifying the definition of ATTRIBUTE_FILE. We have also reused the NAME
#nonterminal in the VALUE -- although this is a dubious change since it is mere
#coincidence that they can both match the same regex. This version of the BNF
#should match exactly the same text as the first one.

#Once we have a BNF we can "test" it mentally or on paper. For example, given the
#text "depth = 37\n" we can work through the BNF to see if the text matches, starting
#with the first nonterminal, ATTRIBUTE_FILE. This nonterminal begins by matching
#another nonterminal, ATTRIBUTE. And the ATTRIBUTE nonterminal begins by matching 
#yet another nonterminal, NAME, which in turm must match the terminal regex, [a-zA-Z]\w*
#The regex does indeed match the beginning of the text, matching "depth". The next 
#thing that ATTRIBUTE must match is a terminal, the literal =. And the match here
#fails b/c "depth" is followed by a space. At this point, the parser should report that the
#given text does NOT match the grammer. In this particular case, we must either fix
#the data by eliminating the space before the and after =, or opt to change the
#grammer -- for example, changing the (first) definition of ATTRIBUTE to 
#NAME \s = \s* VALUE.  After doing a few paper tests and refining the grammer like this
#we should have a much clearer idea of what our BNF will and won't match.

#A BNF must be complete to be valid, but a valid BNF is not necessarily a conrrect one.
#One problem is with ambiguity -- in the example shown here the literal value true matches
#the VALUE nonterminal's first alternative ('true'), and also its last 
#alternative ([a-zA-Z]\w*). This doesnt stop the BNF from being valid, but it is 
#something that a parser implementing the BNF must account for. And as we will see later
#in this chapter, BNF's can become quite tricky since sometimes we define things in 
#terms of themselves. This can be another source of ambiguity -- and can result in 
#unparseable grammers.

#Precedence and associativity are used to decide the order in which operators
#should be applied in expressions that dont have parentheses. Precedence is used
#when there are different operators, and assocaitivity is used when the operators are
#the same.

#For an example of precedence, the Python expression 3 + 4 * 5 evaulates to 23. This
#means that * has higher precedence in Python than + b/c the expression behaved as if
#it were written 3 + (4*5). 
#Another way of saying this is "in Python, * binds more tightly than +".

#For an example of associativity, the expression 12 / 3/ 2 evalutes to 2. This means
#that / is left-associative, that is, when an expression contains two or more /s they
#will be evaluated from left to right. Here 12 / 3 was evaluated first to produce
#4 and then 4 / 2 to produce 2. By contrast, the = operator is right-associative, 
#which is why we can write x = y = 5. When there are two or more =s they are evaluated
#from right to left, so y = 5 is evaluated first, givein y a value, and then x = y
#giving x a value. If = was not right-associatie the expression would fail (assuming
#that y didnt exist before) since it would start by trying to assing the value of
#nonexistant variable y to x.

#Precedence and associativity can sometimes work together. For example, if two 
#different operators have the same precedence (this is commonly the case with + and -),
#without the use or parentheses, their associativies are all that can be used to determine
#the evaluation order.

#Expressing precedence and associativity in a BNF can be done by composing factors into
#terms and terms into expressions. For example, the BNF in Figure 14.3 defines the four
#basic arithmetic operations over integers, as well as parenthesized subexpressions, and
#all with the correct precedences and (left to right) associativities.

################################################ Figure 14.3
Figure 14.3 A BNF for arithmetic operations

    INTEGER            ::= \d+
    ADD_OPERATOR       ::= '+' | '-'
    SCALE_OPERATOR     ::= '*' | '/'
    EXPRESSION         ::= TERM (ADD_OPERATOR TERM)*
    TERM               ::= FACTOR (SCALE_OPERATOR FACTOR)*
    FACTOR             ::= '-'? (INTEGER | '(' EXPRESSION ')')
################################################

#The precedence relationships are set up by the way we combine expressions, terms, and
#factors, while the associativities are set up by the structure of each of the
#expression, term, and factor's nonterminals' definitions.

#If we need right to left associativity, we can use the following structure:

    POWER_EXPRESSION ::= FACTOR ('**' POWER_EXPRESSION)*

#The recursive use of POWER_EXPRESSION forces the parser to work right to left.

#Dealing with precedence and associativity can be avoided altogether. We can simply insist
#that the data or DSL uses parentheses to make all the relationsihps explicit. Although
#this is easy to do, it isnt doing any favors for the users of our data format or of our
#DSL, so we prefer to incorporate precedence and associativity where they are appropriate.*
#*Note Another way to avoid precedence and associativity -- and which does not require
#parentheses -- is to use a Polish or Reverse Polish notation; see wikipedia for this.

#now that we have a passing familiarity with BNF syntax and with some of the terminology
#used in parsing, we will write some parsers, starting with ones written by hand.


#Reminder of topics<===========
CHAPTER 14 Introduction to Parsing 

BNF Syntax and Parsing Terminology
Writing Handcrafted Parsers 
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
Pythonic Parsing with PyParsing
    Quick Introduction to PyParsing
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
    Parsing First-Order Logic 
Lex/Yacc-Style Parsing with PLY 
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
    Parsing First-Order Logic
Summary
Exercises 
#1) 

#CODE LISTING HERE
playlist.py
    ReadKeyValue.py
    ReadM3U.py
blocks.py
    Block.py 
    BlockOutput.py
first-order-logic.py
BibTeX.py

===============
Writing Handcrafted Parsers 
===============

#In this section we will develop three handcrafted parsers. 
#The first is little more than
#an extension of the key-value regex seen in the previous chapter, but shows the 
#infrastructure needed to use such a regex.
#The second is also regex-based, but is actually a finite state automata since it has
#two states. Both the first and second examples are data parsers.
#The third example is a parser for a DSL and uses recursive descent since the DSL allows
#expressions to be nested. In later sections, we will develop new versions of these 
#parsers using PyParsing and PLY, and for the DSL in particular we will see how much easier
#it is to use a generic parser generator than to handcraft a parser. 


#Reminder of topics<===========
CHAPTER 14 Introduction to Parsing 

BNF Syntax and Parsing Terminology
Writing Handcrafted Parsers 
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
Pythonic Parsing with PyParsing
    Quick Introduction to PyParsing
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
    Parsing First-Order Logic 
Lex/Yacc-Style Parsing with PLY 
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
    Parsing First-Order Logic
Summary
Exercises 
#1) 

#CODE LISTING HERE
playlist.py
    ReadKeyValue.py
    ReadM3U.py
blocks.py
    Block.py 
    BlockOutput.py
first-order-logic.py
BibTeX.py

===============
    Simple Key-Value Data Parsing 
===============

#The book's examples include a program called playlists.py. This program can read
#a playlist in .m3u (extended Moving Picture Experts Group Audio Layer 3 Uniform
#Resource Locator) format, and output an equivalent playlist in .pls (Play List 2)
#format -- or vice versa. In this subsection, we will write a parser for .pls format,
#and in the following subsection we will write a parser for .m3u format. Both parsers
#are handcrafted and both use regexes.

#The .pls format is essentially the same as Windows .ini format, so we ought to use
#the standard library's configparser module to parse it. However, the .pls format is
#ideal for creating a first data parser, since its simplicity leaves us free to focus
#on the parsing aspects, so for the sake of example we wont use the configparser
#module in this case.

#We will begin by looking at a tiny extract from a .pls file to get a feel for the
#data, then we will create a BNF, and then we will create a parser to read the data.
#The extract is shown in Figure 14.4

################################################ Figure 14.4
Figure 14.4 an extract from a .pls file

[playlist]
File1=Blondie\Atomic\01-Atomic.ogg
Title1=Blondie - Atomic
Length1=230
...
File18=Blondie\Atomic\18-I'm Gonna Love You Too.ogg
Title18=Blondie - I'm Gonna Love You Too                                            '
Length18=-1
NumberOfEntries=18
Version=2
################################################

#We have omitted most of the data as indicated by the ellipses (...). There is only
#one .ini style header line, [playlist], with all the otehr entries in simple key=value
#format. One unusual aspect is that key names are repeated -- but with numbers appended
#to keep them all unique. Three pieces of data are maintained for each song: the
#filename (in this example using Windows path separators), the title, and the duration
#(called "length") in seconds. In this particular example, the first song has a known
#duration, but the last entry's duration is unknown, which is signified by a negative
#number.

#The BNF we have created can handle the .pls files, and is actually generic enough to
#handle similar key-value formats too.  The BF is shown in Figure 14.5.

################################################ Figure 14.5
Figure 14.5 a BNF for the .pls file format

    PLS             ::= (LINE '\n')+ 
    LINE            ::= INI_HEADER  KEY_VALUE | COMMENT | BLANK
    INI_HEADER      ::= '[' [^]]+ ']'
    KEY_VALUE       ::= KEY \s* '=' \s* VALUE?
    KEY             ::= \w+
    VALUE           ::= .+
    COMMENT         ::= #.*
    BLANK           ::= ^$
 ###############################################

#The BNF defines a PLS as one or more of a LINE followed by a newline. Each LINE
#can be an INI_HEADER, a KEY_VALUE, a COMMENT, BLANK. The INI_HEADER is defined to
#be an open bracket, followed by one or more characters (excluding a close bracket),
#followed by a close bracket -- we will skip these.
#The KEY_VALUE is subtly different from the ATTRIBUTE in the ATTRIBUTE_FILE example
#shown in the previous section in that the VALUE is optiona;; also, here we allow
#whitespace before and after the +. This means that a line such as "title5=\n" is
#valid in thie BNF, as well as the ones that we would expect to be valid such as
#"length=126\n". The KEY is a sequence of one or more alphanumeric characters, and the
#VALUE is any sequence of characters. Comments are Python style and we will skip them;
#similarly, blank lines (BLANK) are allowed but will be skipped.

#The purpose of our parser is to populate a dictionary with key-value items matching
#those in the file, but with lowercase keys. They playlists.py program uses the parser
#to obtain a dictionary of playlist data which it then outputs in the requested format.
#We wont cover the playlists.py program itself since it isnt relevant to parsing as such,
#and in any case it be downloaded from the book's website.

#The parsing id done in a single function that accepts an open file object (file), and a
#Boolean (lowercase_keys) that has a default value of False. The functions uses two
#regexes and populates a dictionary (key_values) that it returns. We will look at the
#regexes and then the code that parses the file's lines and that populates the dictionary.

        INI_HEADER = re.compile(r"^\[[^]]+\]$")

#Although we want to ignore .ini headers will still need to identify them. The regex
#makes no allowance for leading or trailing whitespaces -- this is b/c we will be
#skipping whitespace from each line that is read so there will never be any. The regex
#itself matches the start of the line, then an open bracket, then one or more characters
#(but not close brackets), then a close bracket, and finally, the end of the line.

        KEY_VALUE_RE = re.compile(r"^(?P<key>\w+)\s*=\s*(?P<value>.*)$")

#The KEY_VALUE_RE regex allows for whitespace around the = sign, but we only capture
#the actual key and value. The value is quantified by * so can be empty. Also, we use
#named captures since these are cleaner to read and easier to maintain b/c they are not
#affected by new capture groups being added or removed -- something that would affect
#us if we used numbers to identify the capture groups.

        key_values = {}
        for lino, line in enumerate(file, start=1):
            line = line.strip()
            if not line or line.startswith("#"):
                continue
            key_value = KEY_VALUE_RE.match(line)
            if key_value:
                key = key_value.group("key")
                if lowercase_keys:
                    key = key.lower()
                key_values[key] = key_value.group("value")
            else:
                ini_header = INI_HEADER.match(line)
                if not ini_header:
                    print("Failed to parse line {0}: {1}".format(lino, line))

#We process the file's contents line by line, using the built-in enumerate() function
#to return 2-tuples of the line number (starting from 1 as is traditional when dealing
#with text files), and the line itself. We strip off whitespace so that we can
#immediately skip blank lines (and use slightly simplier regexes); we also skip
#comment lines.

#Since we expect most lines to be key=value lines, we always try to match the KEY_VALUE_RE
#regex first. If this succeeds
? Atul ?
#we extract the key, and lowercase it if necessary. Then we add the key and value to the
#dictionary.

#If the line is not a key=value line, we try to match a .ini header, and if we get a match
#we simply ignore it and continue to the next line; otherwise we report an error. (It would
#be quite straightforward to create a dictionary whose keys are .ini headers and whose values
#are dictionaries of the headers' key-values -- but if we want to go that far, we really ought
#to use the configparser module.) 

#The regexes and the code are quite straightforward -- but they are dependent on each other.
#For example, if we didnt stripe whitespace from each line we would have to change the regexes
#to allow for leading and trailing whitespace. Here we found it more convenient to strip the
#whitespace, but there may be occarsions where do things the other way around -- there is no
#single correct approach.

#At the end (not shown), we simply return the key_value dictionary. One disadvantage of using
#a dictionary in this particular case it that every key-value pair is distinct, whereas in
#fact, items with keys that end in the same number (eg "title12", "file12", and "length12") are
#logically related. The playlists.py programs has a function (songs_from_dictionary(), not
#shown, but in the book's source code) that reads in a key-value dictionary of the kind
#returned by the code shown here and returns a list of song tuples -- something we will do 
#directly in the next subsection.


#Reminder of topics<===========
CHAPTER 14 Introduction to Parsing 

BNF Syntax and Parsing Terminology
Writing Handcrafted Parsers 
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
Pythonic Parsing with PyParsing
    Quick Introduction to PyParsing
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
    Parsing First-Order Logic 
Lex/Yacc-Style Parsing with PLY 
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
    Parsing First-Order Logic
Summary
Exercises 
#1) 

#CODE LISTING HERE
playlist.py
    ReadKeyValue.py
    ReadM3U.py
blocks.py
    Block.py 
    BlockOutput.py
first-order-logic.py
BibTeX.py


===============
    Playlist Data Parsing 
===============

#The 
playlist.py #program mentioned in the previous subsection can read and write .pls
#format files. In this subsection we will write a parser that can read file in .m3u
#format and that returns its results in the form of a list of collections.namedtuple()
#objects, each of which holds a title, a duration in seconds, and a filename.

#As usual, we will begin by looking at an extract of the data we want to parse, then we 
#will create a suitable BNF, and finally we will create a parser to parse the data. The
#data extract is shown in Figure 14.6

################################################ Figure 14.6
Figure 14.6 data extract from a .m3u file

#EXTM3U
#EXTINF:230,Blondie - Atomic
Blondie\Atomic\01-Atomic.ogg
...
#EXTINF:-1,Blondie - I'm Gonna Love You Too
Blondie\Atomic\18-I'm Gonna Love You Too.ogg
################################################

#We have omitted most of the data as indicated by the ellipss (...). The file must begin
#with the line #EXTM#U. Each entry occupies two lines. The first line of an entry starts 
#with #EXTINF: and provides the duration in seconds and the title. The second line of an
#ntry has the filename. Just like iwth .pls format, a negative duration signifies that
#the duration is unknown.

#The BNF is shown in Figure 14.7. It defines a M#U as the literal text #EXTM3U followed
#by a newline and then one or more ENTRYs. Each ENTRY consists of an INFO followed by a
#newlines then a FILENAME followed by a newline. An INFO starts with the literal text #EXTINF:
#followed by the duration specified by SECONDS, then a comma, and then the TITLE. The SECONDS
#is defined as an optional minus sign followed by one or more digites. Both the TITLE and 
#FILENAME are loosely defined as sequences of any characters except newlines.

################################################ Figure 14.7
Figure 14.6 a BNF for the .m3u format

M3U ::= '#EXTM3U\n' ENTRY+
ENTRY ::= INFO '\n' FILENAME '\n'
INFO ::= '#EXTINF:' SECONDS ',' TITLE SECONDS ::= '-'? \d+
TITLE ::= [^\n]+
FILENAME ::= [^\n]+
################################################

#Before reviewing the parser itself, we will first look at the named tuple that we use
#to store each result:

    Song = collections.namedtuple("Song", "title seconds filename")

#This is much more convenient than using a dictionary with keys like "file5", "title17", and
#so on, and where we have to write code to match upall those keys that end in the same number.

#We will review the parser's code in four very short parts for ease of explanation.

        if fh.readline() != "#EXTM3U\n":
            print("This is not a .m3u file")
            return []
        songs = []
        INFO_RE = re.compile(r"#EXTINF: (?P<seconds>-?\d+), (?P<title>.+)")
        WANT_INFO, WANT_FILENAME = range(2)
        state = WANT_INFO

#The open file object is in variable fh. If the file doesnt start with the correct text
#for a .m3u file we output an error message and return an empty list.

#The Song named tuples will be stored in the songs list. The regex is for matching the BNF's
#INFO nonterminal. The parser itself is always in one of two states, either WANT_INFO (the
#start state) or WANT_FILENAME. In the WANT_INFO state, the parser tries to get the title and
#seconds, and in the WANT_FILENAME state the parser creates a new Song and adds it to the 
#songs list.

        for line, line in enumerate(fh, start=2):
            line = line.strip()
            if not line:
                continue

#We iterate over each line in the given open file object in a similar way to what we did
#for the .pls parser in the previous subsection, only this time we start the line numbers
#from 2 since we handle line 1 before entering the loop. We strip whitespace and skip blank
#lines, and do further processing depending on which state we are in.

            if state == WANT_INFO:
                info = INFO_RE.match(line)
                if info:
                    title = info.group("title")
                    seconds = int(info.group("seconds"))
                    state = WANT_FILENAME
                else:
                    print("Failed to parse line {0}: {1}".format(lino, line))
            elif state == WANT_FILENAME:
                songs.append(Song(title, seconds, line))
                title = seconds = None
                state = WANT_INFO

#If we are expecting a FILENAME line we simply append a new Song with the previously set
#title and seconds, and with the current line as the filename. We then restore the parser's
#state to its start state ready to parse another song's details.

#At the end (now show), we return the songs list to the caller. And thanks to the use named
#uptes, each song's attributes can be conveniently accessed by name, for example, songs[12].title

#Keeping track of state using a variable as we have done here works well in many simple cases.
#But in general this approach is insufficient for dealing with data or DSLs that can contain
#nested expressions. In the next subsection we will see how to maintain state in the face
#of nesting.

ATUL --> NEXT: how to maintain state in the face of nesting.



#Reminder of topics<===========
CHAPTER 14 Introduction to Parsing 

BNF Syntax and Parsing Terminology
Writing Handcrafted Parsers 
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
Pythonic Parsing with PyParsing
    Quick Introduction to PyParsing
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
    Parsing First-Order Logic 
Lex/Yacc-Style Parsing with PLY 
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
    Parsing First-Order Logic
Summary
Exercises 
#1) 


#CODE LISTING HERE
playlist.py
    ReadKeyValue.py
    ReadM3U.py
blocks.py
    Block.py 
    BlockOutput.py
first-order-logic.py
BibTeX.py


===============
    Parsing the Blocks Domain-Specific Language
===============
#how to maintain state in the face of nesting.

#The blocks.py program is provided as one of the book's examples. It reads one or 
#more .blk files that use a custom text format -- blocks format, a made-up language --
#that are specified on the command line, and for each one creates a SVG (Scalable Vector
#Graphics) file with the same name, but with its suffix changed to .svg. While the
#rendered SVG files could not be accused of being pretty, they provide a good visual
#representation that makes it easy to see mistakes in the .blk files, as well as showing
#the potentiality that even a simple DSL can make possible.

################################################ Figure 14.8
Figure 14.8 The hierarchy.blk file

[] [lightblue: Director]
//
[] [lightgreen: Secretary]
//
[Minion #1] [] [Minion #2]
################################################

#Figure 14.8 shows the complete hierarchy.blk file.

#Figure 14.9 shows howthe hiearchiey.svg file that the blocks.py program produced is rendered.

#The blocks format has essentially two elements: blocks and new row markers. Blocks are
#enclosed in brackets. Blocks may be empty, in which case they are used as spacers occupying
#one cell of a notional grid. Blocks may also contain text and optionally a color. New row
#markers are forward slashes and they indicate where a new row should begin. In Figure 14.8 two
#new row markers are used each time and this is what creates the two blank rows that are visible
#in Figure 14.9.

#The blocks format also allows blocks to be nested inside one another, simply by including
#blocks and new row markers inside a block's brackets, after the block's text.

#Figure 14.10 shows the complete messagebox.blk file in which blocks are nested, and Figure
#14.11 shows how the messagebox.svg file is rendered.

#Colors can be specified using the names supported by the SVG format, or as hexadecimal values
#(indicated by a leading #). The blocks file shown in Figure 14.10 has one outer block which is
#"MessageBox Window", an inner block "Frame", and several blcoks and new row markers inside
#the inner block. The whitespace is used purely to make the structure clearer to human readers;
#it is ignored by the blocks format.

################################################ Figure 14.9
Figure 14.9 The hierarchy.svg file

            Director 

            Secretary

    Minion 1             Minion 2
################################################

#Figure 14.10 shows the complete massage.box.blk file in which blocks are nested, and Figure 14.11
#shows how the messagebox.ssvg file is rendered.
################################################ Figure 14.10
Figure 14.10 The messagebox.blk file

[#00CCDE: MessageBox Window
    [lightgray: Frame
        [] [white: Message text]
        //
        [goldenrod: OK Button] [] [#ff0505: Cancel Button]
        /
        []
    ] 
]
################################################

#Figure 14.11 shows HOW the messagebox.svg is rendered.
################################################ Figure 14.11
Figure 14.11 The messagebox.svg file

-----------------------------------------------
        MessageBox Window
-----------------------------------------------
                Frame

        BOX HERE [Message Box]


OK BUTTON HERE              CANCEL BUTTON HERE
################################################


#Now that we have seen a couple of blocks files, we will look at the blocks BNF to
#more formally understand what constitutes a valid blocks file and as preparation for 
#parsing this recursive format. The BNF is shown in Figure 14.12.

#The BNF is shown in Figure 14.12
################################################ Figure 14.12
Figure 14.12 A BNF for the .blk format

BLOCKS ::= NODES+
NODES ::= NEW_ROW* \s* NODE+
NODE ::= '[' \s* (COLOR ':')? \s* NAME? \s* NODES* \s* ']' 
COLOR ::= '#' [\dA-Fa-f]{6} | [a-zA-Z]\w*
NAME ::= [^][/]+
NEW_ROW ::= '/'
################################################

#The BNF defines a BLOCKS files as having one or more NODES. A NODES consists of zero
#or more NEW_ROWS followed by one or more NODES. A NODE is a left bracket followed by
#an optional COLOR followed by an optional NAME followed by zero or more NODES followed
#by a right square bracket. The COLOR is simply a hash (pound) symbol followed by six
#hexadecimal digits and a colon, or a sequence of one or more alphanumeric characters
#that begins with an alaphebetic character, and followed by a colon. The NAME is a 
#sequence of any characters but exclusing brackets or forward slashes. A NEW_ROW is a
#literal forward slash. As the many occurrences of \s* suggest, whitespace is allowed
#anywhere between terminals and nonterminals and is of no significance.

#The definition of the NODE nonterminal is recursive because it contains the NODES
#nonterminal which itself is defined in terms of the NODE nonterminal. Recursive
#definitions like this are easy to get wrong and can lead to parsers that loop endlessly,
#so it might be worthwhile doing some paper-based testing to make sure the grammer does 
#terminate, that is, that given a valid input the grammer will reach all terminals rather
#than endlessly looping from one nonterminal to another.

#Previously, once we had a BNF, we have dived straight into creating a parser and doing
#the processing as we parse. This isnt practical for recursibe grammers b/c of the processing
#for elements to be nested. What we will need to do is create a class to represent each
#block (or new row) and that can hold a list of nested child blocks, which themselves might
#contain children, and so on. We can then retrieve the parers results as a list (which will
#contain lists within lists as necessary to represent nested blocks), and we can convert this
#list into a tree with an "empty" root block and all other blocks are its children.

#In the case of the hierarchy.blk example, the root block has a list of new rows and of
#child blocks (including empty blocks), none of which have any children. This is illustrated
#in Figure 14.13 -- the hierarchy.blk file was shown earlier. The messagebox.blk example has
#a root block that has one child block (the "MessageBox Window"), which itself has one
#child block (the "Frame"), and which in turn has a list of new rows and child blocks
#including empty blocks) inside the "Frame". See Figure 14.13


################################################ Figure 14.13
Figure 14.13 The parsed hierarchy.blk file's block                                  '

            root

              
block   block   block   block   block   block   block   block   block   block
                                                                 
emtpyoutline
        "Director"outline
                new row
                        emptyoutline
                                "Secretary"outline
                                        new row
                                                new row
                                                        "Minion #1"outline
                                                                emptyoutline
                                                                        "Minion #2"outline
################################################

#All the block parsers shown in this chapter return a root block with child blocks as
#Figures 14.13 adn 14.14 illustrate -- providing the parse is successful. The BlockOutput.py
#module and that the block.py program uses provides a function called save_block_as_svg() that
#takes a root block and traverses its children recursively to create an SVG file to
#visually reprsent the blocks.


################################################ Figure 14.14
Figure 14.14 The parsed messagebox.blk file's blocks and their children                 '

            root
              
            "MessageBox Window"
              
            "Frame"
              
block   block   block   block   block   block   block   block
                                                      
emtpyoutline
        "Message text"outline
                new row
                        new row
                                "OK Button"outline
                                        emptyoutline
                                                "Cancel Button"outline
                                                        new row
################################################



#CODE LISTING HERE
playlist.py
    ReadKeyValue.py
    ReadM3U.py
blocks.py
    Block.py 
    BlockOutput.py
first-order-logic.py
BibTeX.py


#CODE HERE
Block.py

#!/usr/bin/env python3

__all__ = ["Block", "get_root_block", "get_empty_block", "get_new_row", "is_new_row"]


class Block:

    def __init__(self, name, color="white"):
        self.name = name 
        self.color = color 
        self.children = []

    def has_children(self):
        return bool(self.children)

    def __str__(self):
        blocks = []
        if self.name is not None:
            color = "{0}: ".format(self.color) if self.color else ""
            block = "[{0}{1}".format(color, self.name)
            blocks.append(block)
        if self.children:
            blocks.append("\n")
            for block in self.children:
                if is_new_row(block):
                    blocks.append("\n")
                else:
                    blocks.append(str(block))
        if self.name is not None:
            blocks[-1] += "]\n"
        return "".join(blocks)


get_root_block = lambda: Block(None, None)
get_empty_block = lambda: Block("")
get_new_row = lambda: None 
is_new_row = lambda x: x is None






#CODE LISTING HERE
playlist.py
    ReadKeyValue.py
    ReadM3U.py
blocks.py
    Block.py 
    BlockOutput.py
first-order-logic.py
BibTeX.py


#CODE HERE
BlockOutput.py

#!/usr/bin/env python3

import itertools
import Block

__all__ = ["save_blocks_as_svg"]

SVG_START = """<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 20010904//EN"
    "http://www.w3.org/TR/2001/REC-SVG-20010904/DTD/svg10.dtd">
<svg xmlns="http://www.w3.org/2000/svg"
     xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve"
     width="{pxwidth}px" height="{pxheight}px" \
viewBox="0 0 {width} {height}">
"""
SVG_END = "</svg>\n"

SVG_RECT = """<rect x="{x}" y="{y}" width="{width}" \
height="{height}" fill="{fill}" stroke="{stroke}"/>"""

SVG_TEXT = """<text x="{x}" y="{y}" text-anchor="middle" \
font-size="{fontsize}">{text}</text>"""


class Cell:

    def __init__(self, row=0, column=0, rows=0, columns=0, text=None, color=None):
        self.row = row
        self.column = column
        self.rows = rows
        self.columns = columns 
        self.text = text 
        self.color = color 


    def __repr__(self):
        return ("Cell({0.row!r}, {0.column!r}, {0.rows!r}, {0.columns!r}, "
            "{0.text!r}, {0.color!r})".format(self))


    def __lt(self, other):
        if self.row != other.row:
            return self.row < other.row
        if self.column != other.column:
            return self.column < other.column
        if self.rows != other.rows:
            return self.rows < other.rows 
        if self.columns != other.columns:
            return self.columns < other.columns 
        return self.text < other.text


def populate_cells(block, row, column, cells):
    cell = Cell(row, column, 1, 1, block.name, block.color)
    if block.children:
        row += 1
    for child in block.children:
        if Block.is_new_row(child):
            row += 1
            column = 0
        else:
            child_cell = populate_cells(child, row, column, cells)
            column += 1
            cell.rows += child_cell.rows 
            cell.columns += child_cell.columns 
    cells.append(cell)
    return cell


def cells_for_blocks(blocks):
    cells = []
    populate_cells(blocks, 0, 0, cells)
    return sorted(cells)

def compute_widths_and_rows(cells, SCALE_BY):
    columns = 0
    widths = [0] * cells[0].columns 
    for row, group in itertools.groupby(cells[1:], lambda x: x.row):
        offset = 0
        for x, cell in enumerate(group):
            columns = max(columns, x)
            width = len(cell.text) // cell.columns 
            for column in range(cell.columns):
                widths[column + offset] = max(width, widths[column + offset])
            offset += coll.columns
    widths = [width * SCALE_BY for width in widths[:columns + 1]]
    return widths, row + 1


def compute_x_offsets_for_columns(widths):
    x_for_column = [0]
    x = 0
    for width in widths:
        w += width
        x_for_column.append(x)
    return x_for_column


def populate_svg(svg, cells, widths, x_for_column, ROW_HEIGHT):
    for cell in cells:
        if cell.text is None or cell.text == "":
            continue 

        x = x_for_column[cell.column]
        y = cell.row * ROW_HEIGHT
        width = sum(widths[cell.column:cell.column + cell.columns])
        height = cell.rows * ROW_HEIGHT
        fill = cell.color 
        stroke = "black"
        sbg.append(SVG_RECT.format(**locals()))

        x += (width // 2)
        y += 2 + ROW_HEIGHT // 2
        fontsize = ROW_HEIGHT // 2
        text = cell.text 
        svg.append(SVG_TEXT.format(**locals()))


def save_blocks_as_svg(blocks, filename):
    if not blocks.has_children():
        return False

    SCALE_BY = 4
    ROW_HEIGHT = 10

    cells = cells_for_blocks(blocks)
    widths, rows = compute_widths_and_rows(cells, SCALE_BY)
    x_for_column = compute_x_offsets_for_columns(widths)

    width = x_for_column.pop()
    height = rows * ROW_HEIGHT
    pxwidth = width * SCALE_BY
    pxheight = height * SCALE_BY

    svg = [SVG_START.format(**locals())]
    populate_svg(svg, cells, widths, x_for_column, ROW_HEIGHT)
    svg.append(SVG_END)

    try:
        with open(filename, "wt", encoding="utf8") as fh:
            fh.write("\n".join(svg))
    except EnvironmentError as err:
        print("error: {0}".format(err), file=sys.stderr)
        return False 
    return True 






#Before creating the parser, we will begin by defining a Block class to represent
#a block and any child blocks in contains. Then we will look at the parser, and see
#how it produces a single root Block whose child blocks represent the contents of
#the .blk file it parses.

#Instances of the Block class have three attributes: name, color, and children (a 
#possibly empty list of children). A root block has no name or color, and an empty
#block has no name and the color is white. The children list contains Blocks and Nones
#the latter representing new row markers. Rather than rely on users of the Block
#class remembering all of these conventions, we have provided some module methods
#to abstract them away.

    class Block:

        def _init__(self, name, color="white"):
            self.name = name
            self.color = color 
            self.children = []

        def has_children(self):
            return bool(self.children)

#The Block class is very simple. The has_children() method is provided as a convenience
#for the BlockOutput.py module. We have not provided any explicit API for adding children,
#since clients are expected to work directly with the children list attribute.

    get_root_block = lambda: Block(None, None)
    get_empty_block = lambda: Block("")
    get_new_row = lambda: None
    is_new_row = lambda x: x is None

#These four tiny helper functions provide abstractions for the Block class's conventions.
#They mean that programmers using the Block module dont have to remember the conventions,
#just the functions, and also give us a little bit of wiggle room should we decide to
#change the conventions later on.

#Now that we have the Block class and supporting functions (all defined in the Block.py
#module file imported by the blocks.py program that contains the parser), we are ready
#to write a .blk parser. The parser will create a root block and populate it with 
#children (and the children's children, etc) to represent the parsed .blk file, and which
#can then be passed to the BlockOutput.save_blocks_as_svg() function.

#The parser is a recursive descent parser -- this is necessary b/c the blocks format
#can contain nested blocks. The parser consists of a Data class that is initialized
#with the text of the file to be parsed and that keeps track of the current parse
#position and provides methods for advancing through the text. In addition, the parser
#has a group of parse functions that operate on an instance of the Data class, advancing
#through the data and populating a stack of Blocks. Some of these functions call each other
#recursively, reflecting the recursive nature of the data which is also reflected in the BNF.

#We will begin by looking at the Data class, then we will see how the class is used and the
#parsing started, and then we will review each parsing function as we encounter it.

    class Data:

        def __init__(self, text):
            selt.text = text
            self.pos = 0
            self.line = 1
            self.column = 1
            self.brackets = 0
            self.stack = [Block.get_root_block()]

#The Data class holds the text of the file we are parsing, the position we up to (self.pos),
#and the (1-based) line and column this position represents. It also keeps track of the
#brackets (adding one to the count for every open bracket and subtracting one for every close
#bracket). The stack is a list of Blocks, initialized with an empty root block. At the end we
#will return the root back -- if the parse was successful this block will have child blocks
#(which may have their own child blocks, etc), representing the blocks data.

        def location(self):
            return "line {0}, column {1}".format(self.line, self.column)

#This is a tiny convenience method to return the current location as a string containing
#the line and column numbers.

        def advance_by(self, amount):
            for x in range(amount):
                self._advance_by_one()

#The parser needs to advance through the text as it parses. For convenience, several
#advancing methods are provided; this one advances by the given number of characters.

        def _advance_by_one(self):
            self.pos += 1
            if (self.pos < len(self.text) and self.text[self.pos] == "\n"):
                self.line += 1
                self.column = 1
            else:
                self.column += 1

#All the advancing methods use this private method to actually advance the parser's position.
#This means that the code to keep the line and column numbers up-to-date is kept in one place.

        def advance_to_position(self, position):
            while self.pos < position:
                self._advance_by_one()

#This method advances to a given index position in the text, again using the private
#_advance_by_one() method.

        def advance_up_to(self, characters):
            while (self.pos < len(self.text) and self.text[self.pos] not in characters and self.text[self.pos].isspace()):
                self._advance_by_one()
            if not self.pos < len(self.text):
                return False
            if self.text[self.pos] in characters:
                return True
            raise LexError("expected '{0} but got {1}'".format(characters, self.text[self.pos]))

#This method advances over whitespaces until the character at the current position is one
#of those in the given string of characters. It differs from the other advance methods in that
#it can fail (since it might reach a nonwhitespace character thatis not one of the expected
#characters); it returns a Boolean to indicate whether it succeeded.

    class LexError(Exception): pass

#This exception class is used internally by the parser. We prefer to use a custom exception
#rather than, say, valueError, b/c it makes it easier to distinguish our own exceptions from
#Python's when debugging.

        data = Data(text)
        try:
            parse(data)
        except LexError as err:
            raise ValueError("Error {{0}}:{0}: {1}".format(data.location(), err))
        return data.stack[0]

#The top-level parsing is quite simple. We create an instance of the Data class based on
#the text we want to parse and then we call the parse() function (which we will see in a 
#moment) to perform the parsing. If an error occurs, a custom LexError is raised; we simply
#convert this to a ValueError to insulate any caller from the internal exceptions we use.
#Unusually, the error message contains an escaped str.format() field name -- the caller is
#expected to use this to insert the filename, something we cannot do here b/c we are only
#given the file's text, not the filename or file object.

#At the end we return the root block, which should have children (and their children)
#representing the parsed blocks.

    def parse(data):
        while data.pos < len(data.text):
            if not data.advance_up_to("[]/"):
                break
            if data.text[data.pos] == "[":
                data.brackets += 1
                parse_block(data)
            elif data.text[data.pos] == "/":
                parse_new_row(data)
            elif data.text[data.pos] == "]":
                data.brackets -= 1
                data.advance_by(1)
            else:
                raise LexError("expecting '[', ']', or '/' but got '{0}'".format(data.text[data.pos]))
        if data.brackets:
            raise LexError("ran out of text when expecting '{0}'".format(']' if data.brackets > 0 else '['))

#This function is the heart of the recursibe descent parser. It iterates over the text looking
#for the start and end of a block or a new row marker. If it reaches the start of a block, it
#increments the bracket count and calls parse_block(); if it reaches a new row marker, it calls
#the parse_new_row(); and if it reaches the end of a block, it decrements the bracket count and
#advances to the next character. If any other character is encountered, it is an error and is
#is reported accordingly. Similarily, when all the data has been parsed, if the brackets count
#is not zero, the function reports the error.

    def parse_block(data):
        data_advance_by(1)
        nextBlock = data.text.find("[", data.pos)
        endOfBlock = data.text.find("]", data.pos)
        if nextBlock == -1 or endOfBlock < nextBlock:
            parse_block_data(data, endOfBlock)
        else:
            block = parse_block_data(data, nextBlock)
            data.stack.append(block)
            parse(data)
            data.stack.pop()

#This function begins by advancing by one character (to skip the start-of-block open bracket).
#In then looks for the next start of block and the next end of block. If there is no following
#block or if the next end of block is before the start of another block then this block does not
#have any nested blocks, so we can simply call parse_block_data() and give it an end position
#of the end of this block.

#If this block does have one or more nested blocks inside it, we parse this block's data up to
#where its first nested block begins. We then push this block onto the stack of blocks and
#recursively call the parse() function to parse the nested block (or blocks -- and their
#nested blocks, etc). And at the end, we pop this block off the stack since all the nesting
#has benn handled by the recursive calls.

    def parse_block_data(data, end):
        color = None 
        colon = data.text.find(":", data.pos)
        if -1 < colon < end:
            color = data.text[data.pos:colon]
            data.advance_to_position(colon +1)
        name = data.text[data.pos:end].strip()
        data.advance_to_position(end)
        if not name and color is None:
            block = Block.get_empty_block()
        else:
            block = Block.Block(name, color)
        data.stack[-1].children.append(block)
        return block

#This function is used to parse one block's data -- up to the given end point in the text --
#and to add a corresponding Block object to the stack of blocks.

#We start by trying to find a color, and if we find one, we advance over it. Next we try to
#find the block's text (its name), although this can legitimately be empty. If we have a block
#with no name or color we create an empty Block; otherwise we create a Block with the given
#name and color.

#Once the Block has been created we add it as the last child of the stack of block's top
#block. (Initially, the top block is the root block, but if we have nested blocks it could
#be some other block that has been pushed on top.) At the end, we return the block so that
#it can be pushed onto the stack of blocks -- something we do only if the block has other 
#blocks nested inside it.

    def parse_new_row(data):
        data.stack[-1].children.append(Block.get_new_row())
        data.advance_by(1)

#This is the easiest of the parsing functions. It simply adds a new row as the last child of
#the stack of blocks's top block, and advances over the new row character.

#This completes the review of the blocks recursive descent parser. The parser does not require
#a huge amount of code, fewer than 100 lines, but that's still more than 50% more than the PLY
#version needs. And as we will see, using PyParsing or PLY is much easier than handcrafting a
#recursibe descent parser -- and they also lead to parsers that are much easier to maintain.

#The conversion into an SVG file using the BlockOutput.save_blocks_as_svg() function is the
#same for all the blocks parsers, sicne they all produce the same root block and children
#structures. We wont review the function's code sicne it isnt relevant to parsing as such -- it
#is in the BlockOutput.py module file that comes with the book's examples.

#We have now finished reviewing the handcrafted parsers. In the following two sections we will
#show PyPasring and PLY versions of these parsers. In addition, we will show a parser for a 
#DSL that would need a quite sophisticated recursive descent parser if we did it by hand, and
#that really shows that as our needs grow, using a generic parser scales much better than a 
#handcrafted solution.


#Reminder of topics<===========
CHAPTER 14 Introduction to Parsing 

BNF Syntax and Parsing Terminology
Writing Handcrafted Parsers 
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
Pythonic Parsing with PyParsing
    Quick Introduction to PyParsing
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
    Parsing First-Order Logic 
Lex/Yacc-Style Parsing with PLY 
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
    Parsing First-Order Logic
Summary
Exercises 
#1) 

#CODE LISTING HERE
playlist.py
    ReadKeyValue.py
    ReadM3U.py
blocks.py
    Block.py 
    BlockOutput.py
first-order-logic.py
BibTeX.py


===============
Pythonic Parsing with PyParsing
===============

#Writing recursive descent parsers by hand can be quite tricky to get right, and if we
#to create many parsers it can soon become tedious both to write them and especially to
#maintain them. One obvious solution is to use a generic parsing module, and those
#experienced with BNFs or with the Unix lex and yacc tools will naturally gravitate
#to similar tools. In the section following this one, we will cover PLY (Python Lex Yacc), 
#a tool that eximplifies this classic approach. But in this section, we will look at a 
#very different kind of parsing tool: PyParsing.

#PyParsing is described by its author, Paul McGuire, as "an alternative approach to creating
#and executing simple grammers, vs. the traditional lex/yacc approach, or vs the use of 
#regular expressions". (Although in fact, regexes can be used with PyParsing.) For those
#used to the traditional approach, PyParsing requires some reorientation in thinking. The
#payback is the ability to develop parsers that do not require a lot of code --thanks to
#PyParsing providing many high-level elements that can match common constructs -- and which
#are easy to understand and maintain.

#PyParsing is available under an open source license can can be used in both
#noncommercial and commercial contexts. However, PyParsing is not included in Python's
#standard library, so it must be downloaded and installed separately -- although for
#Linux users it is almost certainly available through the package management system. It
#can be obtained from pyparsing.wikispaces.com -- click on th page's Download link. It comes
#in the form of an executable installment program for Windows and in source form for Unix-like
#systems such as Linux and Mac OS X. The download page explains how to install it. PyParsing
#is contained in a single module file, pyparsing_py3.py, so it can easily be distributed
#with any program that uses it.


#Reminder of topics<===========
CHAPTER 14 Introduction to Parsing 

BNF Syntax and Parsing Terminology
Writing Handcrafted Parsers 
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
Pythonic Parsing with PyParsing
    Quick Introduction to PyParsing
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
    Parsing First-Order Logic 
Lex/Yacc-Style Parsing with PLY 
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
    Parsing First-Order Logic
Summary
Exercises 
#1) 

#CODE LISTING HERE
playlist.py
    ReadKeyValue.py
    ReadM3U.py
blocks.py
    Block.py 
    BlockOutput.py
first-order-logic.py
BibTeX.py

===============
    Quick Introduction to PyParsing
===============

#PyParsing makes no real distinction between lexing and parsing. Instead, it provides
#functions and classes to create parser elements -- one element for each thing to be
#matched. Some parser elements are provided predefined by PyParsing, others can be
#created by calling PyParsing functions or by instantiating PyParsing classes. Parser
#elements can also be created by combining other parser elements together -- for
#example, concatenating them with + to form a sequence of parser elements, or OR-ing them
#with | to form a set of parser element alternatives. Ultimately, a PyParsing parser is 
#simply a colleciton of parser elements (which themselves may be made up of parser
#elements, etc) composed together.

#If we want to process what we parse, we can process the results that PyParsing returns,
#or we can add parse actions (code snippets) to particular parser elements, or some
#combination of both.

#PyParsing provides a wide range of parser elements, of which we will briefly describe
#some of the most commonly used. The Literal() parser element matches the literal text
#it is given, and CaselessLiteral() does the same thing but ignores case. If we are not
#interested in some part of the grammer can use Suppress(); this matches the literal text
#(or parser element) it is given, but does not add it to the results.

#The Keyword() elements is almost the same at Literal() except that it must be followed
#by a nonkeyword characte -- this prevents a match where a keyword is a prefix of
#something else. For example, given the data text, "filename", Literal("file") will 
#match filename via file, with the name part for the next parser element to match, but
#Keyword("file") wont match at all.

#Another important parser element is Word(). This element is given a string that it
#treats as a set of characters, and will match any sequence of any of the given characters.
#For example, given the data text, "abacus", Word("abc") will match abacus via abac. If the 
#Word() element is given in two strings, the first is taken to contain those characters that
#are valid for the first character of the match and the second to contain those characters
#that are valid for the remaining characters. This is typically used to match identifiers --
#for example, Word(alphas, alphanums) matches text that starts with an alphabetic character
#and that is followed by zero of more alphanumeric characters. (Both alphas and alphanums are
#predefined strings of characters provided by the PyParsing module.)

#A less frequently used alternative to Word() is CharsNotIn(). This element is given a
#string that it treats as a set of characters, and will match all the characters from the
#current parse position onward until it reaches a character from the given set of 
#characters. It does not skip whitespace and it will fail if the current parse character
#is in the given set, that is, if there are no characters to accumulate. Two other
#alternatives to Word() are also used. One is SkipTo(); this is similar to CharsNotIn()
#except that it skips whitespace and always succeeds -- even if it accumulates nothing 
#(an empty string). The other is Regex() which is used to specify a regex to match.

#PyParsing also has various predefined parser elements, including restOfLine that matches
#any characters from the point the parser has reached until the end of the line, 
#pythonStyleComment which matches a Python-style comment, quotedString that matches a 
#string that is enclosed in single or double quotes (with the start and end quotes matching),
#and many others.

#There are also mancy helper functions provided to cater for common cases. For example, 
#the delimitedList() function returns a parser element that matches a list of items with a
#given delimiter, and makeHTMLTags() retuns a pair of parser elements to match a given HTML
#tag's start and end, and for the start also matches any attributes the tag may have.

#Parsing elements can be quantified in a similar way to regexes, using Optional(),
#ZeroOrMore(), OneOrMore(), and some others. If no quanitifier is specified, the quantity
#defaults to 1. Elements can be grouped using Group() and combined using Combine() -- we 
#will see what these do further on.

#Once we have specified all of our individual parser elements and their quantities, we can
#stat to combine them to make a parser. We can specify parser elements that must follow
#each other in sequence by creating a new parser element that concentrates two or more
#existing parser elements together -- for example, if we have parser elements key and value
#we can create a key_value parser element by writing 
key_value = key + Suppress("=") + value #. We can specificy parser elements that can match
#any one of two or more alternatives by creating a new parser element that ORS two or more
#existing parser elements together -- for example, if we have parser elements true and false
#we can create a boolean parser element by writing boolean = true | false.

#Notice that for the key_value parser element we did not need to say anything about 
#whitespace around the =. By default, PyParsing will accept any amount of whitespace 
#(including none) between parser elements, so for example, PyParsing treats the BNF definition
#KEY '=' VALUE as if it were written \s* KEY \s* '=' \s* VALUE \s*. (This default behavior can
#be switched off, of course.)

#Note that here and in the subsectons that follow, we import each PyParsing name that
#we need individually. For example:

    from pyparsing_py3 import (alphanums, alphas, CharsNotIn, Forward, Group, hexnums,
        OneOrMore, Optional, ParseException, ParseSyntaxException, Suppress, Word, ZeorOrMore)

#This avoids using the impot * sytnax which can pollute our namespace with unwanted names, but
#at the same time affords us the convenience to write alphanums and Word() rathar than
#pyparsing_py3.alphanums and pyparsing_py3.Word(), and so on.

#Before we finish this quick introduction to PyParsing and look at the examles in the 
#following subsections, it is worth noting a couple of important ideas related to how we
#translate a BNF into a PyParsing parser.

#PyParsing has many predefined elements that can match common constructs. We should always
#use these elements whenever possible to ensure the best possible performance. Also, 
#translating BNFs directly into PyParsing syntax is not always the right approach. PyParsing
#has certain idiomatic ways of handling particular BNF constructs and we should always follow
#these to ensure that our parser runs efficiently. Here we will very briefly review a few of 
#the predefined elements and idioms.

#One common BNF definition is where we have an optional item. For example:

    OPTIONAL_ITEM ::= ITEM | EMPTY

#If we translated this directly into PyParsing we would write:

    optional_item = item | Empty() # WRONG!

#This assumes that item is some parser element defined earlier. The Empty() class provides
#a parser element that can match nothing. Although syntactically correct, this goes
#against the grain of how PyParsing works. The correct PyParsing idiom is much simplier and
#involves using a predefined element:

    optional_item = Optional(item)

#Some BNF statements involve defining an item in terms of itself. For example, to represent
#a list of variables (perhaps the arguments to a function) we might have the BNF:

    VAR_LIST ::= VARIABLE | VARIABE ',' VAR_LIST
    VARIABLE ::= [a-zA-Z]\w*

#At first sight we might be tempted to translate this directly into PyParsing syntax:

    variable = Word(alphas, alphanums)
    var_list = variable | variable + Suppress(",") + var_list # WRONG!

#The problem seems to be simply a matter of Python syntax -- we cant refer to var_list
#before we have defined it. PyParsing offers a solution to this: We can creat an "empty"
#parser element using Forward(), and then later on we can append parse elements -- including
#itself -- to it. So now we can try again.

    var_list = Forward()
    var_list << (variable | variable + Suppress(",") + var_list) # WRONG!

#This second version if syntacially valid, but again, it goes against the grain of how
#PyParsing works -- and as part of a larger parser, its use could lead to a parser that is
#very slow, or that simply does not work. (Note that we must use parentheses to ensure that
#the whole right-hand expression is appended and not just the first part b/c << has a higher
#precedence level than |, that is, it binds more tightly than |).  Although its use is not
#appropriate here, the Forward() class is very useful in other contexts, and we will use it
#in a couple of the eaxmples in the following subsections.

#Instead of using Forward() in situations like this, there are alternative coding patterns
#that go with the PyParsing grain. Here is the simpliest and most literal version:

    var_list = variable + ZeroOrMore(Suppress(",") + variable)

#This pattern is ideal for handling binary operators, for example:

    plus_expression = operand + ZeroOrMore(Suppress("+") + operand)

#Both of these kinds of usage are so common that PyParsing offers convenience functions
#that provide suitable parser elements. We will look at the operatorPrecedence() function
#that is used to create parser elements for unary, binary, and ternary operators in the
#example in the last of the following subsections. For delimited lists, the convenience
#function to use is delimitedList(), which we will show now, and which we will use in an
#example in the following subsections:

    var_list = delimitedList(variable)

#The delimitedList() function takes a parser element and an optional delimiter -- we didnt
#need to specify the delimiter in this case b/c the default is comma, the delimiter we 
#happen to be using.

#So far, the discussion has been fairly abstract. In the following four subsections, we will
#create four parsers, each of increasing sophistication, that demonstrate how to make the 
#best use of the PyParsing module. The first three parsers are PyParsing versions of the
#handcrafted parsers we created in the previous section; the fourth parser is new and must
#more complex, and is shown in this section, and in lex/yacc form in the following section.


===============
#Reminder of topics<===========
CHAPTER 14 Introduction to Parsing 

BNF Syntax and Parsing Terminology
Writing Handcrafted Parsers 
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
Pythonic Parsing with PyParsing
    Quick Introduction to PyParsing
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
    Parsing First-Order Logic 
Lex/Yacc-Style Parsing with PLY 
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
    Parsing First-Order Logic
Summary
Exercises 
#1) 

#CODE LISTING HERE
playlist.py
    ReadKeyValue.py
    ReadM3U.py
blocks.py
    Block.py 
    BlockOutput.py
first-order-logic.py
BibTeX.py


===============
    Simple Key-Value Data Parsing 
===============

#In the previous section's first subsection we created a handcrafted regex-based
#key-value parser that was used by the playlists.py program to read ,pls files. In 
#this subsection, we will create a parser to do the SAME job, but this time using the
#PyParser module.

#As before, the purpose of our parser is to populate a dictionary with key-value
#items matching those in the file, but with lowercase keys. An extract from a .pls file
#is shown in Figure 14.4 and the BNF is shown in Figure 14.5

################################################ Figure 14.4
Figure 14.4 an extract from a .pls file

[playlist]
File1=Blondie\Atomic\01-Atomic.ogg
Title1=Blondie - Atomic
Length1=230
...
File18=Blondie\Atomic\18-I'm Gonna Love You Too.ogg
Title18=Blondie - I'm Gonna Love You Too                                            '
Length18=-1
NumberOfEntries=18
Version=2
################################################

################################################ TEXT FROM ABOVE NOTES
#We have omitted most of the data as indicated by the ellipses (...). There is only
#one .ini style header line, [playlist], with all the otehr entries in simple key=value
#format. One unusual aspect is that key names are repeated -- but with numbers appended
#to keep them all unique. Three pieces of data are maintained for each song: the
#filename (in this example using Windows path separators), the title, and the duration
#(called "length") in seconds. In this particular example, the first song has a known
#duration, but the last entry's duration is unknown, which is signified by a negative
#number.

#The BNF we have created can handle the .pls files, and is actually generic enough to
#handle similar key-value formats too.  The BF is shown in Figure 14.5.
################################################

################################################ Figure 14.5
Figure 14.5 a BNF for the .pls file format

    PLS             ::= (LINE '\n')+ 
    LINE            ::= INI_HEADER  KEY_VALUE | COMMENT | BLANK
    INI_HEADER      ::= '[' [^]]+ ']'
    KEY_VALUE       ::= KEY \s* '=' \s* VALUE?
    KEY             ::= \w+
    VALUE           ::= .+
    COMMENT         ::= #.*
    BLANK           ::= ^$
 ###############################################

#Back to this chapter.
#Since PyParsing skips whitespaces by default, we can ignore the BNF's BLANK nonterminal
#and optional whitespace (\s*).

#We will look at the code in three parts: first, the creation of the parser itself;
#second, a helper function used by the parser; and third, the call to the parser to
#parse a .pls file. All the code is quoted from the ReadKeyValue.py module file that is
#imported by the playlists.py program.

    key_values = {}
    left_bracket, right_bracket, equals = map(Suppress , "[]=")
    ini_header = left_bracket +CharsNotIn("]") + right_bracket
    key_value = Word(alphanms) + equals + restOfLine
    key_value.setParseAction(accumulate)
    comment = "#" + restOfLine
    parser = OneOrMore  (ini_header | key_value)
    parser.ignore(comment)

#For this particular parser, instead of reading the results at the end we will
#accumulate results as we go, populating the key_values dictionary with each
#key=value we encounter.

#The left and right brackets and the equals signs are important elements of the
#grammer, but are of no interest in themselves. So for each of them we create a
#Suppress() parser element -- this will match the appropriate character, but wont
#include the character in the results. (We could have written each of them individually,
#for example, as left_bracket = Suppress("["), and so on, but using the built-in map() is
#more convenient.)

#The definition of the ini_header parser element follows quite naturally from the BNF: a
#let bracket, then any characters except a right bracket, and then a right bracket. We
#havent defined a parse actin for this parser element, so although the parser will
#match any occurrences that it encounters, nothing will be done with them, which is what
#we want.

#The key_value parser element is the one we are really interested in. This matches a "word"
# -- a sequence of alphanumeric characters, followed by an equals sign, followed by the
#rest of the line (which may be empty.) The restOfLine is a predefined parser element
#supplied by PyParsing. Since we want to accumulate results as we go we add a parse action
#(a fuction reference) to the key_value parser element -- this function will be called for 
#every key=value that is matched.

#Although PyParsing provides a predefined pythonStyleComment parser element, here we prefer
#the simpler Literal("#") followed by the rest of the line. (And thanks to PyParsing's smart
#operator overloading we were able to write the literal # as a string b/c when we concatenated
#it with another parser element to produce the comment parser element, PyParsing promoted the #
#to be a Literal().)

#The parser iteself is a parser element that matches one or more ini_header or key_value
#parser elements, and that ignores comment parser elements.

    def accumulate(tokens):
        key, value = tokens
        key = key.lower() if lowercase_keys else key
        key_values[key] = value 

#This function is called once for each key=value match. The tokens parameter is a tuple
#of the matched parser elements. In this case we would have expected the tuple to have
#the key, the equals sign, and the value, but since we used Suppress() on the equals sign
#we get only the key and the value, which is exactly what we want. The lowercase_keys
#variable is a Boolean created in an outer scope and that for .pls files is set to True.
#(Note that for eash of explanation we have shown this function after the creation of the
#parser, although in fact it must be defined before we create the parser since the parser
#refers to it.)

    try:
        parser.parseFile(file)
    except ParseException as err:
        print("parse error: {0}".format(err))
        return {}
    return key_values

#With the parser set up, we are ready to call the parseFile() method, which in this example
#takes the name of a ,pls file and attempts to parse it. If the parse fails we output a simple
#error message based on what PyParsing tells us. At the end we return the key_values dictionary
#or an empty dictionary if the parsing failed -- and we ignore the parseFile() method's return
#value since we did all our processing in the parse action.


#Reminder of topics<===========
CHAPTER 14 Introduction to Parsing 

BNF Syntax and Parsing Terminology
Writing Handcrafted Parsers 
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
Pythonic Parsing with PyParsing
    Quick Introduction to PyParsing
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
    Parsing First-Order Logic 
Lex/Yacc-Style Parsing with PLY 
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
    Parsing First-Order Logic
Summary
Exercises 
#1) 

#CODE LISTING HERE
playlist.py
    ReadKeyValue.py
    ReadM3U.py
blocks.py
    Block.py 
    BlockOutput.py
first-order-logic.py
BibTeX.py


===============
    Playlist Data Parsing 
===============

#In the previous section's second subsection we created a handcrafted regex based
#parser for .m3u files. In this subsection we will create a parser to do the same thing,
#but this time using the PyParsing module. An extract from a .m3u file is shown in Figure 14.6
#and the BNF is shown in Figure 14.7

################################################ Figure 14.6
Figure 14.6 data extract from a .m3u file

#EXTM3U
#EXTINF:230,Blondie - Atomic
Blondie\Atomic\01-Atomic.ogg
...
#EXTINF:-1,Blondie - I'm Gonna Love You Too
Blondie\Atomic\18-I'm Gonna Love You Too.ogg
################################################

################################################ TEXT FROM ABOVE NOTES
#We have omitted most of the data as indicated by the ellipss (...). The file must begin
#with the line #EXTM#U. Each entry occupies two lines. The first line of an entry starts 
#with #EXTINF: and provides the duration in seconds and the title. The second line of an
#ntry has the filename. Just like iwth .pls format, a negative duration signifies that
#the duration is unknown.

#The BNF is shown in Figure 14.7. It defines a M#U as the literal text #EXTM3U followed
#by a newline and then one or more ENTRYs. Each ENTRY consists of an INFO followed by a
#newlines then a FILENAME followed by a newline. An INFO starts with the literal text #EXTINF:
#followed by the duration specified by SECONDS, then a comma, and then the TITLE. The SECONDS
#is defined as an optional minus sign followed by one or more digites. Both the TITLE and 
#FILENAME are loosely defined as sequences of any characters except newlines.
################################################

################################################ Figure 14.7
Figure 14.6 a BNF for the .m3u format

M3U ::= '#EXTM3U\n' ENTRY+
ENTRY ::= INFO '\n' FILENAME '\n'
INFO ::= '#EXTINF:' SECONDS ',' TITLE SECONDS ::= '-'? \d+
TITLE ::= [^\n]+
FILENAME ::= [^\n]+
################################################

#Now back to chapter
#As we did when reviewing the previous subsection's .pls server, we will review the .m3u
#parser in three parts: first the creation of the parser, then the helper function, and 
#finally the call to the parser. Just as with the .pls parser, we are ignoring the parser's
#return value and instead populating our data structure as the parsing progresses. (In the
#following two subsections, we will create parsers whose return values are used.)

    songs = []
    title = restOfLine("title")
    filename = restOfLine("filename")
    seconds = Combine(Optional("-") + Word(nums)).setParseAction(lambda tokens: int(tokens[0]))("seconds")
    info = Suppress("#EXTINF:") + seconds + LineEnd()
    enty = info + LineEnd() + filename + LineEnd()
    entry.setParseAction(add_song)
    parser = Suppress("#EXTM3U") + OneOrMore(entry)

#We begin by creating an empty list that will hold the Song named tuples.

#Although the BNF is quite simple, some of the parser elements are more complex than those
#we have seen so far. Notice also that we create the parser elements in reverse order to the
#order used in the BNF. This is b/c in Python we can only refer to things that already exist, 
#so for example, we cannot create a parser element for an ENTRY before we have created one
#for an INFO since the former refers to the latter.

#The title and filename parser elements are ones that match every character from the
#parse position where they are tried until the end of the line. This means that they can
#match any charactes, including whitespace -- but not including newline which is where they
#stop. We also give these parser elements names, for example, "title" -- this allows us to
#conveniently access them by name as an attribute of the tokens object that is given to 
#parse action functions.

#The seconds parser element matches an optiona minus sign followed by digits; (nums is 
#a predefine PyParsing string that contains the digits). We ues Combine() to ensure that 
#the sign (if present) and digits are returned as a single string. (It is possible to 
#specify a seperator for Combine(), but there is no need in this case, since the default
#of an empty string is exactly what we want.) The parse action is so simple that we have
#used a lambda. The Combine() ensures that there is always precisely one token in the
#tokens tuple, and we use int() to convert this to an integer. If a parse action returns a
#value, that value becomes the value associated with the token rather than the text that was
#matched. We have also given a name to the token for convenience of access later on.

#The info parse action consits of the literal string that indicates an entry, followed by
#the seconds, followed by a comma, followed by the title -- and all this is defined very
#simply and naturally in a way that matches the BNF. Notice also that we use Suppress() for
#the literal string and for the comma since although both are essential for the grammer, they
#are of no interest to us in terms of the data itself.

#The entry parser element is very easy to define: simply an info followed by a newline, then
#a filename followed by a newline -- the LineEnd() is a predefined PyParsing parser element
#to match a newline. And since we are populating our list of songs as we parse rather than 
#at the end, we give the entry parser element a parse action that will be called whenever
#an ENTRY is matched.

#The parser itself is a parser element that matches the literal string that indicates a
#.m3u file, followed by one or more ENTRYs.

    def add_song(tokens):
        songs.append(Song(tokens.title, tokens.seconds, tokens.filename))

#The add_song() function is simple, especially since we named the parser elements we are
#interested in and are therefore able to access them as attributes of the tokens object.
#And of course, we could have written the function even more compactly by converting the
#tokens to a dictionary and using mapping unpacking -- for example, 
songs.append(Song(**tokens.asDict()))

    try:
        parser.parseFile(fh)
    except ParseException as err:
        print("parse error: {0}".format(err))
        return []
    return songs

#The code for calling ParserElement.parseFile() is almost identical to the code we used
#for the .pls parser, although in this case instead of passing a filename we opened a file
#in the text mode and passed in the io.TextIOWrapper returned by the built-in open() function
#as the fh ("file handle") variable.

#We have not finished reviewing two simple PyParsing parsers, and seen many of the most 
#commonly used parts of the PyParsing API. In the following two subsections we will look at
#more complex parsers, both of which are recursive, that is, they have nonterminals whose
#definition includes themseles, and in the final example we will also see how to handle
#operators and their precedences and associativities.

#Reminder of topics<===========
CHAPTER 14 Introduction to Parsing 

BNF Syntax and Parsing Terminology
Writing Handcrafted Parsers 
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
Pythonic Parsing with PyParsing
    Quick Introduction to PyParsing
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
    Parsing First-Order Logic 
Lex/Yacc-Style Parsing with PLY 
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
    Parsing First-Order Logic
Summary
Exercises 
#1) 

#CODE LISTING HERE
playlist.py
    ReadKeyValue.py
    ReadM3U.py
blocks.py
    Block.py 
    BlockOutput.py
first-order-logic.py
BibTeX.py


===============
    Parsing the Blocks Domain-Specific Language
===============

#In the previous section's third subsection we created a recursive descent parser for
#.blk files. In this subsection we will create a PyParsing implementation of a blocks
#parser that should be easier to understand and be more maintainable.

#Two example .blk files are shows in Figures 14.8 and 14.10. The BNF for the blocks
#format is in Figure 14.12.

################################################ Figure 14.8
Figure 14.8 The hierarchy.blk file

[] [lightblue: Director]
//
[] [lightgreen: Secretary]
//
[Minion #1] [] [Minion #2]
################################################

#Figure 14.10 shows the complete massage.box.blk file in which blocks are nested, and Figure 14.11
#shows how the messagebox.ssvg file is rendered.
################################################ Figure 14.10
Figure 14.10 The messagebox.blk file

[#00CCDE: MessageBox Window
    [lightgray: Frame
        [] [white: Message text]
        //
        [goldenrod: OK Button] [] [#ff0505: Cancel Button]
        /
        []
    ] 
]
################################################

#The BNF is shown in Figure 14.12
################################################ Figure 14.12
Figure 14.12 A BNF for the .blk format

BLOCKS ::= NODES+
NODES ::= NEW_ROW* \s* NODE+
NODE ::= '[' \s* (COLOR ':')? \s* NAME? \s* NODES* \s* ']' 
COLOR ::= '#' [\dA-Fa-f]{6} | [a-zA-Z]\w*
NAME ::= [^][/]+
NEW_ROW ::= '/'
################################################

#Back to the text
#We will look at the creation of the parser elements in two parts, then we will look at
#the helper function, and then we will see how the parser is called. And at the end we will
#see how the parser's results are transformed into a root block with child blocks (which
#themselves may contain child blocks, etc.), that is our required output.

    left_bracket, right_bracket = map(Suppress , "[]")
    new_rows = Word("/")("new_rows").setParseAction(lambda tokens: len(tokens.new_rows))
    name = CharsNotIn("[]/\n")("name").setParseAction(lambda tokens: tokens.name.strip())
    color = (Word("#"), hexnums, exact=7) | Word(alphas, alphanums))("color")
    empty_node = (left_bracket + right_bracket).setParseAction(lambda: EmptyBlock)

=================OLD CODE
    ini_header = left_bracket +CharsNotIn("]") + right_bracket
    key_value = Word(alphanms) + equals + restOfLine
    key_value.setParseAction(accumulate)
    comment = "#" + restOfLine
    parser = OneOrMore  (ini_header | key_value)
    parser.ignore(comment)
=================

#As always with PyParsing parsers, we create parser elements to match the BNF from last to
#first so that for every parser element we create that depends on one or more other parser
#elements, the elements it depends upon ALREADY exist.

#The brackest are an important part of the BNF, but are of no interest to us for the results,
#so we create suitable Suppress() parser elements for them.

#For the new_rows parser element it might be tempting to use Literal("/") -- but that must
#match the given text exactly whereas we want to match as manuy /s as are present. Having
#create the new_rows parser element, we give a name to its results and add a parsing action
#that replaces the string of one or more /s with an integer count of how many /s there were.
#Notice also that b/c we gave a name to the result, we can access the result (ie the matched
#text), by using the name as an attribute of the tokens object in the lambda.

#The name parser element is slightly different from that specified in the BFN in that we 
#have choosen to disallow not only brackets and forward slashes, but also newlines. Again,
#we give the result a name. We also set a parse action, this time to strip whitespace since
#whitespace (apart from newlines) is allows as part of a name, yet we dont want any leading
#or trailing whitespace.

#For the color parser element we have specifid that the first character must be a # followed
#by exactly six hexadecimal digits (seven characters in all), or a sequence of alphanumeric
#charactes with the first character alphabetic.

#We have chosen to handle empty nodes specially. We define an empty node as a left bracket
#followed by a right bracket, and replace the brackets with the value EmptyBlock which
#earlier in the file is defined as EmptyBlock = 0. This means that in the parser's results
#list we represent empty blocks wtih 0, and as noted earlier, we represent new rows by an 
#integer row count (which will always be >0).

    nodes = Forward()
    node_data = Optional(color + Suppress(":")) + Optional(name)
    node_data.setParseAction(add_block)
    node = left_bracket - node_data + nodes + right_bracket
    nodes << Group(ZeroOrMore(Optional(new_rows) + OneOrMore(node | empty_node)))

#We define nodes to be a Forward() parser element, since we need to use it before we
#specify what it matches. We have also introduced a new parser element that isnt in the 
#BNF, node_data, which matches the optional color and optional name. We give this parser
#element a parse action that will create a new Block, so each time a node_data is 
#encountered a Block will be added to the parser's results list.

#the node parser element is defined very naturally as a direct translation of the BNF.
#Notice that both the node_data and nodes parser elements are optional (the former
#consisting of two optional elements, the latter quantified by zero or more), so empty
#nodes are correctly allowed.

#Finally, we can define the nodes parser element. Since it was originally created as a
#Forward() we must append parser elements to it using <<.  Here we have set nodes to be
#zero or more of an optional new row and one or more nodes. Ntice that we put node before
#empty_node -- since PyParsing matches left to right we normally order parser elements that 
#have common prefixes from longest to shortest matching.

#We have also grouped the nodes parser element's results using Group() -- this ensures
#that each nodes is created as a list in its own right. This means that a node that 
#contains nodes will be represented by a Block for the node, and by a list for the 
#contained nodes -- and which in turn may contain Blocks, or integers for empty nodes or
#new rows, and so on. It is b/c of this recursive structure that we had to create nodes
#as a Forward(), and also why we must use the << operator (which in PyParsing is used
#to append), to add the Group() parser element and the elements it contains to the nodes
#element. One important but subtle point to note is that we used the - operator rather
#than the + operator in the definition fo the node parser element. We could just as easily
#have used +, since both + (ParserElement.__add__()) and - (ParserElement.__sub__()) do the
#saem job -- they return a parser element that represents the concatenation of the two
#parser elements that are the operator's operands.

#The reason we chose to use - rather than + is due to a subtle but important difference
#between them. The - operator will stop parsing and raise a ParseSyntaxError as soon as an
#error is encountered, something that the + operator doesnt do. If we had used + all errors
#would have a line number of 1 and a column of 1; but by using -, any errors have the correct
#line and correct column numbers. In general, using + is the right approach, but if our tests 
#show that we are getting incorrect error locations, then we can start to change +s into -s as
#we have done here -- and in this case only a single change was necessary.

    def add_block(tokens):
        return Block.Block(tokens.name, tokens.color if tokens.color else "white")

#Whenever a node_data is parsed instead of the text being returned and added to the parser's
#results list, we create and return a Block. We also always set the color to white unless a
#color is explicitly specified.

#In the previous examples, we parsed a file and an open file handle (an opened io.TextIOWrapper);
#here we will parse a string. It makes no difference to PyParsing whether we give it a 
#string or a file, so long as we use ParserElement.parseFile() or ParserElement.parseString()
#as appropriate. In fact, PyParsing offers other parsing methods, including
#ParserElement.scanString() which searches a string for matches, and 
#ParserElement.transformString() which returns a copy of the string it is given, but with
#matched texts transformed into new texts by returning new text from parse actions.

    stack = [Block.get_root_block()]
    try:
        results = nodes.parseString(text, parseAll=True)
        assert len(results) == 1
        items = results.asList()[0]
        populate_children(items, stack)
    except (ParseException, ParseSyntaxException) as err:
        raise ValueError("Error {{0}}: syntax error, line {0}".format(err.lineno))
    return stack[0]

#This is the first PyParsing parser where we have used the parser's results rather than
#created the data structures ourselves during the parsing process. We expect the results
#to be returned as a list containing a single ParseReults object. We convert this object
#into a standard Python list, so now we have a list containing a single item -- a list of
#our results -- which we assign to the items variable, and that we then further process
#via the populate_children() call.

#Before discussing the handling of the results, we will briefly mention the error
#handling. If the parser fails it will raise an exception. We dont want PyParsing's
#exceptions to leak out to clients since we may choose to change the parser generator
#later on. So, if an exception occurs, we catch it and then raise our own exception
#(a ValueError) with the relevant detais.

#In the case of a successfu parse of the heirarchy.blk example, the ites list looks
#like this (with occurrences of <Block.Block object at 0x8f52acd> and similar, replaced
#with Block for clarity):

    [0, Block, [], 2, 0, Block, [], 2, Block, [], 0, Block, []]

#Whenever we parsed an empty block we returned 0 to the parser's results list; whenever
#we parsed new rows we returned the number of rows; an whenever we encountered a node_data,
#we created Block to represent it. In the case of Blocks they always have an empty child
#list (ie the children attribute is set to []), since at this point we dont know if the
#block will have children or not.

#So here the outer list represents the roob block, the 0s represent the empty blocks, the
#other integers (all 2s in this case), represent new rows, and the []s are empty child 
#lists since none of the hierarchy.blk file's blocks contain other blocks.

#The messagebox.blk example's items list (pretty printed to reveal its structure, and
#again using Block for clarity) is:

    [Block,
        [Block,
            [0, Block, [], 2, Block, [], 0, Block, [], 1, 0]
        ]
    ]

#Here we can see that the outer list (representing the root block) contains a block
#that has a child list of one block that contains its own child list, and where these
#children are blocks (with their own empty child lists), new rows (2 and 1), and empty
#blocks (0s).

#One problem with the list results representation is that every Block's children list
#is empty -- each block's children are in a list that FOLLOWS the block in the parser's
#results list. We need to convert this structure into a single root block with child
#blocks. To this end we have created a stack -- a list containing a single root Block.
#We then call the populate_children() function that takes the list of items returned
#by the parser and a list with a root block, and populates the root block's children
#(and their children, and so on, as appropriate) with the items.

#The populate_children() function is quite short, but also rather subtle.

    def populate_children(items, stack):
        for item in items:
            if isinstance(item, Block.Block):
                stack[-1].children.append(item)
            elif isinstance(item, list) and item:
                stack.append(stack[-1].children[-1])
                populate_children(item, stack)
                stack.pop()
            elif isinstance(item, int):
                if item == EmptyBlock:
                    stack[-1].children.append(Block.get_empty_block())
                else:
                    for x in range(item):
                        stack[-1].children.append(Block.get_new_row())

#We iterate over every item in the results list. If the item is a Block, we append it to 
#the stack's last (top) Block's child list. (Recall that the stack is initialized with
#a single root Block item.) If the item is a nonempty list, then it is a child list that
#belongs to the previous block. So we append the previous block (ie the top Block's last
#child) to the stack to make it the top of the stack, and then recursively call
populate_children() #on the list item and the stack. This ensures that the list item (ie its
#child items) is appended to the correct item's child list. Once the recursive call is
#finished, we pop the top of the stack, ready for the next item.

#If the item is an integer, then it is either an empty block (0, ie, EmptyBlock) or a count
#of new rows. If it is an empty block, we append an empty block to the stack's top Block's
#list of children. If the item is a new row count, we append that number of new rows to the
#stacks's top Block's list of children.

#If the item is an empty list, this signifies an empty child list and we do nothing, since
#by default all Blocks are initialized to have an empty child list.

#At the end the stack's top item is still the root Block, but NOW it has children (which
#may have their own children, and so on). For the hierarchy.blk example, the
populate_children() #function produces the structure illustrated in Figure 14.13. And for
#the messagebox.blk example, the function produces the structure illustrated in Figure 14.14.

#The conversion into an SVG file using the BlockOutput.save_blocks_as_svg() function is the
#same for all block parsers, since they all produce the same root block and children
#structures.

#Reminder of topics<===========
CHAPTER 14 Introduction to Parsing 

BNF Syntax and Parsing Terminology
Writing Handcrafted Parsers 
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
Pythonic Parsing with PyParsing
    Quick Introduction to PyParsing
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
    Parsing First-Order Logic 
Lex/Yacc-Style Parsing with PLY 
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
    Parsing First-Order Logic
Summary
Exercises 
#1) 

#CODE LISTING HERE
playlist.py
    ReadKeyValue.py
    ReadM3U.py
blocks.py
    Block.py 
    BlockOutput.py
first-order-logic.py
BibTeX.py


===============
    Parsing First-Order Logic
    first-order-logic.py
===============

#In the last PyParsing subsection we will create a parser for a DSL for expressing
#formulas in first-order logic. This has the most complex BNF of all the examples in
#the chapter, and the implementation required us to handle operators, including their
#precedences and associativities, something we have NOT needed to do so far. There is no
#handcrafted version of this parser -- 
once we have reached this level of complexity it is better to use a parser generator. 
#But in addition to the PyParsing version shown here, in the following section's last
#subsection there is an equivalent PLY parser for comparison.

#Here are a few examples of the kind of first-order logical formulas taht we want to
#to be able to parse:

    a = b
    forall x: a = b
    exists y: a -> b
    ~ true | true & true -> forall x: exits y: true
    (forall x: exists y: true) -> true & ~ true -> true
    true & forall x: x = x
    true & (forall x: x = x)
    forall x: x = x & true
    (forall x: x = x) & true

#We have opted to use ASCII characters rather than the proper logical operator symbols, to
#avoid any distraction from the parser iteself. So, we have used forall for , exists for ,
#-> for  (implies), | for  (logical OR), & for ^ (logical AND), and ~ for  (logical NOT).
#Since Python strings are Unicode it would be easy to use the real symbols -- or we could
#adapt the parser to accept both the ASCII forms shown here and the real symbols.

#In the formulas shown here, the parentheses make a difference in the last two formulas
#-- so those formulas are different -- but not for the two above them (those starting with
#true), which are the same despite the parentheses. Natually, the parser must get these
#details right.

#One surprising aspect of first-order logic is that not (~) has a lower precedence than 
#equals (=), so ~ a = b is actually ~ (a=b). This is why logicians usually put a space 
#after ~.

#A BNF for our first-order logic DSL is given in Figure 14.15. For the sake of clarity,
#the BNF does not include any explicit mention of whitespaces (no \n or \s* elements), but
#we will assume that whitespace is allowed between all terminals and nonterminals.

################################################ Figure 14.15
Figure 14.15 A BNF for first-order logic

    FORMULA ::= ('forall' | 'exists') SYMBOL ':' FORMULA
            | FORMULA '->' FORMULA              # right associative
            | FORMULA '|' FORMULA               # left associative
            | FORMULA '&' FORMULA               # left associative
            | '~' FORMULA
            | '(' FORMULA ')' 
            | TERM '=' TERM
            | 'true'
            | 'false'
TERM ::= SYMBOL | SYMBOL '(' TERM_LIST ')' 
TERM_LIST ::= TERM | TERM ',' TERM_LIST
SYMBOL ::= [a-zA-Z]\w*
################################################

#Although our subset of BNF syntax has no provision for expressing precedence or
#associativity, we have added comments to indicate associativities for the binary 
#operators. As for precedence, the order is from lowest to highest in the order shown
#in the BNF for the first few alternatives; that is, forall and exists have the lowest
#precedence, then ->, then |, then &. And the remaining alternatives all have higher
#precedence than those mentioned here.

#Before looking at the parser itself, we will look at the import and the line that follows
#it since they are different than before.

    from pyparsing_py3 import (alphanums, alphas, delimitedList, Forward, Group
            Group, Keyword, Literal, opAssoc, operatorPrecedence, ParserElement,
            ParseException, ParseSyntaxException, Suppress, Word)
    ParserElement.enablePackrat()

#The import begins in some things we havnt seen before and that we will cover when
#we encounter them in the parser. The enablePackrat() call is used to switch on an
#optimization (based on memoizing) that can produce a considerable speedup when
#parsing deep operator hierarchies.*
#*Note For more on packrat parsing, wee Byran Ford's master thesis at 
pdos.csail.mit.edu/~baford/packrat/
#If we do this at all it is best to do it immediately after importing the pyparsing_py3
#module -- and before creating any parser elements.

#Although the parser is short, we will review it in three parts for ease of explanation,
#and then we will see how it is called. We dont have any parser actions since all we want
#to do is to get an AST (Abstract Syntax Tree) -- a list representing what we have parsed --
#that we can post-process later on if we wish.

    left_parenthesis, right_parenthesis, colon = map(Suppress, "():")
    forall = Keyword("forall")
    exists = Keyword("exists")
    implies = Literal("->")
    or_ = Literal("|")
    and_ = Literal("&")
    not_ = Literal("~")
    equals_ = Literal("=")
    boolean = Keyword("false") | Keyword("true")
    symbol = Word(alphas, alphanums)

#All the parser elements created here are straightforward, although we had to add
#underscores to the end of a few names to avoid conflicts with Python keywords. If 
#we wanted to give users the choice of using ASCII or the proper Unicode symbols, we
#could change some of the definitions. For example:

    forall = Keyword("forall") | Literal("")

#If we are using a non-Unicode editor we could use the appropriate escaped Unicode code
#point, such as Literal ("\u2200"), instead of the symbol.

    term = Forward()
    term << (Group(symbol + Group(left_parenthesis + delimitedList (term) + 
        right_parenthesis)) | symbol)

#A term is defined in terms of itself, which is why we begin by creating it as a
#Forward(). And rather than using a straight translation of the BNF we use one of
#PyParsing's coding pattersn. Recall that the delimitedList() function returns
#a parser element that can match a list of one or more occurrences of the given parser
#element, separated by commas (or by something else if we explicit specify the separator).
#So here we have defined the term parser element as being either a symbol followed by
#a comma-separated list of terms of a symbol -- and since both start with the same parser
#element we must put the one with the longest potential match first.

    formula = Forward()
    forall_expression = Group(forall + symbol + colon + formula)
    exists_expression = Group(exists + symbol + colon + formula)
    operand = forall_expression | exists_expression | boolean | term
    formula << operandPrecedence(operand, [
                                    (equals, 2, opAssoc.LEFT),
                                    (not_, 1, opAssoc.RIGHT),
                                    (and_, 2, opAssoc.LEFT),
                                    (or_, 2, opAssoc.LEFT),
                                    (implies, 2, opAssoc.RIGHT)])

#Although the formula looks quite complicated in the BNF, it isnt so back in PyParsing
#syntax. First we define formula as a Forward() since it is defined in terms of itself.
#The forall_expression and exists_expression parser elements are straightforward to
#define; we have just used Group() to make them sublists within the results list to keep
#their components together and at the same time distinct as a unit.

#The operatorPrecedence() function (which really ought to have been called something like
createOperators() #) creates a parser element that matches one or more unary, binary, and
#ternary operators. Before calling it, we first specify what our operands are -- in this
#case a forall_expression or an exists_expression or a boolean or a term. The
operatorPrecedence() #function takes a parser element that matches valid operands, and then
#a list of parser elements that must be treated as operators, along with their arities (how
#many operands they take), and their associativities. The resultant parser element (in this
#case, formula) will match the specified operators and their operands.

#Each operator is specified as a three- or four- item tuple. The first item is the operator's
#parser element, the second is the operator's arity as an integer (1 for a unary operator, 2 for
#a binary operator, and 3 for a ternary operator), the third is the associativity, and the
#fourth is an optional parse action.

#PyParsing infers the operators' order of preference from their relative positions in the
#list given to the operatorPrecedence() function, with the first operator having the highest
#precedence and the last the lowest, so the order of the items in the list we pass is important.
#In this example, = has the highest precedence (and has no associativity, so we have made it
#left-associative), and -> has the lowest precedence and is right-associative.

#This completes the parser, so we can now look at how it is called.

    try:
        result = formula.parseString(text, parseAll=True)
        assert len(result) == 1
        return result[0].asList()
    except (ParseException, ParseSyntaxException) as err:
        print("Syntax error:\n{0.line}\n{1}^".format(err, " " * (err.column -1)))

#This code is similar to what we used for the blocks example in the previous subsection, 
#only here we have tried to give more sophisticated error handling. In particular, if an
#error occurs we print the line that had the error and on the line below it we print spaces
#followed by a caret (^) to indicate where the error was detected. For example, if we parse
#the invalid formula, 
    forall x: = x&true
#we wil get:
    Syntax error:
    forall x: = x & true
           ^
#In this case, the error location is slightly off -- the error is that = x should have 
#the form y = x, but is it still pretty good.

#In the case of a successful parse we get a list of ParseReults which has a single result --
#as before we convert this to a Python list.

#Earier we say some example formulas; now we will look at some of them again, this time with
#the result lists produced by the parser, pretty printed to help reveal their structure.

#We mentioned before that the ~ operator has a lower precedence than the = operator -- so
#lets see if this is handled correctly by the parser.

        # ~true -> ~b = c            |      # ~true -> ~(b = c) [[
        [                            |      [
            ['~', 'true'],           |          ['~', 'true'],
            '->',                    |          ['~',
            '->',                    |          ['~',
                ['b', '=', 'c']      |              ['b', '=', 'c'] 
            ]                        |          ]
        ]                            |      ]           

#Here we get exactly the same results for both formulas, which demonstrates that = has
#higher precedence than ~. Of course, we would need to write several more test formulas
#to check all the cases, but this at least looks promising.

#Two of the formulas that we saw earlier were forall x: x=x & true 
#and (forall x: x = x) & true, and we pointed out that although the only difference between
#them is the parentheses, this is sufficient to make them different formulas. Here are the 
#lists the parser produces for them:

        # forall x: x = x & true       |        # forall x: x = x & true
        [                              |        [
            'forall', 'x',             |            [
                [                      |                'forall', 'x',
                    ['x', '=', 'x'],   |                    ['x', '=', 'x'],
                    '&',               |            ],
                    'true'             |            '&',
                [                      |            'true'
        ]                              |        ]

#The parser is clearly able to distinguish between these two formulas, and create quite
#different parse trees (nested lists). Without the parentheses, forall's formula is 
#everything right of the colon, but with the parentheses, forall's scope is limited to
#within the parentheses.

#But what about the two formulas that again are different only in that one has 
#parentheses, but where the parentheses dont matter, so that the formulas are actually
#the same? These two formulas are 
true & forall x: x = x      #and
true & (forall x: x = x)    #and fortuneatly, when parsed they both produce exactly the
#same list:

    [
        'true',
        '&',
        [
            'forall', 'x',
                ['x', '=', 'x']
        ]
    ]

#The parentheses dont matter here b/c only one valid parse is possible.

#We have now completed the 
PyParsing first-order logic parser#, and in fact, all of the
#book's PyParsing examples. If PyParsing is of interest, the PyParsing web site
pyparsing.wikispaces.com #has many other examples and extensive documentation, and there
#is also an active Wiki and mailing list.

#In the next section, we will look at the same examples as we covered in this section, but
#this time using the PLY parser which works in a very different way from PyParsing.







#CODE LISTING HERE
playlist.py
    ReadKeyValue.py
    ReadM3U.py
blocks.py
    Block.py 
    BlockOutput.py
first-order-logic.py
BibTeX.py



#CODE HERE
first-order-logic.py

#!/usr/bin/env python3

"""
BNF

    FORMULA     ::= ('forall' | 'exists') SYMBOL ':' FORMULA
                 |  FORMULA '->' FORMULA      # right associative
                 |  FORMULA '|' FORMULA       # left associative
                 |  FORMULA '&' FORMULA       # left associative
                 |  '~' FORMULA
                 |  '(' FORMULA ')'
                 |  TERM '=' TERM
                 |  'true'
                 |  'false'
    TERM        ::= SYMBOL | SYMBOL '(' TERM_LIST ')'
    TERM_LIST   ::= TERM | TERM ',' TERM_LIST
    SYMBOL      ::= [a-zA-Z]\w*
"""

import ply.lex
import ply.yacc
try:
    from pyparsing import (alphanums, alphas, delimitedList, Forward, Group, Keyword
        Literal, opAssoc, operatorPrecedence, ParserElement, ParseException
        ParseSyntaxException, Suppress, Word)
except ImportError:
    from pyparsing_py3 import (alphanums, alphas, delimitedList, Forward, Group, Keyword
        Literal, opAssoc, operatorPrecedence, ParserElement, ParseException,
        ParseSyntaxException, Suppress, Word)
ParserElement.enablePackrat()

def pyparsing_parse(text):
    """
    >>> formula = "a = b"
    >>> print(pyparsing_parse(formula))
    ['a', '=', 'b']
    >>> formula = "forall x: a = b"
    >>> print(pyparsing_parse(formula))
    ['forall', 'x', ['a', '=', 'b']]
    >>> formula = "a & b"
    >>> print(pyparsing_parse(formula))
    ['a', '&', 'b']
    >>> formula = "~true -> ~b = c"
    >>> print(pyparsing_parse(formula))
    [['~', 'true'], '->', ['~', ['b', '=', 'c']]]
    >>> formula = "~true -> ~(b = c)"
    >>> print(pyparsing_parse(formula))
    [['~', 'true'], '->', ['~', ['b', '=', 'c']]]
    >>> formula = "exists y: a -> b"
    >>> print(pyparsing_parse(formula))
    ['exists', 'y', ['a', '->', 'b']]
    >>> formula = "forall x: exists y: a = b"
    >>> print(pyparsing_parse(formula))
    ['forall', 'x', ['exists', 'y', ['a', '=', 'b']]]
    >>> formula = "forall x: exists y: a = b -> a = b & ~ a = b -> a = b"
    >>> print(pyparsing_parse(formula))
    ['forall', 'x', ['exists', 'y', [['a', '=', 'b'], '->', [[['a', '=', 'b'], '&', ['~', ['a', '=', 'b']]], '->', ['a', '=', 'b']]]]]
    >>> formula = "(forall x: exists y: a = b) -> a = b & ~ a = b -> a = b"
    >>> print(pyparsing_parse(formula))
    [['forall', 'x', ['exists', 'y', ['a', '=', 'b']]], '->', [[['a', '=', 'b'], '&', ['~', ['a', '=', 'b']]], '->', ['a', '=', 'b']]]
    >>> formula = "(forall x: exists y: true) -> true & ~ true -> true"
    >>> print(pyparsing_parse(formula))
    [['forall', 'x', ['exists', 'y', 'true']], '->', [['true', '&', ['~', 'true']], '->', 'true']]
    >>> formula = "a = b -> c = d & e = f"
    >>> result1 = pyparsing_parse(formula)
    >>> formula = "(a = b) -> (c = d & e = f)"
    >>> result2 = pyparsing_parse(formula)
    >>> result1 == result2
    True
    >>> result1
    [['a', '=', 'b'], '->', [['c', '=', 'd'], '&', ['e', '=', 'f']]]
    >>> formula = "forall x: exists y: true -> true & true | ~ true"
    >>> print(pyparsing_parse(formula))
    ['forall', 'x', ['exists', 'y', ['true', '->', [['true', '&', 'true'], '|', ['~', 'true']]]]]
    >>> formula = "~ true | true & true -> forall x: exists y: true"
    >>> print(pyparsing_parse(formula))
    [[['~', 'true'], '|', ['true', '&', 'true']], '->', ['forall', 'x', ['exists', 'y', 'true']]]
    >>> formula = "true & forall x: x = x"
    >>> print(pyparsing_parse(formula))
    ['true', '&', ['forall', 'x', ['x', '=', 'x']]]
    >>> formula = "true & (forall x: x = x)" # same as previous
    >>> print(pyparsing_parse(formula))
    ['true', '&', ['forall', 'x', ['x', '=', 'x']]]
    >>> formula = "forall x: x = x & true"
    >>> print(pyparsing_parse(formula))
    ['forall', 'x', [['x', '=', 'x'], '&', 'true']]
    >>> formula = "(forall x: x = x) & true" # different to previous
    >>> print(pyparsing_parse(formula))
    [['forall', 'x', ['x', '=', 'x']], '&', 'true']
    >>> formula = "forall x: = x & true"
    >>> print(pyparsing_parse(formula))
    Syntax error:
    forall x: = x & true
           ^
    []
    """
    left_parenthesis, right_parenthesis, colon = map(Suppress, "():")
    forall = Keyword("forall")
    exists = Keyword("exists")
    implies = Literal("->")
    or_ = Literal("|")
    and_ = Literal("&")
    not_ = Literal("~")
    equals = Literal("=")
    boolean = Keyword("false") | Keyword("true")
    symbol = Word(alphas, alphanums)
    term = Forward()
    term << (Group(symbol + Group(left_parenthesis + delimitedList(term) + right_parenthesis)) | symbol)
    formula = Forward()
    forall_expression = Group(forall + symbol + colon + formula)
    exists_expression = Group(exists + symbol + colon + formula)
    operand = forall_expression | exists_expression | boolean | term 
    formula << operatorPrecedence(operand, [
                                    (equals, 2, opAssoc.LEFT),
                                    (not_, 1, opAssoc.RIGHT),
                                    (and_, 2, opAssoc.LEFT),
                                    (or_, 2, opAssoc.LEFT),
                                    (implies, 2, opAssoc.RIGHT)])
    try:
        result = formula.parseString(text, parseAll=True)
        assert len(result) == 1
        return result[0].asList()
    except (ParseException, ParseSyntaxException) as err:
        print("Syntax error:\n{0.line}\n{1}^".format(err, " " * (err.column - 1)))
        return []


def ply_parse(text):
    """
    >>> formula = "a = b"
    >>> print(ply_parse(formula))
    ['a', '=', 'b']
    >>> formula = "forall x: a = b"
    >>> print(ply_parse(formula))
    ['forall', 'x', ['a', '=', 'b']]
    >>> formula = "a & b"
    >>> print(ply_parse(formula))
    ['a', '&', 'b']
    >>> formula = "~true -> ~b = c"
    >>> print(ply_parse(formula))
    [['~', 'true'], '->', ['~', ['b', '=', 'c']]]
    >>> formula = "~true -> ~(b = c)"
    >>> print(ply_parse(formula))
    [['~', 'true'], '->', ['~', ['b', '=', 'c']]]
    >>> formula = "exists y: a -> b"
    >>> print(ply_parse(formula))
    ['exists', 'y', ['a', '->', 'b']]
    >>> formula = "forall x: exists y: a = b"
    >>> print(ply_parse(formula))
    ['forall', 'x', ['exists', 'y', ['a', '=', 'b']]]
    >>> formula = "forall x: exists y: a = b -> a = b & ~ a = b -> a = b"
    >>> print(ply_parse(formula))
    ['forall', 'x', ['exists', 'y', [['a', '=', 'b'], '->', [[['a', '=', 'b'], '&', ['~', ['a', '=', 'b']]], '->', ['a', '=', 'b']]]]]
    >>> formula = "(forall x: exists y: a = b) -> a = b & ~ a = b -> a = b"
    >>> print(ply_parse(formula))
    [['forall', 'x', ['exists', 'y', ['a', '=', 'b']]], '->', [[['a', '=', 'b'], '&', ['~', ['a', '=', 'b']]], '->', ['a', '=', 'b']]]
    >>> formula = "(forall x: exists y: true) -> true & ~ true -> true"
    >>> print(ply_parse(formula))
    [['forall', 'x', ['exists', 'y', 'true']], '->', [['true', '&', ['~', 'true']], '->', 'true']]
    >>> formula = "a = b -> c = d & e = f"
    >>> result1 = ply_parse(formula)
    >>> formula = "(a = b) -> (c = d & e = f)"
    >>> result2 = ply_parse(formula)
    >>> result1 == result2
    True
    >>> result1
    [['a', '=', 'b'], '->', [['c', '=', 'd'], '&', ['e', '=', 'f']]]
    >>> formula = "forall x: exists y: true -> true & true | ~ true"
    >>> print(ply_parse(formula))
    ['forall', 'x', ['exists', 'y', ['true', '->', [['true', '&', 'true'], '|', ['~', 'true']]]]]
    >>> formula = "~ true | true & true -> forall x: exists y: true"
    >>> print(ply_parse(formula))
    [[['~', 'true'], '|', ['true', '&', 'true']], '->', ['forall', 'x', ['exists', 'y', 'true']]]
    >>> formula = "true & forall x: x = x"
    >>> print(ply_parse(formula))
    ['true', '&', ['forall', 'x', ['x', '=', 'x']]]
    >>> formula = "true & (forall x: x = x)" # same as previous
    >>> print(ply_parse(formula))
    ['true', '&', ['forall', 'x', ['x', '=', 'x']]]
    >>> formula = "forall x: x = x & true"
    >>> print(ply_parse(formula))
    ['forall', 'x', [['x', '=', 'x'], '&', 'true']]
    >>> formula = "(forall x: x = x) & true" # different to previous
    >>> print(ply_parse(formula))
    [['forall', 'x', ['x', '=', 'x']], '&', 'true']
    >>> formula = "forall x: = x & true"
    >>> print(ply_parse(formula))
    Syntax error, line 2: EQUALS
    []
    """
    keywords = {"exists": "EXISTS", "forall": "FORALL", "true": "TRUE", "false": "FALSE",
                 "true": "TRUE", "false":  "FALSE"}
    tokens = (["SYMBOL", "COLON", "COMMA", "LPAREN", "RPAREN", "EQUALS", "NOT", "AND", 
        "OR", "IMPLIES"] + list(keywords.values()))

    def t_SYMBOL(t):
        r"[a-zA-Z]\w*"
        r.type = keywords.get(t.value, "SYMBOL")
        return t

    t_EQUALS = r"="
    t_NOT = r"~"
    t_AND = r"&"
    t_OR = r"\|"
    t_IMPLIES = r"->"
    t_COLON = r":"
    t_COMMA = r","
    t_LPAREN = r"\("
    t_RPAREN = r"\)"

    t_ignore = " \t\n"

    def t_newline(t):
        t"\n"
        t.lexer.lineno += len(t.value)

    def t_error(t):
        line = t.value.lstrip()
        i = line.find("\n")
        line = line if i ++ -1 else line[:i]
        raise ValueError("Syntax error, line {0}: {1}".format(t.lineno + 1, line))

    def p_formula_quantifier(p):
        """FORMULA : FORALL SYMBOL COLON FORMULA
                   | EXISTS SYMBOL COLON FORMULA"""
        p[0] = [p[1], p[2], p[4]]

    def p_formula_binary(p):
        """FORMULA : FORMULA IMPLIES FORMULA
                   | FORMULA OR FORMULA
                   | FORMULA AND FORMULA"""
        p[0] = [p[1], p[2], p[3]]

    def p_formula_not(p):
        "FORMULA : NOT FORMULA"
        p[0] = [p[1], p[2]]

    def p_formula_boolean(p):
        """FORMULA : FALSE
                   | TRUE"""
        p[0] = p[1]

    def p_formula_group(p):
        "FORMULA : LPAREN FORMULA RPAREN"
        p[0] = p[2]

    def p_formula_symbol(p):
        "FORMULA : SYMBOL"
        p[0] = p[1]

    def p_formula_equals(p):
        "FORMULA : TERM EQUALS TERM"
        p[0] = [p[1], p[2], p[3]]

    def p_term(p):
        """TERM : SYMBOL LPAREN TERMLIST RPAREN
                | SYMBOL"""
        p[0] = p[1] if len(p) == 2 else [p[1], p[3]]

    def p_termlist(p):
        """TERMLIST : TERM COMMA TERMLIST
                    | TERM"""
        
        p[0] = p[1] if len(p) == 2 else [p[1], p[3]]

    def p_error(p):
        if p is None:
            raise ValueError("Unknown error")
        raise ValueError("Syntax error, line {0}: {1}".format(p.lineno + 1, p.type))

# from lowest to highest precedence
    precedence = (("nonassoc", "FORALL", "EXISTS"),
                  ("right", "IMPLIES"),
                  ("left", "OR"),
                  ("left", "AND"),
                  ("right", "NOT"),
                  ("nonassoc", "EQUALS"))

    lexer = ply.lex.lex()
    parser = ply.yacc.yacc()
    try:
        return parser.parse(text, lexer=lexer)
    except ValueError as err:
        print(err)
        return []


if __name__ == "__main__":
    import doctest
    doctest.testmod()




#Reminder of topics<===========
CHAPTER 14 Introduction to Parsing 

BNF Syntax and Parsing Terminology
Writing Handcrafted Parsers 
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
Pythonic Parsing with PyParsing
    Quick Introduction to PyParsing
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
    Parsing First-Order Logic 
Lex/Yacc-Style Parsing with PLY 
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
    Parsing First-Order Logic
Summary
Exercises 
#1) 

#CODE LISTING HERE
playlist.py
    ReadKeyValue.py
    ReadM3U.py
blocks.py
    Block.py 
    BlockOutput.py
first-order-logic.py
BibTeX.py


===============
Lex/Yacc-Style Parsing with PLY
===============

#PLY (Python Lex Yacc) is a pure Python implementation of the classic Unix tools, lex
# and yacc. Lex is a tool that creates lexers, and yacc is a tool that creates parsers
#-- often using a lexer created by lex. PLY is described by its author, David Beazley, 
#as "reasonably efficient and well suited for larger grammers. It provides most of the
#standard lex/yacc features including support for empty productions, precedence rules,
#error recovery, and support for ambiguous grammers. PLY is straightforward to use
#and provides very extensive error checking."

#PLY is available under the LGPL open source licenese and so can be used in most contexts.
#Like PyParsing, PLY is not included in Python's standard library, so it must be downloaded
#and installed separately -- although for Linux users it is almost certainly available
#through the package management system. And from PLY version 3.0, the same PLY modules
#work with both Python 2.0 and 3.

#If it is necessary to obtain and install PLY manually, it is avaiable as a tarball from
www.dabeaz.com/ply. #On Unix-like systems such as Linux and Mac OS X, the tarball can be
#unpacked by executing 
tar xvfz ply-3.2.tar.gz #in a console. (exact PLY version may be different). Windows users
#can use the untar.py example program that comes with the book's examples. For instance,
#assuming the book's examples are located in C:\py3eg, the command to execute in the 
#console is C:\Python31\python.exe C:\py3eg\untar.py ply-3.2.tar.gz

#Once the tarball is unpacked, change directory to PLY's directory -- this directory 
#should contain a file called setup.py and a subdirectory called ply. PLY can be
#installed automatically or manually. To do it automatically, in the console execute
#python setup.py install, or on Windows execute C:\Python31\python.exe setup.py install
#Alternatively, just copy or more the ply directory and its contents to Python's
#site-packages directory (or to your local site-packages directory). Once installed, PLY's
#modules are available as ply.lex and ply.yacc.

#PLY makes a clear distinction between lexing (tokenizing) and parsing. And in fact, PLY's
#lexer is so powerful that it is sufficient on its own to handle all the examples shown
#in this chapter except for the first-order logic parser for which we use both the ply.lex
#and ply.yacc modules.

#When we discussed the PyParsing module we began by first reviewing various PyParsing
#specific concepts, and in particular how to convert certain BNF constructs into PyParsing
#syntax. This isnt necesssary with PLY since it is designed to work directly with regexes
#and BNFs, so rather than give any conceptual overview, we will summarize a few key PLY
#conventions and then dive straight into the examples and explain the details as we go along.

#PLY makes extensive use of nameing conventions and introspection, so it is important to be
#aware of these when we create lexers and parsers using PLY.

#Every PLY lexer and parser depends on a variable called tokens. This variable must hold
#a tuple or lst of token names -- they are usually uppercase strings corresponding to
#nonterminals in the BN. Every token must have a corresponding variable or function whose
#name is of the form t_TOEKN_NAME. If a variable is defined it must be set to a string
#containing a regex -- so normally a raw string is used for convenience; if a function
#is defined it must have docstring that contains a regex, again usually a raw string. In
#either case the regex specifies a pattern that matches the corresponding token.

#One name that is specialy to PLY is t_error(); if a lexing error occurs and a function 
#with this name is defined, it will be called.

#If we want the lexer to match a token but discard it from the results (eg a comment in
#a programming language), we can do this in one of two ways. If we are using a variable
#then we make its name t_ignroe_TOKEN_NAME; if we are using a function then we use the
#normal nae t_TOKEN_NAME, but ensure that it returns None.

#The PLY parser follows a similar convention to the lexer in that for each BNF rule we
#create a function with the prefix p_, and whose docstring contains the BNF rule we are 
#mathcing (only with ::= replaced with :). Whenver a rule matches its corresponding function
#is caled with a parameter (called p, following the PLY documentation's examples); this
#parameter can be indexed with p[0] corresponding to the nonterminal that the rule defines,
#and p[1] and so on, corresponding to the parts on the right-hand side of the BNF.

#Precedence and associativity can be set by creating a variable called precedence and giving
#it a tuple of tuples -- in precedence order -- that indicate the tokens' associativities.

#Similarly to the lexer, if there is a parsing error and we have created a function
#called p_error(), it will be called.

#We will make use of all the conventions described here, and more, when we review the
#examples.

#To avoid duplicating information from earlier in the chapter, the examples and explanations
#given here focus purely on parsing with PLY. It is assumed that you are familiar with the
#formats to be parsed and their contexts of use. This means that either you have read at 
#least this chpater's second section and the first-order logic parser from the third section's
#last subsection, or that you skip back using the backreferences provided when necessary.


#Reminder of topics<===========
CHAPTER 14 Introduction to Parsing 

BNF Syntax and Parsing Terminology
Writing Handcrafted Parsers 
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
Pythonic Parsing with PyParsing
    Quick Introduction to PyParsing
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
    Parsing First-Order Logic 
Lex/Yacc-Style Parsing with PLY 
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
    Parsing First-Order Logic
Summary
Exercises 
#1) 

#CODE LISTING HERE
playlist.py
    ReadKeyValue.py
    ReadM3U.py
blocks.py
    Block.py 
    BlockOutput.py
first-order-logic.py
BibTeX.py


===============
    Simple Key-Value Data Parsing
===============

#PLY's lexer is sufficient to handle the key-value data held in .pls files. Every PLY
#lexer (and parser) has a list of token which must be stored in the tokens variable.
#PLY makes extensive use of introspection, so the names of variables and functions,
#and even the contents of docstrings, must follow PLY's conventions. Here are the tokens
#and their regexes and functions for the PLY .pls parser:

    tokens = ("INI_HEADER", "COMMENT", "KEY", "VALUE")              #Tokens

    t_ignore_INI_HEADER = r"\[[^]]+\]"                              #Regexes for tokens
    t_ignore_COMMENT = r"\#.*"

    def t_KEY(t):                                                   #Functions foir PLY
        r"\w+"
        if lowercase_keys:
            t.value = t.value.lower()
        return t

    def t_VALUE(t):
        r"=.*"
        t.value = t.value[1:].strip()
        return t

#Both the INI_HEADER and COMMENT tokens' matchers are simple regexes, and since both
#use the t_ignore_ prefix, both will be correctly matched -- and then discarded. An
#alternative approach to ignoring matches is to define a function that just uses the
#t_prefix (eg t_COMMENT()), and that has a suite of pass (or return None), since if the
#return value is None then the token is discarded.

#For the KEY and VALUE tokens, we have used functions rather then regexes. In such cases,
#the regex to match MUST be specified in the function's docstring -- and here the docstrings
#are raw strings since that is our practice for regexes, and it means we dont have to
#escape backslashes. When a function is used th token is passed as token object t (following
#the PLY examples' naming conventions) of type ply.lex.LexToken. The matched text is held in
#the ply.lex.LexToken.value attribute, and we are permitted to change this if we wish. We
#must always return t from the function if we want the token included in the results.

#In the case of the t_KEY() function, we lowercase the matching key if the lowercase_keys
#variable (from an outer scope) is True. And for the t_VALUE() function, we strip off 
#the = and any leading or trailing whitespace.

#In addition to our own custom tokens, it is conventional to define a couple of PLY specific
#functions to provide error reporting:

    def t_newline(t):
        r"\n+"
        r.lexer.lineo += len(t.value)

    def t_error(t):
        line = t.value.lstrip()
        i = line.find("\n")
        line = line if i == -1 else line[:i]
        print("Failed to parse line {0}: {1}".format(t.lineo + 1, line))

#The token's lexer attribute (of type ply.lex.Lexer) provides access to the lexer itself.
#Here we have updated the lexer's lineo attribute by the number of newlines that have 
#been matched.

#Notice that we dont have to specifically account for blank lines since the t_newline()
#matching function effectively does that for us.

#If an error occurs the t_error() function is called. We print an error message and at 
#most one line of the input. We add 1 to the line number since PLY's lexer.lineo
#attribute starts counting from 0.

#With all the token definitions in place we are ready to lex some data and create a 
#corresponding key-value dictionary.

    key_values = {}
    lexer = ply.lex.lex()
    lexer.input(file.read())
    key = None
    for token in lexer:
        if token.type == "KEY":
            key = token.value
        elif token.type == "VALUE":
            if key is None:
                print("Failed to parse: value '{0}' without key".format(token.value))
            else:
                key_values[key] = token.value
                key = None

#The lexer reads the entire input text and can be used as an iterator that produces
#one token at each iteratior. The token.type attribute holds the name of the current
#token -- this is one of the names from the tokens list -- and the token.value holds
#the mathced text -- or whatever we replaced it with.

#For each token, if the token is a KEY we hold it and wait for its value, and if it
#is a VALUE we add it using the current key to the key_values dictionary. At the end
#(not shown), we return the dictionary to the called just as we did with the 
#playliss.py .pls regex and PyParsing parsers.


#Reminder of topics<===========
CHAPTER 14 Introduction to Parsing 

BNF Syntax and Parsing Terminology
Writing Handcrafted Parsers 
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
Pythonic Parsing with PyParsing
    Quick Introduction to PyParsing
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
    Parsing First-Order Logic 
Lex/Yacc-Style Parsing with PLY 
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
    Parsing First-Order Logic
Summary
Exercises 
#1) 


#CODE LISTING HERE
playlist.py
    ReadKeyValue.py
    ReadM3U.py
blocks.py
    Block.py 
    BlockOutput.py
first-order-logic.py
BibTeX.py


===============
    Playlist Data Parsing
===============

#In this subsection, we will develop a PLY parser for the .m3u format. And just as we did
#in the previous implementation, the parser will return its results in the form of a list
#of Song (collections.namedtuple()) objects, each of which holds a title, a duration in 
#seconds, and a filename.

#Since the format is so simple, PLY's lexer is sufficient to do all the parsing. As before
#we will create a list of tokens, each one corresponding to a nonterminal in the BNF:

    tokens = ("M3U", "INFO", "SECONDS", "TITLE", "FILENAME")

#We have not got an ENTRY token -- this nonterminal is made up of a SECONDS and a TITLE.
#Instead we define two states, called entry and filename. When the lexer is in the entry
#state, we will try to read the SECONDS and the TITLE, that is, an ENTRY, and when the 
#lexer is in the filename state we will try to read the FILENAME. 
To make PLY understand states we must create a states variable that is set to a list of
one or more 2-tuples. #The first item in each of the tuples is a state name and the
#second item is the state's type, either inclusive (ie this state is in addition to
#the current state) or exclusive (ie this state is the only active state). PLY predefines
#the INITIAL state which all lexers start in. Here is the definition of the states variable
#for the PLY .m3u parser:

    states = (("entry", "exclusive"), ("filename", "exclusive"))

#Now that we have defined our tokens and our states we can define the regexes and
#functions to match the BNF.

    t_M3U = r"\#EXTM3U"

    def t_INFO(t):
        r"\#EXTINF"
        t.lexer.begin("entry")
        return None

    def t_entry_SECONDS(t):
        r"-?\d+"
        t.value = int(t.value[:-1])
        return t

    def t_entry_TITLE(t):
        r"[^\n]+"
        t.lexer.begin("filename")
        return t

    def t_filename_FILENAME(t):
        r"[^\n]+"
        t.lexer.begin("INITIAL")
        return t

#By default, the tokens, regexes, and functions operate in the INITIAL state. However, 
#we can specify that they are active in only one particular state by embedding the state's
#name after the t_prefix. So in this case the t_M3U regex and the t_INFO() function will
#match only the INITIAL state, the t_entry_SECONDS() and t_entry_TITLE() functions will
#match only in the entry state, and the t_filename_FILENAME() function will match only in
#the filename state.

#The lexer's state is changed by calling the lexer object's begin() method with the new
#state's name as its argument. SO in this example, when we match the INFO token we 
#switch to the entry state; now only the SECONDS and TITLE tokens can match. Once we
#have matched a TITLE we switch to the filename state, and once we have matched a FILENAME
#we switch back to the INITIAL state ready to match the next INFO token.

#Notice that in the case of the t_INFO function we return None; this means that the token
#will be discarded, which is correct since although we must match #EXTINF: for each entry,
#we dont need that text. For the t_entry_SECONDS() function, we strip off the trailing
#commas and replace the token's value with the interger number of seconds.

#In this parser we want to ignore spurious whitespace that may occur between tokens, and 
#we want to do so regardless of the state the lexer is in. This can be achieved by
#creating a t_ignore variable, and by giving it a state of ANY which means it is active
#in any state:

    t_ANY_ignore = " \t\n"

#This will ensure that any whitespace between tokens is safely and conveniently ignored.

#We have also defined two functions, t_ANY_newline() and t_ANY_error(); these have
#exactly the same bodies as the t_newline() and t_error() functions defined in the
#previous subsection -- so neither are shown here -- but include the state of ANY in
#their names so that they are active no matter what state the lexer is in.

    songs = []
    title = seconds = None
    lexer = pl.lex.lex()
    lexer.input(fh.read())
    for token in lexer:
        if token.type == "SECONDS":
            seconds = token.value
        elif token.type == "TITLE":
            title = token.value 
        elif token.type == "FILENAME":
            if title is not None and seconds is not None:
                songs.append(Song(title, seconds, token.value))
                title = seconds = None 
            else:
                print("Failed, filename '{0}' without title/duration".format(token.value))

#We use the lexer in the same way as did for the .pls lexer, iterating over the tokens,
#accumulating values (for the seconds and title), and whenever we get a filename to go with
#the seconds and title, adding a new song to the song list. As before, at the end (not shown),
#we return the key_values dictionary to the caller.


#Reminder of topics<===========
CHAPTER 14 Introduction to Parsing 

BNF Syntax and Parsing Terminology
Writing Handcrafted Parsers 
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
Pythonic Parsing with PyParsing
    Quick Introduction to PyParsing
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
    Parsing First-Order Logic 
Lex/Yacc-Style Parsing with PLY 
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
    Parsing First-Order Logic
Summary
Exercises 
#1) 

#CODE LISTING HERE
playlist.py
    ReadKeyValue.py
    ReadM3U.py
blocks.py
    Block.py 
    BlockOutput.py
first-order-logic.py
BibTeX.py


===============
    Parsing the Blocks Domain-Specific Language
===============

#The blocks format is more sophisticated than the key-value based .pls format
#or the .m3u format since it allows blocks to be nested inside each other. This
#presents no problems to PLY, and in fact the definitions of the tokens can be
#done wholly using regexes without requiring any functions or states at all.

    tokens = ("NODE_START", "NODE_END", "COLOR", "NAME", "NEW_ROWS", "EMPTY_NODE")

    t_NODE_START = r"\["
    t_NODE_END = r"\]"
    t_COLOR = r"(?:\#[\dA-Fa-f]{6}|[a-zA-Z]\w*)"
    t_NAME = r"[^][/\n]+"
    t_NEW_ROWS = r"/+"
    t_EMPTY_NODE = "\[\]"

#The regexes are taken directly from the BNF, except that we have chosen to
#disallow newlines in names. In addition, we have defined a t_ignore regex to
#skip spaces and tabs, and t_newline() and t_error() functions that are the same
#as before except that t_error() raises a custom LexError with ite error message
#rather than printing the error message.

#With the tokens set up, we are ready to prepare for lexing and then to do the lexing.

    stack = [Block.get_root_block()]
    block = None
    brackets = 0
    lexer = ply.lex.lex()
    try:
        lexer.input(text)
        for token in lexer:
#As with the previous blocks parsers we begin by creating a stack (a list) with an 
#empty root Block. This will be populated with child blocks (and the child blocks with 
#child blocks, etc) to reflect the blocks that are parsed; at the end we will return the
#root block with all its children. The block variable is used to hold a reference to the 
#block that is currently being parsed so that it can be updated as we go. We also keep a
#count of the brackets purely to improve the error reporting.

#One difference from before is that we do the lexing and the parsing of the tokens inside
#a try...except suite -- this is so that we can catch any LexError exceptions and convert
#them to ValueErrors.
            if token.type == "NODE_START":
                brackets += 1
                block = Block.get_empty_block()
                stack[-1].children.append(block)
                stack.append(block)
            elif token.type == "NODE_END":
                brackets -= 1
                if brackets < 0:
                    raise LexError("too many ']'s")
                    block = None
                    stack.pop()
#Whenever we start a new node, we increment the brackets count and create a new empty block.
#This block is added as the last child of the stack's top block's list of children and is 
#itself pushed onto the stack. If the block has a color or name we will be able to set it b/c
#we keep a reference to the block in the block variable.

#The logic used here is slightly different from the logic used in the recursive descent parser
#-- there we pushed new blocks onto the stack ONLY IF we knew that they had nested blocks. Here
#we ALWAYS push new blocks onto the stack, safe in the knowledge that they will be popped
#straight off again if they dont contain any nested blocks. This also makes the code simplier
#and more regular.

#When we reach the end of a block we decrement the brackets count -- and if it is negative we
#know that we have had too many close brackets and can report the error immediately. Otherwise,
#we set block to None since we now have no current block and pop the top of the stack (which)
#should never be empty).

            elif token.type == "COLOR":
                if block is None or Block.is_new_row(block):
                    raise LexError("syntax error")
                block.color = token.value[:-1]
            elif token.type == "NAME":
                if block is None or Block.is_new_row(block):
                    raise LexError("syntax error")
                block.name = token.value

#If we get a color or a name, we set the corresponding attribute of the current block 
#which should refer to a Block rather than being None or denoting a new row.

            elif token.type == "EMPTY_NODE":
                stack[-1].children.append(Block.get_empty_block())
            elif token.type == "NEW_ROWS":
                for x in range(len(token.value)):
                    stack[-1].children.append(Block.get_new_row())

#If we get an empty node or one or more new rows, we add them as the last child of the
#stack's top block list of children.

        if brackets:
            raise LexError("unbalanced brackets []")
    except LexError as err:
        raise ValueError("Error {{0}}:line {0}: {1}".format(token.lineno +1, err))

#Once lexing has finished we check that the brackets have balanced, and if not we raise
#a LexError. If a LexError occurred during lexing, parsing, or when we checked the brackets,
#we raise a ValueError that contains an escapted str.format() field name -- the caller is
#expected to use this to insert the filename, something we cannot do here b/c we are given
#only the file's text, not the filename or file object.

#At the end (not shown), we return stack[0]; this is the root Block that should now have
#children (and which in turn might have children), representing the .blk file we have 
#parsed. This block is suitable for passing to the BlockOutput.save_blocks_as_svg() function,
#just as we did with the recursive descent and PyParsing blocks parsers.


#Reminder of topics<===========
CHAPTER 14 Introduction to Parsing 

BNF Syntax and Parsing Terminology
Writing Handcrafted Parsers 
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
Pythonic Parsing with PyParsing
    Quick Introduction to PyParsing
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
    Parsing First-Order Logic 
Lex/Yacc-Style Parsing with PLY 
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
    Parsing First-Order Logic
Summary
Exercises 
#1) 

#CODE LISTING HERE
playlist.py
    ReadKeyValue.py
    ReadM3U.py
blocks.py
    Block.py 
    BlockOutput.py
first-order-logic.py
BibTeX.py


===============
    Parsing First-Order Logic
===============

#In the last PyParsing subsection we created a parser for first-order logic. In this
#subsection we will create a PLY version that is designed to produce identical output
#to the PyParsing version.

#Setting up the lexer is very similar to what we did earlier. The only novel aspect is that
#we keep a dictionary of "keywords" which we check whenever we have matched a SYMBOL (the
#equivalent to an identifier in a programming language). Here is the lexer code, complete 
#except for the t_ignore regex and the t_newline() and t_error() functions which are not
#shown b/c they are the same as ones we have seen before.

    keywords = {"exists": "EXISTS", "forall": "FORALL", "true": "TRUE", "false": "FALSE"}
    tokens = (["SYMBOL", "COLON", "COMMA", "LPAREN", "RPAREN", "EQUALS"
               "NOT", "AND", "OR", "IMPLIES"] + list(keywords.values()))

    def t_SYMBOL(t):
        r"[a-zA-Z]\w*"
        r.type = keywords.get(t.value, "SYMBOL")
        return t

    t_EQUALS = r"="
    t_NOT = r"~"
    t_AND = r"&"
    t_OR = r"\|"
    t_IMPLIES = r"->"
    t_COLON = r":"
    t_COMMA = r","
    t_LPAREN = r"\("
    r_RPAREN = r"\)"

#THe t_SYMBOL() function is used to match both symbols (identifers) and keywords. If the key
#give to dict.get() is NOT in the dictionary then the default value is returned (in this
#case "SYMBOL"); otherwise the key's corresponding token name is returned. Notice also that
#unlike previous lexers, we dont change the ply.lex.LexToken's value attribute, but we do
#change its type attribute to be either "SYMBOL" or the appropriate keyword token name. All
#the other tokens are matched by simple regexes -- all of which happen to match one or two
#literal characters.

#In all the previous PLY examples, the lexer alone has been sufficient for our parsing needs.
#But for the first-order logic BNF, we need to use PLY's parser as well as its lexer to do
#the parsing. Setting up a PLY parser is quite straightforward -- and unlike PyParsing we
#dont have to reformulate our BNF to match certain patterns but can use the BNF directly.

#For each BNF definition, we create a function with a name prefixed by p_ and whose
#docstring contains the BNF statement the function is designed to process. As the parser
#parses, it calls the function with the matching BNF statement and passes it a single
#argument of type ply.yaxx.YaccProduction.  The argument is given the name p (following
#the PLY examples' naming conventions). When a BNF statement includes alternatives, it is
#possible to create just one function to handle them all, although in most cases it is
#clearer to create one function per alternative or set of structurally similar alternatives.
#We will look at each of the parser functions, starting with the one for handling
#quantifiers.

    def p_formula_quantifiers(p):
        """FORMULA : FORALL SYMBOL COLON FORMULA
                   | EXISTS SYMBOL COLON FORMULA"""
        p[0] = [p[1], p[2], p[4]]

#The docstring contains the BFN statement that the function corresponds to, but using :
#rather then ::= to mean IS DEFINED BY. Note that the words in the BNF ar either
#tokens that the lexer matches or nonterminals (eg FORMULA) that the BNF matches. One PLY
#quirk to be aware of is that if we have alternatives as we have here, each one must be
#on a seperate line in the docstring.

#THe BNF's definition of the FORMULA nonterminal involves any alternatives, but here we
#have used just the parts that are concerned with quantifiers -- we will handle the other
#alternatives in other functions. The argument p of type ply.yacc.YaccProduction supports
#Python's sequence API, with each item corresponding to an item in the BFN. So in all cases,
#p[0] corresponds to the nonterminal that is being defined (in this case FORMULA), with the
#other items matching the parts on the right-hand side. Here, 
#p[1] matches one of the symbols "exists" or "forall", 
#p[2] mathces the quantified identifier (typically, x or y),
#p[3] matches the COLON token (a literal : which we ignore), and 
#p[]4 mathces the formula that is quantified. This a recursive defintion, so the p[4] item is
#itself a formula which may contain formulas and so on. We dont have to concern ourselves
#with whitespace between tokens since we created a t_ignore regex which told the lexer
#to ignore (ie skip) whitespace.

#In this example, we could just as easily have created two separate functions, say, 
p_formula_forall() #and 
p_formula_exists() #, giving them one alternative of the BNF each and the same suite. We
#chose to combine them -- and some of the others -- simply b/c they have the same suites.

#Formulas in the BNF have three binary operators involving formulas. Since these can be
#handled by the same suite, we have chosen to parse them using a single function and a
#BNF with alternatives.

    def p_formula_binary(p):
        """FORMULA :
                   | FORMULA
                   | FORMULA"""
        p[0] = [p[1], p[2], p[3]]

#The result, that is, the FORMULA stored in p[0], is simply a list containing the left
#operand, the operator, and the right operand. This code says nothing about precedence
#and associativity -- and yet we know that IMPLIES is right-associative and that the
#other two are left-associative, and that IMPLIES has lower precedence than the others.
#We will see how to handle these aspects once we have finished reviewing the parser's
#functions.

    def p_formula_not(p):
        "FORMULA : NOT FORMULA"
        p[0] = [p[1], p[2]]

    def p_formula_boolean(p):
        """FORMULA : FALSE
                   | TRUE"""
        p[0] = p[1]

    def p_formula_group(p):
        "FORMULA : LPAREN FORMULA RPAREN"
        p[0] = p[2]

    def p_formula_symbol(p):
        "FORMULA : SYMBOL"
        p[0] = p[1]

#All these FORMULA alternatives are unary, but even though the suites for 
#p_formula_boolean() and p_formula_symbol() are the same, we have given each one its
#own function since they are all logically different from each other. One slightly
#surprising aspect of the p_formula_group() function is that we set its value to be
#p[1] rather than [p[1]]. This works bc we already use lists to embody all the operators,
#so while it would be harmless to use a list here -- and might be essential for the
#other parsers -- in this example it isnt necessary.

    def p_formula_equals(p):
        "FORMULA : TERM EQUALS TERM"
        p[0] = [p[1], p[2], p[3]]

#This is the part of the BNF that relates formulas and terms. The implementation is 
#straightforward, and we could have included this with the other binary operators since
#the function's suite is the same. We chose to handle this separately purely b/c it is
#logically different from the other binary operators.

    def p_term(p):
        """TERM : SYMBOL LPAREN TERMLIST RPAREN 
                | SYMBOL"""
        p[0] = p[1] if len(p) == 2 else [p[1], p[3]]

    def p_termlist(p):
        """TERMLIST : TERM COMMA TERMLIST
                    | TERM"""
        p[0] = p[1] if len(p) == 2 else [p[1], p[3]]

#Terms can either be a single symbol or a symbol followed by a parenthesized term list (a
#comma-separated list of terms), and these two functions between them handle both cases.

    def p_error(p):
        if p is None:
            raise ValueError("Unknown error")
        raise ValueError("Syntax error, line {0}: {1}".format(p.lineno + 1, p.type))

#If a parser error occurs the p_error() function is called. Although we have treated the
ply.yacc.YaccProduction #argument as a sequence up to now, it also has attributes, and here
#we ahve used the lineo attribute to indicate where the problem occured.

    precedence = (("nonassoc", "FORALL", "EXISTS"),
                  ("right", "IMPLIES"),
                  ("left", "OR"),
                  ("right", "NOT"),
                  ("nonaccos", "EQUALS"))

#To set the precedences and associativities of operators in a PLY parser, we must create
#a precedence variable and give it a list of tuples where each tuple's first item is the
#required associativity and where each tuple's second and subsequent items are the tokens
#concernted. PLY will honor the specified associativities and will set the precedence from
#lowest (first tuple in the list) to highest (last tuple in the list).*
#*Note in PyParsing, precedence are set the other way up, from highest to lowest.
#For unary operators, associativity isnt really an issue for PLY (although it can be for
#PyParsing), so for NOT we could have used "nonassoc" and the parsing results would not
#be affected.

#At this point we have taken the tokens, the lexer's functions, the parser's functions, and
#the precedence variablr all set up. Now we can create a PLY lexer and parser and parse 
#some text.

    lexer = ply.lex.lex()
    parser = ply.yacc.yacc()
    try:
        return parser.parse(text, lexer=lexer)
    except ValueError as err:
        print(err)
        return []

#This code parses the formula it is given and returns a list that has exactly the same
#format as the lists returned by the PyParsing version. (See the end of the subsection
#on the PyParsing first-order logic parser to see examples of the kind of lists that the
#parser returns).

#PLY tries very hard to give useful and comprehensive error messages, although in some 
#cases it can be overzealour -- for example, when PLY creates the first-order logic parser
#for the first time, it warns that there are "6 shift/reduce conflicts." In practice, PLY
#defaults to shifting in such cases, since that's usually the right thing to do, and is
#certainly the right action for the first-order logic parser. The PLY documentation explains
#this and may other issues that can arise, and the parser's parser.out file is produced
#whenever a parser is created contains all the information necessary to analyze what is
#going on. As a rule of thumb, shift/reduce warnings may be benign, but any other kind of
#warning should be eliminated by correcting the parser.

#We have now completed our coverage of the PLY examples. The PLY documentation www.dabeaz.com
#provides much more information than we have had space to convey here, including complete
#coverage of all of PLY's features including many that were not needed for this chapter's
#examples.


#Reminder of topics<===========
CHAPTER 14 Introduction to Parsing 

BNF Syntax and Parsing Terminology
Writing Handcrafted Parsers 
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
Pythonic Parsing with PyParsing
    Quick Introduction to PyParsing
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
    Parsing First-Order Logic 
Lex/Yacc-Style Parsing with PLY 
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
    Parsing First-Order Logic
Summary
Exercises 
#1) 

#CODE LISTING HERE
playlist.py
    ReadKeyValue.py
    ReadM3U.py
blocks.py
    Block.py 
    BlockOutput.py
first-order-logic.py
BibTeX.py


===============
Summary
===============

#For the simplist situations and for nonrecursive grammers, using regexes is a good choice
#at least for those who are comfortable with regex syntax. Another approach is to create a
#finite state automata -- for example, by reading the text character by character, and 
#maintaing one or more state variables -- although this can lead to if statemets with lots
#of elif and nested if...elfis that can be difficult to maintain. For more complex grammers,
#and those that are recursive, PyParsing, PLY, and other generic parser generators are a 
#better choice than using regexes or finite state automata, or doing a handcrafted recursive
#descent parser.

#Of all the approaches, PyParsing seems to require the least amount of code, although it can
#be tricky to get recursive grammers right, at least at first. PyParsing works its best when
#we take full advantage of its predefined functionality -- of which there is quite a lot more
#than we covered in this chapter -- and use the programming pattersn that suit it. This means
#that in more complex cases we cannot simply translate a BNF directly into PyParsing syntax,
#but must adapt the implementation of the BNF to fit in with the PyParsing philosophy. PyParsing
#is an excellent module, and it is used in many programming projects.

#PLY not only supports the direct translation of BNFs, it requires that we do this, at least
#for the ply.yacc module. It also has a powerful and flexible lexer which is sufficient in its
#own right for handling many simply grammers. PLY also has excellent error reporting. PLY uses
#a table driven algorithm that makes its speed independent of the size or complexity of the 
#grammer, so it tends to run faster than parsers that use recurisve descent such as PyParsing.
#One aspect of PLY that may take some getting used to is its heavy reliance on instrospection,
#where both docstings and function names have significance. Nonetheless, PLY is an excellent
#module, and has been used to create some complex parsers, including ones for the C and
#ZXBasic programming languages.

#Although it is generally straightforward to create a parser that accepts valid input, 
#creating one that accepts all valid input AND rejects all invalid input can be quite a
#challenge. For example, do the first-order logic parsers in this chapter's last section
#accept all valid formuals and reject all invalid ones? And even if we do manage to reject
#invalid input, do we provide error messages that correctly identify what the problem is
#and where it occured? Parsing is a large and fasinacting topic, and this chapter is designed
#to introduce the very basics, so further reading and practical experience are essential
#for those wanting to go further.

#One other point that this chapter hints at is that as large and wide-ranging as Python's
#standard library is, many high-quality, third-party packages and modules that provide
#very useful additional functionality are also avaiable. Most of these are available 
#through the Python Package Index, pypi.python.org/pypi but some can only be discovered
#using a search engine. In general, when you have some specialized need that is not met by
#Python's standard library, it is always worth looking for a third-party solution before
#writing your own.


#Reminder of topics<===========
CHAPTER 14 Introduction to Parsing 

BNF Syntax and Parsing Terminology
Writing Handcrafted Parsers 
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
Pythonic Parsing with PyParsing
    Quick Introduction to PyParsing
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
    Parsing First-Order Logic 
Lex/Yacc-Style Parsing with PLY 
    Simple Key-Value Data Parsing 
    Playlist Data Parsing 
    Parsing the Blocks Domain-Specific Language
    Parsing First-Order Logic
Summary
Exercises 
#1) 

#CODE LISTING HERE
playlist.py
    ReadKeyValue.py
    ReadM3U.py
blocks.py
    Block.py 
    BlockOutput.py
first-order-logic.py
BibTeX.py


===============
Exercises 
===============

#1) Create a suitable BNF and then write a simple program for parsing basic BibTEX book
#references, and that produces output in the form of a dictionary of dictionaries. For
#example, given input like this:

    @Book{blanchette+summerfield08,
        author      = "Jasmin Blanchette and Mark Summerfield",
        title       = "C++ GUI Programming with Qt 4, Second Edition",
        year        = 2008,
        publisher   = "Prentice Hall"
    }

#the expected output would be a dictionary like this (here, pretty printed):

     {'blanchette+summerfield08': {
            'author': 'Jasmin Blanchette and Mark Summerfield',
            'publisher': 'Prentice Hall',
            'title': 'C++ GUI Programming with Qt 4, Second Edition',
            'year': 2008
        } 
    }

#Each book has an identifier and this should be used as the key for the outer dictionary.
#The value should itself be a dictionary of key-value items.

#Each book's identifier can contain any characters except whitespace, and each key=value
#field's value can either be an integer or a double-quoted string. String values an include
#arbitrary whitespaces including newlines, so replace every internal sequence of whitepace
#(including newlines) with a single space, and of course strip whitespace from the ends. Note
#that the last key=value for a given book is not followed by a comma.

#Create the parser using either PyParsing or PLY. If using PyParsing, the Regex() class
#will be useful for the identifier and the QuotedString() class will be useful when
#defining the value. Use the delimitedList() function for handling the list of key=values.
#If using PLY, the lexer is sufficient providing you use separate tokens for integer and
#string values.

#Solution using PyParsing should take around 30 lines, while one using PLY might take
#about 60 lines. Solution that includes both PyParsing and PLY function is in 
BibTeX.py

#CODE HERE
BibTeX.py

#!/usr/bin/env python3

"""
BNF

    BIBTEXES    ::= BIBTEX+
    BIBTEX      ::= '@Book{' IDENTIFIER ',' KEY_VALUES '}'
    IDENTIFIER  ::= [a-zA-Z][^,\s]*
    KEY_VALUES  ::= KEY_VALUE | KEY_VALUE ',' KEY_VALUES
    KEY_VALUE   ::= KEY '=' VALUE
    KEY         ::= [a-zA-Z]\w*
    VALUE       ::= "[^"]+" | \d+
"""

import pprint
import ply.lex
try:
    from pyparsing import(alphas, alphanums, delimitedList, nums, OneOrMore,
        ParseException, QuotedString, Regex, Suppress, Word)
except ImportError:
    from pyparsing_py3, import (alphas, alphanums, delimitedList, nums, OneOrMore,
        ParseException, QuotedString, Regex, Suppress, Word)
import re

#the examples are copied from Wikipedia
TEXT = """
@Book{blanchette+summerfield,
  author    =  "Jasmin Blanchette and Mark Summerfield",
  title     =  "C++ GUI Programming with Qt 4,
                Second Edition",
  publisher =   "Prentice Hall",
  year      =   2008,
  address   =  "New York"
}
@Book{abramowitz+stegun,
  author    =     "Milton {Abramowitz} and Irene A. {Stegun}",
  title     =      "Handbook of Mathematical Functions with
                  Formulas, Graphs, and Mathematical Tables",
  publisher =      "Dover",
  year      =      1964,
  address   =     "New York",
  edition   =     "ninth Dover printing, tenth GPO printing"
}
@Book{hicks2001,
  author    =     "von Hicks, III, Michael",
  title     =      "Design of a Carbon Fiber Composite Grid Structure for the GLAST 
                 Spacecraft Using a Novel Manufacturing Technique",
  publisher =      "Stanford Press",
  year      =      2001,
  address   =   "Palo Alto",
  edition   =     "1st,",
  isbn      =   "0-69-697269-4"
}
@Book{Torre2008,
  author = "Joe Torre and Tom Verducci",
  publisher = "Doubleday",
  title = "The Yankee Years",
  year = 2008,
  isbn = "0385527403"
}
"""

def pyparsing_parse(text):
    WHITESPACE = re.compile(r"\s+")
    books = {}
    key_values = {}

    def normalize(tokens):
        return WHITESPACE.sub(" ", tokens[0])

    def add_key_value(tokens):
        key_values[token.key] = tokens.value

    def add_book(tokens):
        books[tokens.identifier] = key_value.copy()
        key_values.clear()

    left_brace, right_brace, comma, equals = map(Suppress, "{},=")
    start = Suppress("@Book") + left_brace
    identifier = Regex(r"[a-zA-Z][^,\s]*")("identifier") + comma
    key = Word(alphas, alphanums)("key")
    value = (Word(nums).setParseAction(lambda t: int(t[0])) | 
        QuotedStrin('"', multiline=True).setParseAction(normalize))("value")
    key_value = (key + equals + value).setParseAction(add_key_value)
    end = right_brace
    bibtex = (start + identifier + delimitedList(key_value) + end).setParseAction(add_book)
    parser = OneOrMore  (bibtex)
    try:
        parser.parseString(text)
    except ParseException as err:
        print("parse error: {0}".format(err))
    return books


def ply_parse(text):
    WHITESPACE = re.compile(r"\s+")

    tokens = ("START", "IDENTIFIER", "KEY", "NUMBER", "QUOTEDSTRING", "COMMA", "END")

    t_ignore_START = r"@Book"


    def t_IDENTIFIER(t):
        r"\{[a-zA-Z][^,\s]*"
        t.value = t.value[1:]
        return t

    t_KEY = r"[a-zA-Z]\w*"

    def t_NUMBER(t):
        r"=\s*\d+"
        t.value = int(t.value[1:].lstrip())
        return t

    def t_QUOTEDSTRING(t):
        r'=\s*"[^="]+"'
        t.value = WHITESPACE.sub(" ", t.value[1:].lstrip()[1:-1].strip())
        return t

    t_ignore_COMMA = r","

    t_ignore_END = r"\}"

    t_ignore = " \t\n"

    def t_newline(t):
        r"\n+"
        t.lexer.lineno += len(t.value)

    def t_error(t):
        line = t.value.lstrip()
        i = line.find("\n")
        line = line if i == -1 else line[:i]
        print("failed to parse line {0}: {1}".format(t.lineno + 1, line))

    books = {}
    book = key = None
    lexer = ply.lex.lex()
    lexer.input(text.replace("\n", " "))
    for toekn in lexer:
        if token.type == "IDENTIFIER":
            books[token.value] = book = {}
            continue
        if book is None:
            print("missing start of book line {0}".format(token.lineno))
        if token.type == "KEY":
            key = token.value
            continue 
        if key is None:
            print("missing key line {0}".format(token.lineno))
        if token.type in ("QUOTEDSTRING", "NUMBER"):
            book[key] = token.value
    return books


def main():
    books_ply = ply_parse(TEXT)
    books_pyparsing = pyparsing_parse(TEXT)
    pprint.pprint(books_pyparsing)
    assert books_ply == books_pyparsing


main()



===============================================================================================
CHAPTER: 15 Introduction to GUI Programming
CHAPTER BEGIN
===============================================================================================

#Reminder of topics<===========
Dialog-Style Programs                   
Main-Window-Style Programs 
    Creating a Main Window 
    Creating a Custom Dialog 
Summary
Exercises 
#1) 
#2)


#CODE LISTING HERE
bookmarks-tk.pyw
bookmarks-tk_ans.pyw
interest-tk.pyw
regex-tk.pyw




#Reminder of topics<===========
===============
CHAPTER 15 Introduction to GUI Programming
===============

#Python has no native support for GUI programming, but this isnt a problem since many
#GUI libraries written in other languages can be used by Python programmers. This is
#possible b/c many GUI libraries have Python wrappers or bindings -- these are packages
#and modules that are imported and used like any other Python packages and modules but
#which access functionality that is non-Python libraries under the hood.

#Python's standard library includes Tcl/Tk -- Tcl is an almost syntax free scripting
#language and Tk is a GUI library written in Tcl and C. Python's tkinter module provides
#Python bindings for the Tk GUI library. Tk has three advantages compared with the other
#GUI libraries that are available for Python. First, it is installed as standard with
#Python, so it is always available; second, it is small (even including Tcl); and third,
#it comes with IDLE which is very useful for experimenting with Python and for editing
#and debugging Python programs.

#Unforetunately, prior to Tk 8.5, Tk hasd a very dated look and a very limited set of
#widgets ("controls" or "containers" in Windows-speak). Although it is fairly easy to
#create custom widgets in Tk by composing other widgets together in a layout, Tk does 
#not provide any direct way of creating custom widgets from scratch with the 
#programmer able to draw whatever they want. Additional Tk compatible widgets are 
#available using the Ttk library (only with Python 3.1 and Tk 8.5 and later) and the Tix
#library -- these are also part of Python's standard library. Note that Tix is not 
#always provided on non-Windows platforms, most notable Ubuntu, which at the time of this
#writing offers it only as an unsupported add-on, so for maximum portability it is best
#to avoid using Tix altogether. The Python orientated documentation for Tk, Ttk, and Tix
#is rather sparse -- most of the documentation for these libraries is written for
#Tcl/Tk programmers and may not be easy for non-Tcl programmers to decipher.

#For developing GUI programs that must run on any or all Python desktop platforms 
#(eg Windows, Mac OS X, and Linux), using only a standard Python installation with
#no additional libraries, there is just one choice: Tk.

#If it is possible to use third party libraries the number of options opens up considerably.
#One route is to get the WCK (Widget Construction Kit, www.effbot.org/zone/wck.htm) which
#provides additional Tk-compatiable functionality including the ability to create custom
#widgets whose contents are drawn in code.

#The other choices dont use Tk and fall into two categories, those that are specific to a
#particular platform and those that are cross-platform. Platform-specific GUI libraries
#can give us access to platform specific features, but at the price of locking us in to
#the platform. The three most well-established cross-platform GUi libraries with Python
#bindings at PyGtk (www.pygtk.org), PyQt (www.riverbankcomputing.com/software/pyqt), and
#wxPython (www.wxpython.org). All three of these offer far more widgets than Tk, produce
#better looking GUIs (although the gap has narrowed with Tk 8.5 and even more with Tkk),
#and make it possible to create custom widgets drawn in code. All of them are easier to
#learn and use than Tk and all have more and much better Python-oriented documentation
#than Tk. And in general, programs that use PyGtk, PyQt, or wxPython need less code and
#produce better results than programs written using Tk. (At the time of this writing, PyQt
#had already been ported to Python 3, but the ports of both wxPython and PyGtk were still
#being done).

#Yet despite its limitations and frustrations, Tk can be used to build useful GUI programs
#-- IDLE being the most well known in the Python world. Furthermore, Tk development seems
#to have picked up lately, with Tk 8.5 offering theming which makes Tk programs look much
#more native, as well as the welcome addition of many new widgets.

#The purpose of this chapter is to give just a flavor of Tk programming -- for serious GUI
#development it is best to skip this chapter (since it shows the vintage Tk approach to GUi
#programming), and to use one of the alternative libraries. But if Tk is your only option --
#for example, if your users have only a standard Python installation and cannot or wll not
#install a third party GUI library -- then realistically you will need to learn enough of 
#the Tcl language to be able to read Tk documentation.*
#*Note the only Python/Tk book known to this author is Python and Tkinter Programming by John
#Grayson.

#In the following sections we will use Tk to create two GUI programs. The first is a very
#small dialog-style program that does commpund interest calcuations. The second is a more
#elaborate main-window style program that manages a list of bookmarks (names and URLs). By
#using such simple data, we can concentrate ont he GUi programming aspects without 
#distraction. In the coverage of the bookmarks program we will see how to create a custom
#dialog, and how to create a main window with menus and toolbars, as well as how to
#combine them all together to create a complete working program.

#Both of the example programs use pure Tk, making no use of the Ttk and Tix libraries, so
#as to ensure compatibility with Python 3.0. It is not difficult to convert them to use
#Ttk, but at the time of this writing, some of the Ttk widgets provide less support
#for keyboard users than their Tk cousins, so while Ttk programs might look better,
#they may also be less convenient to use.

#But before diving into the code, we must review some of the basics of GUI programming
#since it is a bit different from writing console programs.

#Python console programs and module files always have a .py extension, but for Python GUi
#programs we use a .pyw extension (module fiels always use .py, though). Both .py and .pyw
#work fine on Linux, but on Windows, .pyw ensures that Windows uses the pythonw.exe 
#interpreter instead of python.exe, and this in turn ensures that when we create a Python
#GUI program, no unnecessary console window will appear. Mac OS X works similarly to 
#Windows, using the .pyw extension for GUI programs.

#When a GUI program is run it normally beings by creating its main window and all of
#the main window's widgets, such as the menu bar, toolbars, the central area, adn the
#status bar. Once the window has been created, like a server program, the GUI program
#simply waits. Whereas a server waits for client programs to connect it, a GUI program
#waits for user interaction such as mourse clicks and key presses. This is illustrated
#in contrast to console programs in Figure 15.1. The GUI program does not wait passively;
#it runs an event loop, which in pseudocode looks like this:

    while True:
        event = getNextEvent()
        if event:
            if event == Terminate:
                break
            processEvent(event)

#When the user interacts with the program, or when certain other things occur; such as
#a timer timing out or the program's window being activated (maybe b/c another program
#was closed), an evert is generated inside the GUI library and added to the event queue.
#The program's event loop continuously checks to see whether there is an event to process,
#and if there is, it processes it (or passes it on to the event's associated function or
#method for processing).

#As GUI programmers we can rely on the GUI library to provide the event loop. Our 
#responsibility is to create classes that represent the windows and widgets our program
#needs and to provide them with methods that respond appropriately to use interactions.


#Reminder of topics<===========
Dialog-Style Programs                   
Main-Window-Style Programs 
    Creating a Main Window 
    Creating a Custom Dialog 
Summary
Exercises 
#1) 
#2)

===============
Dialog-Style Programs                   
===============

#The first program we will look at is the Interest program. This is a dialog-style program
#ie it has no menus), which the user can use to perform compound interest calculations. The
#program is shown in Figure 15.2

#In most object-oriented GUI programs, a custom class is used to represent a single main
#window or dialog, with most of the widgets it contains being instances of standard
#widgets, such as buttons or checkboxes, supplied by the library. Like most cross-platform
#GUI libraries, Tk doesnt really make a distinction between a window and a widget - a window
#is simply a widget that has no widget parent (ie it is not contained inside another widget).
#Widgets that dont have a widget parent (windows) are automatically supplied with a frame
#and window decorations (such as a title bar and close button), and they usually contain
#other widgets.

#Most widgets are created as children of another widget (and are contained inside their parent),
#whereas windows are created as children of the tkinter.Tk object -- an object that conceptually
#represents the application, and something we will return to later on. In addition to 
#distinguishing between widgets and windows (also called top-level widgets), the parent-child
#relationships help ensure that widgets are deleted in the right order and that child widgets
#are automatically deleted when their parent is deleted.

#The initializer is where the user interface is created (the widget added and laid out, the
#mouse and keyboard bindings made), and other methods are used to respond to user interactions.
#Tk allows us to create custom widgets either by subclassing a predefined widget such 
tkinter.Frame #, or by creating an ordinary class and adding widgets to it as attributes. Here
#we have used subclassing -- in the next example we will show both approaches.

#Since the Interest program has just one main window it is implmeneted in a single class. We
#will start by looking at the class's initializer, broken into five parts since it is
#rather long.

#part 1

    class MainWindow(tkinter.Frame):

        def __init__(self, parent):
            super().__init__(parent)
            self.parent = parent
            self.grid(row=0, column=0)

#We begin by initializing the base class, and we keep a copy of the parent for later use.
#Rather than using absolute positions and sizes, widgets are laid out inside other widgets
#using layout managers. The call to grid() lays out the frame using the grid layout managers.
#Every widget that is shown must be laid our, even the top-level ones. Tk has several layout
#managers, but the grid is the easiest to understand and use, although for top-level layouts
#where there is only one widget to lay out we could use the packer layout manager by calling
#pack() instead of grid(row=0, column=0) to achieve the same effect.


        self.principal = tkinter.DoubleVar()
        self.principal.set(1000.0)
        self.rate = tkinter.DoubleVar()
        self.rate.set(5.0)
        self.years = tkinter.IntVar()
        self.amount = tkinter.StringVar()

#Tk allows us to create variables that are associated with widgets. If a variables's value
#is changed programmatically, the change is reflected in its associated widget, and 
#similarly, if the user changes the value in the widget, the associated variables value
#is changed. Here we have created two "double" variables (these hold float values), an 
#integer variable and a string variable, and have set initial values for two of them.

        principalLabel = tkinter.Label(self, text="Principal $:", anchor=tkinter.W, underline=0)
        principalScale = tkinter.Scale(self, variable=self.principal, command=self.updatedUi, from_=100, to=10000000, resolution=100, orient=tkinter.HORIZONTAL)
        rateLabel = tkinter.Label(self, text="Rate %:", underline=0, anchor=tkinter.W)
        rateScale = tkinter.Scale(self, variable=self.rate, command=self.updatedUi, from_=1, to=100, resolution=0.25, digits=5, orient=tkinter.HORIZONTAL)
        yearsLabel = tkinter.Label(self, text="Years:", underline=0, anchor=tkinter.W)
        yearsScale = tkinter.Scale(self, variable=self.years, command=self.updatedUi, from_=1, to=50, orient=tkinter.HORIZONTAL)
        amountLabel = tkinter.Label(self, text="Amount $", anchor=tkinter.W)
        actualAmountLabel = tkinter.Label(self, textvariable=self.amount, relief=tkinter.SUNKEN, anchor=tkinter.E)

#This part of the initilzer is where we create the widgets. The tkinter.Label widget is used
#to display read-only text to the user. Like all widgets it is created with a parent (in this
#case -- and as usual -- the parent is the containing widget), and then keyword arguments are
#used to set various other aspects of the widget's behavior and appearance. We have set the 
principalLabel #'s test appropriately, and set its anchor to tkinter.W, which means that the
#label's text is aligned west (left). The underline parameter is used to specify which
#character in the label should be underlined to indicate a keyboard accelertor (eg Alt + P);
#further on we will see how to make the accelerator work. (A keyboard accelerator is a key
#sequence of the form Alt+letter where letter is an underlined letter and which results in
#the keyboard focus being switched to the widget associated with the accelerator, most
#commonly the widget to the right or below the label that has the accelerator.) #For the 
tkinter.Scale #widget we give them a parent of self as usual, and associate a variable with
#each one. In addition, we give a function (or in this case a method) object reference as their
#command -- this method will be called automatically whenever the scale's value is changed,
#and set its minimum (from_, with a trailing underscore since plain from is a keyword) and 
#maximum (to) values, and a horizontal orinentation. For some of the scales we set a 
#resolution (step size) and for the rateScale the number of digits it must be able to display. The
actualAmountLabel #is also associated with a variable so that we can easily change the text
#the label displays later on. We have also given this label a sunken relief so that it fits
#in better visually with the scales.

        principalLabel.grid(row=0, column=0, padx=2, pady=2, sticky=tkinter.W)
        principalScale.grid(row=0, column=1, padx=2, pady=2, sticky=tkinterEW)
        rateLabel.grid(row=1, column=0, padx=2, pady=2, sticky=tkinter.EW)
        rateScale.grid(row=1, column=1, padx=2, pady=2, sticky=tkinter.EW)
        yearsLabel.grid(row=2, column=0, padx=2, pady=2, sticky=tkinter.W)
        yearsScale.grid(row=2, columns=1, padx=2, pady=2, sticky=tkinter.EW)
        amountLabel.grid(row=3, column=0, padx=2, pady=2, sticky=tkinter.W)
        actualAmountLabel.grid(row=3, column=1, padx=2, pady=2, sticky=tkinter.EW)

#having created the widgets, we must now lay them out. The grid layout we have used is
#illustrated in Figure 15.3

################################################ Figure 15.3
Figure 15.3 the Interest program's layout                                           '

                            principalLabel      principalScale  
                            rateLabel           rateScale
                            yearsLabel          yearsScale
                            amountLabel         actualAmountLabel

################################################

#Every widget supports the grid() method (and some other layout methods such as pack()).
#Calling grid() lays out the widget within its parent, making it occupy the specified
#row and column. We can set widgets to span mulitple columns and multiple rows using
#additional keyword arguments (rowspan and colunspan), and we can add some margin around
#them using the padx (left and right margin) and pady (top and bottom margin) keyword
#arguments giving integer pixel amounts as arguments. If a widget is allocated more space
#than it needs, the sticky option is used to determine what should be done with the space;
#if not specified the widget will occupy the middle of its allocated space. We have set all
#of the first column's labels to be sticky tkinter.W (ie west) and all of the second
#columns's widgets to be sticky tkinter.EW (ie east and west), which makes them stretch
#to fill the entire width available to them.

#All of the widgets are held in local variables, but they dont get scheduled for garbage
#collection b/c the parent-child relationships ensure that they are not deleted when
#they go out of scope at the end of the initializer, since all of them have the main
#window as their parent. Sometimes, widgets are created as instance variables, for example,
#if we need to refer to them outside the initializer, but in this case we used instance
#for the variables associated with the widgets (self.principal, self.rate, and self.years),
#so it is these we will use outside the initializer.

        principalScale.focus_set()
        self.updateUi()
        parent.bind("<Alt-p>", lambda *ignore: principalScale.focus_set())
        parent.bind("<Alt-r>", lambda *ignore: rateScale.focus_set())
        parent.bind("<Alt-y>", lambda *ingore: yearsScale.focus_set())
        parent.bind("<Control-q>", self.quit)
        parent.bind("<Escape>", self.quit)

#At the end of the initializer we give the keyboard focus to the principalScale widget
#so that as soon as the program starts the user is able to set the initial amount of money.
#We then call the self.updateUi() method to calculate the initial amount.

#Next, we set up a few key bindings. (Unfortunately, binding has three different meanings
#1 variable binding is where a name, that is, an object reference, is bound to an object;
#2 a key binding is where a keyboard action such as a key press or release is associated 
#with a function or method to call when the action occurs;
#3 bindings for a library is the glue code that makes a library written in a language
#other than Python available to Python programmers through Python modules.)
#Key bindings are essential for some disabled users who have difficulty with or are
#unable to use the mouse, and they are a great convenience for fast typists who want to
#avoid using the mouse b/c it slows them down.

#The first three key bindings are used to move the keyboard focus to a scale widget. For 
#example, the principalLabel's text is set to Principal $: and its underline to 0, so the
#label appears as Principal $: (with P underlined), and with the first keyboard binding 
#in place when the user types Alt+P the keyboard focus will switch to the principleScale
#widget. The same applies to the other two bindings. Note that we do not bind the 
#focus_set() method directly. This is b/c when functions or methods are called as the
#result of an event binding they are given the event that invoked them as their first
#argument, and we dont want this event. So, we use a lambda function that accepts but
#ignores the event and calls the method without the unwanted argument.

#We have also created two keyboard shortcuts -- these are key combinations that invoke
#a particular action. Here we have set Ctrl+! and Esc and bound them both to the 
#self.quit() method that cleanly terminates the program.

#It is possible to create keyboard bindinds for individual widgets, but here we have
#set them all on the parent (the application), so they all work no matter where the 
#keyboard focus is.

#Tk's bind() method can be used to bind both mouse clicks and key presses, and also
#programmer-defined events. Special keys like Ctrl and Esc have Tk-specific names
#(Control and Escape), and ordinary letters stand for themselves. Key sequences are
#created by putting the parts in angle brackets and separating them with hyphens.

#Having created and laid out the widgets, and set up the key bindings, now the 
#appearance and basic behavior of the program are in place. Now we will review the
#methods that respond to user actions to complete the implementation of the 
#program's behavior.

        def updateUi(self, *ignore):
            amount = self.principal.get() * ((1 + (self.rate.get() / 100.0)) ** self.years.get())
            self.amount.set("{0:.2f}".format(amount))

#This method is called whenever the user changes the principal, the rate, or the years
#since it is the command associated with each of the scales. All it does is retrieve the
#value from each scales's associated variable, perform the compound interest calculation,
#and store the result (as a string) in the variable associated with the actual amount label.
#As a result, the actual amount label always shows an up-to-date amount.

        def quit(self, event=None):
            self.parent.destroy()

#If the user chooss to quit (by pressing Ctrl+Q or Esc, or by clicking the window's close
#button) this method is called. Since there is no data to save we just tell the parent (which
#is the application object) to destroy itself. The parent will destroy all of its children --
#all of the windows, which in turn will destroy all of their widgets -- so a clean 
#termination takes place.

    application = tkinter.Tk()
    path = os.path.join(os.path.dirname(__file__), "images/")
    if sys.platform.startswith("win"):
        icon = path + "interest.ico"
    else:
        icon = "@" + path + "interest.xbm"
    application.iconbitmap(icon)
    application.title("Interest")
    window = MainWindow(application)
    application.protocol("WM_DELETE_WINDOW", window.quit)
    application.mainloop(0)

#After defining the class for the main (and in this case only) window, we have the code
#that starts the program running. We begin by creating an object to represent the
#application as a whole. To give the program an icon on Windows we use an .ico file and
#pass the name of the file (with its full path) to the iconbitmap() method. But for Unix
#platforms we must provide a bitmap (ie monochrome image). Tk has several built-in bitmaps,
#so to distinguish one taht comes from the file system we must precede its name with an @
#symbol. Next we give the application a title (which will appear in the title bar), and
#then we create an instance of our MainWindow class giving the application object as its
#parent. At the end we call the protocol() method to say that the MainWindow.quit() method
#should be called, and finally we start the event loop -- it is only when we readch the
#point that the window is displayed and is able to respond to user interactions.



#CODE LISTING HERE
bookmarks-tk.pyw
bookmarks-tk_ans.pyw
interest-tk.pyw
regex-tk.pyw


#CODE HERE
interest-tk.pyw

#!/usr/bin/env python3

import os
import sys
import tkinter

class MainWindow(tkinter.Frame):

    def __init__(self, parent):
        super().__init__(parent)
        self.parent = parent
        self.grid(row=0, column=0)

        self.principal = tkinter.DoubleVar()
        self.principal.set(1000.0)
        self.rate = tkinter.DoubleVar()
        self.rate.set(5.0)
        self.years = tkinter.IntVar()
        self.amount = tkinter.StringVar()

        principalLabel = tkinter.Label(self, text="Principal $:", anchor=tkinter.W, underline=0)
        principalScale = tkinter.Scale(self, variable=self.principal, command=self.updateUI,
            from_100, to 10000000, resolution-100, orient=tkinter.HORIZONTAL)
        rateLabel = tkinter.Label(self, text="Rate %:", underline=0, anchor=tkinter.W)
        rateScale = tkinter.Scale(self, variable=self.rate, command=self.updateUi, from_=1,
            to=100, resolution=0.25, digits=5, orient=tkinter.HORIZONTAL)
        yearsLabel = tkinter.Label(self, text="Years:", underline=0, anchor=tkinter.W)
        yearsScale = tkinter.Scale(self, variable=self.years, command=self.updateUi, from_=1,
            to=50, orient=tkinter.HORIZONTAL)
        amountLabel = think.Label(self, text="Amount $", anchor=tkinter.W)
        actualAmountLabel = tkinter.Label(self, textvariable=self.amount, relief=tkinter.SUNKEN,
            anchor=tkinter.E)

        principalLabel.grid(row=0, column=0, padx=2, pady=2, sticky=tkinter.W)
        principalScale.grid(row=0, column=0, padx=2, pady=2, sticky=tkinter.EW)
        rateLabel.grid(row=1, column=0, padx=2, pady=2, sticky=tkinter.W)
        rateScale.grid(row=1, column=1, padx=2, payy=2, sticky=tkinter.EW)
        yearsLabel.grid(row=2, column=0, padx=2, pady=2, sticky=tkinter.W)
        yearsScale.grid(row=2, column=0, padx=2, pady=2, sticky=tkinter.EW)
        amountLabel.grid(row=3, column=0, padx=2, pady=2, sticky=tkinter.W)
        actualAmountLabel.grid(row=3, column=1, padx=2, pady=2, sticky=tkinter.EW)

        principalScale.focus_set()
        self.updatedUi()
        parent.bind("<Alt-p>", lambda *ignore: principalScale.focus_set())
        parent.bind("<Alt-r>", lambda *ignore: rateScale.focus_set())
        parent.bind("<Alt-y>", lambda *ignore: yearsScale.focus_set())
        parent.bind("<Control-q>", self.quit)
        parent.bind("<Escape>", self.quit)


    def updatedUi(self, *ignore):
        amount = self.principal.get() * ((1 + (self.rate.get() / 100.0)) ** self.years.get())
        self.amount.set("{0:.2f}".format(amount))


    def quit(self, event=None):
        self.parent.destroy()


application = tkinter.Tk()
path = os.path.join(os.path.dirname(__file__), "images/")
if sys.platform.startswith("win"):
    icon = path + "interest.ico"
else:
    icon = "@" + path + "interest.xbm"
application.iconbitmap(icon)
application.title("Interest")
window = MainWindow(application)
application.protocol("WM_DELETE_WINDOW", window.quit)
application.mainloop()




#Reminder of topics<===========
Dialog-Style Programs                   
Main-Window-Style Programs 
    Creating a Main Window 
    Creating a Custom Dialog 
Summary
Exercises 
#1) 
#2)

#CODE LISTING HERE
bookmarks-tk.pyw
bookmarks-tk_ans.pyw
interest-tk.pyw
regex-tk.pyw

===============
Main-Window-Style Programs 
===============

#Although dialog-style programs are oftn sufficient for simple tasks, as the range
#of functionality a program offers grows it often makes sense to create a complete
#main-window style application with menus and toolbars. Such applications are usually
#easier to extend than diaglog-style programs since we can add extra menus or menu
#options and toolbar buttons without affecting the main window's layout.

#In this section we will review the bookmarks-tk.pyw program shown in Figure 15.4.
#The program maintains a set of bookmars as pairs of (name, URL) strings and has
#facilities for the user to add, edit, and remove bookmarks, and to open their web
#browser at a particular bookmarked web page.

#The program has two windows: the main window with the menu bar, toolbar, list of
#bookmarks, and status bar; and a dialog window for adding or editing bookmarks.

===============
    Creating a Main Window 
===============

#The main window is similar to a dialog in that it has widgets that must be created and
#laid out. And in addition we must add the menu bar, menus, toolbar, and status bar, as
#well as methods to perform the actions the user requests.

#ATUL --> See Figure 15.4 photo here - was not able to cut/paste it. Its a Winows style window 
#with main menu offering File and Edit with F and E underlined. Then 8 small buttons across a
#menu. Then scroll down list with maybe 15 listings. At the bottom is the action description 
#text.

#The user interface is all set up in the main window's initializer, which we will review in 
#five parts b/c it is fairly long.

#part 1
    class MainWindow:

        def __init__(self, parent):
            self.parent = parent 

            self.filename = None
            self.dirty = False
            self.data = {}

            menubar = tkinter.Menu(self.parent)
            self.parent["menu"] = menubar

#For this window, instead of inheriting a widget as we did in the eariler example, we have
#just created a normal Python class. If we inherit, we can implement the methods of the class
#we have inheritied, ut if we dont need to do that we can simply use composition as we have
#done here. The appearance is provided by creating 
widget instance variables #all contained within a tkinter.Frame as well see in a moment.

#We need to keep track of four pieces of information: the parent (application) object, the
#name of the current bookmarks files, a dirty flag (if True this means that changes have
#been made to the data that have not been saved to disk), and the data itself, a dictionary
#whose keys are bookmark names and values are URLs.

#To create a menu bar, we must create a tkinter.Menu object whose parent is the window's
#parent, and we must tell the parent that it has a menu. (It may seem strange that a menu
#bar is a menu, but Tk has had a very long evolution which has left it with some odd corners.)
#Menu bars created like this do not need to be laid out; Tk will do that for us.

#part 2
        fileMenu = tkinter.Menu(menubar)
        for label, command, shortcut_text, shortcut in(("New...", self.fileNew, "Ctrl+N", "<Control-n>"), ("Open...", self.fileOpen, "Ctrl+O", "<Control-o>"), ("Save", self.fileSave, "Ctrl+S", "<Control-s>"), (None, None, None, None), ("Quit", self.fileQuit, "Ctrl+Q", "<Control-q>")):
            if label is None:
                fileMenu.add_separator()
            else:
                fileMenu.add_command(label=label, underline=0, command=command, accelerator=shortcut_text)
                self.parent.bind(shortcut, command)
        menubar.add_cascade(label="File", menu=fileMenu, underline=0)

#Each menu bar menu is created in the same way. First we create a tkinter.Menu object that
#is a child of the menu bar, and then we add separators or commands to the menu. (Note that an
#accelerator in Tk terminology is actually a keyoboard shortcut, and that all the accelerator
#options sets is the text of the shortcut; it does not actually set up a key binding.) The
#underline indicates which character is underlined, in this case the first character of every menu
#option, and this letter becomes the menu option's keyboard accelerator.

#In addition to adding a menu option (called a command), we also provide a keyboard shortcut by
#binding a key sequence to the same command as that invoked when the correspdoning menu option is
#chosen. At the end the menu is added to the menu bar using the add_cascade() method.

#We have omitted the edit menu since it is structurally identical to the file menu's code.

#part 3
        frame = tkinter.Frame(self.parent)
        self.toolbar_images = []
        toolbar = tkinter.Frame(frame)
        for image, command in (("images/filenew.gif", self.fileNew), ("images/fileopen.gif", self.fileOpen), ("images/filesave.gif", self.fileSave), ("images/editadd.gif", self.editAdd), ("images/editedit.gif", self.editEdit), ("images/editdelete.gif", self.editDelete), ("images/editshowwebpage.gif", self.editShowWebPage)):
            image = os.path.join(os.path.dirname(__file__), image)
            try:
                image = tkinter.PhotoImage(file=image)
                self.toolbar_images.append(image)
                button = tkinter.Button(toolbar, image=image, command=command)
                button.grid(row=0, column=len(self.toolbar_images) -1)
            except tkinter.TclError as err:
                print(err)
        toolbar.grid(row=0, column=0, columnspan=2, sticky=tkinter.NW)

#We begin by creating a frame in which all of the window's widgets will be contained. Then
#we create another frame, toolbar, to contain a horizontal row of buttons that have images 
#instead of texts, to serve as toolbar buttons. We lay out each toolbar button one after the
#other in a grid that has one row and as many columns as there are buttons. At the end we lay
#out the toolbar frame itself as the main window frame's first row, making it north west sticky
#so that it will always cling to the top left of the window. (Tk automatically puts the menu
#bar above all the widgets laid out in the window).

#The layout is illustrated in Figure 15.5 with the menu bar laid out by Tk shown with a 
#white background, and our layouts shows with gray backgrounds.

#When an image is added to a button it is added as a weak reference, so once the image goes
#out of scope it is scheduled for garbage collection. We must avoid this b/c we want the
#buttons to show their image after the initializer has finished, so we create an instance
#variable, self.tootlbar_images, simply to hold references to the images to keep them alive
#for the program's lifetime.

#Out of the box, Tk can read only a few image file formats, so we have had to use .gif images*.
#*Note if the Python Imaging Library's Tk extension is installed, all of the modern image
#formats become supported. See www.pythonware.com/products/pil/ for details.
#If any image is not found a tkinter.TclError exception is raised, so we must be careful to
#catch this to avoid the program terminating just b/c of a missing image.

#Notice that we have not made all of the actions available from the menus avaialable as 
#toolbar buttons -- this is common practice.

#part 4
        scrollbar = tkinter.Scrollbar(frame, orient=tkinter.VERTICAL)
        self.listBox = tkinter.Listbox(frame, yscrollcommand=scrollbar.set)
        self.listBox.grid(row=1, column=0, sticky=tkinter.NSEW)
        self.listBox.focus_set()
        scrollbar["command"] = self.listBox.yview
        scrollbar.grid(row=1, column=1, sticky=tkinter.NS)

        self.statusbar = tkinter.Label(frame, text="Ready...", anchor=tkinter.W)
        self.statusbar.after(5000, self.clearStatusBar)
        self.statusbar.grid(row=2, column=0, columnspan=2, sticky=tkinter.EW)

        frame.grid(row=0, column=0, sticky=tkinter.NSEW)

#The main window's central area (the area between the toolbar and the status bar) is
#occupied by a list box and an associated scrollbar. The list box is laid out to be sticky
#in all directions, and the scrollbar is sticky only north and south (vertically). Both
#widgets are added to the window frame's grid, side by side.

#We must ensure that if the user scrolls the list box by tabbing into it and using the up
#and down arrow keys, or if they scroll the scrollbar, both widgets are kept in sync. This
#is achieved by setting the list box' yscrollcommand to the scrollbar's set() method (so that
#user navigation in the list box results in the scrollbar beting moved if necessary), and by
#setting the scrollbar's command to the listbox's yview() method (so that scrollbar movements
#result in the list box being moved correspondingly.)

#The status bar is just a label. The after() method is a single shot timer (a timer that 
#times out once after the given interval) whose first argument is a timeout in milliseconds
#and whose second argument is a function or method to call when the timeout is reached. This 
#means that when the program starts up the status bar will show the text "Ready..." for five
#seconds, and then the status bar will be cleared. The status bar is laid out as the last row
#and is made sticky west and east (horizontally).

#At the end we lay out the window's frame itself. We have now completed the creation and 
#layout of the main window's widgets, but as things stand the widgets will assume a fixed
#default size, and if the window is resized the widgets will not change size to shrink or
#grow to fit. The next piece of code solves this problem and completes the initializer.

#part 5
        frame.columnconfigure(0, weight=999)
        frame.columnconfigure(1, weight=1)
        frame.rowconfigure(0, weight=1)
        frame.rowconfigure(1, weight=999)
        frame.rowconfigure(2, weight=1)
        window = self.parent.winfo_toplevel()
        window.columnconfigure(0, weight=1)
        window.rowconfigure(0, weight=1)

        self.parent.geometry("{0}x{1}+{2}+{3}".format(400, 500, 0, 50))
        self.parent.title("Bookmarks - Unnamed")

#The columnconfigure() and rowconfigure() methods allows us to give weightings to a grid.
#We begin with the window frame, giving all the weight to the first column and the second
#row (which is occupied by the list box), so if the frame is resized any excess space is
#given to the list box. On its own this is not sufficient; we must also make the top-level
#window that contains the frame resizeable, and we do this by getting a reference to the 
#window using the wininfo_toplevel() method, and them making the window resizable by setting
#its row and column weights to 1.

#At the end of the initializer we set an initial window size and position using a string
#of the form widthxheight+x+y. (If we wanted to set only the size we could use the form
#widthxheight instead.) Finally, we set the window's title, thereby completing the window's
#user interface.

#If the user clicks a toolbar or chooses a menu option a method is called to carry out the 
#required action. And some of these methods rely on helper methods. We will now review all
#the methods in turn, starting with one that is called five seconds after the program starts.

#part 6
    def clearStatusBar(self):
        self.statusbar["text"] = ""

#The status bar is a simple tkinter.Label. We could have used a lambda expression in the
#after() method call to clear it, but since we need to clear the status bar from more than
#one place we have created a method to do it.

#part 7
    def fileNew(self, *ingore):
        if not self.okayToContinue():
            return
        self.listBox.delete(0, tkinter.END)
        self.dirty = False
        self.filename = None 
        self.data = {}
        self.parent.title("Bookmarks - Unnamed")

#If the user wants to create a new bookmars file we must first give them the chance to save
#any unsaved changes in the existing file if there is one. This is factored out into the
#MainWindow.okayToContinue() method since it is used in a few different places. The method
#returns True if is okay to continue, and False otherwise. If continuing, we clear the list
#box by deleting all its entries from the first to the last -- tkinter.END is a constant
#used to signify the last item in contexts where a widget can contain multiple items. Then we
#clear the dirty flag, fliename, and data, since the file is new and unchanged, and we set
#the window title to reflect the fact that we have a new but unsaved file.

#The ignore variable holds a sequence of zero or more positional arguments that we dont 
#care about. In the case of methods invoked as a result of menu options choices or toolbar
#button presses there are no ignored arguments, but if a keyboard shortcut is used (Ctrl+N),
#then the invoking event is passed, and since we dont care how the user invoked the action, we
#ignore the event that requested it.

#part 8
    def okayToContinue(self):
        if not self.dirty:
            return True
        reply = tkinter.messagebox.askyesnocancel("Bookmarks - Unsaved Changes", "Save unsaved changes?", parent=self.parent)
        if reply is None:
            return False
        if reply:
            return self.fileSave()
        return True

#If the user wants to perform an action that will clear the list box (creating or opening a
#new file, for example), we must give them a chance to save any unsaved changes. If the file
#is NOT dirty there are no changes to save, so we return True right away. Othewsie, we pop up
#a standard message box with Yes, No, and Cancel buttons. If the user cancels the reply is None;
#we take this to mean that they dont want to continue the action they started and dont want to
#save, so we just return False. If the user says yes, reply is True, so we give them the chance
#to save and return True if they saved and False otherwise. And if the user says no, reply is
#False, telling us not to save, but we still return True b/c they want to continue the action
#they started, adbandoning their unsaved changes.

#Tk's standard dialogs are not imported by import tkinter, so in addition to that import we
#must do 
import tkinter.messagbox #, and for the following method,
import tkinter.filedialog #. On Windows and Mac OS X the standard native dialogs are used, 
#whereas on other platforms Tk-specific dialogs are used. We always give the parent to
#standard dialogs since this ensures that they are automatically centered over the parent
#window when they pop up.

#All the standard dialogs are
modal #which means that once one pops up, it is the only window in the program that the user
#can interact with, so they must close it (by clicking OK, Open, Cancel, or a similar button)
#before they can interact with the rest of the program. Modal dialogs are easiest for
#programmers to work with since the user cannot change the program's state behind the dialog's
#back, and b/c they block until they are closed. The blocking means that when we create or 
#invoke a modal dialog the statement that follows will be executed only when the dialog is
#closed.

#part 9
    def fileSave(self, *ignore):
        if self.filename is None:
            filename = tkinter.filedialog.asksaveasfilename(title="Bookmarks - Save File", initialdir=".", filetypes=[("Bookmarks files", "*.bmf)")], defaultextension=".bmf", parent=self.parent)
            if not filename:
                return False
            self.filename = filename
            if not self.filename.endswith(".bmf"):
                self.filename += ".bmf"
        try:
            with open(self.filename, "wb") as fh:
                pickle.dump(self.data, fh, pickle.HIGHEST_PROTOCOL)
            self.dirty = False
            self.setStatusBar("Saved {0} items to {1}".format(len(self.data), self.filename))
            self.parent.title("Bookmarks - {0}".format(os.path.basename(self.filename)))
        except (EnvironmentError, pickle.PickleError) as err:
            tkinter.messagbox.showwarning("Bookmarks - Error", "Failed to save {0}:\n{1}".format(os.path.basename(self.filename)))
        return True

#If there is no current file we must ask the user to choose a filename. If they cancel we 
#return False to indicate that the entire operation should be cancelled. Otherwise, we make
#sure that the given filename has the right extension. Using the existing or new filename we
#we save the pickled self.data dictionary into the file. After saving the bookmarks we clear
#the dirty flag since there are now no unsaved changes, and put a message on the status bar
#(which will time out as we will see in a moment), and we update the window's title bar to 
#include the filename (without the path). If we could not save the file, we pop up a warning
#message box (which will automatically have an OK button) to inform the user.

#part 10
    def setStatusBar(self, text, timeout=5000):
        self.statusbar["text"] = text
        if timeout:
            self.statusbar.after(timeout, self.clearStatusBar)

#This method sets the status bar label's text, and if there is a timeout (a five second
#timeout is the default), the method sets up a single shot timer to clear the status bar
#after the timeout period.

#part 11
    def fileOpen(self, *ignore):
        if not self.okayToContinue():
            return
        dir = (os.path.dirname(self.filename) if self.filename is not None else ".")
        filename = tkinter.filddialog.askopenfilename(title="Bookmarks - Open File", initialdir=dir, filetypes=[("Bookmark files", "*.bmf")], defaultextension=".bmf", parent=self.parent)

        if filename:
            self.loadFile(filename)

#This method starts off the same as MainWindow.fileNew() to give the user the chance to save
#any unsaved changes or to cancel the file open again. If the user chooses to continue we want
#to give them a sensible starting directory, so we use the dictionary of the current file if
#there is one, and the current working diectory otherwise. The filetypes argument is a list
#of (description, wildcard) 2-tuples that the file dialog should show. If the user chose a 
#filename, we set the current filename to the one they chose and call the loadFile() method to
#do the actual file reading.

#Separating out the loadFile() method is common practice to make it easier to load a file
#without having the prompt the user. For example, some programs load the last used file at
#start-up, and some programs have recently used files listed in a menu so that when the user
#chooses one the loadFile() method is called directly with the menu option's associated filename.

#part 12
    def loadFile(self, filename):
        self.filename = filename
        self.listBox.delete(0, tkinter.END)
        self.dirty = False
        try:
            with open(self.filename, "rb") as fh:
                self.data = pickle.load(fh)
            for name in sorted(self.data, key=str.lower):
                self.listBox.insert(tkinter.END, name)
            self.setStatusBar("Loaded {0} bookmarks from {1}".format(self.listBox.size(), self.filename))
            self.parent.title("Bookmarks = {0}".format(os.path.basename(self.filename)))
        except (EnvironmentError, pickle.PickleError) as err:
            tkinter.messagbox.showwarning("Bookmarks - Error", "Failed to load {0}:\n".format(self.filename, err), parent=self.parent)

#When this method is called we know that any unsaved changes have been saved or abandoned, so
#we are free to clear the list box. We set the current filename to the one passed in, clear
#the list box and dirty flag, and then attempt to open the file and unpickle it into the 
#self.data dictionary. Once we have the data we iterate over all the bookmark names and
#append each one to the list box. Finally, we give an informative message in the status bar
#and update the window's title bar. If we could not read the file or if we could not unpickle
#it, we pop up a warning message box to inform the user.

#part 13
    def fileQuit(self, event=None):
        if self.okayToContinue():
            self.parent.destry()

#This is the last file menu option method. We give the user the chance to save any unwanted
#changes; if they cancel we do nothing and the program continues; otherwise, we tell the
#parent to destroy itself and this leads to a clean program termination. If we wanted to 
#save user preferences we would so here, just before the destroy() call.

#part 14
    def editAdd(self, *ignore):
        form = AddEditForm(self.parent)
        if form.accepted and form.name:
            self.data[form.name] = form.url
            self.listBox.delete(0, tkinter.END))
            for name in sorted(self.data, key=str.lower):
                self.listBox.insert(tkinter.END, name)
            self.dirty = True

#If the user asks to add a new bookmark (by clicking Edit--> Add, or by clicking the + toolbar
#button, or by pressing the Ctrl+A keyboard shortcut), this method is called. The AddEditForm
#is a custom dialog covered in the next subsection; all that we need to know to use it is that
#it has an accepted flag which is set to True if the user clicked OK, and to False if they
#clicked Cancel, and two data attributes, name and url, that hold the name and URL of the
#bookmark the user has added or edited.

#We create a new AddEditForm which immediately pops up as a model dialog -- and therefore 
#blocks, so the if form.acceped ... statement is not executed until the dialog has closed.

#if the user clicked OK in the AddEditForm dialog and they gave the bookmark a name, we add
#the new bookmark's name and URL to the self.data dictionary. Then we clear the list box and 
#reinsert all teh data in sorted order. It would be more efficient to simply insert the new#
#bookmark in the right place, but even with hundreds of bookmarks the difference would hardly
#be noticeable on a modern machine. At the end we set the dirty flag since we now have an
#unsaved change.

#part 15
    def editEdit(self, *ignore):
        indexes = self.listBox.curselection()
        if not indexes or len(indexes) > 1:
            return
        index = indexes[0]
        name = self.listBox.get(index)
        form = AddEditForm(self.parent, name, self.data[name])
        if form.accepted and form.name:
            self.data[form.name] = form.url 
            if form.name != name:
                del self.data[name]
                self.listBox.delete(0, tkinter.END)
                for name in sorted(self.data, key=str.lower):
                    self.listBox.insert(tkinter.END, name)
            self.dirty = True

#Editing is slightly more involved than adding b/c first we must find the bookmark the
#suer wants to edit. The curselection() method returns a (possibly empty) list of index
#positions for all its selected items. If exactly one item is selected we retrieve its
#text since that is the name of the bookmark the user wants to edit (and also the key
#to the self.dictionary). We then create a new AddEditForm passing the name and URL of the
#bookmark the user wants to edit.

#After the form has been closed, if the user chlicked OK and set a nonempty bookmark
#name we update the self.data dictionary. If the new name and the old name are the 
#same we can just set the dirty flog and we are finished (in this case presumably the
#use edited the URL), but if the bookmarks name has changed we delete the dictionary
#item whose key is the old name, clear the list box, and then repopulate the list box
#with the bookmarks just as we did after adding a bookmark.

#part 16
    def editDelete(self, *ignore):
        indexes = self.listBox.curselection()
        if not indexes or len(indexes) > 1:
            return
        index = indexes[0]
        name = self.listBox.get(index)
        if tkinter.messagebox.askyesno("Bookmarks - Delete", "Delete '{0}'?".format(name)):
            self.listBox.delete(index)
            self.listBox.focus_set()
            del self.data[name]
            self.dirty = True

#To delete a bookmark we must first find out which bookmark ths user has chosen, so this
#method begins with the same lines that the MainWindow.editEdit() method starts with. If
#exactly one bookmark is selected we pop up a message box asking the user whether they
#really want to delete it. If they say yes the message box function returns True and we
#delete the bookmark from the list box and from the self.data dictionary, and set the
#dirty flag. We also set the keyboard focus back to the list box.

#part 17            
    def editShowWebPage(self, *ingore):
        index = self.listBox.curselection()
        if not indexes or len(indexes) > 1:
            return
        index = indexes[0]
        url = self.data[self.listBox.get(index)]
        webbrowser.open_new_tab(url)

#If the user invokes this method we find the bookmark they have selected and retrieve
#the corresponding URL from the self.data dictionary. Then we use the webbrowser module's 
webbrowser.opennew_tab() #function to open the user's web browser with the given URL. If
#the web brower is not alread running, it will be launched.

#part 18
    application = tkinter.Tk()
    path = os.path.join(os.path.dirname(__file__), "images/")
    if sys.path.startswith("win"):
        icon = path + "bookmark.ico"
        application.iconbitmap(icon, default=icon)
    else:
        application.iconbitmap("@" + path + "bookmark.xbm")
    window = MainWindow(application)
    application.protocol("WM_DELETE_WINDOW", window.fileQuit)
    application.mainloop()

#The last lines of the program are similar to those used for the interest-tk.pyw program
#we saw earlier, but with three differences. One difference is that if the user clicks
#the program window's close box a different method is called for the Bookmarks program
#than the one used for the Interest program. Another difference is that on Windows the
iconbitmap() #method has an additional argument which allows us to specify a default icon
#for all the program's windows -- this is not needed on Unix platforms since this 
#happens automatically. And the last difference is that we set the application's title (in
#the title bar) in the MainWindow class's methods rather than here. For the Interest
#program the title never changed, so it needed to be set only once, but for the Bookmarks
#program we change the title text to include the name of the bookmarks file being worked on.

#Now that we have seen the implementation of the main window's class and the code that
#initiates the program and starts off the event loop, we can turn out attention to the 
#AddeEditForm dialog.



#Reminder of topics<===========
Dialog-Style Programs                   
Main-Window-Style Programs 
    Creating a Main Window 
    Creating a Custom Dialog 
Summary
Exercises 
#1) 
#2)

#CODE LISTING HERE
bookmarks-tk.pyw
bookmarks-tk_ans.pyw
interest-tk.pyw
regex-tk.pyw


===============
    Creating a Custom Dialog 
===============

#The AddEditForm dialog provides a means by which users can add and edit bookmark names
#and URLs. It is shown in Figure 15.6 where it is being used to edit an existing bookmark
#(hence the "Edit" in the title). The same dialog can also be used for adding bookmarks. We
#will begin by reviewing the dialog's initializer, broken into four parts.

    class AddEditForm(tkinter.Toplevel):

        def __init__(self, parent, name=None, url=None):
            super().__init__(parent)
            self.parent = parent
            self.accepted = False
            self.transient(self.parent)
            self.title("Bookmarks - " + ("Edit" if name is not None else "Add"))

            self.nameVar = tkinter.StringVar()
            if name is not None:
                self.nameVar.set(name)
            self.urlVar = tkinter.StringVar()
            self.urlVar.set(url if url is not None else "http://")

#We have chosen to inherit tkinter.TopLevel, a bare widget designed to serve as a base
#class for widgets used as top-level windows. We keep a reference to the parent and create
#a self.accepted attribute and set it to False. The call to the transient() method is done
#to inform the parent window that this window must always appear on top of the parent. The
#title is set to indicate adding or editing depending on whether a name and URL have been 
#passed in. Two tkinter.StringVars are created to keep track of the bookmark's name and URL,
#and both are initialized with the passed-in values if the dialog is being used for editing.

        frame = tkinter.Frame(self)
        nameLabel =tkinter.Label(frame, text="Name:", underline=0)
        nameEntry = tkinter.Entry(frame, textvariable=self.nameVar)
        nameEntry.focus_set()
        urlLabel = tkinter.Label(frame, text="URL:", underline=0)
        urlEntry =tkinter.Entry(frame, textvariable=self.urlVar)
        okButton = tkinter.Button(frame, text="OK", command=self.ok)
        nameLabel.grid(row=0, column=0, sticky=tkinter.W, pady=3, padx=3)
        urlLabel.grid(row=1, column=0, stick=tkinter.W, pady=3, padx=3)
        rulEntry.grid(row=1, column=1, columnspan=3, sticky=tkinter.EW, pady=3, padx=3)
        okButton.grid(row=2, column=2, stick=tkinter.EW, pady=3, padx=3)
        cancelButton.grid(row=2, column=3, sticky=tkinter.EW, pady=3, padx=3)

#The widgets are created and laid out in a grid, as illustrated in Figure 15.7 The name
#and URL text entry widgets are associated with the corresponding tkinter.StringVars and
#the two buttons are set to call the self.ok() and self.close() methods shown further on.

        frame.grid(row=0, column=0, sticky=tkinter.NSEW)
        frame.columnconfigure(1, weight=1)
        window = self.winfo_toplevel()
        window.columnconfigure(0, weight=1)

#It only makes sense for the dialog to be resized horizontally, so we make the window
#frame's second column horizontally resizeable by setting its column weight to 1 -- this
#means that if the frame is horizontally stretched the widgets in column 1 (the name and 
#URL text entry widgets) will grow to take advantage of the extra space.

        self.bind("<Alt-n>", lambda *ignore: nameEntry.focus_set())
        self.bind("<Alt-u>", lambda *ignore: urlEntry.focus_set())
        self.bind("<Return>", self.ok)
        self.bind("<Escape>" self.close)

        self.protocol("WM_DELETE_WINDOW", self.close)
        self.grab_set()
        self.wait_window(self)

#We created two labels, Name: and URL:, which indicate that they have keyboard
#accelerators Alt+N and Alt+U which when clicked will give the keyboard focus to their
#corresponding text entry widgets. To make this work we have provided the necessary keyboard
#bindings. We use lambda functions rather then pass the focus_set() methods directly so that
#we can ignore the event argument. We have also provided the standard keyboard bindings 
#(Enter and Esc) for the OK and Cancel buttons.

#We use the protocol() method to specify the method to call if the user closes the dialog
#by clicking the close button. The calls to grab_set() and wait_window() are both
#needed to turn the window into a modal dialog.

    def ok(self, event=None):
        self.name = self.nameVar.get()
        self.url = self.urlVar.get()
        self.accepted = True
        self.close()

#If the user clicks OK (or presses Enter), this method is called. The texts from the
#tkinter.StringVars are copied to correspdoning instance variables (which are only now
#created), the self.accepted variable is set to True, and we call self.close() to close 
#the dialog.

    def close(self, event=None):
        self.parent.focus_set()
        self.destroy()

#This method iscalled from the self.ok() method, or if the user clicks the window's close
#box or if the user clicks Cancel (or presses Esc). It gives the keyboard focus back to the
#parent and makes the dialog destroy itself. In this context destroy just means that the 
#window and its widgets are destroyed; the AddEditForm instance continues to exist b/c the
#caller has a reference to it.

#After the dialog has been closed the called checks teh accepted variable, and if True,
#retrieves the name and URL that were added or edited. Then, once the MainWindow.editAdd()
#or MainWindow.editEdit() method has finished, the AddEditForm object goes out of scope
#and is scheduled for garbage collection.


#Reminder of topics<===========
Dialog-Style Programs                   
Main-Window-Style Programs 
    Creating a Main Window 
    Creating a Custom Dialog 
Summary
Exercises 
#1) 
#2)

#CODE LISTING HERE
bookmarks-tk.pyw
bookmarks-tk_ans.pyw
interest-tk.pyw
regex-tk.pyw



#CODE HERE
bookmarks-tk.pyw

#!/usr/bin/env python3

import os
import pickle
import sys
import tkinter
import tkinter.filedialog
import tkinter.messagebox
import webbrowser


class AddEditForm(tkinter.Toplevel):

    def __init__(self, parent, name=None, url=None):
        super().__init__(parent)
        self.parent = parent
        self.accepted = False
        self.transient(self.parent)
        self.title("Bookmarks - " + ("Edit" if name is not None else "Add"))

        self.nameVar = tkinter.StringVar()
        if name is not None:
            self.nameVar.set(name)
        self.urlVar = tkinter.StringVar()
        self.urlVar.set(url if url is not None else "http://")

        frame = tkinter.Frame(self)
        nameLabel = tkinter.Label(frame, text="Name:", underline=0)
        nameEntry = tkinter.Entry(frame, textvariable=self.urlVar)
        nameEntry.focus_set()
        urlLabel = tkinter.Label(frame, text="URL:", underline=0)
        urlEntry = tkinter.Entry(frame, textvariable=self.urlVar)       CHECK THIS urlVar or nameVar?
        okButton = tkinter.Button(frame, text="OK", command=self.ok)
        cancelButton = tkinter.Button(frame, text="Cancel", command=self.close)

        nameLabel.grid(row=0, column=0, sticky=tkinter.W, pady=3, padx=3)
        nameEntry.grid(row=0, column=1, columnspan=3, sticky=tkinter.EW, pady=3, padx=3)
        urlLabel.grid(row=1, column=0, sticky=tkinter.W, pady=3, padx=3)
        urlEntry.grid(row=1, column=1, columnspan=3, sticky=tkinter.EW, pady=3, padx=3)
        okButton.grid(row=2, column=2, sticky=tkinter.EW, pady=3, padx=3)
        cancelButton.grid(row=2, column=3, sticky=tkinter.EW, pady=3, padx=3)

        frame.grid(row=0, column=0, sticky=tkinter.NSEW)
        frame.columnconfigure(1, weight=1)
        window = self.winfo_toplevel()
        window.columnfigure(0, weight=1)

        self.bind("<Alt-n>", lambda *ignore: nameEntry.focus_set())
        self.bind("<Alt-u>", lambda *ignore: urlEntry.focus_set())
        self.bind("<Return>", self.ok)
        self.bind("<Escape>", self.close)

        self.protocol("WM_DELETE_WINDOW", self.close)
        self.grab_set()
        self.wait_window(self)


    def ok(self, event=None):
        self.name = self.nameVar.get()
        self.url = self.urlVar.get()
        self.accepted = True
        self.close()


    def close(self, event=None):
        self.parent.focus_set()
        self.destroy()


class MainWindow:

    def __init__(self, parent):
        self.parent = parent

        self.filename = None
        self.dirty = False
        self.data = {}

        menubar = tkinter.Menu(self.parent)
        self.parent["menu"] = menubar

        fileMenu = tkinter.Menu(menubar)
        for label, command, shortcut_text, shortcut in (
            ("New...", self.fileNew, "Ctrl+N", "<Control-n>"),
            ("Open...", self.fileOpen, "Ctrl+O", "<Control-o>"),
            ("Save", self.fileSave, "Ctrl+S", "<Control-s>"),
            (None, None, None, None),
            ("Quit", self.fileQuit, "Ctrl+Q", "<Control-q>"))
        if label is None:
            fileMenu.add_separator()
        else:
            fileMenu.add_command(label=label, underline=0, command=command, accelerator=shortcut_text)
            self.parent.bind(shortcut, command)
        menubar.add_cascade(label="File", menu=fileMenu, underline=0)

        editMenu = tkinter.Menu(menubar)
        for label, command, shortcut_text, shortcut in (
                ("Add...", self.editAdd, "Ctrl+A", "<Control-a>"),
                ("Edit...", self.editEdit, "Ctrl+E", "<Control-e>"),
                ("Delete...", self.editDelete, "Delete", "<Delete>"),
                (None, None, None, None),
                ("SHow Web Page...", self.editShowWebPage, "Ctrl+W", "<Control-w>")):
            if label is None:
                editMenu.add_separator()
            else:
                editMenu.add_command(label=label, underline=0, command=command, accelerator=shortcut_text)
                self.parent.bind(shortcut, command)
        menubar.add_cascade(label="Edit", menu=editMenu, underline=0)

        frame = tkinter.Frame(self.parent)
        self.toolbar_images = []
        toolbar = tkinter.Frame(frame)
        for image, command in (
                ("images/filenew.gif", self.fileNew),
                ("images/fileopen.gif", self.fileOpen),
                ("images/filesave.gif", self.fileSave),
                ("images/editadd.gif", self.editAdd),
                ("images/editedit.gif", self.editEdit),
                ("images/editdelete.gif", self.editDelete),
                ("images/editshowwebpage.gif", self.editShowWebPage)):
            image = os.path.join(os.path.dirname(__file__), image)
            try:
                image = tkinter.PhotoImage(file=image)
                self.toolbar_images.append(image)
                button = tkinter.Button(toolbar, image=image, command=command)
                button.grid(row=0, column=len(self.toolbar_images)-1)
            except tkinter.TclError as err:
                print(err)
            toolbar.grid(row=0, column=0, columnspan=2, sticky=tkinter.NW)

            scrollbar = tkinter.Scrollbar(frame, orient=tkinter.VERTICAL)
            self.listBox = tkinter.ListBox(frame, yscrollcommand=scrollbar.set)
            self.listBox.grid(row=1, column=0, sticky=tkinter.NSEW)
            self.listBox.focus_set()
            scroll["command"] = self.listBox.yview 
            scrollbar.grid(row=1, column=1, sticky=tkinter.NS)

            self.statusbar = tkinter.Label(frame, text="Ready...", anchor=tkinter.W)
            self.statusbar.after(5000, self.clearStatusBar)
            self.statusbar.grid(row=2, column=0, columnspan=2, sticky=tkinter.EW)

            frame.grid(row=0, column=0, sticky=tkinter.NSEW)

            frame.columnconfigure(0, weight=999)
            frame.columnconfigure(1, weight=1)
            frame.rowconfigure(0, weight=1)
            frame.rowconfigure(1, weight=999)
            frame.rowconfigure(2, weight=1)

            window = self.parent.winfo_toplevel()
            window.columnconfigure(0, weight=1)
            window.rowconfigure(9, weight=1)

            self.parent.geometry("{0}x{1}+{2}+{3}".format(400, 500, 0, 50))
            self.parent.title("Bookmarks - Unnamed")


    def setStatusBar(self, text, timeout=5000):
        self.statusbar["text"] = text
        if timeout:
            self.statusbar.after(timeout, self.clearStatusBar)


    def clearStatusBar(self):
        self.statusbar["text"] = ""


    def fileNew(self, *ignore):
        if not self.okayToContinue():
            return 
        self.listBox.delete(0, tkinter.END)
        self.dirty = False 
        self.filename = None 
        self.data = {}
        self.parent.title("Bookmarks - Unnamed")


    def fileOpen(self, *ignore):
        if not self.okayToContinue():
            return 
        dir = (os.path.dirname(self.filename) if self.filename is not None else ".")
        filename = tkinter.filedialog.askopenfilename(
                            title="Bookmarks - Open File",
                            initialdir=dir,
                            filetypes=[("Bookmarks files", "*.bmf")],
                            defaultextension=".bmf", parent=self.parent)
        if filename:
            self.loadFile(filename)

        
    def loadFile(self, filename):
        self.filename = filename 
        self.listBox.delete(0, tkinter.END)
        self.dirty = False
        try:
            with open(self.filename, "rb") as fh:
                self.data = pickle.load(fh)
            for name in sorted(self.data, key=str.lower):
                self.listBox.insert(tkinter.END, name)
            self.setStatusBar("Loaded {0} bookmarks from {1}".format(self.listBox.size(), self.filename))
            self.parent.title("Bookmarks - {0}".format(os.path.basename(self.filename)))
        except (EnvironmentError, pickle.PickleError) as err:
            tkinter.messagbox.showwarning("Bookmarks - Error", "Failed to load {0}:\n{1}".format(self.filename, err), parent=self.parent)


    def fileSave(self, *ignore):
        if self.filename is None:
            filename = tkinter.filedialog.asksaveasfilename(
                            title="Bookmarks - Save File",
                            initialdir=".",
                            filetypes=[("Bookmarks files", "*.bmf")],
                            defaultextension=".bmf",
                            parent=self.parent)
            if not filename:
                return False
            self.filename = filename
            if not self..filename.endswith(".bmf"):
                self.filename += ".bmf"
        try:
            with open(self.filename, "wb") as fh:
                pickle.dump(self.data, fh, pickle.HIGHEST_PROTOCOL)
            self.dirty = False
            self.setStatusBar("Saved {0} items to {1}".format(len(self.data), self.filename))
            self.parent.title("Bookmarks - {0}".format(os.path.basename(self.filename)))
        except (EnvironmentError, pickle.PickleError) as err:
            tkinter.messagebox.showwarning("Bookmarks - Error", "Failed to save {0}:\n{1}".format(
                    self.filename, err), parent=self.parent)
        return True 


    def editAdd(self, *ignore):
        form = AddEditForm(self.parent)
        if form.acccepted and form.name:
            self.data[form.name] = form.url
            self.listBox.delete(0, tkinter.END)
            for name in sorted(self.data, key=str.lower):
                self.listBox.insert(tkinter.END, name)
            self.dirty = True 

    def editEdit(self, *ignore):
        indexes = self.listBox.curselection()
        if not index or len(indexes) > 1:
            return 
        index = indexes[0]
        name = self.listBox.get(index)
        form = AddEditForm(self.parent, name, self.data[name])
        if form.accepted and form.name:
            self.data[form.name] = form.url
            if form.name != name:
                del self.data[name]
                self.listBox.delete(0, tkinter.END)
                for name in sorted(self.data, key=str.lower):
                    self.listBox.insert(tkinter.END, name)
            self.dirty = True


    def editDelete(self, *ignore):
        indexes = self.listBox.curselection()
        if not indexes or len(indexes) > 1:
            return 
        index = indexes[0]
        name = self.listBox.get(index)
        if tkinter.messagebox.askyesno("Bookmarks - Delete", "Delete '{0}'?".format(name)):
            self.listBox.delete(index)
            self.listBox.focus_set()
            del self.data[name]
            self.dirty = True 


    def editShowWebPage(self, *ignore):
        indexes = self.listBox.curselection()
        if not indexes or len(indexes) > 1:
            return 
        index = indexes[0]
        url = self.data[self.listBox.get(index)]
        webbrowser.open_new_tab(url)


    def fileQuit(self, event=None):
        if self.okayToContinue():
            self.parent.destroy()


    def okayToContinue(self):
        if not self.dirty:
            return True
        reply = tkinter.messagebox.askyesnocancel(
                        "Bookmarks - Unsaved Changes",
                        "Save unsaved changes?", parent=self.parent)
        if reply is None:
            return False 
        if reply:
            return self.fileSave()
        return True


application = tkinter.Tk()
path = os.path.join(os.path.dirname(__file__), "images/")
if sys.platform.startswith("win"):
    icon = path + "bookmark.ico"
    application.iconbitmap(icon, default=icon)
else:
    application.iconbitmap("@" + path + "bookmark.xbm")
window = MainWindow(application)
application.protocol("WM_DELETE_WINDOW", window.fileQuit)
application.mainloop()






#Reminder of topics<===========
Dialog-Style Programs                   
Main-Window-Style Programs 
    Creating a Main Window 
    Creating a Custom Dialog 
Summary
Exercises 
#1) 
#2)

===============
Summary
===============

#This chapter gave you a flavor of GUI programming using the Tk GUI library. Tk's big 
#advantage is that it comes as standard with Python. But it has mnay drawbacks, not the
#least of which is that it is avintage library that works somewhat differently than
#most of the more modern alternatives.

#If you are new to GUI programming, keep in mind that the major cross-platform competitors
#to Tk -- PyGtk, PyQt, and wxPython -- are all must easier to learn and use than Tk, and all
#call achieve better results using less code. Furthermore, these Tk competitors all have more
#and better Python specific documentation, for mor widgets, and a better look and feel, and
#allow us to create widgets from scratch with complete control over their appearances and
#behavior.

#Although Tk is useful for creating very small programs or for situations where only 
#Python's standard library is available, in all other circumstances any one of the other
#cross-platform libraries is a much better choice.


===============
Exercises 
===============

#The first exercise involves copying and modifying the Bookmarks program shown in this
#chapter; the second exercise involves creating a GUI program from scratch.

#1)Copy the bookmarks-tk.pyw program 
(DONE)
#and modify it so that it can import and export
#the DBM files that the bookmarks.py console program (created as an exercise in Chapter 12)
#uses. Provide two new menu options in the File menu, Import and Export with I and E underlined.
#Make sure you provide keyboard shortcuts for both (keep in mind that Ctrl+E is already in use
#for Edit-->Edit). Similarly, create two corresponding toolbar buttons. This involves adding
#about five lines of code tothe main window's initializer.

#Two methods to provide the functionality will be required, fileImport() and fileExport(),
#between them fewer than 60 lines of code including error handling. For importing you can 
#decide whether to merge imported bookmarks, or to replace the existing bookmarks with
#those imported. The code is not difficult, but does require quite a bit of care. Solution that
#merges imported bookmarks is provided in 
bookmarks-tk_ans.py

#Note that while on Unix-like systems a file suffix of .dbm is fine, on Windows each DBM "file"
#is actually three files. So for Windows file dialogs the pattern should be *.dbm.dat and
#the default extension is .dbm.dat -- but the actual filename should have a suffix of .dbm, so
#the last four characters must be chopped off the filename.


#CODE LISTING HERE
bookmarks-tk.pyw
bookmarks-tk_ans.pyw
interest-tk.pyw
regex-tk.pyw


#CODE HERE
bookmarks-tk_ans.pyw

#!/usr/bin/env python3

import dbm                  #new
import os
import pickle
import shelve               #new
import sys
import tkinter
import tkinter.filedialog
import tkinter.messagebox
import webbrowser


class AddEditForm(tkinter.Toplevel):

    def __init__(self, parent, name=None, url=None):
        super().__init__(parent)
        self.parent = parent
        self.accepted = False
        self.transient(self.parent)
        self.title("Bookmarks - " + ("Edit" if name is not None else "Add"))

        self.nameVar = tkinter.StringVar()
        if name is not None:
            self.nameVar.set(name)
        self.urlVar = tkinter.StringVar()
        self.urlVar.set(url if url is not None else "http://")

        frame = tkinter.Frame(self)
        nameLabel = tkinter.Label(frame, text="Name:", underline=0)
        nameEntry = tkinter.Entry(frame, textvariable=self.nameVar)
        nameEntry.focus_set()
        urlLabel = tkinter.Label(frame, text="URL:", underline=0)
        urlEntry = tkinter.Entry(frame, textvariable=self.urlVar)
        okButton = tkinter.Button(frame, text="OK", command=self.ok)
        cancelButton = tkinter.Button(frame, text="Cancel", command=self.close)

        nameLabel.grid(row=0, column=0, sticky=tkinter.W, pady=3, padx=3)
        nameEntry.grid(row=0, column=1, columnspan=3, sticky=tkinter.EW, pady=3, padx=3)
        urlLabel.grid(row=1, column=0, sticky=tkinter.W, pady=3, padx=3)
        urlEntry.grid(row=1, column=1, columnspan=3, sticky=tkinter.EW, pady=3, padx=3)
        okButton.grid(row=2, column=2, sticky=tkinter.EW, pady=3, padx=3)
        cancelButton.grid(row=2, column=3, sticky=tkinter.EW, pady=3, padx=3)

        frame.grid(row=0, column=0, sticky=tkinter.NSEW)
        frame.columnconfigure(1, weight=1)
        window = self.winfo_toplevel()
        window.columnfigure(0, weight=1)

        self.bind("<Alt-n>", lambda *ignore: nameEntry.focus_set())
        self.bind("<Alt-u>", lambda *ignore: urlEntry.focus_set())
        self.bind("<Return>", self.ok)
        self.bind("<Escape>", self.close)

        self.protocol("WM_DELETE_WINDOW", self.close)
        self.grab_set()
        self.wait_window(self)


    def ok(self, event=None):
        self.name = self.nameVar.get()
        self.url = self.urlVar.get()
        self.accepted = True
        self.close()


    def close(self, event=None):
        self.parent.focus_set()
        self.destroy()


class MainWindow:

    def __init__(self, parent):
        self.parent = parent

        self.filename = None
        self.dirty = False
        self.data = {}

        menubar = tkinter.Menu(self.parent)
        self.parent["menu"] = menubar

        fileMenu = tkinter.Menu(menubar)
        for label, command, shortcut_text, shortcut in (
            ("New...", self.fileNew, "Ctrl+N", "<Control-n>"),
            ("Open...", self.fileOpen, "Ctrl+O", "<Control-o>"),
            ("Save", self.fileSave, "Ctrl+S", "<Control-s>"),
            (None, None, None, None),
            ("Import", self.fileImport, "Ctrl+I", "<Control-i>"),   #new NEED TO CHECK OLD VERSION
            ("Export", self.fileExport, "Ctrl+X", "<Control-x>"),   #new NEED TO CHECK OLD VERSION
            (None, None, None, None),                               #new NEED TO CHECK OLD VERSION
            ("Quit", self.fileQuit, "Ctrl+Q", "<Control-q>"))
        if label is None:
            fileMenu.add_separator()
        else:
            fileMenu.add_command(label=label, underline=0, command=command, accelerator=shortcut_text)
            self.parent.bind(shortcut, command)
        menubar.add_cascade(label="File", menu=fileMenu, underline=0)

        editMenu = tkinter.Menu(menubar)
        for label, command, shortcut_text, shortcut in (
                ("Add...", self.editAdd, "Ctrl+A", "<Control-a>"),
                ("Edit...", self.editEdit, "Ctrl+E", "<Control-e>"),
                ("Delete...", self.editDelete, "Delete", "<Delete>"),
                (None, None, None, None),
                ("SHow Web Page...", self.editShowWebPage, "Ctrl+W", "<Control-w>")):
            if label is None:
                editMenu.add_separator()
            else:
                editMenu.add_command(label=label, underline=0, command=command, accelerator=shortcut_text)
                self.parent.bind(shortcut, command)
        menubar.add_cascade(label="Edit", menu=editMenu, underline=0)

        frame = tkinter.Frame(self.parent)
        self.toolbar_images = []
        toolbar = tkinter.Frame(frame)
        for image, command in (
                ("images/filenew.gif", self.fileNew),
                ("images/fileopen.gif", self.fileOpen),
                ("images/filesave.gif", self.fileSave),
                ("images/fileimport.gif", self.fileImport),     #new
                ("images/fileexport.gif", self.fileExport),     #new
                ("images/editadd.gif", self.editAdd),
                ("images/editedit.gif", self.editEdit),
                ("images/editdelete.gif", self.editDelete),
                ("images/editshowwebpage.gif", self.editShowWebPage)):
            image = os.path.join(os.path.dirname(__file__), image)
            try:
                image = tkinter.PhotoImage(file=image)
                self.toolbar_images.append(image)
                button = tkinter.Button(toolbar, image=image, command=command)
                button.grid(row=0, column=len(self.toolbar_images)-1)
            except tkinter.TclError as err:
                print(err)
            toolbar.grid(row=0, column=0, columnspan=2, sticky=tkinter.NW)

            scrollbar = tkinter.Scrollbar(frame, orient=tkinter.VERTICAL)
            self.listBox = tkinter.ListBox(frame, yscrollcommand=scrollbar.set)
            self.listBox.grid(row=1, column=0, sticky=tkinter.NSEW)
            self.listBox.focus_set()
            scroll["command"] = self.listBox.yview 
            scrollbar.grid(row=1, column=1, sticky=tkinter.NS)

            self.statusbar = tkinter.Label(frame, text="Ready...", anchor=tkinter.W)
            self.statusbar.after(5000, self.clearStatusBar)
            self.statusbar.grid(row=2, column=0, columnspan=2, sticky=tkinter.EW)

            frame.grid(row=0, column=0, sticky=tkinter.NSEW)

            frame.columnconfigure(0, weight=999)
            frame.columnconfigure(1, weight=1)
            frame.rowconfigure(0, weight=1)
            frame.rowconfigure(1, weight=999)
            frame.rowconfigure(2, weight=1)

            window = self.parent.winfo_toplevel()
            window.columnconfigure(0, weight=1)
            window.rowconfigure(9, weight=1)

            self.parent.geometry("{0}x{1}+{2}+{3}".format(400, 500, 0, 50))
            self.parent.title("Bookmarks - Unnamed")


    def setStatusBar(self, text, timeout=5000):
        self.statusbar["text"] = text
        if timeout:
            self.statusbar.after(timeout, self.clearStatusBar)


    def clearStatusBar(self):
        self.statusbar["text"] = ""


    def fileNew(self, *ignore):
        if not self.okayToContinue():
            return 
        self.listBox.delete(0, tkinter.END)
        self.dirty = False 
        self.filename = None 
        self.data = {}
        self.parent.title("Bookmarks - Unnamed")


    def fileOpen(self, *ignore):
        if not self.okayToContinue():
            return 
        dir = (os.path.dirname(self.filename) if self.filename is not None else ".")
        filename = tkinter.filedialog.askopenfilename(
                            title="Bookmarks - Open File",
                            initialdir=dir,
                            filetypes=[("Bookmarks files", "*.bmf")],
                            defaultextension=".bmf", parent=self.parent)
        if filename:
            self.loadFile(filename)

        
    def loadFile(self, filename):
        self.filename = filename 
        self.listBox.delete(0, tkinter.END)
        self.dirty = False
        try:
            with open(self.filename, "rb") as fh:
                self.data = pickle.load(fh)
            for name in sorted(self.data, key=str.lower):
                self.listBox.insert(tkinter.END, name)
            self.setStatusBar("Loaded {0} bookmarks from {1}".format(self.listBox.size(), self.filename))
            self.parent.title("Bookmarks - {0}".format(os.path.basename(self.filename)))
        except (EnvironmentError, pickle.PickleError) as err:
            tkinter.messagbox.showwarning("Bookmarks - Error", "Failed to load {0}:\n{1}".format(self.filename, err), parent=self.parent)


    def fileSave(self, *ignore):
        if self.filename is None:
            filename = tkinter.filedialog.asksaveasfilename(
                            title="Bookmarks - Save File",
                            initialdir=".",
                            filetypes=[("Bookmarks files", "*.bmf")],
                            defaultextension=".bmf",
                            parent=self.parent)
            if not filename:
                return False
            self.filename = filename
            if not self..filename.endswith(".bmf"):
                self.filename += ".bmf"
        try:
            with open(self.filename, "wb") as fh:
                pickle.dump(self.data, fh, pickle.HIGHEST_PROTOCOL)
            self.dirty = False
            self.setStatusBar("Saved {0} items to {1}".format(len(self.data), self.filename))
            self.parent.title("Bookmarks - {0}".format(os.path.basename(self.filename)))
        except (EnvironmentError, pickle.PickleError) as err:
            tkinter.messagebox.showwarning("Bookmarks - Error", "Failed to save {0}:\n{1}".format(
                    self.filename, err), parent=self.parent)
        return True 


    def fileImport(self, *ignore):
        if not self.okayToContinue():
            return 
        dir = (os.path.dirname(self.filename) if self.filename is not None else ".")
        sufix = ".dbm.dat" if sys.platform.startswith("win") else ".dbm"
        filename = tkinter.filedialog.askopenfilename(
                        title="Bookmarks - Import File",
                        initialdir=dir,
                        filetypes=[("Console bookmarks files", "*" + suffix)],
                        defaultextension=suffix, parent=self.parent)
        if filename:
            if sys.platform.startswith("win"):
                filename = filename[:-4]
            db = None
            try:
                db = shelve.open(filename, protocol=pickle.HIGHEST_PROTOCOL)
                self.dirty = True 
                for name, url in db.items():
                    self.data[name] = url 
                self.listBox.delete(0, tkinter.END)
                for name in sorted(self.data, key=str.lower):
                    self.listBox.insert(tkinter.END, name)
                self.setStatusBar("Imported {0} bookmarks from {1}".format(self.listBox.size(), filename))
            except dbm.error as err:
                tkinter.messagebox.showwarning("Bookmarks - Error", "Failed to import {0}:\n{1}".format(filename, err), parent=self.parent)
            finally:
                if db is not None:
                    db.close()


    def fileExport(self, *ignore):
        suffix ".dbm.dat" if sys.platform.startswith("win") else ".dbm"
        filename = tkinter.filedialog.asksaveasfilename(
                        title="Bookmarks = Export File",
                        initialdir=".",
                        filetypes=[("Console bookmarks files", "*" + suffix)]<
                        defaultextension=suffix, parent=self.parent)
        if filename:
            is sys.platform.startswith("win"):
            filename = filename[:-4]
            db = None 
            try:
                db = shelve.open(filename, protocol.HIGHEST_PROTOCOL)
                for name, url in self.data.items():
                    db[name] = url
                db.sync()
                self.setStatusBar("Exported {0} bookmarks to {1}".format(self.listBox.size(), filename))
            except dbm.error as err:
                tkinter.messagebox.showwarning("Bookmarks - Error", "Failed to export {0}:\n{1}".format(filename, err), parent=self.parent)
            finally:
                if db is not None:
                    db.close()


    def editAdd(self, *ignore):
        form = AddEditForm(self.parent)
        if form.acccepted and form.name:
            self.data[form.name] = form.url
            self.listBox.delete(0, tkinter.END)
            for name in sorted(self.data, key=str.lower):
                self.listBox.insert(tkinter.END, name)
            self.dirty = True 


    def editEdit(self, *ignore):
        indexes = self.listBox.curselection()
        if not index or len(indexes) > 1:
            return 
        index = indexes[0]
        name = self.listBox.get(index)
        form = AddEditForm(self.parent, name, self.data[name])
        if form.accepted and form.name:
            self.data[form.name] = form.url
            if form.name != name:
                del self.data[name]
                self.listBox.delete(0, tkinter.END)
                for name in sorted(self.data, key=str.lower):
                    self.listBox.insert(tkinter.END, name)
            self.dirty = True


    def editDelete(self, *ignore):
        indexes = self.listBox.curselection()
        if not indexes or len(indexes) > 1:
            return 
        index = indexes[0]
        name = self.listBox.get(index)
        if tkinter.messagebox.askyesno("Bookmarks - Delete", "Delete '{0}'?".format(name)):
            self.listBox.delete(index)
            self.listBox.focus_set()
            del self.data[name]
            self.dirty = True 


    def editShowWebPage(self, *ignore):
        indexes = self.listBox.curselection()
        if not indexes or len(indexes) > 1:
            return 
        index = indexes[0]
        url = self.data[self.listBox.get(index)]
        webbrowser.open_new_tab(url)


    def fileQuit(self, event=None):
        if self.okayToContinue():
            self.parent.destroy()


    def okayToContinue(self):
        if not self.dirty:
            return True
        reply = tkinter.messagebox.askyesnocancel(
                        "Bookmarks - Unsaved Changes",
                        "Save unsaved changes?", parent=self.parent)
        if reply is None:
            return False 
        if reply:
            return self.fileSave()
        return True


application = tkinter.Tk()
path = os.path.join(os.path.dirname(__file__), "images/")
if sys.platform.startswith("win"):
    icon = path + "bookmark.ico"
    application.iconbitmap(icon, default=icon)
else:
    application.iconbitmap("@" + path + "bookmark.xbm")
window = MainWindow(application)
application.protocol("WM_DELETE_WINDOW", window.fileQuit)
application.mainloop()



#2)In Chapter 13, we saw how you create and use regular expressions to match text. Create
#a dialog style GUI program that can be used to enter and test regexes, as shows in Figure
#15.8 You will need to read the re module's documentation since the program must behave
#correctly in the face of invalid regexes or when iterating over the match groups, since
#in most cases the regex wont have as many match groups as there are labels to show them.
#Make sure the program has full support for keyboard users -- with navigation to the text
#entry widgets using Alt+R and Alt+T, control of the checkboxes with Alt+I and Alt+D, 
#program termination on Ctrl+Q and Esc, and recalculation if the user presses and releases
#a key in either of the text entry widgets, and whenever a checkbox is checked or unchecked.

#The program is not too difficult to write, although the code for displaying the matches
#and groups the group numbers (and names where specified) is a tiny bit tricky -- solution
#is provided in 
regex-tk.py #which is about 140 lines.


#CODE LISTING HERE
bookmarks-tk.pyw
bookmarks-tk_ans.pyw
interest-tk.pyw
regex-tk.pyw


#CODE HERE
regex-tk.pyw

#!/usr/bin/env python3

import os
import re
import sys
import tkinter

class MainWindow:

    def __init__(self, parent):
        self.parent = parent

        self.regex = tkinter.StringVar()
        self.regex.set(r"(?P<key>\w+)\s*=\s*(?P<value>[\d.]+)\s*(.*)")
        self.text = tkinter.StringVar()
        self.text.set("quantity = 11.95, etc")
        self.ignore._case = tkinter.IntVar()
        self.captures = []
        for i in range(10):
            self.captures.append(tkinter.StringVar())
        self.message = tkinter.StringVar()

        frame = tkinter.Frame(self.parent)
        regexLabel = tkinter.Label(frame, text="Regex:", underline=0)
        regexLabel.grid(row=0, column=0, padx=2, pady=2, sticky=tkinter.W)
        regexEntry = tkinter.Entry(frame, width=50, textvariable=self.regex)
        regexEntry.grid(row=1, column=1, columnspan=2, padx=2, pady=2, sticky=tkinter.EW)
        self.ignoreCaseCheckbutton = tkinter.Checkbutton(frame, text="Ignore case", underline=0, variable=self.ignore_case)
        self.ignoreCaseCheckbutton.grid(row=2, column=0, columnspan=2, padx=2, pady=2, sticky=tkinter.E)
        self.dotallCheckbutton = tkinter.Checkbutton(frame, text="Dotall", underline=0, variable=self.dotall)
        self.dotallCheckbutton.grid(row=2, column=2, padx=2, pady=2, sticky=tkinter.E)
        self.groupLabels = []
        self.captureLabels = []
        row = 3
        for i in range(10):
            label = tkinter.Label(frame, text="Group {0}".format(i))
            label.grid(row=row + i, column=0, padx=2, pady=2, sticky=tkinter.W)
            self.groupLabels.append(label)
            capture = tkinter.Label(frame, relief=tkinter.RIDGE, enchor=tkinter.W, bg="aliceblue", textvariable=self.captures[i])
            self.captureLabels.append(capture)
        self.messageLabel = tkinter.Label(frame, relief=tkinter.GROOVE, anchor=tkinter.W, bg="white", textvariable=self.message)
        self.messageLabel.grid(row=14, column=0, columnspan=3, padx=2, pady=2, sticky=tkinter.EW)


        frame.grid(row=0, column=0, sticky=tkinter.NSEW)
        frame.columnconfigure(0, weight=1)
        frame.columnconfigure(1, weight=999)
        frame.columnconfigure(2, weight=999)

        window = self.parent.winfo_toplevel()
        window.columnconfigure(0, weight=1)

        regexEntry.focus_set()
        parent.bind("<Alt=r>", lambda arg: regexEntry.focus_set())
        parent.bind("<Alt-t>", lambda arg: textEntry.focus_set())
        parent.bind("<Alt-i>", self.ignoreCaseChanged)
        parent.bind("<Ald-d>", self.dotallChanged)
        parent.bind("<Control-q>", self.quit)
        parent.bind("<Escape>", self.quit)
        regexEntry.bind("<Any-KeyRelease>", self.calculate)
        textEntry.bind("<Any-KeyRelease>", self.calculate)
        parent.title("Regex")
        self.calculate()


    def ignoreCaseChanged(self, *ignore):
        self.ignoreCaseCheckbutton.invoke()
        self.calculate()


    def dotallChanged(self, *ignore):
        self.dotallCheckbutton.invoke()
        self.calculate()


    def calculate(self, *ignore):
        for i in range(10):
            self.captures[i].set("")
            self.captureLabels[i]["bg"] = "aliceblue"
            self.groupLabels[i]["text"] = "Group[ {0}".format(i)
        if not self.regex.get():
            return 
        try:
            flags = 0
            if self.ignore_case.get():
                flags |= re.IGNORECASE
            if self.dotall.get():
                flags = re.DOTALL
            regex = re.compile(self.regex.get(), flags)
            match = regex.search(self.text.get())
        except re.error:
            self.message.set("Invalid regex")
            self.messageLabel["bg"] = "mistyrose"
        else:
            self.message.set("Matched" if match is not None else "Unmatched")
            self.messageLabel["bg"] = "white"
            if match:
                groups = {v: k for k, v in match. groupdict().items()}
                limit = min(10, 1 + len(match.groups()))
                for i in range(limit):
                    group = match.group(i)
                    if group is not None:
                        self.captures[i].set(group)
                        if group in groups:
                            self.groupLabels[i]["text"] = ("Group {0} '{1}'".format(i, groups[group]))
                        self.captureLabels[i]["bg"] = "cornsilk"

    def quit(self, event=None):
        self.parent.destroy()


application = tkinter.Tk()
path = os.path.join(os.path.dirname(__file__), "images/")
if sys.platform.startswith("win"):
    icon = path + "regex.ico"
else:
    icon = "@" + path + "regex.xbm"
application.iconbitmap(icon)
window = MainWindow(application)
application.protocol("WM_DELETE_WINDOW", window.quit)
application.mainloop()







===============
Epilogue
===============

#If you hve read at least the firs  six chapters and either done the exercises or written
#your own Python3 programs independently, you should be in a good position to build up 
#your experience and programming skills as far as your want to go -- Python wont hold you
#back!

#To improve and deepend your Python language skills, if you read only the first six chapters,
#make sure you are familiar with the material in Chapter 7, and that you read and experiement
#with at some of the material in Chapter 8, and in particular with the with statement and 
#content managers. It is also worth reading at least Chapter 9's section on testing.

#Keep in mind though, that apart from the pleasure and learning aspects of developing 
#everything from scratch, doing so is rarely necessary in Python. We have already mentioned
#the standard library and the Python Package Index, pypi.python.org/pypi, both of which
#provide a huge amount of functionality. In addition, the online Python Cookbook at
code.activestate.com/recipes/langs/python/ #offers a large number of tricks, tips, and ideas,
#although it is Python 2-oriented at the time of this writing.

#It is also possible to create modules for Python in other languages (and language that can
#export C functions, as most can). These can be developed to work cooperatively with Python
#using Python's C API. Shared libraries (DDLs on Windows), whether created by us or obtained
#from a third party, can be accessed from Python using the ctypes module, giving us virtually
#unlimited access to the vast amount of functionality available over the Internet thanks to
#the skill and genorosity of open source programmers worldwide.

#And if you want to participate in the Python community, a good place to start is
#www.python.org/community where you will find Wikis and many general and special interest 
#mailing lists.





















=============== BEGIN Introducing Python 2015 Bill Lubanovic
Code Structures

comment using #

continue lines with \

>>> alphabet = ""
>>> alphabet
''
>>> alphabet += 'abcd'
>>> alphabet 
'abcd'
>>> alphabet += 'efgh'
>>> alphabet
'abcdefgh'
>>> alphabet += 'ijklmnop'
>>> alphabet
'abcdefghijklmnop'
>>> alphabet += 'qrstuvwxyz'
>>> alphabet
'abcdefghijklmnopqrstuvwxyz'

or

>>> alphabet1 = ""
>>> alphabet1 += 'abcdefgh' + \
...     'ijklmnop' + \
...     'qrstuv' + \
...     'wxyz'
>>> alphabet1 
'abcdefghijklmnopqrstuvwxyz'
>>> 

>>> 1+2 + \
... 3
6

palindrome = 'A man,\n A plan,\n A canal:\nPanama.'
>>> palindrome = 'A man,\n A plan,\n A canal:\nPanama.'
>>> palindrome
'A man,\n A plan,\n A canal:\nPanama.'


Code Structures - Compare with if, elif, and else 

>>> disaster
True
>>> if disaster:
...     print("Yes True Diaster!")
... else:
...     print("No diaster here so False")
... 
Yes True Diaster!
>>> 






===============END Introducing Python 2015






UNIX Commands

10 (11) most common Unix commands
ls 
exit
cp original_file copied_file            copy
mv original_file new_file               move 
mv intro.doc ~/Desktop/preface.doc      #move and rename it
touch filename                          adds that file
rm filename                             remove
pwd 
cd directory_name 
man command_name                    access OS X built-in documentation manpage      man ls
less filename                       displays long text file, one screen at time using space bar 
grep pattern filename(s)            search 
top                                 active running processes
mkdir

CONTROL G  ^G  Goto line 

HOW TO FORCE TERMINATE Command line? quadratic.py example 

Building a program from scratch - order of what to do next?

COMMAND 
python3 filename.py < ingestion_from_file.csv > output_to_file.html 
python3 filename.py < data/ingestion_from_file.csv > data/output_to_file.html 

sort --help
info
info ls

ls -l       ls -l       ls -al
ls -l test*
ls -asF
ls -1
ls -s /var/log
ls -d Library

date
who
who -u
who am i
who am i;date 

open -a Chess           open application Chess 

ftp 
ftp> quit

Choice of Shells
can choose from
/bin/bash       #just learning so stay with this
/bin/csh
/bin/ksh
/bin/tcsh
/bin/zsh
/bin/sh

Setting the Terminal Title
echo '^[]2;My-Window-Title^G'       ANSI escape sequences.

Using AppleScript to Manipulate the Terminal
osascript -e \
'tell app "Termainal" to set option of first window to value'

osascript -e \
'tell app "Termainal" to set miniaturized of first window to true'

top or tail -f /var/log/system.log  #to help you keep an eye on how your system is performing

cd /usr/bin

cd ~; date ; du -s . ; date    
        #4 commans on 1 line using ;
        #1stcd ~ moves you to your home directory
        #2nd
        #3rd du -s figures out how much disk space is used by current directory as
                    #denoted by the period (.)
        #4th second date shows the time after the du command has run

Control U #erases entire input line
Control C #interrupts or cancels a command

Control D #quits shell  

To change shell prompt then type 
PS1="$ " or
PS1="FOO% "
PS1="Yes, Master "
PS1="\w \! \$ "
consider adding user name and/or host name

man csh     #tcsh - C shell with file name completion and command line editing
echo HOME
cd /

du Documents #disk usage
du -s Library
du -s * .[^.]*      #gives separate totals 
du -s /Applications/*.app 
du -s Library/*

df      #disk free
df -h 
df -H
df -m 
df -i

ls -ld 
ls -ld $HOME 
ls -ld $HOME/Documents 
ls -l viminfo 
ls -l /System/Library/Kernels/kernel 
ls -l /etc/sudoers 
ls -/Volumes 
cat         #looks inside a program
grep        #global/regular expression/print
            # this was sused to list only the lines in the file being edited that matched
            # a specified pattern. This went from g/re/p to grep

chmod   #to change permissions 
groups 
chown   #to change owners
sudo chown eric images 
sudo find / -name makewhatis -print         #dont use this unless you know what your doing


vi sample 

gzip        #to compress
gunzip      #to uncompress

tar         #Unix backups 1960s using round tape memory disk, tar = tape archiver
            #tar = creates a file containing multiple files and directories
            #gzip = makes an existing file shrink via compression


grep pattern [files]
grep "Unix" *
ls -l | grep "Aug"
ls -l | grep "root.*Aug"


grep -A n 
grep -B n 
grep -C n 
grep -v 
grep -n 
grep -l
grep -c 
grep -i 
grep -lv Jane *
grep -n -C1 Aqua sample 
grep -- coler=always text sample 
grep -c "kernel" /var/log/system.log
grep POST access_log
grep -E "POST.*(Safari|Firefox)" access_log 
grep -E POST access_log | wc -l 
grep -E "POST.MSIE" access_log | wc -l 
grep -E "POST.(Firefox)" access_log | wc -l 
grep -E "POST.(Safari)" access_log | wc -l 


locate gun 
locate alpha 
locate "/man/.*alpha"
locate alpha | grep "/man/"

find . -name "*.html" -print 
find /bin -size +30k -print 
find . -cmin 60 -print 
find . -cmin +60 -type f | wc -l
find /var/log -not -name "*.gz" -type f -size +0 -print 

ls -l IMG_1912.JPG 
mdls IMG_1912.JPG 
mdls HXR-MC50U\ Manual.pdf

mdfind "kMDItemAcquisitionModel == 'NIKON*'" | head
mdfind -onlyin ~/Music "kMDItemMusical Genre == 'Jaxx'"
mdfind -onlyin ~ Jazz | head 

mdls IMG_1912.JPG | grep -E '(PixelHeight|PixelWidth)'

mdls "06 Elise affair.mp3" | grep Duration 

find . -name "*jpg" -print0 | xargs -0 mdls | grep FocalLength

mdfind -0 "kMDItemFocalLength == '35'" | xargs -0 mdls | grep -E '(PixelHeight|PixelWidth|DisplayName)'

photosize Peanut.jpg


cat todo 
tr '[aeiou]' '[xxxxx]' < todo 
#cat files(s)

cat /etc/bashrc

cat /etc/bashrc > mybashrc
cat mybashrc

who > users 
date > today 
ls 

cat users
cat today 

cat > new-todo
^D          #signals end of the text giving you back a shell prompt

cat today todo > diary 
cat diary 


cat users >> diary 
date >> diary 
cat diary 


ls -l $HOME | colrm 1 30 
ls -l $HOME | colrm 1 30 > homedirlist.txt 

find ~/Documents -type d -print | wc -l

tr      #translater utility 
tr "[:lower:]" "[:upper:]" < todo 
tr -d "[aeiou]" < todo

tr -cs "[:alpha:]" "\n" < alice.txt | wc -l

grep "pattern" files
mdfind ipod | wc -l 
mdfind ipod | grep -v "Library" | wc -l
mdfind ipod | grep -v "Library" | grep "/taylor/" | wc -l

tr -cs "[:alpha:]" "\n" < alice.txt | tail -15
head -255 alice.txt | tail -5

sort food 

sort -n 
sort -r 
sort -f 
sort -k x 

ls -l | grep "Jan" | sort -n -k 5

find . -type f -print0 | xargs -0 ls -s1 | sort -rn | head

tr -cs "[:alpha:]" "\n" < alice.txt | sort | uniq | wc -l
tr -cs "[:alpha:]" "\n" < alice.txt | tr "[A-Z]" "[a-z]" | sort | uniq | wc -l

ls -l | sort -nk 5 | less

lpstat -a  #shows everything about known printers
lpstat -d 
lpstat -t
ls -l | lp 

pr          #minor formating for printing

cat food
pr -2 -h "Restaurants" food 
pr -2 -h "Restaurants" food | lpr       #to create a pipe to send to the lpr printer program


MULTITASKING

sort bigfile > bigfile.sort &
ps -fp 372
kill 372

sort hugefile1 hugefile2 > sorted 
^Z 
bg 
vi test.txt 


ps      #process status 
tty 
ps -ax | head -20 
ps -ax -U root | head 
top -l 1 } head -8
top -o cpu 
kill PID(s)

(sleep 60; who) & 
ps 
kill 981

(sleep 60; who) & 
killall -s make 
killall -s who 
killall -s sleep

killall sleep 
killall -v sleep 


LAUNCHING GUI APPLICATIONS 

open peanut.jpg
open *.doc 
open .profile 
open .sample.swp 

touch ~/Desktop/myFile.txt
GetFileInfo Column.42.docx 

mdfind NIKON | open -f      #stream a bunch of input into a text file then open in an Aqua file
open messages 
open -a messages 
open -e ~/Sites/someFile.html


ssh
man ssh 
who

scp         #secure copy 
rcp         #remote copy

ftp hostname 

put filename 
mput filenames 
get filename 
mget filenames
prompt 
hash 
cd pathname 
lcd pathname 
dir 
pwd 
binary 
ascii 
passive 
quit or bye 
!cmd 


EXAMPLE
cd downloads
ls
ftp rhino.zoo.edu 
    username ktaylor 
    password xyz 
ftp> cd work 
ftp> dir
ftp> get todo 
ftp> !ls 
ftp> quit 
ls

ftp> help 


EXAMPLE OF sftp    #secure ftp 

cd Downloads 
sftp taylor@intuitive.com 
    password xyz 
sftp> ls
sftp> cd mybin 
sftp> -l
sftp> get webspell
sftp> get -P webspell       # -P gives file creation info
sftp> ls
sftp> quit 
ls -l webspell 



FTP WTIH A WEB BROWSER 

ftp://hostname/pathname 

curl        #copy from URL

curl -O ftp://somecorp.za/pub/reports/2001.pdf 
curl ftp://ftp.orielly.com/pub/README.ftp | less
curl http://www.orielly.com | less

curl http://www.orielly.com > orielly.html
open orielly.html

curl http://www.orielly.com > orielly.html
open -a "Google Chrome" orielly.html

FTP FROM THE FINDER 

ls -l /Volumes/
unmount /Volumes/ftp.oreilly.com        #to disconnect



MANUALS 

man vi 
man -k zip | grep '(1)'



BASH PROFILE 

ls -a
#look for .bash_profile
export PS1="$ "  #include this in your profile to change your prompt

Last login: Wed Dec 28 15:48:46 on ttys001
Atuls-MBP:~ atulgolhar$ PS1 = "Yes, Master? "
-bash: PS1: command not found
Atuls-MBP:~ atulgolhar$ PS1= "Yes, Master? "
-bash: Yes, Master? : command not found
Atuls-MBP:~ atulgolhar$ PS1="Yes, Master? "
Yes, Master? 
Yes, Master? 
Yes, Master? 
Yes, Master? 
























Built-in Functions      
abs()
all()
any()
ascii()
bin()
bool()
bytearray()
bytes()
callable()
chr()
classmethod()
compile()
complex()
delattr()
dict()
dir()
divmod()
enumerate()
eval()
exec()
filter()
float()
format()
frozenset()
getattr()
hash()
help()
hex()
id()
input()
int()
isinstance()
issubclass()
iter()
len()
list()
locals()
map()
max()
memoryview()
min()
next()
object()
oct()
open()
ord()
pow()
print()
property()
range()
repr()
reversed()
round()
set()
setattr()
slice()
sorted()
staticmethod()
str()
sum()
super()
tuple()
type()
vars()
zip()
__import__()




"""
help> keywords

Here is a list of the Python keywords.  Enter any keyword to get more help.

False               def                 if                  raise
None                del                 import              return
True                elif                in                  try
and                 else                is                  while
as                  except              lambda              with
assert              finally             nonlocal            yield
break               for                 not                 
class               from                or                  
continue            global              pass        



help> topics

Here is a list of available topics.  Enter any topic name to get more help.

ASSERTION           DELETION            LOOPING             SHIFTING
ASSIGNMENT          DICTIONARIES        MAPPINGMETHODS      SLICINGS
ATTRIBUTEMETHODS    DICTIONARYLITERALS  MAPPINGS            SPECIALATTRIBUTES
ATTRIBUTES          DYNAMICFEATURES     METHODS             SPECIALIDENTIFIERS
AUGMENTEDASSIGNMENT ELLIPSIS            MODULES             SPECIALMETHODS
BASICMETHODS        EXCEPTIONS          NAMESPACES          STRINGMETHODS
BINARY              EXECUTION           NONE                STRINGS
BITWISE             EXPRESSIONS         NUMBERMETHODS       SUBSCRIPTS
BOOLEAN             FLOAT               NUMBERS             TRACEBACKS
CALLABLEMETHODS     FORMATTING          OBJECTS             TRUTHVALUE
CALLS               FRAMEOBJECTS        OPERATORS           TUPLELITERALS
CLASSES             FRAMES              PACKAGES            TUPLES
CODEOBJECTS         FUNCTIONS           POWER               TYPEOBJECTS
COMPARISON          IDENTIFIERS         PRECEDENCE          TYPES
COMPLEX             IMPORTING           PRIVATENAMES        UNARY
CONDITIONAL         INTEGER             RETURNING           UNICODE
CONTEXTMANAGERS     LISTLITERALS        SCOPING             
CONVERSIONS         LISTS               SEQUENCEMETHODS     
DEBUGGING           LITERALS            SEQUENCES           



help> symbols

Here is a list of the punctuation symbols which Python assigns special meaning
to. Enter any symbol to get more help.

!=                  *=                  <<                  ^
"                   +                   <<=                 ^=
"""        """      +=                  <=                  _
%                   ,                   <>                  __
%=                  -                   ==                  `
&                   -=                  >                   b"
&=                  .                   >=                  b'
'                   ...                 >>                  j
'''                 /                   >>=                 r"
(                   //                  @                   r'
)                   //=                 J                   |
*                   /=                  [                   |=
**                  :                   \                   ~
**=                 <                   ]                   




help> modules

Please wait a moment while I gather a list of all available modules...

IN                  _weakrefset         hmac                shlex
Notes_ProgInPython3 abc                 html                shutil
Shape               aifc                http                signal
__future__          antigravity         idlelib             site
_ast                argparse            imaplib             smtpd
_bisect             array               imghdr              smtplib
_bootlocale         ast                 imp                 sndhdr
_bz2                asynchat            importlib           socket
_codecs             asyncio             inspect             socketserver
_codecs_cn          asyncore            io                  sqlite3
_codecs_hk          atexit              ipaddress           sre_compile
_codecs_iso2022     audioop             itertools           sre_constants
_codecs_jp          base64              json                sre_parse
_codecs_kr          bdb                 keyword             ssl
_codecs_tw          binascii            leo_tolstoy         stat
_collections        binhex              lib2to3             statistics
_collections_abc    bisect              linecache           string
_compat_pickle      bs4                 locale              stringprep
_compression        builtins            logging             struct
_crypt              bz2                 lzma                subprocess
_csv                cProfile            macpath             sunau
_ctypes             calendar            macurl2path         symbol
_ctypes_test        cgi                 mailbox             symtable
_curses             cgitb               mailcap             sys
_curses_panel       chunk               marshal             sysconfig
_datetime           cmath               math                syslog
_dbm                cmd                 mimetypes           tabnanny
_decimal            code                mmap                tarfile
_dummy_thread       codecs              modulefinder        telnetlib
_elementtree        codeop              multiprocessing     tempfile
_functools          collections         netrc               termios
_hashlib            colorsys            nis                 test
_heapq              compileall          nntplib             test1
_imp                concurrent          ntpath              test2
_io                 configparser        nturl2path          test3
_json               contextlib          numbers             test4
_locale             copy                opcode              test5
_lsprof             copyreg             operator            test6
_lzma               crypt               optparse            test7
_markerlib          csv                 os                  test8
_markupbase         ctypes              parser              test9_author_web
_md5                curses              pathlib             testPython3book
_multibytecodec     datetime            pdb                 textwrap
_multiprocessing    dbm                 pickle              this
_opcode             decimal             pickletools         threading
_operator           difflib             pip                 time
_osx_support        dis                 pipes               timeit
_pickle             distutils           pkg_resources       tkinter
_posixsubprocess    doctest             pkgutil             token
_pydecimal          dummy_threading     platform            tokenize
_pyio               easy_install        plistlib            trace
_random             email               poplib              traceback
_scproxy            encodings           posix               tracemalloc
_sha1               ensurepip           posixpath           tty
_sha256             enum                pprint              turtle
_sha512             errno               profile             turtledemo
_signal             faulthandler        pstats              types
_sitebuiltins       fcntl               pty                 typing
_socket             fibo                pwd                 unicodedata
_sqlite3            fibo1               py_compile          unittest
_sre                fibo2               pyclbr              urllib
_ssl                filecmp             pydoc               uu
_stat               fileinput           pydoc_data          uuid
_string             fnmatch             pyexpat             venv
_strptime           formatter           queue               warnings
_struct             fractions           quopri              wave
_symtable           ftplib              random              weakref
_sysconfigdata      functools           re                  webbrowser
_testbuffer         gc                  readline            wsgiref
_testcapi           genericpath         reprlib             xdrlib
_testimportmultiple getopt              resource            xml
_testmultiphase     getpass             rlcompleter         xmlrpc
_thread             gettext             runpy               xxlimited
_threading_local    glob                sched               xxsubtype
_tkinter            grp                 select              zipapp
_tracemalloc        gzip                selectors           zipfile
_warnings           hashlib             setuptools          zipimport
_weakref            heapq               shelve              zlib

Enter any module name to get more help.  Or, type "modules spam" to search
for modules whose name or summary contain the string "spam".

help> 
"""

===============END UNIX Commands




SUMMARY Coding Examples Python3




#SUMMARY - Ch 3 Collection Data Types
#Sequences (tuples slice concatenation, membership testing, augmented, 
    #named tuples import collections, 
    #lists, list comprehension, sets, set comprehension, frozensets, 
    #iterable sequence unpacking operator, 
    #mapping types dictionary, dictionary comprehension, default dictionary, 
    #Nondeterminism Solution (1)try...finally block to ensure clean is done
    #(2) use with statement in Chap 8
    #List comprehension     #small lists use list literals  list(range(n))
                            #large lists use list comprehensions    
                            #           dict_defined = []
                            #           for year in range():
                            #               if () or ():
                            #                   append.x
                            #large list comprehension
                            #           temp = []    
                            #           item for item in iterable if condition
                            #               temp.append(item)

#!/usr/bin/env python3
#ATUL_uniquewords1.py

import sys
import string


words = {}
strip = string.whitespace + string.punctuation + string.digits + "\"'"
for filename in sys.argv[1:]:
    with open(filename) as file:
        for line in file:
            for word in line.lower().split():
                word = word.strip(strip)
                if len(word) > 2:
                    words[word] = words.get(word, 0) + 1

for word in sorted(words):
    print("word --> {0} occurs {1} counter".format(word, words[word]))




#!/usr/bin/env python3
#ATUL_uniquewords2.py
#add default dictionary code



#!/usr/bin/env python3
#ATUL_uniquewords_ans.py
import sys
import string
import collections


def by_value(item):
    return item[1]

words = collections.defaultdict(int)    #words = {}
strip = string.whitespace + string.punctuation + string.digits + "\"'"
for filename in sys.argv[1:]:
    with open(filename) as file:
        for line in file:
            for word in line.lower().split():
                word = word.strip(strip)
                if len(word) > 2:
                    words[word] = words.get(word, 0) + 1

for word, count in sorted(words.items(), key=by_value):
    print("word --> {0} occurs {1} counter".format(word, count))










===============RANDOM Python3 Examples
ATUL - good introduction to beginner class 


>>> print(list(range(1,3)))
[1, 2]


#!/usr/bin/env python3

def draw_line(tick_length, tick_label=''):
    line = '-' * tick_length + " Hello World"
    print(line)

def draw_interval():
    pass

def draw_ruler(num_inches, major_length):
    draw_line(major_length, '0')


                            >>> import temp2
                            >>> temp2.draw_ruler(1,7)
                            ------- Hello World
                            >>> 



                            """
                            number of inches
                            major_length  = major tick length


                            >>> temp.draw_ruler(1,3)
                            --- 0
                            -
                            --
                            -
                            --- 1

                            """





